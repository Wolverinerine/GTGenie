{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement of GTGenie on HMDD in 5-fold cross validation\n",
    "1. 'parser' is used to assign different hyperparameters.\n",
    "2. The cross validation is repeated for ten times. In each time, we use function 'sample' to split the dataset into train set and test set.\n",
    "3. Train set and test set are fed to function 'train' which use the BFN to combine the graph features and text features captured by TRR and GAT to reconstruct the final molecule-disease associations matrix. \n",
    "4. Then the predicted scores returned by fuction 'train' are used to calculate AUC and AUPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow version 1.15.5 has been patched using tfdeterminism version 0.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times: 0, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "WARNING:tensorflow:From /hy-tmp/GTGenie_new/models/GAT.py:8: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /hy-tmp/GTGenie_new/models/GAT.py:19: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /hy-tmp/GTGenie_new/train.py:99: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "Epoch: 0001 | train_loss = 0.12843, train_auc = 0.61596, test_loss = 0.07028, test_auc = 0.59359, time = 2.20971\n",
      "Epoch: 0010 | train_loss = 0.08530, train_auc = 0.88842, test_loss = 0.04919, test_auc = 0.83297, time = 0.05109\n",
      "Epoch: 0020 | train_loss = 0.07379, train_auc = 0.92700, test_loss = 0.04358, test_auc = 0.86355, time = 0.04843\n",
      "Epoch: 0030 | train_loss = 0.06932, train_auc = 0.93888, test_loss = 0.03626, test_auc = 0.93395, time = 0.04593\n",
      "Epoch: 0040 | train_loss = 0.06431, train_auc = 0.94799, test_loss = 0.03777, test_auc = 0.91816, time = 0.04528\n",
      "Epoch: 0050 | train_loss = 0.06301, train_auc = 0.95260, test_loss = 0.03380, test_auc = 0.94473, time = 0.04626\n",
      "Epoch: 0060 | train_loss = 0.05794, train_auc = 0.95922, test_loss = 0.03553, test_auc = 0.92568, time = 0.04595\n",
      "Epoch: 0070 | train_loss = 0.05589, train_auc = 0.96223, test_loss = 0.03591, test_auc = 0.92649, time = 0.04482\n",
      "Epoch: 0080 | train_loss = 0.05318, train_auc = 0.96602, test_loss = 0.03532, test_auc = 0.94936, time = 0.04573\n",
      "Epoch: 0090 | train_loss = 0.05148, train_auc = 0.96841, test_loss = 0.03810, test_auc = 0.95205, time = 0.04504\n",
      "Epoch: 0100 | train_loss = 0.05084, train_auc = 0.96946, test_loss = 0.03735, test_auc = 0.94629, time = 0.04437\n",
      "Epoch: 0110 | train_loss = 0.04968, train_auc = 0.97190, test_loss = 0.03125, test_auc = 0.95960, time = 0.04437\n",
      "Epoch: 0120 | train_loss = 0.04735, train_auc = 0.97329, test_loss = 0.03185, test_auc = 0.95965, time = 0.04839\n",
      "Epoch: 0130 | train_loss = 0.04936, train_auc = 0.97253, test_loss = 0.03012, test_auc = 0.96327, time = 0.04621\n",
      "Epoch: 0140 | train_loss = 0.04627, train_auc = 0.97543, test_loss = 0.03200, test_auc = 0.96010, time = 0.04539\n",
      "Epoch: 0150 | train_loss = 0.04093, train_auc = 0.97967, test_loss = 0.03185, test_auc = 0.96182, time = 0.04617\n",
      "Epoch: 0160 | train_loss = 0.04155, train_auc = 0.97952, test_loss = 0.03203, test_auc = 0.95874, time = 0.05219\n",
      "Epoch: 0170 | train_loss = 0.04045, train_auc = 0.98129, test_loss = 0.02934, test_auc = 0.96392, time = 0.04498\n",
      "Epoch: 0180 | train_loss = 0.04126, train_auc = 0.98091, test_loss = 0.03274, test_auc = 0.95310, time = 0.04527\n",
      "Epoch: 0190 | train_loss = 0.03971, train_auc = 0.98298, test_loss = 0.03201, test_auc = 0.95834, time = 0.04443\n",
      "Epoch: 0200 | train_loss = 0.03782, train_auc = 0.98364, test_loss = 0.03410, test_auc = 0.94679, time = 0.04523\n",
      "Epoch: 0210 | train_loss = 0.03526, train_auc = 0.98464, test_loss = 0.03384, test_auc = 0.96084, time = 0.04465\n",
      "Epoch: 0220 | train_loss = 0.03562, train_auc = 0.98626, test_loss = 0.03505, test_auc = 0.96053, time = 0.04423\n",
      "Epoch: 0230 | train_loss = 0.03562, train_auc = 0.98649, test_loss = 0.03215, test_auc = 0.95977, time = 0.04417\n",
      "Epoch: 0240 | train_loss = 0.03377, train_auc = 0.98676, test_loss = 0.03381, test_auc = 0.96017, time = 0.04423\n",
      "Epoch: 0250 | train_loss = 0.03464, train_auc = 0.98674, test_loss = 0.03274, test_auc = 0.96479, time = 0.04427\n",
      "Epoch: 0260 | train_loss = 0.03152, train_auc = 0.98890, test_loss = 0.03211, test_auc = 0.96164, time = 0.04380\n",
      "Epoch: 0270 | train_loss = 0.03053, train_auc = 0.98977, test_loss = 0.03511, test_auc = 0.95268, time = 0.04412\n",
      "Epoch: 0280 | train_loss = 0.03345, train_auc = 0.98718, test_loss = 0.02975, test_auc = 0.96784, time = 0.04395\n",
      "Epoch: 0290 | train_loss = 0.03365, train_auc = 0.98818, test_loss = 0.03079, test_auc = 0.96410, time = 0.04359\n",
      "Epoch: 0300 | train_loss = 0.03157, train_auc = 0.98984, test_loss = 0.03287, test_auc = 0.96570, time = 0.04772\n",
      "Epoch: 0310 | train_loss = 0.03149, train_auc = 0.98976, test_loss = 0.03447, test_auc = 0.96616, time = 0.04589\n",
      "Epoch: 0320 | train_loss = 0.03276, train_auc = 0.98936, test_loss = 0.03293, test_auc = 0.96920, time = 0.04601\n",
      "Epoch: 0330 | train_loss = 0.02956, train_auc = 0.99088, test_loss = 0.03348, test_auc = 0.96356, time = 0.04490\n",
      "Epoch: 0340 | train_loss = 0.02818, train_auc = 0.99267, test_loss = 0.03147, test_auc = 0.97049, time = 0.04492\n",
      "Epoch: 0350 | train_loss = 0.03031, train_auc = 0.99185, test_loss = 0.02918, test_auc = 0.97100, time = 0.04525\n",
      "Epoch: 0360 | train_loss = 0.02879, train_auc = 0.99209, test_loss = 0.03103, test_auc = 0.97076, time = 0.04615\n",
      "Epoch: 0370 | train_loss = 0.02841, train_auc = 0.99179, test_loss = 0.03283, test_auc = 0.96929, time = 0.04539\n",
      "Epoch: 0380 | train_loss = 0.02745, train_auc = 0.99296, test_loss = 0.02884, test_auc = 0.97823, time = 0.04828\n",
      "Epoch: 0390 | train_loss = 0.02667, train_auc = 0.99407, test_loss = 0.02914, test_auc = 0.97531, time = 0.04664\n",
      "Epoch: 0400 | train_loss = 0.02525, train_auc = 0.99333, test_loss = 0.02740, test_auc = 0.97291, time = 0.04660\n",
      "Epoch: 0410 | train_loss = 0.02600, train_auc = 0.99404, test_loss = 0.03047, test_auc = 0.97258, time = 0.04664\n",
      "Epoch: 0420 | train_loss = 0.02750, train_auc = 0.99321, test_loss = 0.02932, test_auc = 0.97272, time = 0.04512\n",
      "Epoch: 0430 | train_loss = 0.02506, train_auc = 0.99334, test_loss = 0.03190, test_auc = 0.96895, time = 0.04527\n",
      "Epoch: 0440 | train_loss = 0.02765, train_auc = 0.99389, test_loss = 0.02926, test_auc = 0.96937, time = 0.04494\n",
      "Epoch: 0450 | train_loss = 0.02554, train_auc = 0.99446, test_loss = 0.02729, test_auc = 0.97528, time = 0.04530\n",
      "Epoch: 0460 | train_loss = 0.02543, train_auc = 0.99434, test_loss = 0.02914, test_auc = 0.97414, time = 0.04589\n",
      "Epoch: 0470 | train_loss = 0.02274, train_auc = 0.99482, test_loss = 0.02937, test_auc = 0.97379, time = 0.04565\n",
      "Epoch: 0480 | train_loss = 0.02630, train_auc = 0.99395, test_loss = 0.02874, test_auc = 0.97262, time = 0.04553\n",
      "Epoch: 0490 | train_loss = 0.02368, train_auc = 0.99360, test_loss = 0.02821, test_auc = 0.97323, time = 0.04668\n",
      "Epoch: 0500 | train_loss = 0.02383, train_auc = 0.99428, test_loss = 0.02841, test_auc = 0.97162, time = 0.04533\n",
      "times: 0, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15105, train_auc = 0.38808, test_loss = 0.06883, test_auc = 0.61535, time = 0.82570\n",
      "Epoch: 0010 | train_loss = 0.08145, train_auc = 0.91189, test_loss = 0.04993, test_auc = 0.85235, time = 0.05191\n",
      "Epoch: 0020 | train_loss = 0.07267, train_auc = 0.92742, test_loss = 0.04292, test_auc = 0.87160, time = 0.05098\n",
      "Epoch: 0030 | train_loss = 0.06509, train_auc = 0.94756, test_loss = 0.03754, test_auc = 0.91463, time = 0.04853\n",
      "Epoch: 0040 | train_loss = 0.06539, train_auc = 0.94979, test_loss = 0.03940, test_auc = 0.90546, time = 0.04949\n",
      "Epoch: 0050 | train_loss = 0.06046, train_auc = 0.95712, test_loss = 0.03411, test_auc = 0.94299, time = 0.05005\n",
      "Epoch: 0060 | train_loss = 0.05817, train_auc = 0.96017, test_loss = 0.03229, test_auc = 0.95074, time = 0.04887\n",
      "Epoch: 0070 | train_loss = 0.05401, train_auc = 0.96628, test_loss = 0.03290, test_auc = 0.95204, time = 0.04863\n",
      "Epoch: 0080 | train_loss = 0.05314, train_auc = 0.96744, test_loss = 0.03789, test_auc = 0.95052, time = 0.05044\n",
      "Epoch: 0090 | train_loss = 0.05058, train_auc = 0.97129, test_loss = 0.03356, test_auc = 0.95405, time = 0.04946\n",
      "Epoch: 0100 | train_loss = 0.05222, train_auc = 0.97000, test_loss = 0.03277, test_auc = 0.95162, time = 0.05010\n",
      "Epoch: 0110 | train_loss = 0.04854, train_auc = 0.97332, test_loss = 0.03250, test_auc = 0.95447, time = 0.04869\n",
      "Epoch: 0120 | train_loss = 0.04517, train_auc = 0.97684, test_loss = 0.03406, test_auc = 0.95032, time = 0.04838\n",
      "Epoch: 0130 | train_loss = 0.04517, train_auc = 0.97778, test_loss = 0.03003, test_auc = 0.96172, time = 0.04889\n",
      "Epoch: 0140 | train_loss = 0.04164, train_auc = 0.98042, test_loss = 0.03046, test_auc = 0.96000, time = 0.04835\n",
      "Epoch: 0150 | train_loss = 0.04024, train_auc = 0.98224, test_loss = 0.03253, test_auc = 0.95899, time = 0.04836\n",
      "Epoch: 0160 | train_loss = 0.04079, train_auc = 0.98256, test_loss = 0.03422, test_auc = 0.95995, time = 0.04800\n",
      "Epoch: 0170 | train_loss = 0.03849, train_auc = 0.98343, test_loss = 0.03072, test_auc = 0.96068, time = 0.04726\n",
      "Epoch: 0180 | train_loss = 0.03741, train_auc = 0.98526, test_loss = 0.03418, test_auc = 0.95574, time = 0.04752\n",
      "Epoch: 0190 | train_loss = 0.03806, train_auc = 0.98522, test_loss = 0.03038, test_auc = 0.96522, time = 0.05526\n",
      "Epoch: 0200 | train_loss = 0.03762, train_auc = 0.98545, test_loss = 0.02953, test_auc = 0.96637, time = 0.04696\n",
      "Epoch: 0210 | train_loss = 0.03588, train_auc = 0.98599, test_loss = 0.03290, test_auc = 0.95733, time = 0.04803\n",
      "Epoch: 0220 | train_loss = 0.03242, train_auc = 0.98845, test_loss = 0.02978, test_auc = 0.96641, time = 0.04695\n",
      "Epoch: 0230 | train_loss = 0.03227, train_auc = 0.98812, test_loss = 0.03135, test_auc = 0.96445, time = 0.04656\n",
      "Epoch: 0240 | train_loss = 0.03367, train_auc = 0.98755, test_loss = 0.03030, test_auc = 0.96385, time = 0.04948\n",
      "Epoch: 0250 | train_loss = 0.03249, train_auc = 0.98813, test_loss = 0.02993, test_auc = 0.96799, time = 0.04641\n",
      "Epoch: 0260 | train_loss = 0.03133, train_auc = 0.98906, test_loss = 0.03103, test_auc = 0.96808, time = 0.04737\n",
      "Epoch: 0270 | train_loss = 0.03174, train_auc = 0.98927, test_loss = 0.03457, test_auc = 0.96241, time = 0.04825\n",
      "Epoch: 0280 | train_loss = 0.03251, train_auc = 0.98873, test_loss = 0.03020, test_auc = 0.97001, time = 0.04683\n",
      "Epoch: 0290 | train_loss = 0.03186, train_auc = 0.98864, test_loss = 0.02944, test_auc = 0.96948, time = 0.04651\n",
      "Epoch: 0300 | train_loss = 0.02945, train_auc = 0.99033, test_loss = 0.03004, test_auc = 0.96939, time = 0.04700\n",
      "Epoch: 0310 | train_loss = 0.02908, train_auc = 0.99048, test_loss = 0.03145, test_auc = 0.96867, time = 0.05489\n",
      "Epoch: 0320 | train_loss = 0.03013, train_auc = 0.99052, test_loss = 0.02883, test_auc = 0.96940, time = 0.04601\n",
      "Epoch: 0330 | train_loss = 0.02878, train_auc = 0.99076, test_loss = 0.03281, test_auc = 0.96610, time = 0.04764\n",
      "Epoch: 0340 | train_loss = 0.02826, train_auc = 0.99091, test_loss = 0.03361, test_auc = 0.96515, time = 0.04674\n",
      "Epoch: 0350 | train_loss = 0.02652, train_auc = 0.99165, test_loss = 0.03269, test_auc = 0.96694, time = 0.04650\n",
      "Epoch: 0360 | train_loss = 0.02692, train_auc = 0.99138, test_loss = 0.02959, test_auc = 0.96580, time = 0.04661\n",
      "Epoch: 0370 | train_loss = 0.02893, train_auc = 0.99139, test_loss = 0.02945, test_auc = 0.96948, time = 0.04889\n",
      "Epoch: 0380 | train_loss = 0.02666, train_auc = 0.99165, test_loss = 0.03009, test_auc = 0.97155, time = 0.04682\n",
      "Epoch: 0390 | train_loss = 0.02710, train_auc = 0.99221, test_loss = 0.02938, test_auc = 0.97243, time = 0.04772\n",
      "Epoch: 0400 | train_loss = 0.03029, train_auc = 0.99067, test_loss = 0.02982, test_auc = 0.97155, time = 0.04861\n",
      "Epoch: 0410 | train_loss = 0.02525, train_auc = 0.99304, test_loss = 0.03243, test_auc = 0.96963, time = 0.04724\n",
      "Epoch: 0420 | train_loss = 0.02549, train_auc = 0.99222, test_loss = 0.03355, test_auc = 0.96924, time = 0.04792\n",
      "Epoch: 0430 | train_loss = 0.02653, train_auc = 0.99181, test_loss = 0.03119, test_auc = 0.96776, time = 0.04766\n",
      "Epoch: 0440 | train_loss = 0.02491, train_auc = 0.99266, test_loss = 0.03223, test_auc = 0.96622, time = 0.05082\n",
      "Epoch: 0450 | train_loss = 0.02597, train_auc = 0.99214, test_loss = 0.02874, test_auc = 0.97293, time = 0.05084\n",
      "Epoch: 0460 | train_loss = 0.02587, train_auc = 0.99230, test_loss = 0.03086, test_auc = 0.96722, time = 0.04808\n",
      "Epoch: 0470 | train_loss = 0.02638, train_auc = 0.99240, test_loss = 0.03096, test_auc = 0.96777, time = 0.04850\n",
      "Epoch: 0480 | train_loss = 0.02408, train_auc = 0.99311, test_loss = 0.03371, test_auc = 0.96514, time = 0.05003\n",
      "Epoch: 0490 | train_loss = 0.02229, train_auc = 0.99325, test_loss = 0.03030, test_auc = 0.96877, time = 0.04733\n",
      "Epoch: 0500 | train_loss = 0.02496, train_auc = 0.99285, test_loss = 0.03026, test_auc = 0.97283, time = 0.04628\n",
      "times: 0, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14498, train_auc = 0.42268, test_loss = 0.06834, test_auc = 0.62195, time = 0.83600\n",
      "Epoch: 0010 | train_loss = 0.08402, train_auc = 0.89873, test_loss = 0.05231, test_auc = 0.84091, time = 0.04993\n",
      "Epoch: 0020 | train_loss = 0.07568, train_auc = 0.92438, test_loss = 0.04377, test_auc = 0.88485, time = 0.04996\n",
      "Epoch: 0030 | train_loss = 0.06729, train_auc = 0.94528, test_loss = 0.03816, test_auc = 0.92720, time = 0.04890\n",
      "Epoch: 0040 | train_loss = 0.06352, train_auc = 0.95256, test_loss = 0.03888, test_auc = 0.92186, time = 0.04865\n",
      "Epoch: 0050 | train_loss = 0.06107, train_auc = 0.95627, test_loss = 0.03359, test_auc = 0.94413, time = 0.04804\n",
      "Epoch: 0060 | train_loss = 0.05865, train_auc = 0.96014, test_loss = 0.03904, test_auc = 0.93611, time = 0.05452\n",
      "Epoch: 0070 | train_loss = 0.05685, train_auc = 0.96318, test_loss = 0.03295, test_auc = 0.94867, time = 0.04839\n",
      "Epoch: 0080 | train_loss = 0.06081, train_auc = 0.95874, test_loss = 0.03507, test_auc = 0.93955, time = 0.04746\n",
      "Epoch: 0090 | train_loss = 0.05164, train_auc = 0.97044, test_loss = 0.03391, test_auc = 0.94373, time = 0.04748\n",
      "Epoch: 0100 | train_loss = 0.05099, train_auc = 0.97114, test_loss = 0.03663, test_auc = 0.93235, time = 0.04686\n",
      "Epoch: 0110 | train_loss = 0.04756, train_auc = 0.97432, test_loss = 0.03604, test_auc = 0.93488, time = 0.04760\n",
      "Epoch: 0120 | train_loss = 0.04902, train_auc = 0.97395, test_loss = 0.03576, test_auc = 0.94246, time = 0.04727\n",
      "Epoch: 0130 | train_loss = 0.04557, train_auc = 0.97619, test_loss = 0.03263, test_auc = 0.95348, time = 0.04708\n",
      "Epoch: 0140 | train_loss = 0.04132, train_auc = 0.97975, test_loss = 0.03323, test_auc = 0.94858, time = 0.04753\n",
      "Epoch: 0150 | train_loss = 0.04339, train_auc = 0.97910, test_loss = 0.03302, test_auc = 0.95287, time = 0.04737\n",
      "Epoch: 0160 | train_loss = 0.04217, train_auc = 0.98164, test_loss = 0.03523, test_auc = 0.95400, time = 0.04891\n",
      "Epoch: 0170 | train_loss = 0.03927, train_auc = 0.98226, test_loss = 0.03102, test_auc = 0.96033, time = 0.04702\n",
      "Epoch: 0180 | train_loss = 0.03856, train_auc = 0.98357, test_loss = 0.03065, test_auc = 0.96153, time = 0.04700\n",
      "Epoch: 0190 | train_loss = 0.04028, train_auc = 0.98219, test_loss = 0.03433, test_auc = 0.95472, time = 0.04767\n",
      "Epoch: 0200 | train_loss = 0.03674, train_auc = 0.98440, test_loss = 0.03268, test_auc = 0.95591, time = 0.04733\n",
      "Epoch: 0210 | train_loss = 0.03640, train_auc = 0.98463, test_loss = 0.03111, test_auc = 0.96205, time = 0.04732\n",
      "Epoch: 0220 | train_loss = 0.03466, train_auc = 0.98576, test_loss = 0.03183, test_auc = 0.95966, time = 0.04743\n",
      "Epoch: 0230 | train_loss = 0.03385, train_auc = 0.98609, test_loss = 0.03199, test_auc = 0.95550, time = 0.04716\n",
      "Epoch: 0240 | train_loss = 0.03621, train_auc = 0.98535, test_loss = 0.03179, test_auc = 0.96419, time = 0.04696\n",
      "Epoch: 0250 | train_loss = 0.03517, train_auc = 0.98677, test_loss = 0.03079, test_auc = 0.96595, time = 0.04636\n",
      "Epoch: 0260 | train_loss = 0.03560, train_auc = 0.98593, test_loss = 0.03233, test_auc = 0.96303, time = 0.04643\n",
      "Epoch: 0270 | train_loss = 0.03035, train_auc = 0.98858, test_loss = 0.02893, test_auc = 0.96722, time = 0.04618\n",
      "Epoch: 0280 | train_loss = 0.03207, train_auc = 0.98787, test_loss = 0.03347, test_auc = 0.96002, time = 0.04688\n",
      "Epoch: 0290 | train_loss = 0.03227, train_auc = 0.98807, test_loss = 0.03339, test_auc = 0.95347, time = 0.04628\n",
      "Epoch: 0300 | train_loss = 0.02901, train_auc = 0.98940, test_loss = 0.02871, test_auc = 0.96826, time = 0.04640\n",
      "Epoch: 0310 | train_loss = 0.03129, train_auc = 0.98905, test_loss = 0.02928, test_auc = 0.96961, time = 0.04581\n",
      "Epoch: 0320 | train_loss = 0.02941, train_auc = 0.98968, test_loss = 0.02887, test_auc = 0.96915, time = 0.04621\n",
      "Epoch: 0330 | train_loss = 0.02865, train_auc = 0.99054, test_loss = 0.02919, test_auc = 0.97097, time = 0.04596\n",
      "Epoch: 0340 | train_loss = 0.02799, train_auc = 0.99005, test_loss = 0.02972, test_auc = 0.96783, time = 0.04652\n",
      "Epoch: 0350 | train_loss = 0.02930, train_auc = 0.98998, test_loss = 0.03154, test_auc = 0.96525, time = 0.04703\n",
      "Epoch: 0360 | train_loss = 0.02809, train_auc = 0.99009, test_loss = 0.02972, test_auc = 0.96823, time = 0.04631\n",
      "Epoch: 0370 | train_loss = 0.02777, train_auc = 0.99077, test_loss = 0.02954, test_auc = 0.96777, time = 0.04726\n",
      "Epoch: 0380 | train_loss = 0.02742, train_auc = 0.99129, test_loss = 0.02936, test_auc = 0.96621, time = 0.04855\n",
      "Epoch: 0390 | train_loss = 0.02791, train_auc = 0.99086, test_loss = 0.03091, test_auc = 0.96393, time = 0.04837\n",
      "Epoch: 0400 | train_loss = 0.02687, train_auc = 0.99108, test_loss = 0.02759, test_auc = 0.97073, time = 0.04675\n",
      "Epoch: 0410 | train_loss = 0.02696, train_auc = 0.99185, test_loss = 0.02946, test_auc = 0.96629, time = 0.04610\n",
      "Epoch: 0420 | train_loss = 0.02696, train_auc = 0.99156, test_loss = 0.02904, test_auc = 0.96932, time = 0.04672\n",
      "Epoch: 0430 | train_loss = 0.02532, train_auc = 0.99147, test_loss = 0.02969, test_auc = 0.96879, time = 0.04680\n",
      "Epoch: 0440 | train_loss = 0.02515, train_auc = 0.99165, test_loss = 0.02819, test_auc = 0.97281, time = 0.04741\n",
      "Epoch: 0450 | train_loss = 0.02574, train_auc = 0.99124, test_loss = 0.03019, test_auc = 0.96618, time = 0.04634\n",
      "Epoch: 0460 | train_loss = 0.02475, train_auc = 0.99190, test_loss = 0.02985, test_auc = 0.96938, time = 0.04636\n",
      "Epoch: 0470 | train_loss = 0.02523, train_auc = 0.99176, test_loss = 0.03158, test_auc = 0.96710, time = 0.04644\n",
      "Epoch: 0480 | train_loss = 0.02601, train_auc = 0.99164, test_loss = 0.03037, test_auc = 0.96778, time = 0.04681\n",
      "Epoch: 0490 | train_loss = 0.02331, train_auc = 0.99222, test_loss = 0.03105, test_auc = 0.96947, time = 0.04831\n",
      "Epoch: 0500 | train_loss = 0.02427, train_auc = 0.99244, test_loss = 0.02967, test_auc = 0.96841, time = 0.04621\n",
      "times: 0, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13412, train_auc = 0.55812, test_loss = 0.07234, test_auc = 0.57166, time = 0.79315\n",
      "Epoch: 0010 | train_loss = 0.08204, train_auc = 0.90700, test_loss = 0.04666, test_auc = 0.84204, time = 0.05538\n",
      "Epoch: 0020 | train_loss = 0.07392, train_auc = 0.92483, test_loss = 0.04313, test_auc = 0.87568, time = 0.04944\n",
      "Epoch: 0030 | train_loss = 0.06619, train_auc = 0.94445, test_loss = 0.03994, test_auc = 0.91391, time = 0.04850\n",
      "Epoch: 0040 | train_loss = 0.06230, train_auc = 0.95186, test_loss = 0.03754, test_auc = 0.92276, time = 0.04758\n",
      "Epoch: 0050 | train_loss = 0.06208, train_auc = 0.95415, test_loss = 0.03366, test_auc = 0.94515, time = 0.06134\n",
      "Epoch: 0060 | train_loss = 0.05563, train_auc = 0.96428, test_loss = 0.03250, test_auc = 0.94815, time = 0.04769\n",
      "Epoch: 0070 | train_loss = 0.05589, train_auc = 0.96421, test_loss = 0.03935, test_auc = 0.93917, time = 0.04764\n",
      "Epoch: 0080 | train_loss = 0.05699, train_auc = 0.96294, test_loss = 0.03870, test_auc = 0.94196, time = 0.04709\n",
      "Epoch: 0090 | train_loss = 0.05197, train_auc = 0.96843, test_loss = 0.04145, test_auc = 0.94144, time = 0.04712\n",
      "Epoch: 0100 | train_loss = 0.04871, train_auc = 0.97334, test_loss = 0.03165, test_auc = 0.95379, time = 0.04858\n",
      "Epoch: 0110 | train_loss = 0.04721, train_auc = 0.97619, test_loss = 0.03044, test_auc = 0.95821, time = 0.04724\n",
      "Epoch: 0120 | train_loss = 0.04693, train_auc = 0.97630, test_loss = 0.03238, test_auc = 0.95506, time = 0.04755\n",
      "Epoch: 0130 | train_loss = 0.04516, train_auc = 0.97839, test_loss = 0.03524, test_auc = 0.95051, time = 0.04811\n",
      "Epoch: 0140 | train_loss = 0.04081, train_auc = 0.98102, test_loss = 0.03169, test_auc = 0.95895, time = 0.04771\n",
      "Epoch: 0150 | train_loss = 0.04439, train_auc = 0.98049, test_loss = 0.03091, test_auc = 0.95963, time = 0.04711\n",
      "Epoch: 0160 | train_loss = 0.04238, train_auc = 0.98071, test_loss = 0.03397, test_auc = 0.95407, time = 0.04723\n",
      "Epoch: 0170 | train_loss = 0.03821, train_auc = 0.98502, test_loss = 0.03493, test_auc = 0.94934, time = 0.04688\n",
      "Epoch: 0180 | train_loss = 0.03810, train_auc = 0.98602, test_loss = 0.03472, test_auc = 0.96001, time = 0.04744\n",
      "Epoch: 0190 | train_loss = 0.03792, train_auc = 0.98641, test_loss = 0.03384, test_auc = 0.96275, time = 0.04757\n",
      "Epoch: 0200 | train_loss = 0.03559, train_auc = 0.98787, test_loss = 0.03343, test_auc = 0.96237, time = 0.04901\n",
      "Epoch: 0210 | train_loss = 0.03461, train_auc = 0.98813, test_loss = 0.03083, test_auc = 0.96381, time = 0.04750\n",
      "Epoch: 0220 | train_loss = 0.03388, train_auc = 0.98881, test_loss = 0.02888, test_auc = 0.96598, time = 0.04698\n",
      "Epoch: 0230 | train_loss = 0.03329, train_auc = 0.98905, test_loss = 0.03166, test_auc = 0.96201, time = 0.04665\n",
      "Epoch: 0240 | train_loss = 0.03492, train_auc = 0.98793, test_loss = 0.03222, test_auc = 0.96665, time = 0.04647\n",
      "Epoch: 0250 | train_loss = 0.03057, train_auc = 0.99066, test_loss = 0.03579, test_auc = 0.95798, time = 0.04646\n",
      "Epoch: 0260 | train_loss = 0.03331, train_auc = 0.98935, test_loss = 0.03028, test_auc = 0.96401, time = 0.04634\n",
      "Epoch: 0270 | train_loss = 0.03425, train_auc = 0.98964, test_loss = 0.03106, test_auc = 0.96657, time = 0.04789\n",
      "Epoch: 0280 | train_loss = 0.02984, train_auc = 0.99190, test_loss = 0.02881, test_auc = 0.97102, time = 0.04773\n",
      "Epoch: 0290 | train_loss = 0.02712, train_auc = 0.99224, test_loss = 0.02978, test_auc = 0.97042, time = 0.04736\n",
      "Epoch: 0300 | train_loss = 0.02931, train_auc = 0.99188, test_loss = 0.02994, test_auc = 0.97091, time = 0.04778\n",
      "Epoch: 0310 | train_loss = 0.02885, train_auc = 0.99146, test_loss = 0.03117, test_auc = 0.96376, time = 0.05021\n",
      "Epoch: 0320 | train_loss = 0.03022, train_auc = 0.99152, test_loss = 0.03223, test_auc = 0.96017, time = 0.05285\n",
      "Epoch: 0330 | train_loss = 0.02814, train_auc = 0.99210, test_loss = 0.03594, test_auc = 0.94637, time = 0.04937\n",
      "Epoch: 0340 | train_loss = 0.02913, train_auc = 0.99236, test_loss = 0.03178, test_auc = 0.96471, time = 0.04827\n",
      "Epoch: 0350 | train_loss = 0.03153, train_auc = 0.99114, test_loss = 0.03212, test_auc = 0.96757, time = 0.04927\n",
      "Epoch: 0360 | train_loss = 0.02742, train_auc = 0.99384, test_loss = 0.03079, test_auc = 0.97162, time = 0.04845\n",
      "Epoch: 0370 | train_loss = 0.02576, train_auc = 0.99382, test_loss = 0.02934, test_auc = 0.96993, time = 0.05384\n",
      "Epoch: 0380 | train_loss = 0.02527, train_auc = 0.99314, test_loss = 0.03069, test_auc = 0.97106, time = 0.04769\n",
      "Epoch: 0390 | train_loss = 0.02891, train_auc = 0.99295, test_loss = 0.03064, test_auc = 0.96772, time = 0.04894\n",
      "Epoch: 0400 | train_loss = 0.02628, train_auc = 0.99419, test_loss = 0.02983, test_auc = 0.97141, time = 0.04769\n",
      "Epoch: 0410 | train_loss = 0.02599, train_auc = 0.99330, test_loss = 0.03329, test_auc = 0.96160, time = 0.04896\n",
      "Epoch: 0420 | train_loss = 0.02563, train_auc = 0.99403, test_loss = 0.02887, test_auc = 0.97274, time = 0.04767\n",
      "Epoch: 0430 | train_loss = 0.02486, train_auc = 0.99420, test_loss = 0.02897, test_auc = 0.97044, time = 0.04903\n",
      "Epoch: 0440 | train_loss = 0.02329, train_auc = 0.99465, test_loss = 0.03003, test_auc = 0.97156, time = 0.04740\n",
      "Epoch: 0450 | train_loss = 0.02557, train_auc = 0.99398, test_loss = 0.02749, test_auc = 0.97435, time = 0.04732\n",
      "Epoch: 0460 | train_loss = 0.02611, train_auc = 0.99337, test_loss = 0.02883, test_auc = 0.97113, time = 0.04760\n",
      "Epoch: 0470 | train_loss = 0.02180, train_auc = 0.99523, test_loss = 0.03107, test_auc = 0.97162, time = 0.04723\n",
      "Epoch: 0480 | train_loss = 0.02568, train_auc = 0.99384, test_loss = 0.02941, test_auc = 0.97083, time = 0.04707\n",
      "Epoch: 0490 | train_loss = 0.02165, train_auc = 0.99514, test_loss = 0.02912, test_auc = 0.97362, time = 0.04783\n",
      "Epoch: 0500 | train_loss = 0.02273, train_auc = 0.99478, test_loss = 0.02781, test_auc = 0.97266, time = 0.04610\n",
      "times: 0, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13665, train_auc = 0.51104, test_loss = 0.07337, test_auc = 0.54314, time = 0.82001\n",
      "Epoch: 0010 | train_loss = 0.08263, train_auc = 0.90189, test_loss = 0.05447, test_auc = 0.85265, time = 0.05187\n",
      "Epoch: 0020 | train_loss = 0.07608, train_auc = 0.91387, test_loss = 0.04063, test_auc = 0.90896, time = 0.05084\n",
      "Epoch: 0030 | train_loss = 0.06859, train_auc = 0.94358, test_loss = 0.03812, test_auc = 0.91956, time = 0.04645\n",
      "Epoch: 0040 | train_loss = 0.06303, train_auc = 0.95189, test_loss = 0.03642, test_auc = 0.93449, time = 0.04641\n",
      "Epoch: 0050 | train_loss = 0.06196, train_auc = 0.95397, test_loss = 0.03567, test_auc = 0.93924, time = 0.04595\n",
      "Epoch: 0060 | train_loss = 0.05857, train_auc = 0.96075, test_loss = 0.03600, test_auc = 0.94576, time = 0.04533\n",
      "Epoch: 0070 | train_loss = 0.05865, train_auc = 0.96385, test_loss = 0.03409, test_auc = 0.94382, time = 0.04542\n",
      "Epoch: 0080 | train_loss = 0.05501, train_auc = 0.96665, test_loss = 0.03526, test_auc = 0.93152, time = 0.04530\n",
      "Epoch: 0090 | train_loss = 0.05436, train_auc = 0.96630, test_loss = 0.03861, test_auc = 0.92389, time = 0.04495\n",
      "Epoch: 0100 | train_loss = 0.04836, train_auc = 0.97494, test_loss = 0.03186, test_auc = 0.95298, time = 0.04592\n",
      "Epoch: 0110 | train_loss = 0.04802, train_auc = 0.97514, test_loss = 0.03295, test_auc = 0.95151, time = 0.04597\n",
      "Epoch: 0120 | train_loss = 0.04539, train_auc = 0.97841, test_loss = 0.03275, test_auc = 0.95723, time = 0.04621\n",
      "Epoch: 0130 | train_loss = 0.04311, train_auc = 0.98062, test_loss = 0.03308, test_auc = 0.95376, time = 0.04670\n",
      "Epoch: 0140 | train_loss = 0.04480, train_auc = 0.97968, test_loss = 0.03085, test_auc = 0.96240, time = 0.04516\n",
      "Epoch: 0150 | train_loss = 0.04035, train_auc = 0.98306, test_loss = 0.03416, test_auc = 0.95872, time = 0.04533\n",
      "Epoch: 0160 | train_loss = 0.04056, train_auc = 0.98379, test_loss = 0.03632, test_auc = 0.95502, time = 0.04576\n",
      "Epoch: 0170 | train_loss = 0.03909, train_auc = 0.98420, test_loss = 0.03388, test_auc = 0.96018, time = 0.04552\n",
      "Epoch: 0180 | train_loss = 0.03766, train_auc = 0.98520, test_loss = 0.03516, test_auc = 0.95398, time = 0.04596\n",
      "Epoch: 0190 | train_loss = 0.03813, train_auc = 0.98553, test_loss = 0.03162, test_auc = 0.95842, time = 0.04763\n",
      "Epoch: 0200 | train_loss = 0.03616, train_auc = 0.98727, test_loss = 0.03321, test_auc = 0.95994, time = 0.04620\n",
      "Epoch: 0210 | train_loss = 0.03593, train_auc = 0.98690, test_loss = 0.03360, test_auc = 0.95876, time = 0.04548\n",
      "Epoch: 0220 | train_loss = 0.03515, train_auc = 0.98705, test_loss = 0.03492, test_auc = 0.95323, time = 0.04588\n",
      "Epoch: 0230 | train_loss = 0.03412, train_auc = 0.98798, test_loss = 0.03352, test_auc = 0.96018, time = 0.04607\n",
      "Epoch: 0240 | train_loss = 0.03248, train_auc = 0.98898, test_loss = 0.03106, test_auc = 0.96360, time = 0.04511\n",
      "Epoch: 0250 | train_loss = 0.03243, train_auc = 0.98777, test_loss = 0.03163, test_auc = 0.96476, time = 0.04556\n",
      "Epoch: 0260 | train_loss = 0.03205, train_auc = 0.98973, test_loss = 0.02850, test_auc = 0.97035, time = 0.04658\n",
      "Epoch: 0270 | train_loss = 0.03066, train_auc = 0.98983, test_loss = 0.02817, test_auc = 0.97202, time = 0.04580\n",
      "Epoch: 0280 | train_loss = 0.03196, train_auc = 0.99001, test_loss = 0.03108, test_auc = 0.96706, time = 0.04760\n",
      "Epoch: 0290 | train_loss = 0.02795, train_auc = 0.99106, test_loss = 0.03372, test_auc = 0.96661, time = 0.04590\n",
      "Epoch: 0300 | train_loss = 0.03060, train_auc = 0.99014, test_loss = 0.03147, test_auc = 0.96715, time = 0.04590\n",
      "Epoch: 0310 | train_loss = 0.03066, train_auc = 0.99082, test_loss = 0.02970, test_auc = 0.96944, time = 0.04676\n",
      "Epoch: 0320 | train_loss = 0.02736, train_auc = 0.99164, test_loss = 0.02836, test_auc = 0.97110, time = 0.04569\n",
      "Epoch: 0330 | train_loss = 0.03198, train_auc = 0.99065, test_loss = 0.03353, test_auc = 0.95861, time = 0.04620\n",
      "Epoch: 0340 | train_loss = 0.02770, train_auc = 0.99189, test_loss = 0.03305, test_auc = 0.96483, time = 0.04653\n",
      "Epoch: 0350 | train_loss = 0.02642, train_auc = 0.99240, test_loss = 0.03140, test_auc = 0.96686, time = 0.04657\n",
      "Epoch: 0360 | train_loss = 0.02696, train_auc = 0.99220, test_loss = 0.02951, test_auc = 0.97014, time = 0.04663\n",
      "Epoch: 0370 | train_loss = 0.02510, train_auc = 0.99330, test_loss = 0.03036, test_auc = 0.96868, time = 0.04750\n",
      "Epoch: 0380 | train_loss = 0.02863, train_auc = 0.99236, test_loss = 0.03155, test_auc = 0.97128, time = 0.04543\n",
      "Epoch: 0390 | train_loss = 0.02652, train_auc = 0.99314, test_loss = 0.03049, test_auc = 0.97287, time = 0.04630\n",
      "Epoch: 0400 | train_loss = 0.02567, train_auc = 0.99333, test_loss = 0.02965, test_auc = 0.97223, time = 0.04650\n",
      "Epoch: 0410 | train_loss = 0.02364, train_auc = 0.99400, test_loss = 0.02968, test_auc = 0.96894, time = 0.04557\n",
      "Epoch: 0420 | train_loss = 0.02648, train_auc = 0.99405, test_loss = 0.02832, test_auc = 0.97446, time = 0.04943\n",
      "Epoch: 0430 | train_loss = 0.02579, train_auc = 0.99362, test_loss = 0.03062, test_auc = 0.96759, time = 0.04617\n",
      "Epoch: 0440 | train_loss = 0.02820, train_auc = 0.99351, test_loss = 0.02980, test_auc = 0.96508, time = 0.04642\n",
      "Epoch: 0450 | train_loss = 0.02657, train_auc = 0.99350, test_loss = 0.03314, test_auc = 0.97347, time = 0.04620\n",
      "Epoch: 0460 | train_loss = 0.02336, train_auc = 0.99465, test_loss = 0.03188, test_auc = 0.96882, time = 0.04730\n",
      "Epoch: 0470 | train_loss = 0.02368, train_auc = 0.99501, test_loss = 0.02967, test_auc = 0.97395, time = 0.04632\n",
      "Epoch: 0480 | train_loss = 0.02400, train_auc = 0.99542, test_loss = 0.03060, test_auc = 0.97133, time = 0.04780\n",
      "Epoch: 0490 | train_loss = 0.02300, train_auc = 0.99579, test_loss = 0.03486, test_auc = 0.96642, time = 0.04839\n",
      "Epoch: 0500 | train_loss = 0.02398, train_auc = 0.99492, test_loss = 0.03062, test_auc = 0.96890, time = 0.04659\n",
      "times: 1, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14024, train_auc = 0.49346, test_loss = 0.07432, test_auc = 0.53512, time = 0.79171\n",
      "Epoch: 0010 | train_loss = 0.08799, train_auc = 0.88260, test_loss = 0.05531, test_auc = 0.79109, time = 0.05155\n",
      "Epoch: 0020 | train_loss = 0.07595, train_auc = 0.91710, test_loss = 0.04246, test_auc = 0.89581, time = 0.05007\n",
      "Epoch: 0030 | train_loss = 0.06877, train_auc = 0.93970, test_loss = 0.04035, test_auc = 0.91054, time = 0.05164\n",
      "Epoch: 0040 | train_loss = 0.06469, train_auc = 0.95004, test_loss = 0.04169, test_auc = 0.92785, time = 0.04846\n",
      "Epoch: 0050 | train_loss = 0.06189, train_auc = 0.95472, test_loss = 0.03616, test_auc = 0.93479, time = 0.04909\n",
      "Epoch: 0060 | train_loss = 0.05730, train_auc = 0.96089, test_loss = 0.03671, test_auc = 0.94121, time = 0.05020\n",
      "Epoch: 0070 | train_loss = 0.05708, train_auc = 0.96289, test_loss = 0.03547, test_auc = 0.94594, time = 0.05474\n",
      "Epoch: 0080 | train_loss = 0.05442, train_auc = 0.96627, test_loss = 0.03464, test_auc = 0.94430, time = 0.05023\n",
      "Epoch: 0090 | train_loss = 0.05316, train_auc = 0.96901, test_loss = 0.03810, test_auc = 0.92119, time = 0.05079\n",
      "Epoch: 0100 | train_loss = 0.05442, train_auc = 0.96765, test_loss = 0.04039, test_auc = 0.93457, time = 0.05116\n",
      "Epoch: 0110 | train_loss = 0.05003, train_auc = 0.97153, test_loss = 0.04795, test_auc = 0.85379, time = 0.04914\n",
      "Epoch: 0120 | train_loss = 0.04882, train_auc = 0.97400, test_loss = 0.03745, test_auc = 0.93187, time = 0.04925\n",
      "Epoch: 0130 | train_loss = 0.04664, train_auc = 0.97594, test_loss = 0.03113, test_auc = 0.95778, time = 0.04955\n",
      "Epoch: 0140 | train_loss = 0.04673, train_auc = 0.97662, test_loss = 0.03278, test_auc = 0.95831, time = 0.05166\n",
      "Epoch: 0150 | train_loss = 0.04398, train_auc = 0.98027, test_loss = 0.03535, test_auc = 0.94969, time = 0.05101\n",
      "Epoch: 0160 | train_loss = 0.04199, train_auc = 0.98200, test_loss = 0.03206, test_auc = 0.95800, time = 0.04970\n",
      "Epoch: 0170 | train_loss = 0.03992, train_auc = 0.98293, test_loss = 0.03422, test_auc = 0.95108, time = 0.04929\n",
      "Epoch: 0180 | train_loss = 0.03902, train_auc = 0.98304, test_loss = 0.03147, test_auc = 0.96432, time = 0.05588\n",
      "Epoch: 0190 | train_loss = 0.03894, train_auc = 0.98399, test_loss = 0.03119, test_auc = 0.96491, time = 0.05044\n",
      "Epoch: 0200 | train_loss = 0.03870, train_auc = 0.98417, test_loss = 0.03317, test_auc = 0.96411, time = 0.04998\n",
      "Epoch: 0210 | train_loss = 0.03746, train_auc = 0.98571, test_loss = 0.03129, test_auc = 0.96470, time = 0.05086\n",
      "Epoch: 0220 | train_loss = 0.03733, train_auc = 0.98512, test_loss = 0.03255, test_auc = 0.96339, time = 0.04813\n",
      "Epoch: 0230 | train_loss = 0.03528, train_auc = 0.98725, test_loss = 0.03136, test_auc = 0.96381, time = 0.04968\n",
      "Epoch: 0240 | train_loss = 0.03792, train_auc = 0.98571, test_loss = 0.03630, test_auc = 0.95828, time = 0.05002\n",
      "Epoch: 0250 | train_loss = 0.03324, train_auc = 0.98749, test_loss = 0.03437, test_auc = 0.95994, time = 0.04982\n",
      "Epoch: 0260 | train_loss = 0.03381, train_auc = 0.98799, test_loss = 0.03451, test_auc = 0.96504, time = 0.04955\n",
      "Epoch: 0270 | train_loss = 0.03298, train_auc = 0.98795, test_loss = 0.03381, test_auc = 0.96008, time = 0.04919\n",
      "Epoch: 0280 | train_loss = 0.03243, train_auc = 0.98828, test_loss = 0.03035, test_auc = 0.96725, time = 0.05071\n",
      "Epoch: 0290 | train_loss = 0.03076, train_auc = 0.98900, test_loss = 0.03182, test_auc = 0.96706, time = 0.04918\n",
      "Epoch: 0300 | train_loss = 0.02997, train_auc = 0.98903, test_loss = 0.03003, test_auc = 0.96388, time = 0.04934\n",
      "Epoch: 0310 | train_loss = 0.03019, train_auc = 0.99004, test_loss = 0.03173, test_auc = 0.95986, time = 0.04828\n",
      "Epoch: 0320 | train_loss = 0.03029, train_auc = 0.98978, test_loss = 0.03238, test_auc = 0.96351, time = 0.05059\n",
      "Epoch: 0330 | train_loss = 0.02958, train_auc = 0.99044, test_loss = 0.03067, test_auc = 0.96682, time = 0.04930\n",
      "Epoch: 0340 | train_loss = 0.03045, train_auc = 0.99057, test_loss = 0.02947, test_auc = 0.97043, time = 0.05026\n",
      "Epoch: 0350 | train_loss = 0.02903, train_auc = 0.98981, test_loss = 0.02949, test_auc = 0.96756, time = 0.04928\n",
      "Epoch: 0360 | train_loss = 0.03004, train_auc = 0.98978, test_loss = 0.03403, test_auc = 0.96046, time = 0.04956\n",
      "Epoch: 0370 | train_loss = 0.02959, train_auc = 0.98981, test_loss = 0.02982, test_auc = 0.96976, time = 0.04919\n",
      "Epoch: 0380 | train_loss = 0.02722, train_auc = 0.99092, test_loss = 0.03269, test_auc = 0.96245, time = 0.05308\n",
      "Epoch: 0390 | train_loss = 0.02805, train_auc = 0.99060, test_loss = 0.03418, test_auc = 0.96244, time = 0.05010\n",
      "Epoch: 0400 | train_loss = 0.02801, train_auc = 0.99155, test_loss = 0.02956, test_auc = 0.96818, time = 0.05002\n",
      "Epoch: 0410 | train_loss = 0.02711, train_auc = 0.99132, test_loss = 0.02849, test_auc = 0.97241, time = 0.06251\n",
      "Epoch: 0420 | train_loss = 0.02761, train_auc = 0.99165, test_loss = 0.03031, test_auc = 0.96981, time = 0.04981\n",
      "Epoch: 0430 | train_loss = 0.02678, train_auc = 0.99120, test_loss = 0.03039, test_auc = 0.96515, time = 0.05544\n",
      "Epoch: 0440 | train_loss = 0.02607, train_auc = 0.99201, test_loss = 0.03076, test_auc = 0.97087, time = 0.04973\n",
      "Epoch: 0450 | train_loss = 0.02618, train_auc = 0.99141, test_loss = 0.02843, test_auc = 0.97432, time = 0.04716\n",
      "Epoch: 0460 | train_loss = 0.02535, train_auc = 0.99176, test_loss = 0.02915, test_auc = 0.97033, time = 0.04980\n",
      "Epoch: 0470 | train_loss = 0.02774, train_auc = 0.99238, test_loss = 0.03409, test_auc = 0.95761, time = 0.04911\n",
      "Epoch: 0480 | train_loss = 0.02478, train_auc = 0.99231, test_loss = 0.03142, test_auc = 0.96718, time = 0.04886\n",
      "Epoch: 0490 | train_loss = 0.02444, train_auc = 0.99263, test_loss = 0.03119, test_auc = 0.96788, time = 0.04893\n",
      "Epoch: 0500 | train_loss = 0.02592, train_auc = 0.99330, test_loss = 0.03089, test_auc = 0.96686, time = 0.04855\n",
      "times: 1, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14893, train_auc = 0.39394, test_loss = 0.07183, test_auc = 0.56453, time = 0.79002\n",
      "Epoch: 0010 | train_loss = 0.07980, train_auc = 0.91464, test_loss = 0.04452, test_auc = 0.86221, time = 0.05063\n",
      "Epoch: 0020 | train_loss = 0.07543, train_auc = 0.93423, test_loss = 0.04037, test_auc = 0.90654, time = 0.04731\n",
      "Epoch: 0030 | train_loss = 0.06616, train_auc = 0.94358, test_loss = 0.04132, test_auc = 0.90034, time = 0.04490\n",
      "Epoch: 0040 | train_loss = 0.06204, train_auc = 0.95171, test_loss = 0.03532, test_auc = 0.93874, time = 0.04476\n",
      "Epoch: 0050 | train_loss = 0.06149, train_auc = 0.95673, test_loss = 0.03852, test_auc = 0.93663, time = 0.04448\n",
      "Epoch: 0060 | train_loss = 0.05722, train_auc = 0.96086, test_loss = 0.03595, test_auc = 0.92960, time = 0.04329\n",
      "Epoch: 0070 | train_loss = 0.05703, train_auc = 0.96411, test_loss = 0.03416, test_auc = 0.94526, time = 0.04380\n",
      "Epoch: 0080 | train_loss = 0.05408, train_auc = 0.96637, test_loss = 0.03402, test_auc = 0.94741, time = 0.04305\n",
      "Epoch: 0090 | train_loss = 0.05303, train_auc = 0.96811, test_loss = 0.03476, test_auc = 0.94389, time = 0.04425\n",
      "Epoch: 0100 | train_loss = 0.05074, train_auc = 0.97121, test_loss = 0.03292, test_auc = 0.95263, time = 0.04405\n",
      "Epoch: 0110 | train_loss = 0.04712, train_auc = 0.97619, test_loss = 0.03124, test_auc = 0.95833, time = 0.04398\n",
      "Epoch: 0120 | train_loss = 0.04667, train_auc = 0.97419, test_loss = 0.03393, test_auc = 0.94952, time = 0.04365\n",
      "Epoch: 0130 | train_loss = 0.04636, train_auc = 0.97575, test_loss = 0.03266, test_auc = 0.95487, time = 0.04354\n",
      "Epoch: 0140 | train_loss = 0.04619, train_auc = 0.97580, test_loss = 0.03167, test_auc = 0.96505, time = 0.04319\n",
      "Epoch: 0150 | train_loss = 0.04319, train_auc = 0.97985, test_loss = 0.03180, test_auc = 0.96055, time = 0.04380\n",
      "Epoch: 0160 | train_loss = 0.04120, train_auc = 0.98163, test_loss = 0.03188, test_auc = 0.96612, time = 0.04349\n",
      "Epoch: 0170 | train_loss = 0.03962, train_auc = 0.98217, test_loss = 0.03226, test_auc = 0.96313, time = 0.04409\n",
      "Epoch: 0180 | train_loss = 0.04077, train_auc = 0.98218, test_loss = 0.03683, test_auc = 0.95835, time = 0.04436\n",
      "Epoch: 0190 | train_loss = 0.04048, train_auc = 0.98313, test_loss = 0.03001, test_auc = 0.96711, time = 0.04551\n",
      "Epoch: 0200 | train_loss = 0.03781, train_auc = 0.98479, test_loss = 0.02998, test_auc = 0.96918, time = 0.04440\n",
      "Epoch: 0210 | train_loss = 0.03627, train_auc = 0.98530, test_loss = 0.03108, test_auc = 0.96602, time = 0.04398\n",
      "Epoch: 0220 | train_loss = 0.03561, train_auc = 0.98586, test_loss = 0.02992, test_auc = 0.96879, time = 0.04321\n",
      "Epoch: 0230 | train_loss = 0.03685, train_auc = 0.98567, test_loss = 0.03177, test_auc = 0.96508, time = 0.04364\n",
      "Epoch: 0240 | train_loss = 0.03675, train_auc = 0.98584, test_loss = 0.02928, test_auc = 0.97205, time = 0.04368\n",
      "Epoch: 0250 | train_loss = 0.03356, train_auc = 0.98773, test_loss = 0.03126, test_auc = 0.96521, time = 0.04315\n",
      "Epoch: 0260 | train_loss = 0.03157, train_auc = 0.98878, test_loss = 0.02967, test_auc = 0.96874, time = 0.04324\n",
      "Epoch: 0270 | train_loss = 0.03238, train_auc = 0.98851, test_loss = 0.02940, test_auc = 0.96878, time = 0.04401\n",
      "Epoch: 0280 | train_loss = 0.03038, train_auc = 0.98935, test_loss = 0.03253, test_auc = 0.96712, time = 0.04568\n",
      "Epoch: 0290 | train_loss = 0.03148, train_auc = 0.98894, test_loss = 0.03190, test_auc = 0.96581, time = 0.04385\n",
      "Epoch: 0300 | train_loss = 0.03099, train_auc = 0.98946, test_loss = 0.03116, test_auc = 0.97080, time = 0.04297\n",
      "Epoch: 0310 | train_loss = 0.03157, train_auc = 0.98824, test_loss = 0.03138, test_auc = 0.96989, time = 0.04434\n",
      "Epoch: 0320 | train_loss = 0.03190, train_auc = 0.98897, test_loss = 0.04019, test_auc = 0.96412, time = 0.04448\n",
      "Epoch: 0330 | train_loss = 0.02879, train_auc = 0.99035, test_loss = 0.03223, test_auc = 0.97243, time = 0.04522\n",
      "Epoch: 0340 | train_loss = 0.03079, train_auc = 0.98957, test_loss = 0.03378, test_auc = 0.96889, time = 0.04406\n",
      "Epoch: 0350 | train_loss = 0.02773, train_auc = 0.99033, test_loss = 0.03914, test_auc = 0.96405, time = 0.04470\n",
      "Epoch: 0360 | train_loss = 0.02999, train_auc = 0.98969, test_loss = 0.03082, test_auc = 0.97156, time = 0.04472\n",
      "Epoch: 0370 | train_loss = 0.02933, train_auc = 0.98979, test_loss = 0.03086, test_auc = 0.97178, time = 0.04353\n",
      "Epoch: 0380 | train_loss = 0.02655, train_auc = 0.99140, test_loss = 0.03103, test_auc = 0.96947, time = 0.04398\n",
      "Epoch: 0390 | train_loss = 0.02727, train_auc = 0.99116, test_loss = 0.02993, test_auc = 0.97193, time = 0.04416\n",
      "Epoch: 0400 | train_loss = 0.02676, train_auc = 0.99163, test_loss = 0.03351, test_auc = 0.96920, time = 0.04335\n",
      "Epoch: 0410 | train_loss = 0.02945, train_auc = 0.99146, test_loss = 0.02848, test_auc = 0.97595, time = 0.04333\n",
      "Epoch: 0420 | train_loss = 0.02656, train_auc = 0.99171, test_loss = 0.02941, test_auc = 0.97409, time = 0.04355\n",
      "Epoch: 0430 | train_loss = 0.02719, train_auc = 0.99121, test_loss = 0.02645, test_auc = 0.97982, time = 0.04301\n",
      "Epoch: 0440 | train_loss = 0.02577, train_auc = 0.99175, test_loss = 0.02893, test_auc = 0.97494, time = 0.04303\n",
      "Epoch: 0450 | train_loss = 0.02479, train_auc = 0.99176, test_loss = 0.02848, test_auc = 0.97554, time = 0.04296\n",
      "Epoch: 0460 | train_loss = 0.02376, train_auc = 0.99289, test_loss = 0.03462, test_auc = 0.97008, time = 0.04331\n",
      "Epoch: 0470 | train_loss = 0.02670, train_auc = 0.99206, test_loss = 0.03269, test_auc = 0.97177, time = 0.04233\n",
      "Epoch: 0480 | train_loss = 0.02458, train_auc = 0.99292, test_loss = 0.03199, test_auc = 0.97092, time = 0.04341\n",
      "Epoch: 0490 | train_loss = 0.02461, train_auc = 0.99264, test_loss = 0.03058, test_auc = 0.97119, time = 0.04287\n",
      "Epoch: 0500 | train_loss = 0.02567, train_auc = 0.99260, test_loss = 0.03374, test_auc = 0.96780, time = 0.04283\n",
      "times: 1, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13901, train_auc = 0.48247, test_loss = 0.06792, test_auc = 0.61488, time = 0.82265\n",
      "Epoch: 0010 | train_loss = 0.08717, train_auc = 0.89932, test_loss = 0.05623, test_auc = 0.80412, time = 0.04843\n",
      "Epoch: 0020 | train_loss = 0.07753, train_auc = 0.91969, test_loss = 0.04211, test_auc = 0.90005, time = 0.04776\n",
      "Epoch: 0030 | train_loss = 0.07105, train_auc = 0.93735, test_loss = 0.03858, test_auc = 0.92293, time = 0.04633\n",
      "Epoch: 0040 | train_loss = 0.06698, train_auc = 0.94406, test_loss = 0.03429, test_auc = 0.94035, time = 0.04569\n",
      "Epoch: 0050 | train_loss = 0.06264, train_auc = 0.95309, test_loss = 0.03481, test_auc = 0.94083, time = 0.04631\n",
      "Epoch: 0060 | train_loss = 0.05983, train_auc = 0.96014, test_loss = 0.03142, test_auc = 0.95288, time = 0.04606\n",
      "Epoch: 0070 | train_loss = 0.05709, train_auc = 0.96298, test_loss = 0.03315, test_auc = 0.94734, time = 0.04488\n",
      "Epoch: 0080 | train_loss = 0.05493, train_auc = 0.96620, test_loss = 0.03340, test_auc = 0.94905, time = 0.04455\n",
      "Epoch: 0090 | train_loss = 0.05395, train_auc = 0.96701, test_loss = 0.03179, test_auc = 0.95513, time = 0.04568\n",
      "Epoch: 0100 | train_loss = 0.05150, train_auc = 0.97122, test_loss = 0.03165, test_auc = 0.96003, time = 0.04496\n",
      "Epoch: 0110 | train_loss = 0.05034, train_auc = 0.97437, test_loss = 0.03258, test_auc = 0.96249, time = 0.04529\n",
      "Epoch: 0120 | train_loss = 0.04785, train_auc = 0.97556, test_loss = 0.03463, test_auc = 0.95552, time = 0.04451\n",
      "Epoch: 0130 | train_loss = 0.04400, train_auc = 0.97877, test_loss = 0.03539, test_auc = 0.95856, time = 0.04398\n",
      "Epoch: 0140 | train_loss = 0.04237, train_auc = 0.98179, test_loss = 0.03416, test_auc = 0.95513, time = 0.04565\n",
      "Epoch: 0150 | train_loss = 0.04157, train_auc = 0.98109, test_loss = 0.03150, test_auc = 0.95873, time = 0.04509\n",
      "Epoch: 0160 | train_loss = 0.04055, train_auc = 0.98288, test_loss = 0.02956, test_auc = 0.96417, time = 0.04495\n",
      "Epoch: 0170 | train_loss = 0.04241, train_auc = 0.98277, test_loss = 0.02912, test_auc = 0.96606, time = 0.05380\n",
      "Epoch: 0180 | train_loss = 0.03795, train_auc = 0.98498, test_loss = 0.02934, test_auc = 0.96795, time = 0.04481\n",
      "Epoch: 0190 | train_loss = 0.03742, train_auc = 0.98556, test_loss = 0.03007, test_auc = 0.96483, time = 0.05582\n",
      "Epoch: 0200 | train_loss = 0.03624, train_auc = 0.98643, test_loss = 0.03124, test_auc = 0.96951, time = 0.04540\n",
      "Epoch: 0210 | train_loss = 0.03625, train_auc = 0.98634, test_loss = 0.03615, test_auc = 0.96118, time = 0.04639\n",
      "Epoch: 0220 | train_loss = 0.03245, train_auc = 0.98862, test_loss = 0.03057, test_auc = 0.96373, time = 0.04758\n",
      "Epoch: 0230 | train_loss = 0.03631, train_auc = 0.98603, test_loss = 0.03036, test_auc = 0.96934, time = 0.04524\n",
      "Epoch: 0240 | train_loss = 0.03383, train_auc = 0.98887, test_loss = 0.03574, test_auc = 0.96308, time = 0.04523\n",
      "Epoch: 0250 | train_loss = 0.03177, train_auc = 0.98940, test_loss = 0.03026, test_auc = 0.96884, time = 0.04470\n",
      "Epoch: 0260 | train_loss = 0.03112, train_auc = 0.98983, test_loss = 0.03034, test_auc = 0.96584, time = 0.04503\n",
      "Epoch: 0270 | train_loss = 0.03231, train_auc = 0.99062, test_loss = 0.03209, test_auc = 0.96590, time = 0.04466\n",
      "Epoch: 0280 | train_loss = 0.03244, train_auc = 0.98967, test_loss = 0.03003, test_auc = 0.96975, time = 0.04398\n",
      "Epoch: 0290 | train_loss = 0.02950, train_auc = 0.99141, test_loss = 0.03042, test_auc = 0.96826, time = 0.04435\n",
      "Epoch: 0300 | train_loss = 0.02907, train_auc = 0.99091, test_loss = 0.02756, test_auc = 0.97406, time = 0.04397\n",
      "Epoch: 0310 | train_loss = 0.02794, train_auc = 0.99187, test_loss = 0.03331, test_auc = 0.96077, time = 0.04401\n",
      "Epoch: 0320 | train_loss = 0.02878, train_auc = 0.99191, test_loss = 0.03202, test_auc = 0.96225, time = 0.04388\n",
      "Epoch: 0330 | train_loss = 0.02818, train_auc = 0.99177, test_loss = 0.03474, test_auc = 0.96977, time = 0.04401\n",
      "Epoch: 0340 | train_loss = 0.02515, train_auc = 0.99284, test_loss = 0.02798, test_auc = 0.97302, time = 0.04428\n",
      "Epoch: 0350 | train_loss = 0.02853, train_auc = 0.99197, test_loss = 0.02937, test_auc = 0.97037, time = 0.04456\n",
      "Epoch: 0360 | train_loss = 0.02491, train_auc = 0.99303, test_loss = 0.03261, test_auc = 0.96458, time = 0.04456\n",
      "Epoch: 0370 | train_loss = 0.02584, train_auc = 0.99272, test_loss = 0.02894, test_auc = 0.97336, time = 0.04462\n",
      "Epoch: 0380 | train_loss = 0.02786, train_auc = 0.99304, test_loss = 0.02982, test_auc = 0.97230, time = 0.04464\n",
      "Epoch: 0390 | train_loss = 0.02759, train_auc = 0.99231, test_loss = 0.02973, test_auc = 0.97326, time = 0.04417\n",
      "Epoch: 0400 | train_loss = 0.02500, train_auc = 0.99308, test_loss = 0.02931, test_auc = 0.97455, time = 0.04454\n",
      "Epoch: 0410 | train_loss = 0.02760, train_auc = 0.99234, test_loss = 0.02923, test_auc = 0.97303, time = 0.04437\n",
      "Epoch: 0420 | train_loss = 0.02544, train_auc = 0.99314, test_loss = 0.02777, test_auc = 0.97363, time = 0.04420\n",
      "Epoch: 0430 | train_loss = 0.02499, train_auc = 0.99329, test_loss = 0.02985, test_auc = 0.96848, time = 0.04414\n",
      "Epoch: 0440 | train_loss = 0.02273, train_auc = 0.99415, test_loss = 0.03153, test_auc = 0.97395, time = 0.04407\n",
      "Epoch: 0450 | train_loss = 0.02362, train_auc = 0.99345, test_loss = 0.02886, test_auc = 0.97170, time = 0.04422\n",
      "Epoch: 0460 | train_loss = 0.02414, train_auc = 0.99371, test_loss = 0.02899, test_auc = 0.97259, time = 0.04496\n",
      "Epoch: 0470 | train_loss = 0.02419, train_auc = 0.99376, test_loss = 0.03151, test_auc = 0.97186, time = 0.04399\n",
      "Epoch: 0480 | train_loss = 0.02497, train_auc = 0.99315, test_loss = 0.03264, test_auc = 0.97401, time = 0.04448\n",
      "Epoch: 0490 | train_loss = 0.02674, train_auc = 0.99323, test_loss = 0.02955, test_auc = 0.97038, time = 0.04471\n",
      "Epoch: 0500 | train_loss = 0.02433, train_auc = 0.99399, test_loss = 0.02866, test_auc = 0.96924, time = 0.04545\n",
      "times: 1, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13677, train_auc = 0.53056, test_loss = 0.07405, test_auc = 0.52337, time = 0.83936\n",
      "Epoch: 0010 | train_loss = 0.08355, train_auc = 0.90531, test_loss = 0.05253, test_auc = 0.82156, time = 0.05277\n",
      "Epoch: 0020 | train_loss = 0.07272, train_auc = 0.92855, test_loss = 0.04116, test_auc = 0.88573, time = 0.04961\n",
      "Epoch: 0030 | train_loss = 0.06716, train_auc = 0.94324, test_loss = 0.03821, test_auc = 0.91520, time = 0.04883\n",
      "Epoch: 0040 | train_loss = 0.06445, train_auc = 0.95056, test_loss = 0.03661, test_auc = 0.93498, time = 0.04903\n",
      "Epoch: 0050 | train_loss = 0.06314, train_auc = 0.95431, test_loss = 0.03445, test_auc = 0.94544, time = 0.04969\n",
      "Epoch: 0060 | train_loss = 0.05831, train_auc = 0.96139, test_loss = 0.03249, test_auc = 0.94959, time = 0.04810\n",
      "Epoch: 0070 | train_loss = 0.05542, train_auc = 0.96615, test_loss = 0.03289, test_auc = 0.95185, time = 0.04715\n",
      "Epoch: 0080 | train_loss = 0.05498, train_auc = 0.96719, test_loss = 0.03228, test_auc = 0.95302, time = 0.04734\n",
      "Epoch: 0090 | train_loss = 0.05256, train_auc = 0.97052, test_loss = 0.02960, test_auc = 0.96086, time = 0.04665\n",
      "Epoch: 0100 | train_loss = 0.05062, train_auc = 0.97218, test_loss = 0.03382, test_auc = 0.95499, time = 0.04721\n",
      "Epoch: 0110 | train_loss = 0.04817, train_auc = 0.97560, test_loss = 0.03344, test_auc = 0.94568, time = 0.04679\n",
      "Epoch: 0120 | train_loss = 0.04660, train_auc = 0.97713, test_loss = 0.03076, test_auc = 0.95594, time = 0.04731\n",
      "Epoch: 0130 | train_loss = 0.04401, train_auc = 0.97908, test_loss = 0.02896, test_auc = 0.96556, time = 0.04850\n",
      "Epoch: 0140 | train_loss = 0.04530, train_auc = 0.98044, test_loss = 0.03027, test_auc = 0.96590, time = 0.05272\n",
      "Epoch: 0150 | train_loss = 0.04186, train_auc = 0.98212, test_loss = 0.03084, test_auc = 0.96495, time = 0.04877\n",
      "Epoch: 0160 | train_loss = 0.04094, train_auc = 0.98339, test_loss = 0.03137, test_auc = 0.96473, time = 0.04876\n",
      "Epoch: 0170 | train_loss = 0.04127, train_auc = 0.98349, test_loss = 0.03169, test_auc = 0.94946, time = 0.04717\n",
      "Epoch: 0180 | train_loss = 0.03861, train_auc = 0.98446, test_loss = 0.03188, test_auc = 0.96166, time = 0.04830\n",
      "Epoch: 0190 | train_loss = 0.03878, train_auc = 0.98506, test_loss = 0.03118, test_auc = 0.96188, time = 0.05201\n",
      "Epoch: 0200 | train_loss = 0.03848, train_auc = 0.98596, test_loss = 0.03654, test_auc = 0.95990, time = 0.05632\n",
      "Epoch: 0210 | train_loss = 0.03736, train_auc = 0.98674, test_loss = 0.03392, test_auc = 0.96285, time = 0.05243\n",
      "Epoch: 0220 | train_loss = 0.03634, train_auc = 0.98731, test_loss = 0.03446, test_auc = 0.95930, time = 0.04833\n",
      "Epoch: 0230 | train_loss = 0.03234, train_auc = 0.98880, test_loss = 0.03037, test_auc = 0.96739, time = 0.04826\n",
      "Epoch: 0240 | train_loss = 0.03446, train_auc = 0.98859, test_loss = 0.03333, test_auc = 0.96525, time = 0.04739\n",
      "Epoch: 0250 | train_loss = 0.03077, train_auc = 0.98966, test_loss = 0.02923, test_auc = 0.96906, time = 0.04653\n",
      "Epoch: 0260 | train_loss = 0.03039, train_auc = 0.98947, test_loss = 0.02884, test_auc = 0.96773, time = 0.04654\n",
      "Epoch: 0270 | train_loss = 0.03007, train_auc = 0.98953, test_loss = 0.02980, test_auc = 0.96698, time = 0.04687\n",
      "Epoch: 0280 | train_loss = 0.02946, train_auc = 0.99038, test_loss = 0.03032, test_auc = 0.96665, time = 0.04699\n",
      "Epoch: 0290 | train_loss = 0.02896, train_auc = 0.99018, test_loss = 0.02929, test_auc = 0.96900, time = 0.04734\n",
      "Epoch: 0300 | train_loss = 0.02794, train_auc = 0.99070, test_loss = 0.03180, test_auc = 0.96718, time = 0.04692\n",
      "Epoch: 0310 | train_loss = 0.02893, train_auc = 0.99105, test_loss = 0.02828, test_auc = 0.97132, time = 0.04673\n",
      "Epoch: 0320 | train_loss = 0.02872, train_auc = 0.99108, test_loss = 0.03001, test_auc = 0.97158, time = 0.04689\n",
      "Epoch: 0330 | train_loss = 0.02990, train_auc = 0.99035, test_loss = 0.03003, test_auc = 0.96814, time = 0.04684\n",
      "Epoch: 0340 | train_loss = 0.02894, train_auc = 0.99091, test_loss = 0.02926, test_auc = 0.96978, time = 0.04695\n",
      "Epoch: 0350 | train_loss = 0.02653, train_auc = 0.99184, test_loss = 0.03118, test_auc = 0.96884, time = 0.04576\n",
      "Epoch: 0360 | train_loss = 0.02681, train_auc = 0.99201, test_loss = 0.03000, test_auc = 0.96635, time = 0.04848\n",
      "Epoch: 0370 | train_loss = 0.02824, train_auc = 0.99138, test_loss = 0.02870, test_auc = 0.97137, time = 0.04736\n",
      "Epoch: 0380 | train_loss = 0.02675, train_auc = 0.99200, test_loss = 0.03010, test_auc = 0.97075, time = 0.04656\n",
      "Epoch: 0390 | train_loss = 0.02836, train_auc = 0.99110, test_loss = 0.03683, test_auc = 0.95056, time = 0.04572\n",
      "Epoch: 0400 | train_loss = 0.02505, train_auc = 0.99321, test_loss = 0.03046, test_auc = 0.96745, time = 0.04801\n",
      "Epoch: 0410 | train_loss = 0.02646, train_auc = 0.99293, test_loss = 0.02953, test_auc = 0.97223, time = 0.04631\n",
      "Epoch: 0420 | train_loss = 0.02566, train_auc = 0.99307, test_loss = 0.03197, test_auc = 0.96671, time = 0.04587\n",
      "Epoch: 0430 | train_loss = 0.02462, train_auc = 0.99356, test_loss = 0.03128, test_auc = 0.97257, time = 0.04821\n",
      "Epoch: 0440 | train_loss = 0.02619, train_auc = 0.99347, test_loss = 0.02843, test_auc = 0.97550, time = 0.04728\n",
      "Epoch: 0450 | train_loss = 0.02580, train_auc = 0.99333, test_loss = 0.02961, test_auc = 0.97443, time = 0.04593\n",
      "Epoch: 0460 | train_loss = 0.02251, train_auc = 0.99395, test_loss = 0.03400, test_auc = 0.97141, time = 0.04674\n",
      "Epoch: 0470 | train_loss = 0.02570, train_auc = 0.99363, test_loss = 0.02904, test_auc = 0.97423, time = 0.04676\n",
      "Epoch: 0480 | train_loss = 0.02436, train_auc = 0.99393, test_loss = 0.02759, test_auc = 0.97486, time = 0.04600\n",
      "Epoch: 0490 | train_loss = 0.02451, train_auc = 0.99369, test_loss = 0.02798, test_auc = 0.97488, time = 0.04694\n",
      "Epoch: 0500 | train_loss = 0.02411, train_auc = 0.99424, test_loss = 0.03023, test_auc = 0.97154, time = 0.04709\n",
      "times: 1, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14166, train_auc = 0.51011, test_loss = 0.06892, test_auc = 0.60263, time = 0.82321\n",
      "Epoch: 0010 | train_loss = 0.08854, train_auc = 0.89078, test_loss = 0.05521, test_auc = 0.80183, time = 0.04944\n",
      "Epoch: 0020 | train_loss = 0.07900, train_auc = 0.91089, test_loss = 0.04247, test_auc = 0.88582, time = 0.04973\n",
      "Epoch: 0030 | train_loss = 0.07222, train_auc = 0.93046, test_loss = 0.04356, test_auc = 0.87253, time = 0.04798\n",
      "Epoch: 0040 | train_loss = 0.06695, train_auc = 0.94466, test_loss = 0.04022, test_auc = 0.91299, time = 0.04945\n",
      "Epoch: 0050 | train_loss = 0.06416, train_auc = 0.94947, test_loss = 0.03695, test_auc = 0.93459, time = 0.05370\n",
      "Epoch: 0060 | train_loss = 0.06099, train_auc = 0.95835, test_loss = 0.03859, test_auc = 0.92840, time = 0.04697\n",
      "Epoch: 0070 | train_loss = 0.05887, train_auc = 0.96049, test_loss = 0.03814, test_auc = 0.93448, time = 0.04632\n",
      "Epoch: 0080 | train_loss = 0.05854, train_auc = 0.96235, test_loss = 0.03496, test_auc = 0.94458, time = 0.04611\n",
      "Epoch: 0090 | train_loss = 0.05600, train_auc = 0.96651, test_loss = 0.03722, test_auc = 0.94338, time = 0.04570\n",
      "Epoch: 0100 | train_loss = 0.05304, train_auc = 0.96768, test_loss = 0.03419, test_auc = 0.94758, time = 0.04547\n",
      "Epoch: 0110 | train_loss = 0.05076, train_auc = 0.97236, test_loss = 0.03949, test_auc = 0.93556, time = 0.04560\n",
      "Epoch: 0120 | train_loss = 0.04877, train_auc = 0.97415, test_loss = 0.03436, test_auc = 0.94909, time = 0.04511\n",
      "Epoch: 0130 | train_loss = 0.04830, train_auc = 0.97643, test_loss = 0.03641, test_auc = 0.94720, time = 0.04510\n",
      "Epoch: 0140 | train_loss = 0.04383, train_auc = 0.98011, test_loss = 0.03509, test_auc = 0.94769, time = 0.04499\n",
      "Epoch: 0150 | train_loss = 0.04424, train_auc = 0.97982, test_loss = 0.03261, test_auc = 0.95721, time = 0.04647\n",
      "Epoch: 0160 | train_loss = 0.04209, train_auc = 0.98283, test_loss = 0.03271, test_auc = 0.95332, time = 0.04518\n",
      "Epoch: 0170 | train_loss = 0.04214, train_auc = 0.98245, test_loss = 0.03271, test_auc = 0.95736, time = 0.04557\n",
      "Epoch: 0180 | train_loss = 0.03951, train_auc = 0.98432, test_loss = 0.03363, test_auc = 0.95515, time = 0.04629\n",
      "Epoch: 0190 | train_loss = 0.04398, train_auc = 0.98130, test_loss = 0.03420, test_auc = 0.95508, time = 0.04602\n",
      "Epoch: 0200 | train_loss = 0.03802, train_auc = 0.98594, test_loss = 0.03362, test_auc = 0.95680, time = 0.04693\n",
      "Epoch: 0210 | train_loss = 0.03639, train_auc = 0.98734, test_loss = 0.03828, test_auc = 0.95264, time = 0.04638\n",
      "Epoch: 0220 | train_loss = 0.03503, train_auc = 0.98895, test_loss = 0.03349, test_auc = 0.95133, time = 0.04681\n",
      "Epoch: 0230 | train_loss = 0.03519, train_auc = 0.98902, test_loss = 0.03187, test_auc = 0.95897, time = 0.04754\n",
      "Epoch: 0240 | train_loss = 0.03518, train_auc = 0.98889, test_loss = 0.03405, test_auc = 0.95072, time = 0.04531\n",
      "Epoch: 0250 | train_loss = 0.03704, train_auc = 0.98874, test_loss = 0.03225, test_auc = 0.96030, time = 0.04586\n",
      "Epoch: 0260 | train_loss = 0.03297, train_auc = 0.99085, test_loss = 0.03358, test_auc = 0.95882, time = 0.04992\n",
      "Epoch: 0270 | train_loss = 0.03261, train_auc = 0.99143, test_loss = 0.03194, test_auc = 0.96009, time = 0.04557\n",
      "Epoch: 0280 | train_loss = 0.03346, train_auc = 0.99136, test_loss = 0.03294, test_auc = 0.96058, time = 0.04572\n",
      "Epoch: 0290 | train_loss = 0.03339, train_auc = 0.98992, test_loss = 0.03285, test_auc = 0.95933, time = 0.04585\n",
      "Epoch: 0300 | train_loss = 0.03045, train_auc = 0.99162, test_loss = 0.03522, test_auc = 0.95405, time = 0.04584\n",
      "Epoch: 0310 | train_loss = 0.03344, train_auc = 0.99162, test_loss = 0.03233, test_auc = 0.96113, time = 0.04970\n",
      "Epoch: 0320 | train_loss = 0.02892, train_auc = 0.99227, test_loss = 0.03547, test_auc = 0.95913, time = 0.04533\n",
      "Epoch: 0330 | train_loss = 0.02895, train_auc = 0.99363, test_loss = 0.03398, test_auc = 0.96018, time = 0.04508\n",
      "Epoch: 0340 | train_loss = 0.02884, train_auc = 0.99271, test_loss = 0.03378, test_auc = 0.95274, time = 0.04551\n",
      "Epoch: 0350 | train_loss = 0.02734, train_auc = 0.99351, test_loss = 0.03669, test_auc = 0.95092, time = 0.04590\n",
      "Epoch: 0360 | train_loss = 0.02803, train_auc = 0.99318, test_loss = 0.03390, test_auc = 0.96126, time = 0.04532\n",
      "Epoch: 0370 | train_loss = 0.02506, train_auc = 0.99414, test_loss = 0.03358, test_auc = 0.96216, time = 0.04621\n",
      "Epoch: 0380 | train_loss = 0.02544, train_auc = 0.99471, test_loss = 0.03155, test_auc = 0.96311, time = 0.04534\n",
      "Epoch: 0390 | train_loss = 0.02651, train_auc = 0.99386, test_loss = 0.03173, test_auc = 0.96593, time = 0.04587\n",
      "Epoch: 0400 | train_loss = 0.02508, train_auc = 0.99421, test_loss = 0.03243, test_auc = 0.96592, time = 0.04584\n",
      "Epoch: 0410 | train_loss = 0.02416, train_auc = 0.99473, test_loss = 0.03047, test_auc = 0.96833, time = 0.04572\n",
      "Epoch: 0420 | train_loss = 0.02518, train_auc = 0.99452, test_loss = 0.03352, test_auc = 0.96266, time = 0.04553\n",
      "Epoch: 0430 | train_loss = 0.02706, train_auc = 0.99424, test_loss = 0.03364, test_auc = 0.96495, time = 0.04602\n",
      "Epoch: 0440 | train_loss = 0.02363, train_auc = 0.99510, test_loss = 0.03042, test_auc = 0.96741, time = 0.04573\n",
      "Epoch: 0450 | train_loss = 0.02333, train_auc = 0.99505, test_loss = 0.03510, test_auc = 0.95778, time = 0.04571\n",
      "Epoch: 0460 | train_loss = 0.02176, train_auc = 0.99528, test_loss = 0.03132, test_auc = 0.96487, time = 0.04564\n",
      "Epoch: 0470 | train_loss = 0.02306, train_auc = 0.99508, test_loss = 0.03264, test_auc = 0.96450, time = 0.04565\n",
      "Epoch: 0480 | train_loss = 0.02589, train_auc = 0.99511, test_loss = 0.03218, test_auc = 0.96584, time = 0.04494\n",
      "Epoch: 0490 | train_loss = 0.02303, train_auc = 0.99509, test_loss = 0.03359, test_auc = 0.96275, time = 0.04659\n",
      "Epoch: 0500 | train_loss = 0.02365, train_auc = 0.99530, test_loss = 0.03213, test_auc = 0.96503, time = 0.04528\n",
      "times: 2, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15792, train_auc = 0.32091, test_loss = 0.07291, test_auc = 0.53849, time = 0.79730\n",
      "Epoch: 0010 | train_loss = 0.08189, train_auc = 0.91071, test_loss = 0.04764, test_auc = 0.87035, time = 0.05163\n",
      "Epoch: 0020 | train_loss = 0.07251, train_auc = 0.93048, test_loss = 0.04207, test_auc = 0.88975, time = 0.04804\n",
      "Epoch: 0030 | train_loss = 0.06852, train_auc = 0.93981, test_loss = 0.03815, test_auc = 0.91171, time = 0.04734\n",
      "Epoch: 0040 | train_loss = 0.06827, train_auc = 0.94365, test_loss = 0.03481, test_auc = 0.93841, time = 0.04920\n",
      "Epoch: 0050 | train_loss = 0.06223, train_auc = 0.95241, test_loss = 0.03319, test_auc = 0.94638, time = 0.05013\n",
      "Epoch: 0060 | train_loss = 0.05965, train_auc = 0.95802, test_loss = 0.03321, test_auc = 0.94568, time = 0.06236\n",
      "Epoch: 0070 | train_loss = 0.05882, train_auc = 0.96094, test_loss = 0.03756, test_auc = 0.94097, time = 0.04673\n",
      "Epoch: 0080 | train_loss = 0.05596, train_auc = 0.96395, test_loss = 0.03519, test_auc = 0.94899, time = 0.04629\n",
      "Epoch: 0090 | train_loss = 0.05244, train_auc = 0.96838, test_loss = 0.03087, test_auc = 0.95480, time = 0.04772\n",
      "Epoch: 0100 | train_loss = 0.05179, train_auc = 0.96999, test_loss = 0.03298, test_auc = 0.95527, time = 0.04660\n",
      "Epoch: 0110 | train_loss = 0.04867, train_auc = 0.97287, test_loss = 0.03447, test_auc = 0.95048, time = 0.05446\n",
      "Epoch: 0120 | train_loss = 0.04827, train_auc = 0.97439, test_loss = 0.03670, test_auc = 0.94938, time = 0.04655\n",
      "Epoch: 0130 | train_loss = 0.04907, train_auc = 0.97516, test_loss = 0.03208, test_auc = 0.95984, time = 0.04676\n",
      "Epoch: 0140 | train_loss = 0.04632, train_auc = 0.97673, test_loss = 0.03301, test_auc = 0.95572, time = 0.04788\n",
      "Epoch: 0150 | train_loss = 0.04502, train_auc = 0.97860, test_loss = 0.03579, test_auc = 0.95629, time = 0.04735\n",
      "Epoch: 0160 | train_loss = 0.04301, train_auc = 0.98055, test_loss = 0.03404, test_auc = 0.95555, time = 0.04721\n",
      "Epoch: 0170 | train_loss = 0.03891, train_auc = 0.98393, test_loss = 0.03432, test_auc = 0.96231, time = 0.04643\n",
      "Epoch: 0180 | train_loss = 0.04085, train_auc = 0.98371, test_loss = 0.03304, test_auc = 0.95877, time = 0.04668\n",
      "Epoch: 0190 | train_loss = 0.03767, train_auc = 0.98595, test_loss = 0.03223, test_auc = 0.95704, time = 0.04715\n",
      "Epoch: 0200 | train_loss = 0.03641, train_auc = 0.98620, test_loss = 0.02970, test_auc = 0.96546, time = 0.04732\n",
      "Epoch: 0210 | train_loss = 0.03789, train_auc = 0.98562, test_loss = 0.03274, test_auc = 0.95826, time = 0.04643\n",
      "Epoch: 0220 | train_loss = 0.03602, train_auc = 0.98725, test_loss = 0.03384, test_auc = 0.96433, time = 0.04577\n",
      "Epoch: 0230 | train_loss = 0.03341, train_auc = 0.98867, test_loss = 0.03697, test_auc = 0.94087, time = 0.04629\n",
      "Epoch: 0240 | train_loss = 0.03309, train_auc = 0.98860, test_loss = 0.03103, test_auc = 0.96459, time = 0.04573\n",
      "Epoch: 0250 | train_loss = 0.03359, train_auc = 0.98892, test_loss = 0.03079, test_auc = 0.96673, time = 0.04598\n",
      "Epoch: 0260 | train_loss = 0.03311, train_auc = 0.98972, test_loss = 0.02992, test_auc = 0.96811, time = 0.04576\n",
      "Epoch: 0270 | train_loss = 0.03234, train_auc = 0.99034, test_loss = 0.03398, test_auc = 0.96620, time = 0.04576\n",
      "Epoch: 0280 | train_loss = 0.03003, train_auc = 0.99123, test_loss = 0.03155, test_auc = 0.96443, time = 0.04799\n",
      "Epoch: 0290 | train_loss = 0.03051, train_auc = 0.99088, test_loss = 0.02998, test_auc = 0.96981, time = 0.04534\n",
      "Epoch: 0300 | train_loss = 0.03155, train_auc = 0.99153, test_loss = 0.02872, test_auc = 0.97179, time = 0.04573\n",
      "Epoch: 0310 | train_loss = 0.02947, train_auc = 0.99171, test_loss = 0.02899, test_auc = 0.97121, time = 0.04837\n",
      "Epoch: 0320 | train_loss = 0.03004, train_auc = 0.99120, test_loss = 0.03097, test_auc = 0.96920, time = 0.04586\n",
      "Epoch: 0330 | train_loss = 0.03084, train_auc = 0.99117, test_loss = 0.03161, test_auc = 0.96613, time = 0.04667\n",
      "Epoch: 0340 | train_loss = 0.03085, train_auc = 0.99230, test_loss = 0.03134, test_auc = 0.97135, time = 0.05437\n",
      "Epoch: 0350 | train_loss = 0.02749, train_auc = 0.99261, test_loss = 0.02930, test_auc = 0.97356, time = 0.04595\n",
      "Epoch: 0360 | train_loss = 0.02839, train_auc = 0.99269, test_loss = 0.03077, test_auc = 0.96647, time = 0.04560\n",
      "Epoch: 0370 | train_loss = 0.02717, train_auc = 0.99325, test_loss = 0.02845, test_auc = 0.97194, time = 0.04626\n",
      "Epoch: 0380 | train_loss = 0.02847, train_auc = 0.99271, test_loss = 0.02862, test_auc = 0.96848, time = 0.04687\n",
      "Epoch: 0390 | train_loss = 0.02614, train_auc = 0.99333, test_loss = 0.03274, test_auc = 0.96223, time = 0.04888\n",
      "Epoch: 0400 | train_loss = 0.02788, train_auc = 0.99290, test_loss = 0.02690, test_auc = 0.97478, time = 0.04532\n",
      "Epoch: 0410 | train_loss = 0.02916, train_auc = 0.99341, test_loss = 0.03104, test_auc = 0.97239, time = 0.04564\n",
      "Epoch: 0420 | train_loss = 0.02484, train_auc = 0.99439, test_loss = 0.03267, test_auc = 0.97030, time = 0.04622\n",
      "Epoch: 0430 | train_loss = 0.02436, train_auc = 0.99427, test_loss = 0.03211, test_auc = 0.96937, time = 0.04592\n",
      "Epoch: 0440 | train_loss = 0.02593, train_auc = 0.99394, test_loss = 0.02866, test_auc = 0.97431, time = 0.05430\n",
      "Epoch: 0450 | train_loss = 0.02352, train_auc = 0.99457, test_loss = 0.03111, test_auc = 0.96497, time = 0.04636\n",
      "Epoch: 0460 | train_loss = 0.02614, train_auc = 0.99367, test_loss = 0.03179, test_auc = 0.97253, time = 0.04648\n",
      "Epoch: 0470 | train_loss = 0.02659, train_auc = 0.99416, test_loss = 0.02818, test_auc = 0.97388, time = 0.04623\n",
      "Epoch: 0480 | train_loss = 0.02325, train_auc = 0.99509, test_loss = 0.02825, test_auc = 0.97458, time = 0.04598\n",
      "Epoch: 0490 | train_loss = 0.02495, train_auc = 0.99476, test_loss = 0.02898, test_auc = 0.97362, time = 0.04613\n",
      "Epoch: 0500 | train_loss = 0.02447, train_auc = 0.99514, test_loss = 0.02977, test_auc = 0.97029, time = 0.04590\n",
      "times: 2, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15731, train_auc = 0.32117, test_loss = 0.08610, test_auc = 0.31291, time = 0.78590\n",
      "Epoch: 0010 | train_loss = 0.08326, train_auc = 0.90898, test_loss = 0.04812, test_auc = 0.83637, time = 0.05104\n",
      "Epoch: 0020 | train_loss = 0.07469, train_auc = 0.92745, test_loss = 0.04330, test_auc = 0.89138, time = 0.04863\n",
      "Epoch: 0030 | train_loss = 0.06702, train_auc = 0.94295, test_loss = 0.03850, test_auc = 0.91984, time = 0.04849\n",
      "Epoch: 0040 | train_loss = 0.06751, train_auc = 0.94686, test_loss = 0.03827, test_auc = 0.92376, time = 0.04728\n",
      "Epoch: 0050 | train_loss = 0.06133, train_auc = 0.95456, test_loss = 0.03631, test_auc = 0.93630, time = 0.05422\n",
      "Epoch: 0060 | train_loss = 0.05897, train_auc = 0.95869, test_loss = 0.03322, test_auc = 0.94436, time = 0.04644\n",
      "Epoch: 0070 | train_loss = 0.06110, train_auc = 0.95930, test_loss = 0.03596, test_auc = 0.94135, time = 0.04540\n",
      "Epoch: 0080 | train_loss = 0.05940, train_auc = 0.96242, test_loss = 0.03455, test_auc = 0.94143, time = 0.04537\n",
      "Epoch: 0090 | train_loss = 0.05384, train_auc = 0.96690, test_loss = 0.03077, test_auc = 0.95563, time = 0.04495\n",
      "Epoch: 0100 | train_loss = 0.05194, train_auc = 0.97063, test_loss = 0.03240, test_auc = 0.95500, time = 0.04463\n",
      "Epoch: 0110 | train_loss = 0.04894, train_auc = 0.97425, test_loss = 0.03230, test_auc = 0.95609, time = 0.04465\n",
      "Epoch: 0120 | train_loss = 0.04553, train_auc = 0.97755, test_loss = 0.03010, test_auc = 0.96199, time = 0.04698\n",
      "Epoch: 0130 | train_loss = 0.04657, train_auc = 0.97771, test_loss = 0.03279, test_auc = 0.95201, time = 0.04604\n",
      "Epoch: 0140 | train_loss = 0.04458, train_auc = 0.97918, test_loss = 0.03243, test_auc = 0.96137, time = 0.04669\n",
      "Epoch: 0150 | train_loss = 0.04518, train_auc = 0.97873, test_loss = 0.03394, test_auc = 0.95988, time = 0.04696\n",
      "Epoch: 0160 | train_loss = 0.04310, train_auc = 0.98236, test_loss = 0.03186, test_auc = 0.96042, time = 0.04542\n",
      "Epoch: 0170 | train_loss = 0.04090, train_auc = 0.98365, test_loss = 0.03465, test_auc = 0.95986, time = 0.04492\n",
      "Epoch: 0180 | train_loss = 0.04358, train_auc = 0.98238, test_loss = 0.03261, test_auc = 0.96365, time = 0.04522\n",
      "Epoch: 0190 | train_loss = 0.03779, train_auc = 0.98487, test_loss = 0.03093, test_auc = 0.96646, time = 0.04527\n",
      "Epoch: 0200 | train_loss = 0.03612, train_auc = 0.98648, test_loss = 0.02887, test_auc = 0.96875, time = 0.04508\n",
      "Epoch: 0210 | train_loss = 0.03716, train_auc = 0.98666, test_loss = 0.02980, test_auc = 0.96782, time = 0.04429\n",
      "Epoch: 0220 | train_loss = 0.03452, train_auc = 0.98739, test_loss = 0.02668, test_auc = 0.97317, time = 0.04475\n",
      "Epoch: 0230 | train_loss = 0.03482, train_auc = 0.98819, test_loss = 0.02999, test_auc = 0.96850, time = 0.04472\n",
      "Epoch: 0240 | train_loss = 0.03422, train_auc = 0.98850, test_loss = 0.02842, test_auc = 0.96978, time = 0.04448\n",
      "Epoch: 0250 | train_loss = 0.03372, train_auc = 0.98927, test_loss = 0.03161, test_auc = 0.96707, time = 0.04495\n",
      "Epoch: 0260 | train_loss = 0.03433, train_auc = 0.99011, test_loss = 0.03322, test_auc = 0.96505, time = 0.04655\n",
      "Epoch: 0270 | train_loss = 0.03036, train_auc = 0.99083, test_loss = 0.02946, test_auc = 0.96972, time = 0.04500\n",
      "Epoch: 0280 | train_loss = 0.03060, train_auc = 0.99100, test_loss = 0.02796, test_auc = 0.97216, time = 0.04501\n",
      "Epoch: 0290 | train_loss = 0.03012, train_auc = 0.99111, test_loss = 0.02816, test_auc = 0.97315, time = 0.04648\n",
      "Epoch: 0300 | train_loss = 0.03006, train_auc = 0.99068, test_loss = 0.02884, test_auc = 0.97395, time = 0.04579\n",
      "Epoch: 0310 | train_loss = 0.03052, train_auc = 0.99117, test_loss = 0.03360, test_auc = 0.96870, time = 0.04656\n",
      "Epoch: 0320 | train_loss = 0.03363, train_auc = 0.99063, test_loss = 0.03205, test_auc = 0.97194, time = 0.04495\n",
      "Epoch: 0330 | train_loss = 0.02975, train_auc = 0.99177, test_loss = 0.03088, test_auc = 0.97126, time = 0.04662\n",
      "Epoch: 0340 | train_loss = 0.02748, train_auc = 0.99341, test_loss = 0.03227, test_auc = 0.97067, time = 0.04669\n",
      "Epoch: 0350 | train_loss = 0.02618, train_auc = 0.99372, test_loss = 0.03100, test_auc = 0.97160, time = 0.04636\n",
      "Epoch: 0360 | train_loss = 0.02616, train_auc = 0.99485, test_loss = 0.03065, test_auc = 0.97272, time = 0.04561\n",
      "Epoch: 0370 | train_loss = 0.02739, train_auc = 0.99389, test_loss = 0.03027, test_auc = 0.97045, time = 0.04547\n",
      "Epoch: 0380 | train_loss = 0.03008, train_auc = 0.99186, test_loss = 0.02924, test_auc = 0.96681, time = 0.04607\n",
      "Epoch: 0390 | train_loss = 0.02737, train_auc = 0.99349, test_loss = 0.02933, test_auc = 0.97367, time = 0.04563\n",
      "Epoch: 0400 | train_loss = 0.02506, train_auc = 0.99474, test_loss = 0.02819, test_auc = 0.97419, time = 0.04651\n",
      "Epoch: 0410 | train_loss = 0.02586, train_auc = 0.99446, test_loss = 0.02730, test_auc = 0.97501, time = 0.04554\n",
      "Epoch: 0420 | train_loss = 0.03027, train_auc = 0.99348, test_loss = 0.02774, test_auc = 0.97575, time = 0.04518\n",
      "Epoch: 0430 | train_loss = 0.02488, train_auc = 0.99411, test_loss = 0.02587, test_auc = 0.97891, time = 0.04475\n",
      "Epoch: 0440 | train_loss = 0.02390, train_auc = 0.99504, test_loss = 0.02797, test_auc = 0.97594, time = 0.04524\n",
      "Epoch: 0450 | train_loss = 0.02809, train_auc = 0.99417, test_loss = 0.03498, test_auc = 0.96437, time = 0.04481\n",
      "Epoch: 0460 | train_loss = 0.02385, train_auc = 0.99485, test_loss = 0.02821, test_auc = 0.97560, time = 0.04539\n",
      "Epoch: 0470 | train_loss = 0.02525, train_auc = 0.99446, test_loss = 0.03261, test_auc = 0.97264, time = 0.04581\n",
      "Epoch: 0480 | train_loss = 0.02332, train_auc = 0.99556, test_loss = 0.02796, test_auc = 0.97664, time = 0.04746\n",
      "Epoch: 0490 | train_loss = 0.02292, train_auc = 0.99492, test_loss = 0.02811, test_auc = 0.97353, time = 0.04655\n",
      "Epoch: 0500 | train_loss = 0.02234, train_auc = 0.99517, test_loss = 0.02704, test_auc = 0.97764, time = 0.04588\n",
      "times: 2, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13767, train_auc = 0.52887, test_loss = 0.07264, test_auc = 0.55630, time = 0.80195\n",
      "Epoch: 0010 | train_loss = 0.08221, train_auc = 0.89680, test_loss = 0.05335, test_auc = 0.82699, time = 0.04958\n",
      "Epoch: 0020 | train_loss = 0.07539, train_auc = 0.91817, test_loss = 0.03989, test_auc = 0.91336, time = 0.05001\n",
      "Epoch: 0030 | train_loss = 0.06760, train_auc = 0.93973, test_loss = 0.03770, test_auc = 0.92865, time = 0.04952\n",
      "Epoch: 0040 | train_loss = 0.06299, train_auc = 0.94887, test_loss = 0.03953, test_auc = 0.91975, time = 0.04995\n",
      "Epoch: 0050 | train_loss = 0.06201, train_auc = 0.95067, test_loss = 0.03488, test_auc = 0.94044, time = 0.04943\n",
      "Epoch: 0060 | train_loss = 0.06106, train_auc = 0.95702, test_loss = 0.03487, test_auc = 0.94095, time = 0.04778\n",
      "Epoch: 0070 | train_loss = 0.05940, train_auc = 0.95797, test_loss = 0.03599, test_auc = 0.94389, time = 0.04817\n",
      "Epoch: 0080 | train_loss = 0.06324, train_auc = 0.95395, test_loss = 0.03410, test_auc = 0.94629, time = 0.04839\n",
      "Epoch: 0090 | train_loss = 0.05616, train_auc = 0.96208, test_loss = 0.03195, test_auc = 0.95281, time = 0.04715\n",
      "Epoch: 0100 | train_loss = 0.05223, train_auc = 0.96744, test_loss = 0.03145, test_auc = 0.95358, time = 0.04773\n",
      "Epoch: 0110 | train_loss = 0.05051, train_auc = 0.97010, test_loss = 0.03233, test_auc = 0.95098, time = 0.04798\n",
      "Epoch: 0120 | train_loss = 0.04776, train_auc = 0.97377, test_loss = 0.03190, test_auc = 0.95606, time = 0.04682\n",
      "Epoch: 0130 | train_loss = 0.04935, train_auc = 0.97221, test_loss = 0.03272, test_auc = 0.95732, time = 0.04679\n",
      "Epoch: 0140 | train_loss = 0.04678, train_auc = 0.97541, test_loss = 0.03328, test_auc = 0.95885, time = 0.04676\n",
      "Epoch: 0150 | train_loss = 0.04468, train_auc = 0.97814, test_loss = 0.03508, test_auc = 0.95503, time = 0.04722\n",
      "Epoch: 0160 | train_loss = 0.04340, train_auc = 0.97909, test_loss = 0.03120, test_auc = 0.96200, time = 0.04683\n",
      "Epoch: 0170 | train_loss = 0.04231, train_auc = 0.98082, test_loss = 0.03049, test_auc = 0.96133, time = 0.04686\n",
      "Epoch: 0180 | train_loss = 0.04238, train_auc = 0.98193, test_loss = 0.03412, test_auc = 0.95245, time = 0.04678\n",
      "Epoch: 0190 | train_loss = 0.04030, train_auc = 0.98368, test_loss = 0.03438, test_auc = 0.95920, time = 0.04636\n",
      "Epoch: 0200 | train_loss = 0.03857, train_auc = 0.98490, test_loss = 0.03211, test_auc = 0.96428, time = 0.04683\n",
      "Epoch: 0210 | train_loss = 0.03640, train_auc = 0.98491, test_loss = 0.03120, test_auc = 0.96407, time = 0.04614\n",
      "Epoch: 0220 | train_loss = 0.03950, train_auc = 0.98470, test_loss = 0.03167, test_auc = 0.96586, time = 0.04601\n",
      "Epoch: 0230 | train_loss = 0.03465, train_auc = 0.98855, test_loss = 0.03101, test_auc = 0.96894, time = 0.04748\n",
      "Epoch: 0240 | train_loss = 0.03481, train_auc = 0.98765, test_loss = 0.03033, test_auc = 0.96749, time = 0.04866\n",
      "Epoch: 0250 | train_loss = 0.03159, train_auc = 0.98948, test_loss = 0.03344, test_auc = 0.96113, time = 0.04737\n",
      "Epoch: 0260 | train_loss = 0.03358, train_auc = 0.99011, test_loss = 0.03331, test_auc = 0.96607, time = 0.04671\n",
      "Epoch: 0270 | train_loss = 0.03274, train_auc = 0.99058, test_loss = 0.03402, test_auc = 0.96320, time = 0.05303\n",
      "Epoch: 0280 | train_loss = 0.03076, train_auc = 0.99129, test_loss = 0.03301, test_auc = 0.96523, time = 0.04739\n",
      "Epoch: 0290 | train_loss = 0.03187, train_auc = 0.99112, test_loss = 0.02928, test_auc = 0.97146, time = 0.04929\n",
      "Epoch: 0300 | train_loss = 0.03075, train_auc = 0.99173, test_loss = 0.02895, test_auc = 0.97043, time = 0.04957\n",
      "Epoch: 0310 | train_loss = 0.02808, train_auc = 0.99329, test_loss = 0.02942, test_auc = 0.97176, time = 0.04950\n",
      "Epoch: 0320 | train_loss = 0.03190, train_auc = 0.99220, test_loss = 0.03080, test_auc = 0.96616, time = 0.04751\n",
      "Epoch: 0330 | train_loss = 0.02848, train_auc = 0.99358, test_loss = 0.03107, test_auc = 0.97055, time = 0.04775\n",
      "Epoch: 0340 | train_loss = 0.02611, train_auc = 0.99389, test_loss = 0.02974, test_auc = 0.97172, time = 0.04646\n",
      "Epoch: 0350 | train_loss = 0.02744, train_auc = 0.99438, test_loss = 0.02836, test_auc = 0.97154, time = 0.04734\n",
      "Epoch: 0360 | train_loss = 0.02469, train_auc = 0.99522, test_loss = 0.03337, test_auc = 0.96621, time = 0.04669\n",
      "Epoch: 0370 | train_loss = 0.02777, train_auc = 0.99451, test_loss = 0.03065, test_auc = 0.96862, time = 0.04918\n",
      "Epoch: 0380 | train_loss = 0.02880, train_auc = 0.99298, test_loss = 0.02940, test_auc = 0.97021, time = 0.04860\n",
      "Epoch: 0390 | train_loss = 0.02739, train_auc = 0.99379, test_loss = 0.03375, test_auc = 0.96319, time = 0.04711\n",
      "Epoch: 0400 | train_loss = 0.02493, train_auc = 0.99552, test_loss = 0.03125, test_auc = 0.96915, time = 0.04665\n",
      "Epoch: 0410 | train_loss = 0.02423, train_auc = 0.99587, test_loss = 0.02891, test_auc = 0.97189, time = 0.04775\n",
      "Epoch: 0420 | train_loss = 0.02369, train_auc = 0.99604, test_loss = 0.02945, test_auc = 0.97336, time = 0.04712\n",
      "Epoch: 0430 | train_loss = 0.02262, train_auc = 0.99593, test_loss = 0.02754, test_auc = 0.97433, time = 0.04802\n",
      "Epoch: 0440 | train_loss = 0.02271, train_auc = 0.99588, test_loss = 0.03136, test_auc = 0.97229, time = 0.04656\n",
      "Epoch: 0450 | train_loss = 0.02361, train_auc = 0.99561, test_loss = 0.03144, test_auc = 0.96209, time = 0.04850\n",
      "Epoch: 0460 | train_loss = 0.02376, train_auc = 0.99596, test_loss = 0.02785, test_auc = 0.97275, time = 0.04738\n",
      "Epoch: 0470 | train_loss = 0.02312, train_auc = 0.99597, test_loss = 0.03106, test_auc = 0.96612, time = 0.04781\n",
      "Epoch: 0480 | train_loss = 0.02179, train_auc = 0.99608, test_loss = 0.03163, test_auc = 0.97240, time = 0.05056\n",
      "Epoch: 0490 | train_loss = 0.02280, train_auc = 0.99607, test_loss = 0.03167, test_auc = 0.97061, time = 0.04728\n",
      "Epoch: 0500 | train_loss = 0.02255, train_auc = 0.99569, test_loss = 0.03069, test_auc = 0.96965, time = 0.04675\n",
      "times: 2, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13313, train_auc = 0.59918, test_loss = 0.09435, test_auc = 0.19957, time = 0.81843\n",
      "Epoch: 0010 | train_loss = 0.08479, train_auc = 0.88914, test_loss = 0.05151, test_auc = 0.84684, time = 0.05149\n",
      "Epoch: 0020 | train_loss = 0.07347, train_auc = 0.92945, test_loss = 0.04084, test_auc = 0.90120, time = 0.05017\n",
      "Epoch: 0030 | train_loss = 0.06657, train_auc = 0.94642, test_loss = 0.03933, test_auc = 0.92248, time = 0.04924\n",
      "Epoch: 0040 | train_loss = 0.06364, train_auc = 0.94692, test_loss = 0.03687, test_auc = 0.92751, time = 0.04795\n",
      "Epoch: 0050 | train_loss = 0.06109, train_auc = 0.95529, test_loss = 0.03780, test_auc = 0.93529, time = 0.04846\n",
      "Epoch: 0060 | train_loss = 0.06057, train_auc = 0.95695, test_loss = 0.03515, test_auc = 0.94729, time = 0.04821\n",
      "Epoch: 0070 | train_loss = 0.05722, train_auc = 0.96141, test_loss = 0.03381, test_auc = 0.95000, time = 0.04757\n",
      "Epoch: 0080 | train_loss = 0.05528, train_auc = 0.96484, test_loss = 0.03317, test_auc = 0.95055, time = 0.04829\n",
      "Epoch: 0090 | train_loss = 0.05457, train_auc = 0.96653, test_loss = 0.03334, test_auc = 0.95254, time = 0.04723\n",
      "Epoch: 0100 | train_loss = 0.05053, train_auc = 0.97147, test_loss = 0.03442, test_auc = 0.95491, time = 0.04868\n",
      "Epoch: 0110 | train_loss = 0.04989, train_auc = 0.97173, test_loss = 0.03342, test_auc = 0.95679, time = 0.04861\n",
      "Epoch: 0120 | train_loss = 0.04953, train_auc = 0.97551, test_loss = 0.03237, test_auc = 0.95640, time = 0.04783\n",
      "Epoch: 0130 | train_loss = 0.04752, train_auc = 0.97668, test_loss = 0.03305, test_auc = 0.95981, time = 0.04710\n",
      "Epoch: 0140 | train_loss = 0.04475, train_auc = 0.98059, test_loss = 0.03159, test_auc = 0.95835, time = 0.04583\n",
      "Epoch: 0150 | train_loss = 0.04567, train_auc = 0.97956, test_loss = 0.03356, test_auc = 0.95608, time = 0.05619\n",
      "Epoch: 0160 | train_loss = 0.04132, train_auc = 0.98284, test_loss = 0.03544, test_auc = 0.95539, time = 0.04569\n",
      "Epoch: 0170 | train_loss = 0.04047, train_auc = 0.98396, test_loss = 0.02900, test_auc = 0.96706, time = 0.04610\n",
      "Epoch: 0180 | train_loss = 0.03865, train_auc = 0.98434, test_loss = 0.03267, test_auc = 0.95768, time = 0.04519\n",
      "Epoch: 0190 | train_loss = 0.03963, train_auc = 0.98397, test_loss = 0.03259, test_auc = 0.96507, time = 0.04598\n",
      "Epoch: 0200 | train_loss = 0.03773, train_auc = 0.98628, test_loss = 0.03320, test_auc = 0.96616, time = 0.04693\n",
      "Epoch: 0210 | train_loss = 0.03687, train_auc = 0.98595, test_loss = 0.03240, test_auc = 0.96136, time = 0.04608\n",
      "Epoch: 0220 | train_loss = 0.03601, train_auc = 0.98787, test_loss = 0.03011, test_auc = 0.96673, time = 0.04611\n",
      "Epoch: 0230 | train_loss = 0.03293, train_auc = 0.98936, test_loss = 0.03179, test_auc = 0.96632, time = 0.04614\n",
      "Epoch: 0240 | train_loss = 0.03683, train_auc = 0.98798, test_loss = 0.03182, test_auc = 0.96922, time = 0.04769\n",
      "Epoch: 0250 | train_loss = 0.03516, train_auc = 0.98895, test_loss = 0.03385, test_auc = 0.96320, time = 0.04604\n",
      "Epoch: 0260 | train_loss = 0.03299, train_auc = 0.99011, test_loss = 0.02928, test_auc = 0.97064, time = 0.04599\n",
      "Epoch: 0270 | train_loss = 0.03079, train_auc = 0.99152, test_loss = 0.02877, test_auc = 0.97025, time = 0.04618\n",
      "Epoch: 0280 | train_loss = 0.03282, train_auc = 0.99177, test_loss = 0.03112, test_auc = 0.96694, time = 0.04586\n",
      "Epoch: 0290 | train_loss = 0.03250, train_auc = 0.99221, test_loss = 0.02975, test_auc = 0.96989, time = 0.04600\n",
      "Epoch: 0300 | train_loss = 0.03111, train_auc = 0.99279, test_loss = 0.02993, test_auc = 0.96901, time = 0.04618\n",
      "Epoch: 0310 | train_loss = 0.02683, train_auc = 0.99424, test_loss = 0.02904, test_auc = 0.97153, time = 0.04641\n",
      "Epoch: 0320 | train_loss = 0.02923, train_auc = 0.99314, test_loss = 0.02968, test_auc = 0.96933, time = 0.04597\n",
      "Epoch: 0330 | train_loss = 0.03030, train_auc = 0.99304, test_loss = 0.03171, test_auc = 0.96870, time = 0.04589\n",
      "Epoch: 0340 | train_loss = 0.02597, train_auc = 0.99360, test_loss = 0.03107, test_auc = 0.96946, time = 0.04592\n",
      "Epoch: 0350 | train_loss = 0.02655, train_auc = 0.99443, test_loss = 0.02823, test_auc = 0.97131, time = 0.04803\n",
      "Epoch: 0360 | train_loss = 0.02645, train_auc = 0.99485, test_loss = 0.02965, test_auc = 0.97226, time = 0.04549\n",
      "Epoch: 0370 | train_loss = 0.02653, train_auc = 0.99492, test_loss = 0.02884, test_auc = 0.97260, time = 0.04769\n",
      "Epoch: 0380 | train_loss = 0.02434, train_auc = 0.99509, test_loss = 0.02901, test_auc = 0.97273, time = 0.04641\n",
      "Epoch: 0390 | train_loss = 0.02421, train_auc = 0.99497, test_loss = 0.02752, test_auc = 0.97340, time = 0.04592\n",
      "Epoch: 0400 | train_loss = 0.02524, train_auc = 0.99592, test_loss = 0.02987, test_auc = 0.97055, time = 0.04572\n",
      "Epoch: 0410 | train_loss = 0.02426, train_auc = 0.99560, test_loss = 0.02958, test_auc = 0.96935, time = 0.04579\n",
      "Epoch: 0420 | train_loss = 0.02397, train_auc = 0.99609, test_loss = 0.02863, test_auc = 0.97351, time = 0.04586\n",
      "Epoch: 0430 | train_loss = 0.02267, train_auc = 0.99612, test_loss = 0.02876, test_auc = 0.96947, time = 0.04596\n",
      "Epoch: 0440 | train_loss = 0.02450, train_auc = 0.99546, test_loss = 0.03037, test_auc = 0.97120, time = 0.04686\n",
      "Epoch: 0450 | train_loss = 0.02155, train_auc = 0.99613, test_loss = 0.03134, test_auc = 0.96896, time = 0.04659\n",
      "Epoch: 0460 | train_loss = 0.02387, train_auc = 0.99609, test_loss = 0.03023, test_auc = 0.96612, time = 0.04599\n",
      "Epoch: 0470 | train_loss = 0.02251, train_auc = 0.99604, test_loss = 0.03140, test_auc = 0.96545, time = 0.04667\n",
      "Epoch: 0480 | train_loss = 0.02340, train_auc = 0.99639, test_loss = 0.02887, test_auc = 0.96935, time = 0.05259\n",
      "Epoch: 0490 | train_loss = 0.02293, train_auc = 0.99554, test_loss = 0.03084, test_auc = 0.96769, time = 0.05109\n",
      "Epoch: 0500 | train_loss = 0.02211, train_auc = 0.99684, test_loss = 0.03063, test_auc = 0.96902, time = 0.04776\n",
      "times: 2, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14522, train_auc = 0.45801, test_loss = 0.06995, test_auc = 0.59042, time = 0.81518\n",
      "Epoch: 0010 | train_loss = 0.08648, train_auc = 0.88682, test_loss = 0.05063, test_auc = 0.83008, time = 0.05054\n",
      "Epoch: 0020 | train_loss = 0.07628, train_auc = 0.92044, test_loss = 0.04287, test_auc = 0.88787, time = 0.05017\n",
      "Epoch: 0030 | train_loss = 0.06774, train_auc = 0.94325, test_loss = 0.04094, test_auc = 0.90676, time = 0.04891\n",
      "Epoch: 0040 | train_loss = 0.06373, train_auc = 0.95182, test_loss = 0.04083, test_auc = 0.91916, time = 0.04883\n",
      "Epoch: 0050 | train_loss = 0.06683, train_auc = 0.94649, test_loss = 0.03615, test_auc = 0.93693, time = 0.04870\n",
      "Epoch: 0060 | train_loss = 0.05858, train_auc = 0.95980, test_loss = 0.03660, test_auc = 0.93685, time = 0.04967\n",
      "Epoch: 0070 | train_loss = 0.05523, train_auc = 0.96380, test_loss = 0.03553, test_auc = 0.94256, time = 0.05504\n",
      "Epoch: 0080 | train_loss = 0.05210, train_auc = 0.96934, test_loss = 0.03430, test_auc = 0.94304, time = 0.04738\n",
      "Epoch: 0090 | train_loss = 0.05269, train_auc = 0.96974, test_loss = 0.03430, test_auc = 0.94572, time = 0.04765\n",
      "Epoch: 0100 | train_loss = 0.05136, train_auc = 0.97270, test_loss = 0.03451, test_auc = 0.95018, time = 0.04836\n",
      "Epoch: 0110 | train_loss = 0.05063, train_auc = 0.97277, test_loss = 0.03391, test_auc = 0.94804, time = 0.04941\n",
      "Epoch: 0120 | train_loss = 0.04869, train_auc = 0.97455, test_loss = 0.03399, test_auc = 0.95019, time = 0.06062\n",
      "Epoch: 0130 | train_loss = 0.04471, train_auc = 0.97933, test_loss = 0.03211, test_auc = 0.95471, time = 0.04804\n",
      "Epoch: 0140 | train_loss = 0.04638, train_auc = 0.97770, test_loss = 0.03438, test_auc = 0.95343, time = 0.05264\n",
      "Epoch: 0150 | train_loss = 0.04374, train_auc = 0.97920, test_loss = 0.03912, test_auc = 0.93779, time = 0.04875\n",
      "Epoch: 0160 | train_loss = 0.03961, train_auc = 0.98178, test_loss = 0.03208, test_auc = 0.95999, time = 0.04889\n",
      "Epoch: 0170 | train_loss = 0.03963, train_auc = 0.98341, test_loss = 0.03289, test_auc = 0.95310, time = 0.04736\n",
      "Epoch: 0180 | train_loss = 0.03957, train_auc = 0.98353, test_loss = 0.03423, test_auc = 0.95785, time = 0.04843\n",
      "Epoch: 0190 | train_loss = 0.03775, train_auc = 0.98453, test_loss = 0.03092, test_auc = 0.96265, time = 0.04808\n",
      "Epoch: 0200 | train_loss = 0.03750, train_auc = 0.98430, test_loss = 0.03141, test_auc = 0.95923, time = 0.04706\n",
      "Epoch: 0210 | train_loss = 0.03700, train_auc = 0.98631, test_loss = 0.03395, test_auc = 0.95982, time = 0.04903\n",
      "Epoch: 0220 | train_loss = 0.03805, train_auc = 0.98610, test_loss = 0.03007, test_auc = 0.96435, time = 0.04692\n",
      "Epoch: 0230 | train_loss = 0.03484, train_auc = 0.98764, test_loss = 0.03153, test_auc = 0.95914, time = 0.04652\n",
      "Epoch: 0240 | train_loss = 0.03483, train_auc = 0.98775, test_loss = 0.03137, test_auc = 0.95937, time = 0.04651\n",
      "Epoch: 0250 | train_loss = 0.03447, train_auc = 0.98835, test_loss = 0.03399, test_auc = 0.95730, time = 0.04840\n",
      "Epoch: 0260 | train_loss = 0.03257, train_auc = 0.98881, test_loss = 0.03032, test_auc = 0.96600, time = 0.04674\n",
      "Epoch: 0270 | train_loss = 0.03361, train_auc = 0.98947, test_loss = 0.03431, test_auc = 0.95860, time = 0.04671\n",
      "Epoch: 0280 | train_loss = 0.03395, train_auc = 0.98943, test_loss = 0.03250, test_auc = 0.96267, time = 0.04976\n",
      "Epoch: 0290 | train_loss = 0.03388, train_auc = 0.98915, test_loss = 0.03214, test_auc = 0.96404, time = 0.04717\n",
      "Epoch: 0300 | train_loss = 0.03123, train_auc = 0.99068, test_loss = 0.03095, test_auc = 0.96331, time = 0.04634\n",
      "Epoch: 0310 | train_loss = 0.02992, train_auc = 0.99103, test_loss = 0.03290, test_auc = 0.96657, time = 0.04847\n",
      "Epoch: 0320 | train_loss = 0.02808, train_auc = 0.99205, test_loss = 0.03297, test_auc = 0.96931, time = 0.04660\n",
      "Epoch: 0330 | train_loss = 0.02887, train_auc = 0.99159, test_loss = 0.03347, test_auc = 0.96571, time = 0.04732\n",
      "Epoch: 0340 | train_loss = 0.02971, train_auc = 0.99140, test_loss = 0.03047, test_auc = 0.97016, time = 0.04640\n",
      "Epoch: 0350 | train_loss = 0.03012, train_auc = 0.99132, test_loss = 0.03057, test_auc = 0.96684, time = 0.04777\n",
      "Epoch: 0360 | train_loss = 0.02922, train_auc = 0.99299, test_loss = 0.02962, test_auc = 0.96878, time = 0.04674\n",
      "Epoch: 0370 | train_loss = 0.02671, train_auc = 0.99270, test_loss = 0.03098, test_auc = 0.96840, time = 0.04727\n",
      "Epoch: 0380 | train_loss = 0.02839, train_auc = 0.99235, test_loss = 0.03123, test_auc = 0.96569, time = 0.04708\n",
      "Epoch: 0390 | train_loss = 0.02665, train_auc = 0.99280, test_loss = 0.03225, test_auc = 0.96572, time = 0.04663\n",
      "Epoch: 0400 | train_loss = 0.02645, train_auc = 0.99380, test_loss = 0.03176, test_auc = 0.96816, time = 0.04679\n",
      "Epoch: 0410 | train_loss = 0.02517, train_auc = 0.99352, test_loss = 0.03305, test_auc = 0.96885, time = 0.05192\n",
      "Epoch: 0420 | train_loss = 0.02399, train_auc = 0.99418, test_loss = 0.03344, test_auc = 0.96293, time = 0.04749\n",
      "Epoch: 0430 | train_loss = 0.02520, train_auc = 0.99425, test_loss = 0.03262, test_auc = 0.96451, time = 0.04775\n",
      "Epoch: 0440 | train_loss = 0.02434, train_auc = 0.99486, test_loss = 0.02925, test_auc = 0.97123, time = 0.04803\n",
      "Epoch: 0450 | train_loss = 0.02334, train_auc = 0.99508, test_loss = 0.03306, test_auc = 0.96985, time = 0.04707\n",
      "Epoch: 0460 | train_loss = 0.02478, train_auc = 0.99420, test_loss = 0.02954, test_auc = 0.96578, time = 0.04819\n",
      "Epoch: 0470 | train_loss = 0.02422, train_auc = 0.99530, test_loss = 0.02987, test_auc = 0.97339, time = 0.04817\n",
      "Epoch: 0480 | train_loss = 0.02544, train_auc = 0.99448, test_loss = 0.02904, test_auc = 0.97348, time = 0.04765\n",
      "Epoch: 0490 | train_loss = 0.02258, train_auc = 0.99480, test_loss = 0.02918, test_auc = 0.97098, time = 0.05057\n",
      "Epoch: 0500 | train_loss = 0.02119, train_auc = 0.99573, test_loss = 0.03110, test_auc = 0.97413, time = 0.05266\n",
      "times: 3, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13662, train_auc = 0.54196, test_loss = 0.07408, test_auc = 0.53195, time = 0.80322\n",
      "Epoch: 0010 | train_loss = 0.08140, train_auc = 0.91378, test_loss = 0.04713, test_auc = 0.89411, time = 0.05321\n",
      "Epoch: 0020 | train_loss = 0.07727, train_auc = 0.93106, test_loss = 0.03889, test_auc = 0.91671, time = 0.04894\n",
      "Epoch: 0030 | train_loss = 0.07196, train_auc = 0.93345, test_loss = 0.04137, test_auc = 0.90123, time = 0.04851\n",
      "Epoch: 0040 | train_loss = 0.06731, train_auc = 0.94271, test_loss = 0.03651, test_auc = 0.92964, time = 0.04912\n",
      "Epoch: 0050 | train_loss = 0.06321, train_auc = 0.95346, test_loss = 0.03567, test_auc = 0.93926, time = 0.04841\n",
      "Epoch: 0060 | train_loss = 0.06229, train_auc = 0.95582, test_loss = 0.03370, test_auc = 0.94552, time = 0.04847\n",
      "Epoch: 0070 | train_loss = 0.05801, train_auc = 0.96118, test_loss = 0.03780, test_auc = 0.93349, time = 0.04790\n",
      "Epoch: 0080 | train_loss = 0.05414, train_auc = 0.96625, test_loss = 0.03546, test_auc = 0.93984, time = 0.04815\n",
      "Epoch: 0090 | train_loss = 0.05394, train_auc = 0.96892, test_loss = 0.03508, test_auc = 0.94544, time = 0.04759\n",
      "Epoch: 0100 | train_loss = 0.05294, train_auc = 0.96976, test_loss = 0.03248, test_auc = 0.95298, time = 0.04787\n",
      "Epoch: 0110 | train_loss = 0.04843, train_auc = 0.97489, test_loss = 0.03249, test_auc = 0.95324, time = 0.04841\n",
      "Epoch: 0120 | train_loss = 0.04938, train_auc = 0.97489, test_loss = 0.03203, test_auc = 0.95373, time = 0.04718\n",
      "Epoch: 0130 | train_loss = 0.04509, train_auc = 0.97867, test_loss = 0.03202, test_auc = 0.95615, time = 0.04755\n",
      "Epoch: 0140 | train_loss = 0.04719, train_auc = 0.97873, test_loss = 0.03349, test_auc = 0.95159, time = 0.04881\n",
      "Epoch: 0150 | train_loss = 0.04365, train_auc = 0.98082, test_loss = 0.03309, test_auc = 0.94805, time = 0.04820\n",
      "Epoch: 0160 | train_loss = 0.04064, train_auc = 0.98382, test_loss = 0.03196, test_auc = 0.95799, time = 0.06854\n",
      "Epoch: 0170 | train_loss = 0.04079, train_auc = 0.98335, test_loss = 0.03214, test_auc = 0.95701, time = 0.04708\n",
      "Epoch: 0180 | train_loss = 0.03948, train_auc = 0.98321, test_loss = 0.03133, test_auc = 0.95862, time = 0.04738\n",
      "Epoch: 0190 | train_loss = 0.03825, train_auc = 0.98477, test_loss = 0.03179, test_auc = 0.95684, time = 0.04698\n",
      "Epoch: 0200 | train_loss = 0.03643, train_auc = 0.98749, test_loss = 0.03114, test_auc = 0.95854, time = 0.04803\n",
      "Epoch: 0210 | train_loss = 0.03656, train_auc = 0.98840, test_loss = 0.03041, test_auc = 0.96506, time = 0.04748\n",
      "Epoch: 0220 | train_loss = 0.03729, train_auc = 0.98692, test_loss = 0.03107, test_auc = 0.96186, time = 0.04756\n",
      "Epoch: 0230 | train_loss = 0.03311, train_auc = 0.98950, test_loss = 0.02898, test_auc = 0.96496, time = 0.04716\n",
      "Epoch: 0240 | train_loss = 0.03728, train_auc = 0.98810, test_loss = 0.03106, test_auc = 0.96021, time = 0.05082\n",
      "Epoch: 0250 | train_loss = 0.03321, train_auc = 0.98926, test_loss = 0.03155, test_auc = 0.96058, time = 0.04771\n",
      "Epoch: 0260 | train_loss = 0.03521, train_auc = 0.98967, test_loss = 0.02997, test_auc = 0.96555, time = 0.04799\n",
      "Epoch: 0270 | train_loss = 0.03089, train_auc = 0.99194, test_loss = 0.03443, test_auc = 0.96225, time = 0.04817\n",
      "Epoch: 0280 | train_loss = 0.03269, train_auc = 0.99174, test_loss = 0.03053, test_auc = 0.96356, time = 0.04834\n",
      "Epoch: 0290 | train_loss = 0.03432, train_auc = 0.99112, test_loss = 0.03289, test_auc = 0.96560, time = 0.04772\n",
      "Epoch: 0300 | train_loss = 0.03232, train_auc = 0.99182, test_loss = 0.03379, test_auc = 0.96569, time = 0.04850\n",
      "Epoch: 0310 | train_loss = 0.03091, train_auc = 0.99165, test_loss = 0.03286, test_auc = 0.96359, time = 0.04831\n",
      "Epoch: 0320 | train_loss = 0.02664, train_auc = 0.99342, test_loss = 0.03487, test_auc = 0.95214, time = 0.04791\n",
      "Epoch: 0330 | train_loss = 0.02848, train_auc = 0.99298, test_loss = 0.03142, test_auc = 0.96767, time = 0.04869\n",
      "Epoch: 0340 | train_loss = 0.02823, train_auc = 0.99280, test_loss = 0.03312, test_auc = 0.96057, time = 0.04726\n",
      "Epoch: 0350 | train_loss = 0.02858, train_auc = 0.99294, test_loss = 0.03057, test_auc = 0.96749, time = 0.04751\n",
      "Epoch: 0360 | train_loss = 0.02599, train_auc = 0.99404, test_loss = 0.03123, test_auc = 0.96443, time = 0.04786\n",
      "Epoch: 0370 | train_loss = 0.02716, train_auc = 0.99372, test_loss = 0.02994, test_auc = 0.96753, time = 0.04791\n",
      "Epoch: 0380 | train_loss = 0.02870, train_auc = 0.99319, test_loss = 0.03047, test_auc = 0.96589, time = 0.04735\n",
      "Epoch: 0390 | train_loss = 0.02685, train_auc = 0.99357, test_loss = 0.03266, test_auc = 0.96659, time = 0.04801\n",
      "Epoch: 0400 | train_loss = 0.02795, train_auc = 0.99320, test_loss = 0.02810, test_auc = 0.96778, time = 0.04779\n",
      "Epoch: 0410 | train_loss = 0.02489, train_auc = 0.99461, test_loss = 0.03116, test_auc = 0.96356, time = 0.05031\n",
      "Epoch: 0420 | train_loss = 0.02444, train_auc = 0.99440, test_loss = 0.03074, test_auc = 0.96310, time = 0.05993\n",
      "Epoch: 0430 | train_loss = 0.02546, train_auc = 0.99385, test_loss = 0.03014, test_auc = 0.96654, time = 0.04795\n",
      "Epoch: 0440 | train_loss = 0.02517, train_auc = 0.99495, test_loss = 0.03262, test_auc = 0.96641, time = 0.04798\n",
      "Epoch: 0450 | train_loss = 0.02665, train_auc = 0.99462, test_loss = 0.02883, test_auc = 0.96953, time = 0.04748\n",
      "Epoch: 0460 | train_loss = 0.02123, train_auc = 0.99538, test_loss = 0.03130, test_auc = 0.96946, time = 0.04720\n",
      "Epoch: 0470 | train_loss = 0.02436, train_auc = 0.99468, test_loss = 0.02917, test_auc = 0.96834, time = 0.04735\n",
      "Epoch: 0480 | train_loss = 0.02442, train_auc = 0.99475, test_loss = 0.03033, test_auc = 0.96856, time = 0.04906\n",
      "Epoch: 0490 | train_loss = 0.02592, train_auc = 0.99398, test_loss = 0.03358, test_auc = 0.96404, time = 0.04994\n",
      "Epoch: 0500 | train_loss = 0.02532, train_auc = 0.99470, test_loss = 0.02830, test_auc = 0.97129, time = 0.04726\n",
      "times: 3, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13937, train_auc = 0.49385, test_loss = 0.08969, test_auc = 0.29266, time = 0.79116\n",
      "Epoch: 0010 | train_loss = 0.08046, train_auc = 0.91784, test_loss = 0.05581, test_auc = 0.87714, time = 0.04946\n",
      "Epoch: 0020 | train_loss = 0.07106, train_auc = 0.93605, test_loss = 0.04343, test_auc = 0.86517, time = 0.04882\n",
      "Epoch: 0030 | train_loss = 0.06439, train_auc = 0.94916, test_loss = 0.04069, test_auc = 0.88488, time = 0.04916\n",
      "Epoch: 0040 | train_loss = 0.06279, train_auc = 0.95202, test_loss = 0.03878, test_auc = 0.92359, time = 0.04906\n",
      "Epoch: 0050 | train_loss = 0.05952, train_auc = 0.95762, test_loss = 0.03709, test_auc = 0.92914, time = 0.04855\n",
      "Epoch: 0060 | train_loss = 0.05651, train_auc = 0.96370, test_loss = 0.03407, test_auc = 0.94423, time = 0.04754\n",
      "Epoch: 0070 | train_loss = 0.05424, train_auc = 0.96709, test_loss = 0.03459, test_auc = 0.94687, time = 0.04918\n",
      "Epoch: 0080 | train_loss = 0.05250, train_auc = 0.96970, test_loss = 0.03278, test_auc = 0.95123, time = 0.04897\n",
      "Epoch: 0090 | train_loss = 0.05346, train_auc = 0.96993, test_loss = 0.03374, test_auc = 0.95326, time = 0.04836\n",
      "Epoch: 0100 | train_loss = 0.04764, train_auc = 0.97557, test_loss = 0.03748, test_auc = 0.94489, time = 0.04975\n",
      "Epoch: 0110 | train_loss = 0.04774, train_auc = 0.97530, test_loss = 0.03264, test_auc = 0.95464, time = 0.04818\n",
      "Epoch: 0120 | train_loss = 0.04576, train_auc = 0.97913, test_loss = 0.03649, test_auc = 0.94818, time = 0.04846\n",
      "Epoch: 0130 | train_loss = 0.04493, train_auc = 0.97958, test_loss = 0.03387, test_auc = 0.95533, time = 0.04855\n",
      "Epoch: 0140 | train_loss = 0.04283, train_auc = 0.98068, test_loss = 0.03677, test_auc = 0.95130, time = 0.04780\n",
      "Epoch: 0150 | train_loss = 0.04258, train_auc = 0.98204, test_loss = 0.03575, test_auc = 0.95280, time = 0.04856\n",
      "Epoch: 0160 | train_loss = 0.03911, train_auc = 0.98363, test_loss = 0.03547, test_auc = 0.95413, time = 0.04798\n",
      "Epoch: 0170 | train_loss = 0.04190, train_auc = 0.98194, test_loss = 0.03485, test_auc = 0.95529, time = 0.04580\n",
      "Epoch: 0180 | train_loss = 0.03950, train_auc = 0.98354, test_loss = 0.03251, test_auc = 0.95824, time = 0.04653\n",
      "Epoch: 0190 | train_loss = 0.03674, train_auc = 0.98596, test_loss = 0.03354, test_auc = 0.95740, time = 0.04673\n",
      "Epoch: 0200 | train_loss = 0.03764, train_auc = 0.98624, test_loss = 0.03632, test_auc = 0.94836, time = 0.04667\n",
      "Epoch: 0210 | train_loss = 0.03666, train_auc = 0.98630, test_loss = 0.03864, test_auc = 0.95587, time = 0.04722\n",
      "Epoch: 0220 | train_loss = 0.03514, train_auc = 0.98739, test_loss = 0.03480, test_auc = 0.95665, time = 0.04624\n",
      "Epoch: 0230 | train_loss = 0.03657, train_auc = 0.98719, test_loss = 0.03797, test_auc = 0.95394, time = 0.04812\n",
      "Epoch: 0240 | train_loss = 0.03440, train_auc = 0.98788, test_loss = 0.03007, test_auc = 0.96568, time = 0.04599\n",
      "Epoch: 0250 | train_loss = 0.03064, train_auc = 0.98943, test_loss = 0.03509, test_auc = 0.96069, time = 0.04664\n",
      "Epoch: 0260 | train_loss = 0.03047, train_auc = 0.98989, test_loss = 0.03011, test_auc = 0.96431, time = 0.04641\n",
      "Epoch: 0270 | train_loss = 0.03092, train_auc = 0.98974, test_loss = 0.03144, test_auc = 0.96251, time = 0.04706\n",
      "Epoch: 0280 | train_loss = 0.03172, train_auc = 0.98933, test_loss = 0.03074, test_auc = 0.96600, time = 0.04756\n",
      "Epoch: 0290 | train_loss = 0.02968, train_auc = 0.99007, test_loss = 0.03626, test_auc = 0.95355, time = 0.04650\n",
      "Epoch: 0300 | train_loss = 0.02736, train_auc = 0.99059, test_loss = 0.03056, test_auc = 0.96703, time = 0.04797\n",
      "Epoch: 0310 | train_loss = 0.02790, train_auc = 0.99086, test_loss = 0.03171, test_auc = 0.96444, time = 0.04790\n",
      "Epoch: 0320 | train_loss = 0.02745, train_auc = 0.99197, test_loss = 0.03284, test_auc = 0.95614, time = 0.05130\n",
      "Epoch: 0330 | train_loss = 0.02876, train_auc = 0.99143, test_loss = 0.03379, test_auc = 0.95921, time = 0.04777\n",
      "Epoch: 0340 | train_loss = 0.02880, train_auc = 0.99059, test_loss = 0.03058, test_auc = 0.96308, time = 0.04746\n",
      "Epoch: 0350 | train_loss = 0.02828, train_auc = 0.99220, test_loss = 0.03392, test_auc = 0.96198, time = 0.04760\n",
      "Epoch: 0360 | train_loss = 0.02774, train_auc = 0.99137, test_loss = 0.03043, test_auc = 0.96665, time = 0.04682\n",
      "Epoch: 0370 | train_loss = 0.02567, train_auc = 0.99223, test_loss = 0.03065, test_auc = 0.96289, time = 0.04681\n",
      "Epoch: 0380 | train_loss = 0.03065, train_auc = 0.99075, test_loss = 0.03070, test_auc = 0.96824, time = 0.04590\n",
      "Epoch: 0390 | train_loss = 0.02693, train_auc = 0.99200, test_loss = 0.02956, test_auc = 0.96871, time = 0.04695\n",
      "Epoch: 0400 | train_loss = 0.02526, train_auc = 0.99259, test_loss = 0.03167, test_auc = 0.96696, time = 0.04594\n",
      "Epoch: 0410 | train_loss = 0.02504, train_auc = 0.99252, test_loss = 0.03172, test_auc = 0.96677, time = 0.04709\n",
      "Epoch: 0420 | train_loss = 0.02473, train_auc = 0.99258, test_loss = 0.02973, test_auc = 0.96868, time = 0.04685\n",
      "Epoch: 0430 | train_loss = 0.02404, train_auc = 0.99269, test_loss = 0.02956, test_auc = 0.96829, time = 0.04739\n",
      "Epoch: 0440 | train_loss = 0.02477, train_auc = 0.99283, test_loss = 0.03097, test_auc = 0.96731, time = 0.04772\n",
      "Epoch: 0450 | train_loss = 0.02370, train_auc = 0.99314, test_loss = 0.03148, test_auc = 0.96507, time = 0.04712\n",
      "Epoch: 0460 | train_loss = 0.02453, train_auc = 0.99313, test_loss = 0.03118, test_auc = 0.96571, time = 0.04785\n",
      "Epoch: 0470 | train_loss = 0.02479, train_auc = 0.99303, test_loss = 0.03023, test_auc = 0.96855, time = 0.04729\n",
      "Epoch: 0480 | train_loss = 0.02213, train_auc = 0.99367, test_loss = 0.03123, test_auc = 0.96673, time = 0.04775\n",
      "Epoch: 0490 | train_loss = 0.02307, train_auc = 0.99385, test_loss = 0.03227, test_auc = 0.96710, time = 0.04747\n",
      "Epoch: 0500 | train_loss = 0.02291, train_auc = 0.99401, test_loss = 0.03185, test_auc = 0.96677, time = 0.04735\n",
      "times: 3, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13245, train_auc = 0.55852, test_loss = 0.07428, test_auc = 0.53176, time = 0.81776\n",
      "Epoch: 0010 | train_loss = 0.08637, train_auc = 0.90106, test_loss = 0.06114, test_auc = 0.86966, time = 0.05243\n",
      "Epoch: 0020 | train_loss = 0.07485, train_auc = 0.92871, test_loss = 0.04292, test_auc = 0.87956, time = 0.05132\n",
      "Epoch: 0030 | train_loss = 0.07128, train_auc = 0.93679, test_loss = 0.03682, test_auc = 0.93444, time = 0.04866\n",
      "Epoch: 0040 | train_loss = 0.06623, train_auc = 0.94671, test_loss = 0.03620, test_auc = 0.94070, time = 0.04920\n",
      "Epoch: 0050 | train_loss = 0.06126, train_auc = 0.95624, test_loss = 0.03556, test_auc = 0.94514, time = 0.04887\n",
      "Epoch: 0060 | train_loss = 0.06042, train_auc = 0.95870, test_loss = 0.03282, test_auc = 0.94970, time = 0.04988\n",
      "Epoch: 0070 | train_loss = 0.05602, train_auc = 0.96567, test_loss = 0.03238, test_auc = 0.95069, time = 0.04809\n",
      "Epoch: 0080 | train_loss = 0.05505, train_auc = 0.96757, test_loss = 0.03430, test_auc = 0.95484, time = 0.04866\n",
      "Epoch: 0090 | train_loss = 0.05372, train_auc = 0.97031, test_loss = 0.03327, test_auc = 0.95029, time = 0.04850\n",
      "Epoch: 0100 | train_loss = 0.04985, train_auc = 0.97403, test_loss = 0.03174, test_auc = 0.95829, time = 0.04663\n",
      "Epoch: 0110 | train_loss = 0.04782, train_auc = 0.97613, test_loss = 0.03410, test_auc = 0.95829, time = 0.04795\n",
      "Epoch: 0120 | train_loss = 0.04727, train_auc = 0.97827, test_loss = 0.03086, test_auc = 0.96344, time = 0.04924\n",
      "Epoch: 0130 | train_loss = 0.04267, train_auc = 0.98130, test_loss = 0.03014, test_auc = 0.96186, time = 0.04817\n",
      "Epoch: 0140 | train_loss = 0.04405, train_auc = 0.97968, test_loss = 0.03173, test_auc = 0.96565, time = 0.04792\n",
      "Epoch: 0150 | train_loss = 0.04314, train_auc = 0.98129, test_loss = 0.02971, test_auc = 0.96646, time = 0.04675\n",
      "Epoch: 0160 | train_loss = 0.04005, train_auc = 0.98337, test_loss = 0.03000, test_auc = 0.96601, time = 0.04818\n",
      "Epoch: 0170 | train_loss = 0.04169, train_auc = 0.98319, test_loss = 0.02989, test_auc = 0.96507, time = 0.04662\n",
      "Epoch: 0180 | train_loss = 0.03952, train_auc = 0.98468, test_loss = 0.02855, test_auc = 0.96938, time = 0.04666\n",
      "Epoch: 0190 | train_loss = 0.03879, train_auc = 0.98508, test_loss = 0.03439, test_auc = 0.96413, time = 0.04659\n",
      "Epoch: 0200 | train_loss = 0.03729, train_auc = 0.98635, test_loss = 0.03146, test_auc = 0.96650, time = 0.04531\n",
      "Epoch: 0210 | train_loss = 0.03693, train_auc = 0.98553, test_loss = 0.03091, test_auc = 0.97085, time = 0.04622\n",
      "Epoch: 0220 | train_loss = 0.03564, train_auc = 0.98618, test_loss = 0.03033, test_auc = 0.96673, time = 0.04590\n",
      "Epoch: 0230 | train_loss = 0.03500, train_auc = 0.98808, test_loss = 0.03338, test_auc = 0.96425, time = 0.04688\n",
      "Epoch: 0240 | train_loss = 0.03254, train_auc = 0.98847, test_loss = 0.03141, test_auc = 0.96236, time = 0.04527\n",
      "Epoch: 0250 | train_loss = 0.03290, train_auc = 0.98883, test_loss = 0.02967, test_auc = 0.96957, time = 0.04709\n",
      "Epoch: 0260 | train_loss = 0.03295, train_auc = 0.98905, test_loss = 0.02892, test_auc = 0.97096, time = 0.04511\n",
      "Epoch: 0270 | train_loss = 0.03298, train_auc = 0.98930, test_loss = 0.03177, test_auc = 0.96699, time = 0.04596\n",
      "Epoch: 0280 | train_loss = 0.02956, train_auc = 0.99041, test_loss = 0.03079, test_auc = 0.96994, time = 0.04544\n",
      "Epoch: 0290 | train_loss = 0.03228, train_auc = 0.98959, test_loss = 0.03052, test_auc = 0.96630, time = 0.04685\n",
      "Epoch: 0300 | train_loss = 0.03039, train_auc = 0.99056, test_loss = 0.03134, test_auc = 0.96835, time = 0.05120\n",
      "Epoch: 0310 | train_loss = 0.03034, train_auc = 0.99027, test_loss = 0.03048, test_auc = 0.97346, time = 0.04775\n",
      "Epoch: 0320 | train_loss = 0.02859, train_auc = 0.99075, test_loss = 0.03033, test_auc = 0.97062, time = 0.04832\n",
      "Epoch: 0330 | train_loss = 0.02930, train_auc = 0.99075, test_loss = 0.02996, test_auc = 0.96793, time = 0.04673\n",
      "Epoch: 0340 | train_loss = 0.02858, train_auc = 0.99157, test_loss = 0.03594, test_auc = 0.96685, time = 0.04627\n",
      "Epoch: 0350 | train_loss = 0.02823, train_auc = 0.99198, test_loss = 0.02877, test_auc = 0.97162, time = 0.04793\n",
      "Epoch: 0360 | train_loss = 0.03038, train_auc = 0.99068, test_loss = 0.03366, test_auc = 0.96922, time = 0.04649\n",
      "Epoch: 0370 | train_loss = 0.02928, train_auc = 0.99122, test_loss = 0.02997, test_auc = 0.97204, time = 0.04769\n",
      "Epoch: 0380 | train_loss = 0.02632, train_auc = 0.99210, test_loss = 0.03066, test_auc = 0.96776, time = 0.04623\n",
      "Epoch: 0390 | train_loss = 0.02758, train_auc = 0.99259, test_loss = 0.03092, test_auc = 0.96631, time = 0.04771\n",
      "Epoch: 0400 | train_loss = 0.02743, train_auc = 0.99228, test_loss = 0.03579, test_auc = 0.96881, time = 0.04774\n",
      "Epoch: 0410 | train_loss = 0.02570, train_auc = 0.99258, test_loss = 0.03274, test_auc = 0.96601, time = 0.04562\n",
      "Epoch: 0420 | train_loss = 0.02558, train_auc = 0.99309, test_loss = 0.03762, test_auc = 0.95491, time = 0.05010\n",
      "Epoch: 0430 | train_loss = 0.02677, train_auc = 0.99263, test_loss = 0.02905, test_auc = 0.97324, time = 0.04777\n",
      "Epoch: 0440 | train_loss = 0.02653, train_auc = 0.99249, test_loss = 0.03561, test_auc = 0.96353, time = 0.04638\n",
      "Epoch: 0450 | train_loss = 0.02613, train_auc = 0.99236, test_loss = 0.03219, test_auc = 0.95578, time = 0.04710\n",
      "Epoch: 0460 | train_loss = 0.02752, train_auc = 0.99296, test_loss = 0.03075, test_auc = 0.97054, time = 0.04829\n",
      "Epoch: 0470 | train_loss = 0.02413, train_auc = 0.99329, test_loss = 0.03008, test_auc = 0.97131, time = 0.04752\n",
      "Epoch: 0480 | train_loss = 0.02727, train_auc = 0.99267, test_loss = 0.03288, test_auc = 0.96776, time = 0.04673\n",
      "Epoch: 0490 | train_loss = 0.02564, train_auc = 0.99344, test_loss = 0.03189, test_auc = 0.96062, time = 0.04593\n",
      "Epoch: 0500 | train_loss = 0.02221, train_auc = 0.99362, test_loss = 0.02996, test_auc = 0.97318, time = 0.04558\n",
      "times: 3, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14550, train_auc = 0.42036, test_loss = 0.07402, test_auc = 0.54685, time = 0.80894\n",
      "Epoch: 0010 | train_loss = 0.08254, train_auc = 0.90197, test_loss = 0.04777, test_auc = 0.88307, time = 0.05150\n",
      "Epoch: 0020 | train_loss = 0.07454, train_auc = 0.92466, test_loss = 0.04187, test_auc = 0.89102, time = 0.04828\n",
      "Epoch: 0030 | train_loss = 0.06546, train_auc = 0.94690, test_loss = 0.04142, test_auc = 0.90720, time = 0.04814\n",
      "Epoch: 0040 | train_loss = 0.06206, train_auc = 0.95363, test_loss = 0.03608, test_auc = 0.94036, time = 0.04680\n",
      "Epoch: 0050 | train_loss = 0.06196, train_auc = 0.95368, test_loss = 0.03386, test_auc = 0.94668, time = 0.04666\n",
      "Epoch: 0060 | train_loss = 0.05883, train_auc = 0.95827, test_loss = 0.03383, test_auc = 0.94709, time = 0.04657\n",
      "Epoch: 0070 | train_loss = 0.05549, train_auc = 0.96403, test_loss = 0.03323, test_auc = 0.95088, time = 0.04643\n",
      "Epoch: 0080 | train_loss = 0.05281, train_auc = 0.96896, test_loss = 0.03291, test_auc = 0.95696, time = 0.04610\n",
      "Epoch: 0090 | train_loss = 0.05201, train_auc = 0.96994, test_loss = 0.03299, test_auc = 0.95885, time = 0.04564\n",
      "Epoch: 0100 | train_loss = 0.05018, train_auc = 0.97225, test_loss = 0.03122, test_auc = 0.96316, time = 0.04878\n",
      "Epoch: 0110 | train_loss = 0.04641, train_auc = 0.97642, test_loss = 0.03217, test_auc = 0.95944, time = 0.04627\n",
      "Epoch: 0120 | train_loss = 0.04524, train_auc = 0.97797, test_loss = 0.03098, test_auc = 0.96390, time = 0.04627\n",
      "Epoch: 0130 | train_loss = 0.04338, train_auc = 0.97940, test_loss = 0.02997, test_auc = 0.96776, time = 0.04808\n",
      "Epoch: 0140 | train_loss = 0.04100, train_auc = 0.98048, test_loss = 0.03343, test_auc = 0.96142, time = 0.05626\n",
      "Epoch: 0150 | train_loss = 0.04306, train_auc = 0.98062, test_loss = 0.03501, test_auc = 0.95082, time = 0.04604\n",
      "Epoch: 0160 | train_loss = 0.04203, train_auc = 0.98125, test_loss = 0.03247, test_auc = 0.95757, time = 0.04616\n",
      "Epoch: 0170 | train_loss = 0.04039, train_auc = 0.98281, test_loss = 0.03208, test_auc = 0.96617, time = 0.04598\n",
      "Epoch: 0180 | train_loss = 0.03989, train_auc = 0.98251, test_loss = 0.03091, test_auc = 0.96626, time = 0.04597\n",
      "Epoch: 0190 | train_loss = 0.03852, train_auc = 0.98525, test_loss = 0.03239, test_auc = 0.96027, time = 0.04566\n",
      "Epoch: 0200 | train_loss = 0.03870, train_auc = 0.98343, test_loss = 0.02855, test_auc = 0.97539, time = 0.04520\n",
      "Epoch: 0210 | train_loss = 0.03681, train_auc = 0.98526, test_loss = 0.02975, test_auc = 0.97184, time = 0.04554\n",
      "Epoch: 0220 | train_loss = 0.03645, train_auc = 0.98549, test_loss = 0.03453, test_auc = 0.96756, time = 0.04520\n",
      "Epoch: 0230 | train_loss = 0.03475, train_auc = 0.98753, test_loss = 0.03330, test_auc = 0.95586, time = 0.04588\n",
      "Epoch: 0240 | train_loss = 0.03473, train_auc = 0.98827, test_loss = 0.03115, test_auc = 0.96351, time = 0.04496\n",
      "Epoch: 0250 | train_loss = 0.03436, train_auc = 0.98761, test_loss = 0.03127, test_auc = 0.96513, time = 0.04599\n",
      "Epoch: 0260 | train_loss = 0.03349, train_auc = 0.98878, test_loss = 0.03193, test_auc = 0.96506, time = 0.04564\n",
      "Epoch: 0270 | train_loss = 0.03124, train_auc = 0.99039, test_loss = 0.03175, test_auc = 0.97222, time = 0.04688\n",
      "Epoch: 0280 | train_loss = 0.03390, train_auc = 0.98844, test_loss = 0.03229, test_auc = 0.97187, time = 0.04541\n",
      "Epoch: 0290 | train_loss = 0.03301, train_auc = 0.99012, test_loss = 0.03125, test_auc = 0.97309, time = 0.04549\n",
      "Epoch: 0300 | train_loss = 0.03182, train_auc = 0.99137, test_loss = 0.02983, test_auc = 0.97556, time = 0.04585\n",
      "Epoch: 0310 | train_loss = 0.03140, train_auc = 0.99121, test_loss = 0.02700, test_auc = 0.97743, time = 0.04639\n",
      "Epoch: 0320 | train_loss = 0.03236, train_auc = 0.99052, test_loss = 0.02947, test_auc = 0.96881, time = 0.04740\n",
      "Epoch: 0330 | train_loss = 0.02837, train_auc = 0.99209, test_loss = 0.02793, test_auc = 0.97539, time = 0.04744\n",
      "Epoch: 0340 | train_loss = 0.02897, train_auc = 0.99284, test_loss = 0.03145, test_auc = 0.97336, time = 0.04701\n",
      "Epoch: 0350 | train_loss = 0.02646, train_auc = 0.99333, test_loss = 0.03047, test_auc = 0.96785, time = 0.04722\n",
      "Epoch: 0360 | train_loss = 0.02509, train_auc = 0.99370, test_loss = 0.03199, test_auc = 0.96539, time = 0.04763\n",
      "Epoch: 0370 | train_loss = 0.02766, train_auc = 0.99289, test_loss = 0.02971, test_auc = 0.97218, time = 0.04732\n",
      "Epoch: 0380 | train_loss = 0.02645, train_auc = 0.99321, test_loss = 0.02864, test_auc = 0.97367, time = 0.04736\n",
      "Epoch: 0390 | train_loss = 0.02561, train_auc = 0.99390, test_loss = 0.03239, test_auc = 0.97177, time = 0.04639\n",
      "Epoch: 0400 | train_loss = 0.02871, train_auc = 0.99390, test_loss = 0.02757, test_auc = 0.97491, time = 0.04665\n",
      "Epoch: 0410 | train_loss = 0.02468, train_auc = 0.99476, test_loss = 0.02768, test_auc = 0.97666, time = 0.04697\n",
      "Epoch: 0420 | train_loss = 0.02616, train_auc = 0.99410, test_loss = 0.02867, test_auc = 0.97630, time = 0.05058\n",
      "Epoch: 0430 | train_loss = 0.02644, train_auc = 0.99439, test_loss = 0.02791, test_auc = 0.97559, time = 0.04621\n",
      "Epoch: 0440 | train_loss = 0.02352, train_auc = 0.99488, test_loss = 0.03003, test_auc = 0.97348, time = 0.04632\n",
      "Epoch: 0450 | train_loss = 0.02349, train_auc = 0.99440, test_loss = 0.02706, test_auc = 0.97891, time = 0.04593\n",
      "Epoch: 0460 | train_loss = 0.02344, train_auc = 0.99469, test_loss = 0.03083, test_auc = 0.96851, time = 0.04635\n",
      "Epoch: 0470 | train_loss = 0.02392, train_auc = 0.99432, test_loss = 0.02833, test_auc = 0.97418, time = 0.04630\n",
      "Epoch: 0480 | train_loss = 0.02606, train_auc = 0.99438, test_loss = 0.03192, test_auc = 0.97601, time = 0.04715\n",
      "Epoch: 0490 | train_loss = 0.02322, train_auc = 0.99485, test_loss = 0.03049, test_auc = 0.97568, time = 0.04572\n",
      "Epoch: 0500 | train_loss = 0.02211, train_auc = 0.99522, test_loss = 0.02942, test_auc = 0.97341, time = 0.04848\n",
      "times: 3, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15385, train_auc = 0.34561, test_loss = 0.07306, test_auc = 0.55915, time = 0.80817\n",
      "Epoch: 0010 | train_loss = 0.08442, train_auc = 0.89192, test_loss = 0.04806, test_auc = 0.84587, time = 0.05127\n",
      "Epoch: 0020 | train_loss = 0.07455, train_auc = 0.92453, test_loss = 0.04392, test_auc = 0.88392, time = 0.04896\n",
      "Epoch: 0030 | train_loss = 0.07079, train_auc = 0.93530, test_loss = 0.04052, test_auc = 0.90090, time = 0.04907\n",
      "Epoch: 0040 | train_loss = 0.06680, train_auc = 0.94760, test_loss = 0.03577, test_auc = 0.93565, time = 0.04824\n",
      "Epoch: 0050 | train_loss = 0.06462, train_auc = 0.95186, test_loss = 0.03590, test_auc = 0.94613, time = 0.04675\n",
      "Epoch: 0060 | train_loss = 0.06302, train_auc = 0.95687, test_loss = 0.03354, test_auc = 0.95108, time = 0.04670\n",
      "Epoch: 0070 | train_loss = 0.05654, train_auc = 0.96247, test_loss = 0.03442, test_auc = 0.94271, time = 0.04647\n",
      "Epoch: 0080 | train_loss = 0.05563, train_auc = 0.96494, test_loss = 0.03444, test_auc = 0.94148, time = 0.04599\n",
      "Epoch: 0090 | train_loss = 0.05181, train_auc = 0.96966, test_loss = 0.03142, test_auc = 0.95889, time = 0.04588\n",
      "Epoch: 0100 | train_loss = 0.04978, train_auc = 0.97258, test_loss = 0.03403, test_auc = 0.95417, time = 0.04554\n",
      "Epoch: 0110 | train_loss = 0.04819, train_auc = 0.97427, test_loss = 0.03202, test_auc = 0.95692, time = 0.04529\n",
      "Epoch: 0120 | train_loss = 0.04740, train_auc = 0.97530, test_loss = 0.03144, test_auc = 0.95891, time = 0.04510\n",
      "Epoch: 0130 | train_loss = 0.04749, train_auc = 0.97460, test_loss = 0.03478, test_auc = 0.94980, time = 0.04498\n",
      "Epoch: 0140 | train_loss = 0.04590, train_auc = 0.97695, test_loss = 0.02957, test_auc = 0.96407, time = 0.04490\n",
      "Epoch: 0150 | train_loss = 0.04299, train_auc = 0.98025, test_loss = 0.03052, test_auc = 0.96488, time = 0.04687\n",
      "Epoch: 0160 | train_loss = 0.04392, train_auc = 0.97863, test_loss = 0.03434, test_auc = 0.96191, time = 0.04454\n",
      "Epoch: 0170 | train_loss = 0.04059, train_auc = 0.98214, test_loss = 0.03505, test_auc = 0.96381, time = 0.04548\n",
      "Epoch: 0180 | train_loss = 0.04004, train_auc = 0.98255, test_loss = 0.03863, test_auc = 0.94593, time = 0.04579\n",
      "Epoch: 0190 | train_loss = 0.04042, train_auc = 0.98266, test_loss = 0.03410, test_auc = 0.95685, time = 0.05019\n",
      "Epoch: 0200 | train_loss = 0.03855, train_auc = 0.98355, test_loss = 0.03343, test_auc = 0.96149, time = 0.04539\n",
      "Epoch: 0210 | train_loss = 0.03803, train_auc = 0.98483, test_loss = 0.03765, test_auc = 0.95220, time = 0.04516\n",
      "Epoch: 0220 | train_loss = 0.03628, train_auc = 0.98590, test_loss = 0.03784, test_auc = 0.95221, time = 0.04499\n",
      "Epoch: 0230 | train_loss = 0.03656, train_auc = 0.98566, test_loss = 0.03044, test_auc = 0.96667, time = 0.05690\n",
      "Epoch: 0240 | train_loss = 0.03523, train_auc = 0.98601, test_loss = 0.03592, test_auc = 0.96596, time = 0.04482\n",
      "Epoch: 0250 | train_loss = 0.03331, train_auc = 0.98730, test_loss = 0.02923, test_auc = 0.96821, time = 0.04436\n",
      "Epoch: 0260 | train_loss = 0.03332, train_auc = 0.98735, test_loss = 0.03094, test_auc = 0.96742, time = 0.04419\n",
      "Epoch: 0270 | train_loss = 0.03246, train_auc = 0.98789, test_loss = 0.02892, test_auc = 0.96841, time = 0.04397\n",
      "Epoch: 0280 | train_loss = 0.03407, train_auc = 0.98773, test_loss = 0.03037, test_auc = 0.96832, time = 0.04396\n",
      "Epoch: 0290 | train_loss = 0.03247, train_auc = 0.98880, test_loss = 0.02945, test_auc = 0.96900, time = 0.04399\n",
      "Epoch: 0300 | train_loss = 0.03315, train_auc = 0.98915, test_loss = 0.03248, test_auc = 0.96702, time = 0.04373\n",
      "Epoch: 0310 | train_loss = 0.03174, train_auc = 0.98951, test_loss = 0.03056, test_auc = 0.96749, time = 0.05721\n",
      "Epoch: 0320 | train_loss = 0.03143, train_auc = 0.98942, test_loss = 0.02801, test_auc = 0.96914, time = 0.04572\n",
      "Epoch: 0330 | train_loss = 0.03175, train_auc = 0.98962, test_loss = 0.03050, test_auc = 0.96804, time = 0.04654\n",
      "Epoch: 0340 | train_loss = 0.02848, train_auc = 0.99111, test_loss = 0.03594, test_auc = 0.94822, time = 0.04567\n",
      "Epoch: 0350 | train_loss = 0.02882, train_auc = 0.99022, test_loss = 0.03082, test_auc = 0.96875, time = 0.04642\n",
      "Epoch: 0360 | train_loss = 0.03125, train_auc = 0.98977, test_loss = 0.03035, test_auc = 0.97045, time = 0.04552\n",
      "Epoch: 0370 | train_loss = 0.03008, train_auc = 0.98973, test_loss = 0.03124, test_auc = 0.96938, time = 0.04561\n",
      "Epoch: 0380 | train_loss = 0.02837, train_auc = 0.99156, test_loss = 0.03305, test_auc = 0.95963, time = 0.04527\n",
      "Epoch: 0390 | train_loss = 0.02810, train_auc = 0.99127, test_loss = 0.02910, test_auc = 0.97337, time = 0.04602\n",
      "Epoch: 0400 | train_loss = 0.02815, train_auc = 0.99156, test_loss = 0.03164, test_auc = 0.97141, time = 0.04625\n",
      "Epoch: 0410 | train_loss = 0.02796, train_auc = 0.99165, test_loss = 0.02872, test_auc = 0.97155, time = 0.04552\n",
      "Epoch: 0420 | train_loss = 0.02779, train_auc = 0.99202, test_loss = 0.02833, test_auc = 0.97391, time = 0.04679\n",
      "Epoch: 0430 | train_loss = 0.02477, train_auc = 0.99301, test_loss = 0.02828, test_auc = 0.97486, time = 0.05220\n",
      "Epoch: 0440 | train_loss = 0.02720, train_auc = 0.99243, test_loss = 0.03031, test_auc = 0.97305, time = 0.05350\n",
      "Epoch: 0450 | train_loss = 0.02696, train_auc = 0.99192, test_loss = 0.03015, test_auc = 0.97219, time = 0.04596\n",
      "Epoch: 0460 | train_loss = 0.02738, train_auc = 0.99281, test_loss = 0.03007, test_auc = 0.97089, time = 0.05388\n",
      "Epoch: 0470 | train_loss = 0.02613, train_auc = 0.99371, test_loss = 0.02899, test_auc = 0.97590, time = 0.04557\n",
      "Epoch: 0480 | train_loss = 0.02572, train_auc = 0.99296, test_loss = 0.02849, test_auc = 0.97256, time = 0.04502\n",
      "Epoch: 0490 | train_loss = 0.02342, train_auc = 0.99441, test_loss = 0.02758, test_auc = 0.97648, time = 0.04886\n",
      "Epoch: 0500 | train_loss = 0.02462, train_auc = 0.99321, test_loss = 0.02722, test_auc = 0.97671, time = 0.04846\n",
      "times: 4, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14594, train_auc = 0.42623, test_loss = 0.07460, test_auc = 0.52404, time = 0.80984\n",
      "Epoch: 0010 | train_loss = 0.07836, train_auc = 0.92302, test_loss = 0.04429, test_auc = 0.84443, time = 0.04963\n",
      "Epoch: 0020 | train_loss = 0.07038, train_auc = 0.93882, test_loss = 0.04196, test_auc = 0.89339, time = 0.04883\n",
      "Epoch: 0030 | train_loss = 0.06816, train_auc = 0.94250, test_loss = 0.03990, test_auc = 0.91048, time = 0.04847\n",
      "Epoch: 0040 | train_loss = 0.06332, train_auc = 0.95346, test_loss = 0.03604, test_auc = 0.93792, time = 0.04704\n",
      "Epoch: 0050 | train_loss = 0.06037, train_auc = 0.95803, test_loss = 0.03485, test_auc = 0.94633, time = 0.04702\n",
      "Epoch: 0060 | train_loss = 0.06321, train_auc = 0.95889, test_loss = 0.03370, test_auc = 0.94898, time = 0.04762\n",
      "Epoch: 0070 | train_loss = 0.05483, train_auc = 0.96610, test_loss = 0.03292, test_auc = 0.94999, time = 0.04699\n",
      "Epoch: 0080 | train_loss = 0.05162, train_auc = 0.97090, test_loss = 0.03669, test_auc = 0.94664, time = 0.04819\n",
      "Epoch: 0090 | train_loss = 0.04867, train_auc = 0.97408, test_loss = 0.03454, test_auc = 0.95323, time = 0.04655\n",
      "Epoch: 0100 | train_loss = 0.05118, train_auc = 0.97175, test_loss = 0.03270, test_auc = 0.95302, time = 0.04719\n",
      "Epoch: 0110 | train_loss = 0.04689, train_auc = 0.97635, test_loss = 0.03220, test_auc = 0.95878, time = 0.04616\n",
      "Epoch: 0120 | train_loss = 0.04502, train_auc = 0.97902, test_loss = 0.03330, test_auc = 0.95181, time = 0.04605\n",
      "Epoch: 0130 | train_loss = 0.04377, train_auc = 0.97945, test_loss = 0.03207, test_auc = 0.96099, time = 0.04633\n",
      "Epoch: 0140 | train_loss = 0.04162, train_auc = 0.98184, test_loss = 0.03322, test_auc = 0.95781, time = 0.04587\n",
      "Epoch: 0150 | train_loss = 0.04474, train_auc = 0.98140, test_loss = 0.03312, test_auc = 0.96031, time = 0.04622\n",
      "Epoch: 0160 | train_loss = 0.04193, train_auc = 0.98284, test_loss = 0.03210, test_auc = 0.95809, time = 0.04597\n",
      "Epoch: 0170 | train_loss = 0.04026, train_auc = 0.98487, test_loss = 0.03479, test_auc = 0.95977, time = 0.04543\n",
      "Epoch: 0180 | train_loss = 0.03751, train_auc = 0.98561, test_loss = 0.03087, test_auc = 0.96262, time = 0.04539\n",
      "Epoch: 0190 | train_loss = 0.03934, train_auc = 0.98610, test_loss = 0.03137, test_auc = 0.96215, time = 0.04517\n",
      "Epoch: 0200 | train_loss = 0.03835, train_auc = 0.98602, test_loss = 0.03173, test_auc = 0.95907, time = 0.04752\n",
      "Epoch: 0210 | train_loss = 0.03856, train_auc = 0.98683, test_loss = 0.03568, test_auc = 0.96109, time = 0.04673\n",
      "Epoch: 0220 | train_loss = 0.03613, train_auc = 0.98772, test_loss = 0.03330, test_auc = 0.96173, time = 0.04546\n",
      "Epoch: 0230 | train_loss = 0.03836, train_auc = 0.98719, test_loss = 0.03326, test_auc = 0.96373, time = 0.04569\n",
      "Epoch: 0240 | train_loss = 0.03487, train_auc = 0.98892, test_loss = 0.03434, test_auc = 0.96323, time = 0.04542\n",
      "Epoch: 0250 | train_loss = 0.03438, train_auc = 0.98908, test_loss = 0.03021, test_auc = 0.96627, time = 0.04529\n",
      "Epoch: 0260 | train_loss = 0.03304, train_auc = 0.99016, test_loss = 0.03265, test_auc = 0.95697, time = 0.04503\n",
      "Epoch: 0270 | train_loss = 0.03285, train_auc = 0.99106, test_loss = 0.03244, test_auc = 0.96205, time = 0.04523\n",
      "Epoch: 0280 | train_loss = 0.03244, train_auc = 0.99102, test_loss = 0.03077, test_auc = 0.96665, time = 0.04573\n",
      "Epoch: 0290 | train_loss = 0.03024, train_auc = 0.99155, test_loss = 0.03250, test_auc = 0.96446, time = 0.04670\n",
      "Epoch: 0300 | train_loss = 0.03050, train_auc = 0.99206, test_loss = 0.03263, test_auc = 0.96628, time = 0.04634\n",
      "Epoch: 0310 | train_loss = 0.02860, train_auc = 0.99194, test_loss = 0.02915, test_auc = 0.96807, time = 0.04633\n",
      "Epoch: 0320 | train_loss = 0.02989, train_auc = 0.99199, test_loss = 0.02972, test_auc = 0.96773, time = 0.04724\n",
      "Epoch: 0330 | train_loss = 0.02727, train_auc = 0.99303, test_loss = 0.03244, test_auc = 0.96669, time = 0.04600\n",
      "Epoch: 0340 | train_loss = 0.02874, train_auc = 0.99293, test_loss = 0.03108, test_auc = 0.96927, time = 0.04626\n",
      "Epoch: 0350 | train_loss = 0.02859, train_auc = 0.99207, test_loss = 0.03282, test_auc = 0.96836, time = 0.04778\n",
      "Epoch: 0360 | train_loss = 0.02722, train_auc = 0.99277, test_loss = 0.03004, test_auc = 0.96985, time = 0.04636\n",
      "Epoch: 0370 | train_loss = 0.02808, train_auc = 0.99292, test_loss = 0.02942, test_auc = 0.96767, time = 0.04559\n",
      "Epoch: 0380 | train_loss = 0.02729, train_auc = 0.99374, test_loss = 0.03166, test_auc = 0.96636, time = 0.04489\n",
      "Epoch: 0390 | train_loss = 0.02768, train_auc = 0.99354, test_loss = 0.02988, test_auc = 0.97173, time = 0.04620\n",
      "Epoch: 0400 | train_loss = 0.02704, train_auc = 0.99343, test_loss = 0.03061, test_auc = 0.97241, time = 0.04578\n",
      "Epoch: 0410 | train_loss = 0.02415, train_auc = 0.99479, test_loss = 0.02948, test_auc = 0.97209, time = 0.04594\n",
      "Epoch: 0420 | train_loss = 0.02493, train_auc = 0.99460, test_loss = 0.03118, test_auc = 0.97071, time = 0.05188\n",
      "Epoch: 0430 | train_loss = 0.02512, train_auc = 0.99431, test_loss = 0.02873, test_auc = 0.97237, time = 0.04647\n",
      "Epoch: 0440 | train_loss = 0.02378, train_auc = 0.99519, test_loss = 0.03354, test_auc = 0.96873, time = 0.04655\n",
      "Epoch: 0450 | train_loss = 0.02316, train_auc = 0.99553, test_loss = 0.03294, test_auc = 0.96777, time = 0.04567\n",
      "Epoch: 0460 | train_loss = 0.02360, train_auc = 0.99481, test_loss = 0.02965, test_auc = 0.97342, time = 0.04780\n",
      "Epoch: 0470 | train_loss = 0.02535, train_auc = 0.99487, test_loss = 0.02893, test_auc = 0.97055, time = 0.04616\n",
      "Epoch: 0480 | train_loss = 0.02174, train_auc = 0.99545, test_loss = 0.02964, test_auc = 0.97088, time = 0.04539\n",
      "Epoch: 0490 | train_loss = 0.02105, train_auc = 0.99550, test_loss = 0.02991, test_auc = 0.97114, time = 0.04555\n",
      "Epoch: 0500 | train_loss = 0.02488, train_auc = 0.99502, test_loss = 0.03171, test_auc = 0.96960, time = 0.04595\n",
      "times: 4, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15449, train_auc = 0.35049, test_loss = 0.07410, test_auc = 0.52364, time = 0.82376\n",
      "Epoch: 0010 | train_loss = 0.08262, train_auc = 0.90556, test_loss = 0.04882, test_auc = 0.87305, time = 0.05037\n",
      "Epoch: 0020 | train_loss = 0.07116, train_auc = 0.93422, test_loss = 0.04233, test_auc = 0.90104, time = 0.04936\n",
      "Epoch: 0030 | train_loss = 0.06553, train_auc = 0.94936, test_loss = 0.03716, test_auc = 0.93124, time = 0.04784\n",
      "Epoch: 0040 | train_loss = 0.06486, train_auc = 0.95296, test_loss = 0.03967, test_auc = 0.92996, time = 0.04861\n",
      "Epoch: 0050 | train_loss = 0.05947, train_auc = 0.96003, test_loss = 0.03636, test_auc = 0.93601, time = 0.04661\n",
      "Epoch: 0060 | train_loss = 0.05792, train_auc = 0.96327, test_loss = 0.03426, test_auc = 0.94586, time = 0.04650\n",
      "Epoch: 0070 | train_loss = 0.05502, train_auc = 0.96679, test_loss = 0.03487, test_auc = 0.94173, time = 0.04636\n",
      "Epoch: 0080 | train_loss = 0.05371, train_auc = 0.96919, test_loss = 0.03365, test_auc = 0.94714, time = 0.04679\n",
      "Epoch: 0090 | train_loss = 0.05105, train_auc = 0.97246, test_loss = 0.03837, test_auc = 0.94701, time = 0.04577\n",
      "Epoch: 0100 | train_loss = 0.04878, train_auc = 0.97490, test_loss = 0.03384, test_auc = 0.94809, time = 0.04622\n",
      "Epoch: 0110 | train_loss = 0.04576, train_auc = 0.97754, test_loss = 0.03525, test_auc = 0.94706, time = 0.04723\n",
      "Epoch: 0120 | train_loss = 0.04719, train_auc = 0.97838, test_loss = 0.03536, test_auc = 0.95323, time = 0.04843\n",
      "Epoch: 0130 | train_loss = 0.04460, train_auc = 0.97887, test_loss = 0.03391, test_auc = 0.95066, time = 0.04649\n",
      "Epoch: 0140 | train_loss = 0.04462, train_auc = 0.97970, test_loss = 0.03498, test_auc = 0.95465, time = 0.04640\n",
      "Epoch: 0150 | train_loss = 0.04177, train_auc = 0.98234, test_loss = 0.03570, test_auc = 0.94659, time = 0.05022\n",
      "Epoch: 0160 | train_loss = 0.04266, train_auc = 0.98220, test_loss = 0.03263, test_auc = 0.95781, time = 0.04645\n",
      "Epoch: 0170 | train_loss = 0.03937, train_auc = 0.98428, test_loss = 0.03522, test_auc = 0.95529, time = 0.04832\n",
      "Epoch: 0180 | train_loss = 0.03621, train_auc = 0.98671, test_loss = 0.03263, test_auc = 0.95604, time = 0.04617\n",
      "Epoch: 0190 | train_loss = 0.03782, train_auc = 0.98622, test_loss = 0.03072, test_auc = 0.96149, time = 0.04775\n",
      "Epoch: 0200 | train_loss = 0.03642, train_auc = 0.98829, test_loss = 0.03449, test_auc = 0.95528, time = 0.04636\n",
      "Epoch: 0210 | train_loss = 0.03308, train_auc = 0.98808, test_loss = 0.03214, test_auc = 0.96290, time = 0.04554\n",
      "Epoch: 0220 | train_loss = 0.03413, train_auc = 0.98930, test_loss = 0.03288, test_auc = 0.95996, time = 0.04959\n",
      "Epoch: 0230 | train_loss = 0.03437, train_auc = 0.98846, test_loss = 0.03387, test_auc = 0.94957, time = 0.04585\n",
      "Epoch: 0240 | train_loss = 0.03313, train_auc = 0.98971, test_loss = 0.03837, test_auc = 0.93030, time = 0.04699\n",
      "Epoch: 0250 | train_loss = 0.03151, train_auc = 0.98942, test_loss = 0.03445, test_auc = 0.96076, time = 0.04634\n",
      "Epoch: 0260 | train_loss = 0.03308, train_auc = 0.99073, test_loss = 0.03527, test_auc = 0.96159, time = 0.04774\n",
      "Epoch: 0270 | train_loss = 0.03037, train_auc = 0.99019, test_loss = 0.03034, test_auc = 0.96549, time = 0.05210\n",
      "Epoch: 0280 | train_loss = 0.03109, train_auc = 0.99102, test_loss = 0.03515, test_auc = 0.96172, time = 0.04768\n",
      "Epoch: 0290 | train_loss = 0.02943, train_auc = 0.99139, test_loss = 0.03500, test_auc = 0.96187, time = 0.04673\n",
      "Epoch: 0300 | train_loss = 0.03113, train_auc = 0.99145, test_loss = 0.03412, test_auc = 0.95987, time = 0.05133\n",
      "Epoch: 0310 | train_loss = 0.03049, train_auc = 0.99156, test_loss = 0.03276, test_auc = 0.95564, time = 0.04650\n",
      "Epoch: 0320 | train_loss = 0.02849, train_auc = 0.99280, test_loss = 0.03279, test_auc = 0.96146, time = 0.04690\n",
      "Epoch: 0330 | train_loss = 0.02889, train_auc = 0.99256, test_loss = 0.03133, test_auc = 0.96632, time = 0.05184\n",
      "Epoch: 0340 | train_loss = 0.03072, train_auc = 0.99191, test_loss = 0.03364, test_auc = 0.96020, time = 0.04921\n",
      "Epoch: 0350 | train_loss = 0.02998, train_auc = 0.99220, test_loss = 0.03330, test_auc = 0.96282, time = 0.04753\n",
      "Epoch: 0360 | train_loss = 0.02638, train_auc = 0.99345, test_loss = 0.03516, test_auc = 0.95907, time = 0.04715\n",
      "Epoch: 0370 | train_loss = 0.02515, train_auc = 0.99356, test_loss = 0.03240, test_auc = 0.96477, time = 0.04703\n",
      "Epoch: 0380 | train_loss = 0.02430, train_auc = 0.99369, test_loss = 0.03577, test_auc = 0.94833, time = 0.04748\n",
      "Epoch: 0390 | train_loss = 0.03003, train_auc = 0.99178, test_loss = 0.03456, test_auc = 0.96537, time = 0.04747\n",
      "Epoch: 0400 | train_loss = 0.02314, train_auc = 0.99429, test_loss = 0.03394, test_auc = 0.96497, time = 0.04631\n",
      "Epoch: 0410 | train_loss = 0.02624, train_auc = 0.99407, test_loss = 0.03122, test_auc = 0.96164, time = 0.04598\n",
      "Epoch: 0420 | train_loss = 0.02451, train_auc = 0.99469, test_loss = 0.03032, test_auc = 0.96718, time = 0.04627\n",
      "Epoch: 0430 | train_loss = 0.02672, train_auc = 0.99450, test_loss = 0.03233, test_auc = 0.96173, time = 0.04739\n",
      "Epoch: 0440 | train_loss = 0.02546, train_auc = 0.99407, test_loss = 0.03593, test_auc = 0.94799, time = 0.04590\n",
      "Epoch: 0450 | train_loss = 0.02489, train_auc = 0.99406, test_loss = 0.03338, test_auc = 0.96458, time = 0.04584\n",
      "Epoch: 0460 | train_loss = 0.02535, train_auc = 0.99494, test_loss = 0.03034, test_auc = 0.96826, time = 0.04688\n",
      "Epoch: 0470 | train_loss = 0.02438, train_auc = 0.99481, test_loss = 0.03290, test_auc = 0.96614, time = 0.04830\n",
      "Epoch: 0480 | train_loss = 0.02329, train_auc = 0.99516, test_loss = 0.03180, test_auc = 0.96151, time = 0.04632\n",
      "Epoch: 0490 | train_loss = 0.02375, train_auc = 0.99587, test_loss = 0.02994, test_auc = 0.96761, time = 0.04718\n",
      "Epoch: 0500 | train_loss = 0.02151, train_auc = 0.99571, test_loss = 0.03411, test_auc = 0.96480, time = 0.04620\n",
      "times: 4, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15303, train_auc = 0.38505, test_loss = 0.07387, test_auc = 0.54261, time = 0.82432\n",
      "Epoch: 0010 | train_loss = 0.08462, train_auc = 0.90062, test_loss = 0.05458, test_auc = 0.84084, time = 0.05087\n",
      "Epoch: 0020 | train_loss = 0.07759, train_auc = 0.91977, test_loss = 0.04321, test_auc = 0.88591, time = 0.04685\n",
      "Epoch: 0030 | train_loss = 0.07108, train_auc = 0.93382, test_loss = 0.03925, test_auc = 0.91803, time = 0.04730\n",
      "Epoch: 0040 | train_loss = 0.06425, train_auc = 0.94985, test_loss = 0.03821, test_auc = 0.93787, time = 0.04636\n",
      "Epoch: 0050 | train_loss = 0.06978, train_auc = 0.94353, test_loss = 0.03455, test_auc = 0.95052, time = 0.04467\n",
      "Epoch: 0060 | train_loss = 0.06186, train_auc = 0.95406, test_loss = 0.03488, test_auc = 0.94952, time = 0.04471\n",
      "Epoch: 0070 | train_loss = 0.05818, train_auc = 0.96223, test_loss = 0.03582, test_auc = 0.95133, time = 0.04407\n",
      "Epoch: 0080 | train_loss = 0.05381, train_auc = 0.96617, test_loss = 0.03480, test_auc = 0.94810, time = 0.04435\n",
      "Epoch: 0090 | train_loss = 0.05315, train_auc = 0.96841, test_loss = 0.03248, test_auc = 0.95492, time = 0.04414\n",
      "Epoch: 0100 | train_loss = 0.05053, train_auc = 0.97385, test_loss = 0.03508, test_auc = 0.95143, time = 0.04385\n",
      "Epoch: 0110 | train_loss = 0.04833, train_auc = 0.97586, test_loss = 0.03203, test_auc = 0.95921, time = 0.04480\n",
      "Epoch: 0120 | train_loss = 0.04755, train_auc = 0.97591, test_loss = 0.03356, test_auc = 0.95267, time = 0.04487\n",
      "Epoch: 0130 | train_loss = 0.04624, train_auc = 0.97850, test_loss = 0.03527, test_auc = 0.94986, time = 0.04524\n",
      "Epoch: 0140 | train_loss = 0.04506, train_auc = 0.97918, test_loss = 0.03901, test_auc = 0.95834, time = 0.04432\n",
      "Epoch: 0150 | train_loss = 0.04169, train_auc = 0.98181, test_loss = 0.03306, test_auc = 0.96051, time = 0.04464\n",
      "Epoch: 0160 | train_loss = 0.04280, train_auc = 0.98248, test_loss = 0.03114, test_auc = 0.96219, time = 0.04511\n",
      "Epoch: 0170 | train_loss = 0.03898, train_auc = 0.98401, test_loss = 0.03427, test_auc = 0.95629, time = 0.04441\n",
      "Epoch: 0180 | train_loss = 0.03723, train_auc = 0.98605, test_loss = 0.03521, test_auc = 0.94961, time = 0.04424\n",
      "Epoch: 0190 | train_loss = 0.03625, train_auc = 0.98653, test_loss = 0.03156, test_auc = 0.96296, time = 0.04442\n",
      "Epoch: 0200 | train_loss = 0.03602, train_auc = 0.98742, test_loss = 0.03475, test_auc = 0.95776, time = 0.04542\n",
      "Epoch: 0210 | train_loss = 0.03683, train_auc = 0.98685, test_loss = 0.03452, test_auc = 0.95093, time = 0.04493\n",
      "Epoch: 0220 | train_loss = 0.03698, train_auc = 0.98722, test_loss = 0.03190, test_auc = 0.96160, time = 0.04423\n",
      "Epoch: 0230 | train_loss = 0.03513, train_auc = 0.98813, test_loss = 0.03442, test_auc = 0.95360, time = 0.04776\n",
      "Epoch: 0240 | train_loss = 0.03291, train_auc = 0.98960, test_loss = 0.03039, test_auc = 0.97083, time = 0.04786\n",
      "Epoch: 0250 | train_loss = 0.03185, train_auc = 0.99085, test_loss = 0.02838, test_auc = 0.97336, time = 0.04514\n",
      "Epoch: 0260 | train_loss = 0.03179, train_auc = 0.99087, test_loss = 0.02931, test_auc = 0.97030, time = 0.04593\n",
      "Epoch: 0270 | train_loss = 0.03320, train_auc = 0.98988, test_loss = 0.03215, test_auc = 0.96507, time = 0.04525\n",
      "Epoch: 0280 | train_loss = 0.03123, train_auc = 0.99078, test_loss = 0.03355, test_auc = 0.96703, time = 0.04478\n",
      "Epoch: 0290 | train_loss = 0.03297, train_auc = 0.99083, test_loss = 0.03181, test_auc = 0.96889, time = 0.04575\n",
      "Epoch: 0300 | train_loss = 0.02918, train_auc = 0.99151, test_loss = 0.03068, test_auc = 0.96904, time = 0.04543\n",
      "Epoch: 0310 | train_loss = 0.02812, train_auc = 0.99276, test_loss = 0.02947, test_auc = 0.97070, time = 0.04465\n",
      "Epoch: 0320 | train_loss = 0.02745, train_auc = 0.99361, test_loss = 0.03119, test_auc = 0.96491, time = 0.04472\n",
      "Epoch: 0330 | train_loss = 0.02513, train_auc = 0.99382, test_loss = 0.02950, test_auc = 0.97245, time = 0.04484\n",
      "Epoch: 0340 | train_loss = 0.02602, train_auc = 0.99381, test_loss = 0.03358, test_auc = 0.97044, time = 0.04429\n",
      "Epoch: 0350 | train_loss = 0.02615, train_auc = 0.99445, test_loss = 0.03196, test_auc = 0.96656, time = 0.04511\n",
      "Epoch: 0360 | train_loss = 0.02518, train_auc = 0.99463, test_loss = 0.03145, test_auc = 0.96947, time = 0.04437\n",
      "Epoch: 0370 | train_loss = 0.02460, train_auc = 0.99495, test_loss = 0.03043, test_auc = 0.96996, time = 0.04469\n",
      "Epoch: 0380 | train_loss = 0.02602, train_auc = 0.99441, test_loss = 0.03114, test_auc = 0.96406, time = 0.04505\n",
      "Epoch: 0390 | train_loss = 0.02319, train_auc = 0.99573, test_loss = 0.02979, test_auc = 0.97062, time = 0.04386\n",
      "Epoch: 0400 | train_loss = 0.02482, train_auc = 0.99549, test_loss = 0.03255, test_auc = 0.97034, time = 0.04385\n",
      "Epoch: 0410 | train_loss = 0.02576, train_auc = 0.99468, test_loss = 0.03183, test_auc = 0.97054, time = 0.04470\n",
      "Epoch: 0420 | train_loss = 0.02625, train_auc = 0.99554, test_loss = 0.03063, test_auc = 0.97015, time = 0.04471\n",
      "Epoch: 0430 | train_loss = 0.02442, train_auc = 0.99635, test_loss = 0.02956, test_auc = 0.97133, time = 0.04508\n",
      "Epoch: 0440 | train_loss = 0.02557, train_auc = 0.99509, test_loss = 0.03123, test_auc = 0.97099, time = 0.04353\n",
      "Epoch: 0450 | train_loss = 0.02408, train_auc = 0.99605, test_loss = 0.02914, test_auc = 0.97216, time = 0.04466\n",
      "Epoch: 0460 | train_loss = 0.02476, train_auc = 0.99626, test_loss = 0.03006, test_auc = 0.97425, time = 0.04391\n",
      "Epoch: 0470 | train_loss = 0.02199, train_auc = 0.99553, test_loss = 0.03158, test_auc = 0.96758, time = 0.04458\n",
      "Epoch: 0480 | train_loss = 0.02241, train_auc = 0.99616, test_loss = 0.03183, test_auc = 0.96518, time = 0.05213\n",
      "Epoch: 0490 | train_loss = 0.02299, train_auc = 0.99618, test_loss = 0.03235, test_auc = 0.97048, time = 0.04398\n",
      "Epoch: 0500 | train_loss = 0.02211, train_auc = 0.99662, test_loss = 0.02893, test_auc = 0.97287, time = 0.04436\n",
      "times: 4, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15697, train_auc = 0.32966, test_loss = 0.07293, test_auc = 0.55062, time = 0.81924\n",
      "Epoch: 0010 | train_loss = 0.08439, train_auc = 0.90861, test_loss = 0.05113, test_auc = 0.85988, time = 0.05703\n",
      "Epoch: 0020 | train_loss = 0.07152, train_auc = 0.93414, test_loss = 0.03996, test_auc = 0.90629, time = 0.05151\n",
      "Epoch: 0030 | train_loss = 0.06834, train_auc = 0.94134, test_loss = 0.03679, test_auc = 0.92685, time = 0.04914\n",
      "Epoch: 0040 | train_loss = 0.06530, train_auc = 0.95365, test_loss = 0.03542, test_auc = 0.93282, time = 0.04834\n",
      "Epoch: 0050 | train_loss = 0.06071, train_auc = 0.95928, test_loss = 0.03702, test_auc = 0.93658, time = 0.04882\n",
      "Epoch: 0060 | train_loss = 0.06287, train_auc = 0.95179, test_loss = 0.03482, test_auc = 0.93502, time = 0.04834\n",
      "Epoch: 0070 | train_loss = 0.05894, train_auc = 0.96334, test_loss = 0.03324, test_auc = 0.94579, time = 0.04807\n",
      "Epoch: 0080 | train_loss = 0.05440, train_auc = 0.96882, test_loss = 0.03323, test_auc = 0.94353, time = 0.04600\n",
      "Epoch: 0090 | train_loss = 0.05478, train_auc = 0.96898, test_loss = 0.03215, test_auc = 0.94910, time = 0.04753\n",
      "Epoch: 0100 | train_loss = 0.05127, train_auc = 0.97293, test_loss = 0.03400, test_auc = 0.94626, time = 0.04618\n",
      "Epoch: 0110 | train_loss = 0.05005, train_auc = 0.97420, test_loss = 0.03295, test_auc = 0.94856, time = 0.04709\n",
      "Epoch: 0120 | train_loss = 0.05221, train_auc = 0.97528, test_loss = 0.03195, test_auc = 0.95276, time = 0.04761\n",
      "Epoch: 0130 | train_loss = 0.04465, train_auc = 0.98040, test_loss = 0.03281, test_auc = 0.95029, time = 0.04639\n",
      "Epoch: 0140 | train_loss = 0.04559, train_auc = 0.97981, test_loss = 0.03280, test_auc = 0.95591, time = 0.04822\n",
      "Epoch: 0150 | train_loss = 0.04275, train_auc = 0.98190, test_loss = 0.03469, test_auc = 0.95319, time = 0.04745\n",
      "Epoch: 0160 | train_loss = 0.04241, train_auc = 0.98312, test_loss = 0.03077, test_auc = 0.95958, time = 0.04656\n",
      "Epoch: 0170 | train_loss = 0.03968, train_auc = 0.98479, test_loss = 0.03383, test_auc = 0.95674, time = 0.04637\n",
      "Epoch: 0180 | train_loss = 0.03904, train_auc = 0.98459, test_loss = 0.03170, test_auc = 0.95857, time = 0.04928\n",
      "Epoch: 0190 | train_loss = 0.03862, train_auc = 0.98572, test_loss = 0.03175, test_auc = 0.95945, time = 0.04716\n",
      "Epoch: 0200 | train_loss = 0.03871, train_auc = 0.98684, test_loss = 0.03116, test_auc = 0.96148, time = 0.04659\n",
      "Epoch: 0210 | train_loss = 0.03632, train_auc = 0.98808, test_loss = 0.03067, test_auc = 0.96617, time = 0.04568\n",
      "Epoch: 0220 | train_loss = 0.03381, train_auc = 0.98871, test_loss = 0.03235, test_auc = 0.96532, time = 0.04581\n",
      "Epoch: 0230 | train_loss = 0.03323, train_auc = 0.98947, test_loss = 0.03130, test_auc = 0.96377, time = 0.04463\n",
      "Epoch: 0240 | train_loss = 0.03465, train_auc = 0.98934, test_loss = 0.02975, test_auc = 0.96852, time = 0.04510\n",
      "Epoch: 0250 | train_loss = 0.03307, train_auc = 0.99071, test_loss = 0.02825, test_auc = 0.97049, time = 0.04542\n",
      "Epoch: 0260 | train_loss = 0.03060, train_auc = 0.99213, test_loss = 0.03015, test_auc = 0.96640, time = 0.04540\n",
      "Epoch: 0270 | train_loss = 0.03266, train_auc = 0.99144, test_loss = 0.02871, test_auc = 0.96965, time = 0.04512\n",
      "Epoch: 0280 | train_loss = 0.02795, train_auc = 0.99273, test_loss = 0.03220, test_auc = 0.95919, time = 0.04586\n",
      "Epoch: 0290 | train_loss = 0.02786, train_auc = 0.99293, test_loss = 0.03080, test_auc = 0.96664, time = 0.04495\n",
      "Epoch: 0300 | train_loss = 0.02934, train_auc = 0.99353, test_loss = 0.03078, test_auc = 0.97022, time = 0.04504\n",
      "Epoch: 0310 | train_loss = 0.02655, train_auc = 0.99393, test_loss = 0.03435, test_auc = 0.96484, time = 0.04447\n",
      "Epoch: 0320 | train_loss = 0.03198, train_auc = 0.99284, test_loss = 0.03284, test_auc = 0.96903, time = 0.04482\n",
      "Epoch: 0330 | train_loss = 0.02814, train_auc = 0.99366, test_loss = 0.02989, test_auc = 0.96837, time = 0.04615\n",
      "Epoch: 0340 | train_loss = 0.02722, train_auc = 0.99403, test_loss = 0.03244, test_auc = 0.96898, time = 0.04536\n",
      "Epoch: 0350 | train_loss = 0.02736, train_auc = 0.99436, test_loss = 0.02858, test_auc = 0.97344, time = 0.04616\n",
      "Epoch: 0360 | train_loss = 0.02604, train_auc = 0.99431, test_loss = 0.02754, test_auc = 0.97335, time = 0.04650\n",
      "Epoch: 0370 | train_loss = 0.02571, train_auc = 0.99453, test_loss = 0.02904, test_auc = 0.97295, time = 0.04646\n",
      "Epoch: 0380 | train_loss = 0.02099, train_auc = 0.99599, test_loss = 0.02973, test_auc = 0.96805, time = 0.04606\n",
      "Epoch: 0390 | train_loss = 0.02212, train_auc = 0.99563, test_loss = 0.03148, test_auc = 0.96543, time = 0.04663\n",
      "Epoch: 0400 | train_loss = 0.02246, train_auc = 0.99580, test_loss = 0.02667, test_auc = 0.97624, time = 0.04754\n",
      "Epoch: 0410 | train_loss = 0.02277, train_auc = 0.99591, test_loss = 0.02948, test_auc = 0.96906, time = 0.04647\n",
      "Epoch: 0420 | train_loss = 0.02283, train_auc = 0.99598, test_loss = 0.03015, test_auc = 0.96826, time = 0.04599\n",
      "Epoch: 0430 | train_loss = 0.02437, train_auc = 0.99597, test_loss = 0.02905, test_auc = 0.97502, time = 0.04614\n",
      "Epoch: 0440 | train_loss = 0.02529, train_auc = 0.99654, test_loss = 0.03013, test_auc = 0.97070, time = 0.04502\n",
      "Epoch: 0450 | train_loss = 0.02556, train_auc = 0.99588, test_loss = 0.02859, test_auc = 0.97211, time = 0.04562\n",
      "Epoch: 0460 | train_loss = 0.02425, train_auc = 0.99602, test_loss = 0.02906, test_auc = 0.97210, time = 0.04487\n",
      "Epoch: 0470 | train_loss = 0.02454, train_auc = 0.99595, test_loss = 0.02998, test_auc = 0.97139, time = 0.04400\n",
      "Epoch: 0480 | train_loss = 0.02164, train_auc = 0.99641, test_loss = 0.03139, test_auc = 0.97148, time = 0.04458\n",
      "Epoch: 0490 | train_loss = 0.02248, train_auc = 0.99569, test_loss = 0.02978, test_auc = 0.97320, time = 0.04450\n",
      "Epoch: 0500 | train_loss = 0.02146, train_auc = 0.99619, test_loss = 0.02881, test_auc = 0.97130, time = 0.04421\n",
      "times: 4, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15327, train_auc = 0.36078, test_loss = 0.08617, test_auc = 0.31162, time = 0.80808\n",
      "Epoch: 0010 | train_loss = 0.08167, train_auc = 0.90740, test_loss = 0.04130, test_auc = 0.89205, time = 0.05335\n",
      "Epoch: 0020 | train_loss = 0.07416, train_auc = 0.93086, test_loss = 0.03979, test_auc = 0.91022, time = 0.04971\n",
      "Epoch: 0030 | train_loss = 0.06715, train_auc = 0.94646, test_loss = 0.03710, test_auc = 0.93239, time = 0.04956\n",
      "Epoch: 0040 | train_loss = 0.06328, train_auc = 0.95275, test_loss = 0.03453, test_auc = 0.94512, time = 0.04929\n",
      "Epoch: 0050 | train_loss = 0.05990, train_auc = 0.95951, test_loss = 0.03390, test_auc = 0.94709, time = 0.04985\n",
      "Epoch: 0060 | train_loss = 0.06026, train_auc = 0.96029, test_loss = 0.03220, test_auc = 0.95451, time = 0.04824\n",
      "Epoch: 0070 | train_loss = 0.05590, train_auc = 0.96585, test_loss = 0.03327, test_auc = 0.95937, time = 0.04893\n",
      "Epoch: 0080 | train_loss = 0.05617, train_auc = 0.96776, test_loss = 0.03173, test_auc = 0.95876, time = 0.05734\n",
      "Epoch: 0090 | train_loss = 0.05470, train_auc = 0.96770, test_loss = 0.03121, test_auc = 0.95995, time = 0.04885\n",
      "Epoch: 0100 | train_loss = 0.04973, train_auc = 0.97426, test_loss = 0.03077, test_auc = 0.96487, time = 0.04880\n",
      "Epoch: 0110 | train_loss = 0.05039, train_auc = 0.97378, test_loss = 0.03216, test_auc = 0.96105, time = 0.04831\n",
      "Epoch: 0120 | train_loss = 0.04703, train_auc = 0.97920, test_loss = 0.03200, test_auc = 0.96205, time = 0.04991\n",
      "Epoch: 0130 | train_loss = 0.04442, train_auc = 0.98115, test_loss = 0.03368, test_auc = 0.96113, time = 0.04933\n",
      "Epoch: 0140 | train_loss = 0.04252, train_auc = 0.98257, test_loss = 0.03176, test_auc = 0.96702, time = 0.04783\n",
      "Epoch: 0150 | train_loss = 0.04280, train_auc = 0.98137, test_loss = 0.03017, test_auc = 0.96867, time = 0.04771\n",
      "Epoch: 0160 | train_loss = 0.04065, train_auc = 0.98409, test_loss = 0.03066, test_auc = 0.97000, time = 0.04741\n",
      "Epoch: 0170 | train_loss = 0.03662, train_auc = 0.98677, test_loss = 0.03236, test_auc = 0.96588, time = 0.04708\n",
      "Epoch: 0180 | train_loss = 0.04284, train_auc = 0.98294, test_loss = 0.03011, test_auc = 0.96715, time = 0.04825\n",
      "Epoch: 0190 | train_loss = 0.03762, train_auc = 0.98718, test_loss = 0.03212, test_auc = 0.96171, time = 0.04703\n",
      "Epoch: 0200 | train_loss = 0.03550, train_auc = 0.98897, test_loss = 0.03269, test_auc = 0.96568, time = 0.04767\n",
      "Epoch: 0210 | train_loss = 0.03643, train_auc = 0.98918, test_loss = 0.03116, test_auc = 0.96376, time = 0.04703\n",
      "Epoch: 0220 | train_loss = 0.03657, train_auc = 0.98894, test_loss = 0.03034, test_auc = 0.96922, time = 0.04677\n",
      "Epoch: 0230 | train_loss = 0.03301, train_auc = 0.99115, test_loss = 0.03073, test_auc = 0.96784, time = 0.04726\n",
      "Epoch: 0240 | train_loss = 0.02975, train_auc = 0.99192, test_loss = 0.03058, test_auc = 0.96944, time = 0.04805\n",
      "Epoch: 0250 | train_loss = 0.03246, train_auc = 0.99131, test_loss = 0.03336, test_auc = 0.95995, time = 0.04707\n",
      "Epoch: 0260 | train_loss = 0.03239, train_auc = 0.99049, test_loss = 0.03264, test_auc = 0.95584, time = 0.04552\n",
      "Epoch: 0270 | train_loss = 0.03268, train_auc = 0.99128, test_loss = 0.03105, test_auc = 0.97182, time = 0.04818\n",
      "Epoch: 0280 | train_loss = 0.02664, train_auc = 0.99337, test_loss = 0.02804, test_auc = 0.97457, time = 0.04637\n",
      "Epoch: 0290 | train_loss = 0.02860, train_auc = 0.99271, test_loss = 0.02763, test_auc = 0.97487, time = 0.04849\n",
      "Epoch: 0300 | train_loss = 0.02673, train_auc = 0.99353, test_loss = 0.02921, test_auc = 0.97301, time = 0.04848\n",
      "Epoch: 0310 | train_loss = 0.02803, train_auc = 0.99298, test_loss = 0.03038, test_auc = 0.96977, time = 0.05075\n",
      "Epoch: 0320 | train_loss = 0.02924, train_auc = 0.99315, test_loss = 0.02978, test_auc = 0.97273, time = 0.04754\n",
      "Epoch: 0330 | train_loss = 0.02694, train_auc = 0.99371, test_loss = 0.02770, test_auc = 0.97607, time = 0.04707\n",
      "Epoch: 0340 | train_loss = 0.02666, train_auc = 0.99397, test_loss = 0.02840, test_auc = 0.97352, time = 0.04983\n",
      "Epoch: 0350 | train_loss = 0.02748, train_auc = 0.99369, test_loss = 0.02917, test_auc = 0.97400, time = 0.04695\n",
      "Epoch: 0360 | train_loss = 0.02889, train_auc = 0.99334, test_loss = 0.03274, test_auc = 0.97060, time = 0.04917\n",
      "Epoch: 0370 | train_loss = 0.02607, train_auc = 0.99403, test_loss = 0.03029, test_auc = 0.97371, time = 0.04894\n",
      "Epoch: 0380 | train_loss = 0.02527, train_auc = 0.99459, test_loss = 0.02917, test_auc = 0.97394, time = 0.04928\n",
      "Epoch: 0390 | train_loss = 0.02340, train_auc = 0.99476, test_loss = 0.02791, test_auc = 0.97627, time = 0.04958\n",
      "Epoch: 0400 | train_loss = 0.02532, train_auc = 0.99427, test_loss = 0.02861, test_auc = 0.97643, time = 0.05029\n",
      "Epoch: 0410 | train_loss = 0.02576, train_auc = 0.99458, test_loss = 0.02941, test_auc = 0.97284, time = 0.04772\n",
      "Epoch: 0420 | train_loss = 0.02614, train_auc = 0.99471, test_loss = 0.02861, test_auc = 0.97462, time = 0.04682\n",
      "Epoch: 0430 | train_loss = 0.02321, train_auc = 0.99463, test_loss = 0.02888, test_auc = 0.97504, time = 0.04723\n",
      "Epoch: 0440 | train_loss = 0.02347, train_auc = 0.99533, test_loss = 0.02746, test_auc = 0.97681, time = 0.04719\n",
      "Epoch: 0450 | train_loss = 0.02502, train_auc = 0.99467, test_loss = 0.02866, test_auc = 0.97554, time = 0.04677\n",
      "Epoch: 0460 | train_loss = 0.02452, train_auc = 0.99480, test_loss = 0.03001, test_auc = 0.97018, time = 0.04708\n",
      "Epoch: 0470 | train_loss = 0.02522, train_auc = 0.99452, test_loss = 0.03161, test_auc = 0.96626, time = 0.04677\n",
      "Epoch: 0480 | train_loss = 0.02267, train_auc = 0.99519, test_loss = 0.03048, test_auc = 0.97059, time = 0.04608\n",
      "Epoch: 0490 | train_loss = 0.02259, train_auc = 0.99524, test_loss = 0.02801, test_auc = 0.97392, time = 0.04670\n",
      "Epoch: 0500 | train_loss = 0.02316, train_auc = 0.99509, test_loss = 0.02734, test_auc = 0.97830, time = 0.04642\n",
      "times: 5, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.12893, train_auc = 0.62221, test_loss = 0.07415, test_auc = 0.53339, time = 0.85061\n",
      "Epoch: 0010 | train_loss = 0.08099, train_auc = 0.91739, test_loss = 0.04743, test_auc = 0.86347, time = 0.05235\n",
      "Epoch: 0020 | train_loss = 0.07057, train_auc = 0.93711, test_loss = 0.04044, test_auc = 0.90219, time = 0.05643\n",
      "Epoch: 0030 | train_loss = 0.06651, train_auc = 0.94756, test_loss = 0.03816, test_auc = 0.90634, time = 0.04882\n",
      "Epoch: 0040 | train_loss = 0.06444, train_auc = 0.95112, test_loss = 0.03494, test_auc = 0.93256, time = 0.04880\n",
      "Epoch: 0050 | train_loss = 0.06015, train_auc = 0.95487, test_loss = 0.03355, test_auc = 0.94551, time = 0.04826\n",
      "Epoch: 0060 | train_loss = 0.05653, train_auc = 0.96279, test_loss = 0.03543, test_auc = 0.92696, time = 0.04704\n",
      "Epoch: 0070 | train_loss = 0.05482, train_auc = 0.96439, test_loss = 0.03245, test_auc = 0.95283, time = 0.04712\n",
      "Epoch: 0080 | train_loss = 0.05245, train_auc = 0.96763, test_loss = 0.03303, test_auc = 0.95338, time = 0.04663\n",
      "Epoch: 0090 | train_loss = 0.04997, train_auc = 0.97097, test_loss = 0.03159, test_auc = 0.95644, time = 0.04569\n",
      "Epoch: 0100 | train_loss = 0.04944, train_auc = 0.97157, test_loss = 0.03542, test_auc = 0.95133, time = 0.04530\n",
      "Epoch: 0110 | train_loss = 0.05036, train_auc = 0.97339, test_loss = 0.03246, test_auc = 0.95685, time = 0.04554\n",
      "Epoch: 0120 | train_loss = 0.04868, train_auc = 0.97374, test_loss = 0.03513, test_auc = 0.95449, time = 0.04467\n",
      "Epoch: 0130 | train_loss = 0.04443, train_auc = 0.97740, test_loss = 0.03378, test_auc = 0.95815, time = 0.04523\n",
      "Epoch: 0140 | train_loss = 0.04360, train_auc = 0.97833, test_loss = 0.03270, test_auc = 0.95985, time = 0.04512\n",
      "Epoch: 0150 | train_loss = 0.04406, train_auc = 0.97911, test_loss = 0.03212, test_auc = 0.96243, time = 0.04499\n",
      "Epoch: 0160 | train_loss = 0.04094, train_auc = 0.98186, test_loss = 0.03328, test_auc = 0.95991, time = 0.04718\n",
      "Epoch: 0170 | train_loss = 0.04017, train_auc = 0.98134, test_loss = 0.03663, test_auc = 0.94662, time = 0.04561\n",
      "Epoch: 0180 | train_loss = 0.04078, train_auc = 0.98276, test_loss = 0.03221, test_auc = 0.96327, time = 0.04514\n",
      "Epoch: 0190 | train_loss = 0.03813, train_auc = 0.98282, test_loss = 0.03297, test_auc = 0.96369, time = 0.04539\n",
      "Epoch: 0200 | train_loss = 0.03737, train_auc = 0.98428, test_loss = 0.02907, test_auc = 0.96936, time = 0.04612\n",
      "Epoch: 0210 | train_loss = 0.03557, train_auc = 0.98544, test_loss = 0.02936, test_auc = 0.96828, time = 0.04515\n",
      "Epoch: 0220 | train_loss = 0.03493, train_auc = 0.98589, test_loss = 0.03126, test_auc = 0.96525, time = 0.04494\n",
      "Epoch: 0230 | train_loss = 0.03249, train_auc = 0.98666, test_loss = 0.02955, test_auc = 0.97037, time = 0.04527\n",
      "Epoch: 0240 | train_loss = 0.03352, train_auc = 0.98668, test_loss = 0.03088, test_auc = 0.96732, time = 0.04510\n",
      "Epoch: 0250 | train_loss = 0.03299, train_auc = 0.98715, test_loss = 0.03025, test_auc = 0.97171, time = 0.04505\n",
      "Epoch: 0260 | train_loss = 0.03466, train_auc = 0.98672, test_loss = 0.03249, test_auc = 0.96538, time = 0.04516\n",
      "Epoch: 0270 | train_loss = 0.03272, train_auc = 0.98765, test_loss = 0.03186, test_auc = 0.96890, time = 0.04500\n",
      "Epoch: 0280 | train_loss = 0.03279, train_auc = 0.98752, test_loss = 0.03060, test_auc = 0.97007, time = 0.04529\n",
      "Epoch: 0290 | train_loss = 0.03466, train_auc = 0.98652, test_loss = 0.03308, test_auc = 0.97012, time = 0.04588\n",
      "Epoch: 0300 | train_loss = 0.03014, train_auc = 0.98909, test_loss = 0.03022, test_auc = 0.97065, time = 0.04514\n",
      "Epoch: 0310 | train_loss = 0.03248, train_auc = 0.98898, test_loss = 0.03224, test_auc = 0.96869, time = 0.04574\n",
      "Epoch: 0320 | train_loss = 0.02996, train_auc = 0.98940, test_loss = 0.03579, test_auc = 0.96856, time = 0.04498\n",
      "Epoch: 0330 | train_loss = 0.02926, train_auc = 0.98913, test_loss = 0.03119, test_auc = 0.97375, time = 0.04536\n",
      "Epoch: 0340 | train_loss = 0.02842, train_auc = 0.99026, test_loss = 0.03010, test_auc = 0.97248, time = 0.04517\n",
      "Epoch: 0350 | train_loss = 0.02802, train_auc = 0.99021, test_loss = 0.02810, test_auc = 0.97142, time = 0.04593\n",
      "Epoch: 0360 | train_loss = 0.02896, train_auc = 0.98917, test_loss = 0.03705, test_auc = 0.96604, time = 0.04595\n",
      "Epoch: 0370 | train_loss = 0.02709, train_auc = 0.99034, test_loss = 0.03461, test_auc = 0.96127, time = 0.04516\n",
      "Epoch: 0380 | train_loss = 0.02792, train_auc = 0.99107, test_loss = 0.03084, test_auc = 0.97331, time = 0.04600\n",
      "Epoch: 0390 | train_loss = 0.03045, train_auc = 0.98970, test_loss = 0.02838, test_auc = 0.97517, time = 0.04541\n",
      "Epoch: 0400 | train_loss = 0.02965, train_auc = 0.99130, test_loss = 0.02869, test_auc = 0.97661, time = 0.04524\n",
      "Epoch: 0410 | train_loss = 0.02702, train_auc = 0.99203, test_loss = 0.02742, test_auc = 0.97648, time = 0.04417\n",
      "Epoch: 0420 | train_loss = 0.02607, train_auc = 0.99178, test_loss = 0.02664, test_auc = 0.97683, time = 0.04439\n",
      "Epoch: 0430 | train_loss = 0.02714, train_auc = 0.99165, test_loss = 0.03074, test_auc = 0.97332, time = 0.04460\n",
      "Epoch: 0440 | train_loss = 0.02706, train_auc = 0.99227, test_loss = 0.02884, test_auc = 0.97416, time = 0.04568\n",
      "Epoch: 0450 | train_loss = 0.02716, train_auc = 0.99209, test_loss = 0.03260, test_auc = 0.97367, time = 0.04483\n",
      "Epoch: 0460 | train_loss = 0.02720, train_auc = 0.99216, test_loss = 0.02871, test_auc = 0.97565, time = 0.04677\n",
      "Epoch: 0470 | train_loss = 0.02590, train_auc = 0.99189, test_loss = 0.03085, test_auc = 0.96986, time = 0.04485\n",
      "Epoch: 0480 | train_loss = 0.02523, train_auc = 0.99253, test_loss = 0.02887, test_auc = 0.97421, time = 0.04676\n",
      "Epoch: 0490 | train_loss = 0.02510, train_auc = 0.99278, test_loss = 0.02932, test_auc = 0.97534, time = 0.04539\n",
      "Epoch: 0500 | train_loss = 0.02659, train_auc = 0.99230, test_loss = 0.02998, test_auc = 0.97452, time = 0.04517\n",
      "times: 5, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14580, train_auc = 0.42774, test_loss = 0.07157, test_auc = 0.57136, time = 0.80218\n",
      "Epoch: 0010 | train_loss = 0.08244, train_auc = 0.90250, test_loss = 0.05318, test_auc = 0.85760, time = 0.05091\n",
      "Epoch: 0020 | train_loss = 0.07108, train_auc = 0.93273, test_loss = 0.04297, test_auc = 0.89216, time = 0.04800\n",
      "Epoch: 0030 | train_loss = 0.06647, train_auc = 0.94640, test_loss = 0.03553, test_auc = 0.93524, time = 0.04765\n",
      "Epoch: 0040 | train_loss = 0.06296, train_auc = 0.95126, test_loss = 0.03889, test_auc = 0.93145, time = 0.04779\n",
      "Epoch: 0050 | train_loss = 0.06151, train_auc = 0.95767, test_loss = 0.03480, test_auc = 0.93963, time = 0.04670\n",
      "Epoch: 0060 | train_loss = 0.05738, train_auc = 0.96217, test_loss = 0.03477, test_auc = 0.94016, time = 0.04584\n",
      "Epoch: 0070 | train_loss = 0.05621, train_auc = 0.96292, test_loss = 0.03460, test_auc = 0.94398, time = 0.04658\n",
      "Epoch: 0080 | train_loss = 0.05239, train_auc = 0.96808, test_loss = 0.03482, test_auc = 0.94473, time = 0.04571\n",
      "Epoch: 0090 | train_loss = 0.05030, train_auc = 0.97094, test_loss = 0.03601, test_auc = 0.93963, time = 0.04454\n",
      "Epoch: 0100 | train_loss = 0.04909, train_auc = 0.97321, test_loss = 0.03347, test_auc = 0.95227, time = 0.04365\n",
      "Epoch: 0110 | train_loss = 0.04584, train_auc = 0.97618, test_loss = 0.03357, test_auc = 0.95286, time = 0.04373\n",
      "Epoch: 0120 | train_loss = 0.04909, train_auc = 0.97635, test_loss = 0.03515, test_auc = 0.95135, time = 0.04351\n",
      "Epoch: 0130 | train_loss = 0.04554, train_auc = 0.97748, test_loss = 0.03381, test_auc = 0.95362, time = 0.04348\n",
      "Epoch: 0140 | train_loss = 0.04152, train_auc = 0.98145, test_loss = 0.03317, test_auc = 0.95051, time = 0.04387\n",
      "Epoch: 0150 | train_loss = 0.04348, train_auc = 0.98004, test_loss = 0.03490, test_auc = 0.95175, time = 0.04402\n",
      "Epoch: 0160 | train_loss = 0.04003, train_auc = 0.98198, test_loss = 0.03341, test_auc = 0.95463, time = 0.04553\n",
      "Epoch: 0170 | train_loss = 0.04000, train_auc = 0.98277, test_loss = 0.03367, test_auc = 0.95191, time = 0.04502\n",
      "Epoch: 0180 | train_loss = 0.03711, train_auc = 0.98531, test_loss = 0.03267, test_auc = 0.95158, time = 0.04503\n",
      "Epoch: 0190 | train_loss = 0.03667, train_auc = 0.98610, test_loss = 0.03418, test_auc = 0.95728, time = 0.04658\n",
      "Epoch: 0200 | train_loss = 0.03599, train_auc = 0.98744, test_loss = 0.03584, test_auc = 0.96069, time = 0.04503\n",
      "Epoch: 0210 | train_loss = 0.03638, train_auc = 0.98722, test_loss = 0.03233, test_auc = 0.96010, time = 0.04592\n",
      "Epoch: 0220 | train_loss = 0.03579, train_auc = 0.98801, test_loss = 0.03213, test_auc = 0.96309, time = 0.04604\n",
      "Epoch: 0230 | train_loss = 0.03399, train_auc = 0.98878, test_loss = 0.03226, test_auc = 0.95908, time = 0.04624\n",
      "Epoch: 0240 | train_loss = 0.03546, train_auc = 0.98788, test_loss = 0.03329, test_auc = 0.95894, time = 0.04486\n",
      "Epoch: 0250 | train_loss = 0.03431, train_auc = 0.98778, test_loss = 0.03376, test_auc = 0.96420, time = 0.04453\n",
      "Epoch: 0260 | train_loss = 0.03250, train_auc = 0.99000, test_loss = 0.03487, test_auc = 0.96394, time = 0.04490\n",
      "Epoch: 0270 | train_loss = 0.03059, train_auc = 0.99099, test_loss = 0.04367, test_auc = 0.95285, time = 0.04446\n",
      "Epoch: 0280 | train_loss = 0.03236, train_auc = 0.99108, test_loss = 0.03259, test_auc = 0.96390, time = 0.04435\n",
      "Epoch: 0290 | train_loss = 0.02986, train_auc = 0.99160, test_loss = 0.03067, test_auc = 0.96838, time = 0.04442\n",
      "Epoch: 0300 | train_loss = 0.02965, train_auc = 0.99292, test_loss = 0.03421, test_auc = 0.96818, time = 0.04463\n",
      "Epoch: 0310 | train_loss = 0.03255, train_auc = 0.99084, test_loss = 0.03310, test_auc = 0.96852, time = 0.04530\n",
      "Epoch: 0320 | train_loss = 0.03006, train_auc = 0.99191, test_loss = 0.02966, test_auc = 0.97042, time = 0.04545\n",
      "Epoch: 0330 | train_loss = 0.02641, train_auc = 0.99323, test_loss = 0.03200, test_auc = 0.96635, time = 0.04615\n",
      "Epoch: 0340 | train_loss = 0.02903, train_auc = 0.99286, test_loss = 0.02919, test_auc = 0.97268, time = 0.04522\n",
      "Epoch: 0350 | train_loss = 0.02675, train_auc = 0.99368, test_loss = 0.03052, test_auc = 0.96878, time = 0.04499\n",
      "Epoch: 0360 | train_loss = 0.02704, train_auc = 0.99406, test_loss = 0.03145, test_auc = 0.96749, time = 0.04509\n",
      "Epoch: 0370 | train_loss = 0.02736, train_auc = 0.99420, test_loss = 0.03192, test_auc = 0.97247, time = 0.04563\n",
      "Epoch: 0380 | train_loss = 0.02697, train_auc = 0.99321, test_loss = 0.02932, test_auc = 0.97256, time = 0.04506\n",
      "Epoch: 0390 | train_loss = 0.02653, train_auc = 0.99448, test_loss = 0.02880, test_auc = 0.97180, time = 0.04555\n",
      "Epoch: 0400 | train_loss = 0.02489, train_auc = 0.99463, test_loss = 0.03102, test_auc = 0.97317, time = 0.04491\n",
      "Epoch: 0410 | train_loss = 0.02281, train_auc = 0.99558, test_loss = 0.03082, test_auc = 0.97220, time = 0.04463\n",
      "Epoch: 0420 | train_loss = 0.02679, train_auc = 0.99434, test_loss = 0.03188, test_auc = 0.97013, time = 0.06716\n",
      "Epoch: 0430 | train_loss = 0.02781, train_auc = 0.99442, test_loss = 0.03303, test_auc = 0.96623, time = 0.04645\n",
      "Epoch: 0440 | train_loss = 0.02572, train_auc = 0.99508, test_loss = 0.03147, test_auc = 0.96508, time = 0.04684\n",
      "Epoch: 0450 | train_loss = 0.02327, train_auc = 0.99565, test_loss = 0.02874, test_auc = 0.97357, time = 0.04777\n",
      "Epoch: 0460 | train_loss = 0.02594, train_auc = 0.99556, test_loss = 0.03169, test_auc = 0.97155, time = 0.04655\n",
      "Epoch: 0470 | train_loss = 0.02102, train_auc = 0.99608, test_loss = 0.02961, test_auc = 0.97409, time = 0.04987\n",
      "Epoch: 0480 | train_loss = 0.02124, train_auc = 0.99597, test_loss = 0.03049, test_auc = 0.97288, time = 0.04496\n",
      "Epoch: 0490 | train_loss = 0.02273, train_auc = 0.99586, test_loss = 0.03191, test_auc = 0.96627, time = 0.04519\n",
      "Epoch: 0500 | train_loss = 0.02350, train_auc = 0.99577, test_loss = 0.02913, test_auc = 0.97266, time = 0.04456\n",
      "times: 5, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14097, train_auc = 0.51755, test_loss = 0.06844, test_auc = 0.62059, time = 0.80205\n",
      "Epoch: 0010 | train_loss = 0.08290, train_auc = 0.90275, test_loss = 0.04562, test_auc = 0.85449, time = 0.04994\n",
      "Epoch: 0020 | train_loss = 0.07424, train_auc = 0.93046, test_loss = 0.04346, test_auc = 0.87555, time = 0.04966\n",
      "Epoch: 0030 | train_loss = 0.07160, train_auc = 0.92885, test_loss = 0.03944, test_auc = 0.90667, time = 0.04863\n",
      "Epoch: 0040 | train_loss = 0.06580, train_auc = 0.94730, test_loss = 0.03635, test_auc = 0.93261, time = 0.04879\n",
      "Epoch: 0050 | train_loss = 0.06209, train_auc = 0.95398, test_loss = 0.03989, test_auc = 0.91170, time = 0.04719\n",
      "Epoch: 0060 | train_loss = 0.06208, train_auc = 0.95775, test_loss = 0.03750, test_auc = 0.94373, time = 0.04866\n",
      "Epoch: 0070 | train_loss = 0.05922, train_auc = 0.95954, test_loss = 0.03343, test_auc = 0.94633, time = 0.04749\n",
      "Epoch: 0080 | train_loss = 0.05729, train_auc = 0.96310, test_loss = 0.03461, test_auc = 0.94246, time = 0.04550\n",
      "Epoch: 0090 | train_loss = 0.05713, train_auc = 0.96309, test_loss = 0.03282, test_auc = 0.94811, time = 0.04630\n",
      "Epoch: 0100 | train_loss = 0.05153, train_auc = 0.96903, test_loss = 0.03303, test_auc = 0.95124, time = 0.04560\n",
      "Epoch: 0110 | train_loss = 0.04856, train_auc = 0.97372, test_loss = 0.03291, test_auc = 0.95733, time = 0.04651\n",
      "Epoch: 0120 | train_loss = 0.04725, train_auc = 0.97388, test_loss = 0.03310, test_auc = 0.95492, time = 0.04585\n",
      "Epoch: 0130 | train_loss = 0.04611, train_auc = 0.97689, test_loss = 0.03511, test_auc = 0.95029, time = 0.04740\n",
      "Epoch: 0140 | train_loss = 0.04638, train_auc = 0.97619, test_loss = 0.03569, test_auc = 0.94503, time = 0.04575\n",
      "Epoch: 0150 | train_loss = 0.04548, train_auc = 0.97611, test_loss = 0.03155, test_auc = 0.95746, time = 0.04563\n",
      "Epoch: 0160 | train_loss = 0.04337, train_auc = 0.97970, test_loss = 0.03438, test_auc = 0.95993, time = 0.04917\n",
      "Epoch: 0170 | train_loss = 0.04266, train_auc = 0.97962, test_loss = 0.03424, test_auc = 0.95895, time = 0.04982\n",
      "Epoch: 0180 | train_loss = 0.03941, train_auc = 0.98219, test_loss = 0.02996, test_auc = 0.96387, time = 0.04513\n",
      "Epoch: 0190 | train_loss = 0.03775, train_auc = 0.98396, test_loss = 0.03508, test_auc = 0.95735, time = 0.04537\n",
      "Epoch: 0200 | train_loss = 0.03701, train_auc = 0.98411, test_loss = 0.03143, test_auc = 0.96047, time = 0.04598\n",
      "Epoch: 0210 | train_loss = 0.03880, train_auc = 0.98368, test_loss = 0.03379, test_auc = 0.95691, time = 0.04672\n",
      "Epoch: 0220 | train_loss = 0.03612, train_auc = 0.98544, test_loss = 0.03219, test_auc = 0.96018, time = 0.04483\n",
      "Epoch: 0230 | train_loss = 0.03499, train_auc = 0.98551, test_loss = 0.03151, test_auc = 0.96795, time = 0.04500\n",
      "Epoch: 0240 | train_loss = 0.03447, train_auc = 0.98568, test_loss = 0.02956, test_auc = 0.96899, time = 0.04536\n",
      "Epoch: 0250 | train_loss = 0.03472, train_auc = 0.98637, test_loss = 0.03285, test_auc = 0.96759, time = 0.04500\n",
      "Epoch: 0260 | train_loss = 0.03241, train_auc = 0.98733, test_loss = 0.03137, test_auc = 0.96851, time = 0.04523\n",
      "Epoch: 0270 | train_loss = 0.03090, train_auc = 0.98814, test_loss = 0.03516, test_auc = 0.94916, time = 0.04449\n",
      "Epoch: 0280 | train_loss = 0.03389, train_auc = 0.98727, test_loss = 0.03060, test_auc = 0.96815, time = 0.04478\n",
      "Epoch: 0290 | train_loss = 0.03222, train_auc = 0.98830, test_loss = 0.03128, test_auc = 0.96855, time = 0.04474\n",
      "Epoch: 0300 | train_loss = 0.02955, train_auc = 0.98992, test_loss = 0.03277, test_auc = 0.96494, time = 0.04496\n",
      "Epoch: 0310 | train_loss = 0.02958, train_auc = 0.99018, test_loss = 0.03050, test_auc = 0.96804, time = 0.04587\n",
      "Epoch: 0320 | train_loss = 0.02972, train_auc = 0.98993, test_loss = 0.03416, test_auc = 0.96799, time = 0.04510\n",
      "Epoch: 0330 | train_loss = 0.02922, train_auc = 0.98968, test_loss = 0.03450, test_auc = 0.97127, time = 0.04536\n",
      "Epoch: 0340 | train_loss = 0.03030, train_auc = 0.99104, test_loss = 0.03062, test_auc = 0.97033, time = 0.04538\n",
      "Epoch: 0350 | train_loss = 0.02823, train_auc = 0.99019, test_loss = 0.03256, test_auc = 0.96973, time = 0.04468\n",
      "Epoch: 0360 | train_loss = 0.02888, train_auc = 0.99061, test_loss = 0.03297, test_auc = 0.97087, time = 0.04515\n",
      "Epoch: 0370 | train_loss = 0.02824, train_auc = 0.99085, test_loss = 0.03146, test_auc = 0.97192, time = 0.04470\n",
      "Epoch: 0380 | train_loss = 0.02770, train_auc = 0.99114, test_loss = 0.02970, test_auc = 0.97169, time = 0.04464\n",
      "Epoch: 0390 | train_loss = 0.02663, train_auc = 0.99139, test_loss = 0.03179, test_auc = 0.96770, time = 0.04508\n",
      "Epoch: 0400 | train_loss = 0.02963, train_auc = 0.99027, test_loss = 0.03037, test_auc = 0.96791, time = 0.04994\n",
      "Epoch: 0410 | train_loss = 0.02713, train_auc = 0.99188, test_loss = 0.02992, test_auc = 0.97108, time = 0.04458\n",
      "Epoch: 0420 | train_loss = 0.02547, train_auc = 0.99288, test_loss = 0.03071, test_auc = 0.97058, time = 0.04472\n",
      "Epoch: 0430 | train_loss = 0.02821, train_auc = 0.99135, test_loss = 0.03271, test_auc = 0.96742, time = 0.04520\n",
      "Epoch: 0440 | train_loss = 0.02708, train_auc = 0.99291, test_loss = 0.03167, test_auc = 0.96906, time = 0.04471\n",
      "Epoch: 0450 | train_loss = 0.02567, train_auc = 0.99386, test_loss = 0.02758, test_auc = 0.97499, time = 0.04623\n",
      "Epoch: 0460 | train_loss = 0.02543, train_auc = 0.99304, test_loss = 0.02761, test_auc = 0.97362, time = 0.04621\n",
      "Epoch: 0470 | train_loss = 0.02677, train_auc = 0.99292, test_loss = 0.02939, test_auc = 0.97259, time = 0.04573\n",
      "Epoch: 0480 | train_loss = 0.02735, train_auc = 0.99303, test_loss = 0.02835, test_auc = 0.97394, time = 0.04551\n",
      "Epoch: 0490 | train_loss = 0.02331, train_auc = 0.99385, test_loss = 0.02850, test_auc = 0.97216, time = 0.04556\n",
      "Epoch: 0500 | train_loss = 0.02377, train_auc = 0.99373, test_loss = 0.02894, test_auc = 0.97344, time = 0.04552\n",
      "times: 5, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14984, train_auc = 0.38552, test_loss = 0.07350, test_auc = 0.53919, time = 0.79528\n",
      "Epoch: 0010 | train_loss = 0.08690, train_auc = 0.87114, test_loss = 0.05129, test_auc = 0.80946, time = 0.05148\n",
      "Epoch: 0020 | train_loss = 0.07613, train_auc = 0.91986, test_loss = 0.04058, test_auc = 0.89889, time = 0.04823\n",
      "Epoch: 0030 | train_loss = 0.06710, train_auc = 0.94444, test_loss = 0.04066, test_auc = 0.90666, time = 0.04752\n",
      "Epoch: 0040 | train_loss = 0.06228, train_auc = 0.95239, test_loss = 0.03787, test_auc = 0.92402, time = 0.04805\n",
      "Epoch: 0050 | train_loss = 0.05746, train_auc = 0.96137, test_loss = 0.03521, test_auc = 0.93353, time = 0.04828\n",
      "Epoch: 0060 | train_loss = 0.05757, train_auc = 0.96292, test_loss = 0.04045, test_auc = 0.93012, time = 0.04912\n",
      "Epoch: 0070 | train_loss = 0.05907, train_auc = 0.95937, test_loss = 0.03939, test_auc = 0.92956, time = 0.04812\n",
      "Epoch: 0080 | train_loss = 0.05557, train_auc = 0.96472, test_loss = 0.04008, test_auc = 0.92242, time = 0.04905\n",
      "Epoch: 0090 | train_loss = 0.05304, train_auc = 0.96765, test_loss = 0.03354, test_auc = 0.94580, time = 0.04758\n",
      "Epoch: 0100 | train_loss = 0.05060, train_auc = 0.97071, test_loss = 0.03431, test_auc = 0.94384, time = 0.04929\n",
      "Epoch: 0110 | train_loss = 0.04742, train_auc = 0.97417, test_loss = 0.03549, test_auc = 0.94111, time = 0.04748\n",
      "Epoch: 0120 | train_loss = 0.04884, train_auc = 0.97424, test_loss = 0.03434, test_auc = 0.94173, time = 0.04679\n",
      "Epoch: 0130 | train_loss = 0.04726, train_auc = 0.97669, test_loss = 0.03488, test_auc = 0.94958, time = 0.04755\n",
      "Epoch: 0140 | train_loss = 0.04268, train_auc = 0.97885, test_loss = 0.03421, test_auc = 0.94593, time = 0.04681\n",
      "Epoch: 0150 | train_loss = 0.04238, train_auc = 0.98018, test_loss = 0.03891, test_auc = 0.91994, time = 0.04722\n",
      "Epoch: 0160 | train_loss = 0.04078, train_auc = 0.98091, test_loss = 0.03411, test_auc = 0.94274, time = 0.04651\n",
      "Epoch: 0170 | train_loss = 0.03941, train_auc = 0.98199, test_loss = 0.03415, test_auc = 0.95059, time = 0.04695\n",
      "Epoch: 0180 | train_loss = 0.03714, train_auc = 0.98492, test_loss = 0.03370, test_auc = 0.95368, time = 0.04656\n",
      "Epoch: 0190 | train_loss = 0.03791, train_auc = 0.98435, test_loss = 0.03163, test_auc = 0.95508, time = 0.04670\n",
      "Epoch: 0200 | train_loss = 0.03817, train_auc = 0.98435, test_loss = 0.03192, test_auc = 0.95416, time = 0.04615\n",
      "Epoch: 0210 | train_loss = 0.04007, train_auc = 0.98411, test_loss = 0.03634, test_auc = 0.94041, time = 0.04613\n",
      "Epoch: 0220 | train_loss = 0.03432, train_auc = 0.98785, test_loss = 0.03278, test_auc = 0.95335, time = 0.05012\n",
      "Epoch: 0230 | train_loss = 0.03612, train_auc = 0.98821, test_loss = 0.03147, test_auc = 0.95830, time = 0.05292\n",
      "Epoch: 0240 | train_loss = 0.03273, train_auc = 0.98804, test_loss = 0.03332, test_auc = 0.95801, time = 0.04587\n",
      "Epoch: 0250 | train_loss = 0.03172, train_auc = 0.99053, test_loss = 0.03361, test_auc = 0.95676, time = 0.04574\n",
      "Epoch: 0260 | train_loss = 0.03386, train_auc = 0.98811, test_loss = 0.03130, test_auc = 0.96067, time = 0.04545\n",
      "Epoch: 0270 | train_loss = 0.03190, train_auc = 0.98975, test_loss = 0.03307, test_auc = 0.95751, time = 0.04733\n",
      "Epoch: 0280 | train_loss = 0.03174, train_auc = 0.98915, test_loss = 0.03183, test_auc = 0.95966, time = 0.04735\n",
      "Epoch: 0290 | train_loss = 0.02891, train_auc = 0.99055, test_loss = 0.03310, test_auc = 0.95915, time = 0.04715\n",
      "Epoch: 0300 | train_loss = 0.02951, train_auc = 0.99178, test_loss = 0.03256, test_auc = 0.96216, time = 0.04832\n",
      "Epoch: 0310 | train_loss = 0.02958, train_auc = 0.99249, test_loss = 0.03408, test_auc = 0.95723, time = 0.04669\n",
      "Epoch: 0320 | train_loss = 0.02917, train_auc = 0.99092, test_loss = 0.03673, test_auc = 0.95228, time = 0.04734\n",
      "Epoch: 0330 | train_loss = 0.02910, train_auc = 0.99119, test_loss = 0.03437, test_auc = 0.95454, time = 0.04643\n",
      "Epoch: 0340 | train_loss = 0.02831, train_auc = 0.99216, test_loss = 0.03280, test_auc = 0.95929, time = 0.04763\n",
      "Epoch: 0350 | train_loss = 0.02733, train_auc = 0.99126, test_loss = 0.03271, test_auc = 0.95765, time = 0.04811\n",
      "Epoch: 0360 | train_loss = 0.02551, train_auc = 0.99277, test_loss = 0.03271, test_auc = 0.96160, time = 0.04631\n",
      "Epoch: 0370 | train_loss = 0.02949, train_auc = 0.99184, test_loss = 0.03236, test_auc = 0.96500, time = 0.04847\n",
      "Epoch: 0380 | train_loss = 0.02648, train_auc = 0.99275, test_loss = 0.02898, test_auc = 0.96901, time = 0.05092\n",
      "Epoch: 0390 | train_loss = 0.02736, train_auc = 0.99258, test_loss = 0.03177, test_auc = 0.96872, time = 0.04766\n",
      "Epoch: 0400 | train_loss = 0.02445, train_auc = 0.99344, test_loss = 0.03219, test_auc = 0.96676, time = 0.04707\n",
      "Epoch: 0410 | train_loss = 0.02463, train_auc = 0.99367, test_loss = 0.03390, test_auc = 0.96495, time = 0.04628\n",
      "Epoch: 0420 | train_loss = 0.02630, train_auc = 0.99319, test_loss = 0.03305, test_auc = 0.96507, time = 0.04539\n",
      "Epoch: 0430 | train_loss = 0.02443, train_auc = 0.99361, test_loss = 0.03420, test_auc = 0.96026, time = 0.04570\n",
      "Epoch: 0440 | train_loss = 0.02475, train_auc = 0.99390, test_loss = 0.03131, test_auc = 0.96636, time = 0.04989\n",
      "Epoch: 0450 | train_loss = 0.02585, train_auc = 0.99380, test_loss = 0.03273, test_auc = 0.96676, time = 0.04724\n",
      "Epoch: 0460 | train_loss = 0.02590, train_auc = 0.99235, test_loss = 0.03122, test_auc = 0.96759, time = 0.04675\n",
      "Epoch: 0470 | train_loss = 0.02482, train_auc = 0.99335, test_loss = 0.03442, test_auc = 0.96126, time = 0.04669\n",
      "Epoch: 0480 | train_loss = 0.02604, train_auc = 0.99306, test_loss = 0.03219, test_auc = 0.96728, time = 0.04552\n",
      "Epoch: 0490 | train_loss = 0.02246, train_auc = 0.99408, test_loss = 0.03229, test_auc = 0.96457, time = 0.04518\n",
      "Epoch: 0500 | train_loss = 0.02447, train_auc = 0.99377, test_loss = 0.02958, test_auc = 0.96871, time = 0.04489\n",
      "times: 5, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14514, train_auc = 0.45351, test_loss = 0.07365, test_auc = 0.53740, time = 0.80834\n",
      "Epoch: 0010 | train_loss = 0.08373, train_auc = 0.89674, test_loss = 0.05877, test_auc = 0.78543, time = 0.05104\n",
      "Epoch: 0020 | train_loss = 0.07481, train_auc = 0.92707, test_loss = 0.03881, test_auc = 0.91470, time = 0.05009\n",
      "Epoch: 0030 | train_loss = 0.06761, train_auc = 0.94234, test_loss = 0.03623, test_auc = 0.93399, time = 0.04797\n",
      "Epoch: 0040 | train_loss = 0.06576, train_auc = 0.94811, test_loss = 0.03568, test_auc = 0.93810, time = 0.04781\n",
      "Epoch: 0050 | train_loss = 0.06435, train_auc = 0.95130, test_loss = 0.03272, test_auc = 0.95087, time = 0.04809\n",
      "Epoch: 0060 | train_loss = 0.05953, train_auc = 0.95730, test_loss = 0.03462, test_auc = 0.95193, time = 0.04790\n",
      "Epoch: 0070 | train_loss = 0.05739, train_auc = 0.96036, test_loss = 0.03472, test_auc = 0.94982, time = 0.04693\n",
      "Epoch: 0080 | train_loss = 0.05594, train_auc = 0.96244, test_loss = 0.03445, test_auc = 0.94696, time = 0.04847\n",
      "Epoch: 0090 | train_loss = 0.05514, train_auc = 0.96401, test_loss = 0.03468, test_auc = 0.95614, time = 0.04728\n",
      "Epoch: 0100 | train_loss = 0.05210, train_auc = 0.96806, test_loss = 0.03284, test_auc = 0.95399, time = 0.04717\n",
      "Epoch: 0110 | train_loss = 0.05082, train_auc = 0.96947, test_loss = 0.03302, test_auc = 0.95842, time = 0.04689\n",
      "Epoch: 0120 | train_loss = 0.04786, train_auc = 0.97108, test_loss = 0.03108, test_auc = 0.96010, time = 0.04712\n",
      "Epoch: 0130 | train_loss = 0.04682, train_auc = 0.97269, test_loss = 0.03380, test_auc = 0.94660, time = 0.04621\n",
      "Epoch: 0140 | train_loss = 0.04679, train_auc = 0.97547, test_loss = 0.03464, test_auc = 0.95605, time = 0.04688\n",
      "Epoch: 0150 | train_loss = 0.04462, train_auc = 0.97581, test_loss = 0.02989, test_auc = 0.96580, time = 0.04636\n",
      "Epoch: 0160 | train_loss = 0.04423, train_auc = 0.97934, test_loss = 0.03014, test_auc = 0.96719, time = 0.04624\n",
      "Epoch: 0170 | train_loss = 0.04195, train_auc = 0.97998, test_loss = 0.03007, test_auc = 0.96562, time = 0.04592\n",
      "Epoch: 0180 | train_loss = 0.04008, train_auc = 0.98175, test_loss = 0.02813, test_auc = 0.96989, time = 0.04634\n",
      "Epoch: 0190 | train_loss = 0.04107, train_auc = 0.98103, test_loss = 0.02958, test_auc = 0.96739, time = 0.04597\n",
      "Epoch: 0200 | train_loss = 0.03843, train_auc = 0.98298, test_loss = 0.03115, test_auc = 0.96081, time = 0.04580\n",
      "Epoch: 0210 | train_loss = 0.03886, train_auc = 0.98351, test_loss = 0.03324, test_auc = 0.96513, time = 0.04556\n",
      "Epoch: 0220 | train_loss = 0.03721, train_auc = 0.98465, test_loss = 0.03587, test_auc = 0.95271, time = 0.04648\n",
      "Epoch: 0230 | train_loss = 0.03852, train_auc = 0.98488, test_loss = 0.03280, test_auc = 0.96885, time = 0.04961\n",
      "Epoch: 0240 | train_loss = 0.03612, train_auc = 0.98530, test_loss = 0.02836, test_auc = 0.97011, time = 0.04767\n",
      "Epoch: 0250 | train_loss = 0.03505, train_auc = 0.98731, test_loss = 0.02955, test_auc = 0.97088, time = 0.04605\n",
      "Epoch: 0260 | train_loss = 0.03540, train_auc = 0.98684, test_loss = 0.03062, test_auc = 0.96769, time = 0.04598\n",
      "Epoch: 0270 | train_loss = 0.03541, train_auc = 0.98718, test_loss = 0.03408, test_auc = 0.94798, time = 0.04620\n",
      "Epoch: 0280 | train_loss = 0.03050, train_auc = 0.98922, test_loss = 0.03138, test_auc = 0.96653, time = 0.04549\n",
      "Epoch: 0290 | train_loss = 0.03355, train_auc = 0.98845, test_loss = 0.03026, test_auc = 0.96950, time = 0.04579\n",
      "Epoch: 0300 | train_loss = 0.03084, train_auc = 0.98967, test_loss = 0.03093, test_auc = 0.96651, time = 0.04789\n",
      "Epoch: 0310 | train_loss = 0.02908, train_auc = 0.99126, test_loss = 0.02987, test_auc = 0.97119, time = 0.04726\n",
      "Epoch: 0320 | train_loss = 0.02774, train_auc = 0.99130, test_loss = 0.03119, test_auc = 0.96924, time = 0.04611\n",
      "Epoch: 0330 | train_loss = 0.02885, train_auc = 0.99149, test_loss = 0.03029, test_auc = 0.97145, time = 0.04720\n",
      "Epoch: 0340 | train_loss = 0.02948, train_auc = 0.99066, test_loss = 0.03205, test_auc = 0.97139, time = 0.05256\n",
      "Epoch: 0350 | train_loss = 0.02924, train_auc = 0.99156, test_loss = 0.03118, test_auc = 0.96874, time = 0.04682\n",
      "Epoch: 0360 | train_loss = 0.02651, train_auc = 0.99234, test_loss = 0.02831, test_auc = 0.97045, time = 0.04723\n",
      "Epoch: 0370 | train_loss = 0.02736, train_auc = 0.99206, test_loss = 0.02813, test_auc = 0.97471, time = 0.04859\n",
      "Epoch: 0380 | train_loss = 0.02755, train_auc = 0.99282, test_loss = 0.02723, test_auc = 0.97540, time = 0.04674\n",
      "Epoch: 0390 | train_loss = 0.02566, train_auc = 0.99359, test_loss = 0.02801, test_auc = 0.97382, time = 0.04699\n",
      "Epoch: 0400 | train_loss = 0.02796, train_auc = 0.99205, test_loss = 0.03070, test_auc = 0.96874, time = 0.04697\n",
      "Epoch: 0410 | train_loss = 0.02562, train_auc = 0.99342, test_loss = 0.02707, test_auc = 0.97610, time = 0.04634\n",
      "Epoch: 0420 | train_loss = 0.02451, train_auc = 0.99286, test_loss = 0.02904, test_auc = 0.97341, time = 0.04531\n",
      "Epoch: 0430 | train_loss = 0.02637, train_auc = 0.99255, test_loss = 0.03124, test_auc = 0.97599, time = 0.04561\n",
      "Epoch: 0440 | train_loss = 0.02625, train_auc = 0.99305, test_loss = 0.02722, test_auc = 0.97710, time = 0.04652\n",
      "Epoch: 0450 | train_loss = 0.02688, train_auc = 0.99276, test_loss = 0.02765, test_auc = 0.97495, time = 0.04624\n",
      "Epoch: 0460 | train_loss = 0.02573, train_auc = 0.99271, test_loss = 0.03126, test_auc = 0.97050, time = 0.04720\n",
      "Epoch: 0470 | train_loss = 0.02605, train_auc = 0.99290, test_loss = 0.03122, test_auc = 0.97077, time = 0.04632\n",
      "Epoch: 0480 | train_loss = 0.02585, train_auc = 0.99270, test_loss = 0.02878, test_auc = 0.97269, time = 0.04633\n",
      "Epoch: 0490 | train_loss = 0.02541, train_auc = 0.99299, test_loss = 0.02805, test_auc = 0.97412, time = 0.04602\n",
      "Epoch: 0500 | train_loss = 0.02340, train_auc = 0.99383, test_loss = 0.02836, test_auc = 0.97333, time = 0.04699\n",
      "times: 6, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13131, train_auc = 0.57555, test_loss = 0.07421, test_auc = 0.52176, time = 0.80284\n",
      "Epoch: 0010 | train_loss = 0.08110, train_auc = 0.90999, test_loss = 0.05998, test_auc = 0.79229, time = 0.05029\n",
      "Epoch: 0020 | train_loss = 0.07137, train_auc = 0.93478, test_loss = 0.04240, test_auc = 0.88032, time = 0.05089\n",
      "Epoch: 0030 | train_loss = 0.06657, train_auc = 0.94482, test_loss = 0.03770, test_auc = 0.92697, time = 0.04842\n",
      "Epoch: 0040 | train_loss = 0.06361, train_auc = 0.95427, test_loss = 0.03497, test_auc = 0.93676, time = 0.04869\n",
      "Epoch: 0050 | train_loss = 0.06169, train_auc = 0.95355, test_loss = 0.03689, test_auc = 0.93508, time = 0.04828\n",
      "Epoch: 0060 | train_loss = 0.05815, train_auc = 0.96040, test_loss = 0.03715, test_auc = 0.93674, time = 0.05118\n",
      "Epoch: 0070 | train_loss = 0.05529, train_auc = 0.96342, test_loss = 0.03351, test_auc = 0.94655, time = 0.05219\n",
      "Epoch: 0080 | train_loss = 0.05483, train_auc = 0.96698, test_loss = 0.03431, test_auc = 0.94376, time = 0.04746\n",
      "Epoch: 0090 | train_loss = 0.05420, train_auc = 0.96633, test_loss = 0.03291, test_auc = 0.94804, time = 0.04764\n",
      "Epoch: 0100 | train_loss = 0.05260, train_auc = 0.96864, test_loss = 0.03816, test_auc = 0.93970, time = 0.06735\n",
      "Epoch: 0110 | train_loss = 0.04992, train_auc = 0.97102, test_loss = 0.04044, test_auc = 0.94593, time = 0.04960\n",
      "Epoch: 0120 | train_loss = 0.04741, train_auc = 0.97444, test_loss = 0.03806, test_auc = 0.94181, time = 0.04904\n",
      "Epoch: 0130 | train_loss = 0.04521, train_auc = 0.97697, test_loss = 0.03309, test_auc = 0.95314, time = 0.04877\n",
      "Epoch: 0140 | train_loss = 0.04511, train_auc = 0.97729, test_loss = 0.03352, test_auc = 0.95036, time = 0.05088\n",
      "Epoch: 0150 | train_loss = 0.04361, train_auc = 0.97918, test_loss = 0.03220, test_auc = 0.95442, time = 0.04908\n",
      "Epoch: 0160 | train_loss = 0.04220, train_auc = 0.98034, test_loss = 0.03422, test_auc = 0.95832, time = 0.05063\n",
      "Epoch: 0170 | train_loss = 0.04101, train_auc = 0.98175, test_loss = 0.03047, test_auc = 0.96158, time = 0.04951\n",
      "Epoch: 0180 | train_loss = 0.04063, train_auc = 0.98281, test_loss = 0.03328, test_auc = 0.95629, time = 0.04905\n",
      "Epoch: 0190 | train_loss = 0.03790, train_auc = 0.98484, test_loss = 0.03538, test_auc = 0.94497, time = 0.04824\n",
      "Epoch: 0200 | train_loss = 0.03721, train_auc = 0.98583, test_loss = 0.03199, test_auc = 0.96110, time = 0.04954\n",
      "Epoch: 0210 | train_loss = 0.03691, train_auc = 0.98591, test_loss = 0.03634, test_auc = 0.95560, time = 0.04912\n",
      "Epoch: 0220 | train_loss = 0.03770, train_auc = 0.98510, test_loss = 0.03378, test_auc = 0.96129, time = 0.04769\n",
      "Epoch: 0230 | train_loss = 0.03411, train_auc = 0.98924, test_loss = 0.03234, test_auc = 0.96132, time = 0.04763\n",
      "Epoch: 0240 | train_loss = 0.03380, train_auc = 0.98823, test_loss = 0.03590, test_auc = 0.95974, time = 0.04899\n",
      "Epoch: 0250 | train_loss = 0.03417, train_auc = 0.98886, test_loss = 0.03503, test_auc = 0.96058, time = 0.04811\n",
      "Epoch: 0260 | train_loss = 0.03075, train_auc = 0.99058, test_loss = 0.03510, test_auc = 0.95031, time = 0.04719\n",
      "Epoch: 0270 | train_loss = 0.03171, train_auc = 0.99004, test_loss = 0.03310, test_auc = 0.95924, time = 0.05262\n",
      "Epoch: 0280 | train_loss = 0.03195, train_auc = 0.99043, test_loss = 0.03092, test_auc = 0.96440, time = 0.04891\n",
      "Epoch: 0290 | train_loss = 0.03238, train_auc = 0.99083, test_loss = 0.03234, test_auc = 0.96271, time = 0.04701\n",
      "Epoch: 0300 | train_loss = 0.03068, train_auc = 0.99167, test_loss = 0.03150, test_auc = 0.96139, time = 0.04747\n",
      "Epoch: 0310 | train_loss = 0.03061, train_auc = 0.99171, test_loss = 0.03854, test_auc = 0.95874, time = 0.04771\n",
      "Epoch: 0320 | train_loss = 0.03058, train_auc = 0.99226, test_loss = 0.03551, test_auc = 0.94573, time = 0.04693\n",
      "Epoch: 0330 | train_loss = 0.02986, train_auc = 0.99222, test_loss = 0.03215, test_auc = 0.96521, time = 0.04631\n",
      "Epoch: 0340 | train_loss = 0.03129, train_auc = 0.99228, test_loss = 0.03275, test_auc = 0.96674, time = 0.04640\n",
      "Epoch: 0350 | train_loss = 0.02919, train_auc = 0.99250, test_loss = 0.03303, test_auc = 0.96721, time = 0.04624\n",
      "Epoch: 0360 | train_loss = 0.02840, train_auc = 0.99362, test_loss = 0.03082, test_auc = 0.96698, time = 0.04701\n",
      "Epoch: 0370 | train_loss = 0.02744, train_auc = 0.99349, test_loss = 0.03118, test_auc = 0.96436, time = 0.04637\n",
      "Epoch: 0380 | train_loss = 0.02548, train_auc = 0.99416, test_loss = 0.03404, test_auc = 0.96557, time = 0.04750\n",
      "Epoch: 0390 | train_loss = 0.03143, train_auc = 0.99245, test_loss = 0.03286, test_auc = 0.96066, time = 0.04716\n",
      "Epoch: 0400 | train_loss = 0.02654, train_auc = 0.99369, test_loss = 0.02994, test_auc = 0.96988, time = 0.04787\n",
      "Epoch: 0410 | train_loss = 0.02759, train_auc = 0.99391, test_loss = 0.03069, test_auc = 0.97055, time = 0.04906\n",
      "Epoch: 0420 | train_loss = 0.02545, train_auc = 0.99404, test_loss = 0.03013, test_auc = 0.96998, time = 0.04680\n",
      "Epoch: 0430 | train_loss = 0.02261, train_auc = 0.99511, test_loss = 0.03424, test_auc = 0.96533, time = 0.04815\n",
      "Epoch: 0440 | train_loss = 0.02614, train_auc = 0.99430, test_loss = 0.03254, test_auc = 0.97071, time = 0.04730\n",
      "Epoch: 0450 | train_loss = 0.02604, train_auc = 0.99441, test_loss = 0.02959, test_auc = 0.97221, time = 0.04796\n",
      "Epoch: 0460 | train_loss = 0.02444, train_auc = 0.99508, test_loss = 0.02961, test_auc = 0.97317, time = 0.04698\n",
      "Epoch: 0470 | train_loss = 0.02298, train_auc = 0.99577, test_loss = 0.03737, test_auc = 0.93402, time = 0.04807\n",
      "Epoch: 0480 | train_loss = 0.02394, train_auc = 0.99537, test_loss = 0.03160, test_auc = 0.96697, time = 0.04573\n",
      "Epoch: 0490 | train_loss = 0.02153, train_auc = 0.99585, test_loss = 0.03090, test_auc = 0.96702, time = 0.04670\n",
      "Epoch: 0500 | train_loss = 0.02197, train_auc = 0.99583, test_loss = 0.03014, test_auc = 0.97205, time = 0.04607\n",
      "times: 6, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14547, train_auc = 0.42461, test_loss = 0.07317, test_auc = 0.54380, time = 0.80875\n",
      "Epoch: 0010 | train_loss = 0.08133, train_auc = 0.90520, test_loss = 0.05123, test_auc = 0.81432, time = 0.04875\n",
      "Epoch: 0020 | train_loss = 0.07206, train_auc = 0.93737, test_loss = 0.04060, test_auc = 0.90491, time = 0.04809\n",
      "Epoch: 0030 | train_loss = 0.06481, train_auc = 0.94668, test_loss = 0.04023, test_auc = 0.91171, time = 0.04815\n",
      "Epoch: 0040 | train_loss = 0.06232, train_auc = 0.95376, test_loss = 0.03544, test_auc = 0.93899, time = 0.04585\n",
      "Epoch: 0050 | train_loss = 0.06112, train_auc = 0.95524, test_loss = 0.03441, test_auc = 0.94400, time = 0.04606\n",
      "Epoch: 0060 | train_loss = 0.05739, train_auc = 0.96196, test_loss = 0.03457, test_auc = 0.94529, time = 0.04668\n",
      "Epoch: 0070 | train_loss = 0.05459, train_auc = 0.96558, test_loss = 0.03329, test_auc = 0.95081, time = 0.04528\n",
      "Epoch: 0080 | train_loss = 0.05644, train_auc = 0.96228, test_loss = 0.03678, test_auc = 0.94510, time = 0.04622\n",
      "Epoch: 0090 | train_loss = 0.05221, train_auc = 0.96936, test_loss = 0.03593, test_auc = 0.94469, time = 0.04546\n",
      "Epoch: 0100 | train_loss = 0.04998, train_auc = 0.97185, test_loss = 0.03264, test_auc = 0.95522, time = 0.04584\n",
      "Epoch: 0110 | train_loss = 0.04717, train_auc = 0.97542, test_loss = 0.03592, test_auc = 0.94808, time = 0.04611\n",
      "Epoch: 0120 | train_loss = 0.04555, train_auc = 0.97696, test_loss = 0.03228, test_auc = 0.95682, time = 0.04503\n",
      "Epoch: 0130 | train_loss = 0.04707, train_auc = 0.97623, test_loss = 0.03447, test_auc = 0.94901, time = 0.04513\n",
      "Epoch: 0140 | train_loss = 0.04366, train_auc = 0.97905, test_loss = 0.03153, test_auc = 0.95881, time = 0.04482\n",
      "Epoch: 0150 | train_loss = 0.04324, train_auc = 0.98018, test_loss = 0.03211, test_auc = 0.95491, time = 0.04470\n",
      "Epoch: 0160 | train_loss = 0.04270, train_auc = 0.98079, test_loss = 0.03374, test_auc = 0.95036, time = 0.04409\n",
      "Epoch: 0170 | train_loss = 0.04115, train_auc = 0.98137, test_loss = 0.03129, test_auc = 0.95978, time = 0.04398\n",
      "Epoch: 0180 | train_loss = 0.03796, train_auc = 0.98396, test_loss = 0.03227, test_auc = 0.95901, time = 0.04504\n",
      "Epoch: 0190 | train_loss = 0.03736, train_auc = 0.98375, test_loss = 0.03352, test_auc = 0.95922, time = 0.04665\n",
      "Epoch: 0200 | train_loss = 0.03853, train_auc = 0.98391, test_loss = 0.03345, test_auc = 0.95370, time = 0.04577\n",
      "Epoch: 0210 | train_loss = 0.03651, train_auc = 0.98391, test_loss = 0.03273, test_auc = 0.95898, time = 0.04530\n",
      "Epoch: 0220 | train_loss = 0.03581, train_auc = 0.98604, test_loss = 0.03173, test_auc = 0.95803, time = 0.04496\n",
      "Epoch: 0230 | train_loss = 0.03474, train_auc = 0.98642, test_loss = 0.03332, test_auc = 0.95272, time = 0.04702\n",
      "Epoch: 0240 | train_loss = 0.03510, train_auc = 0.98696, test_loss = 0.03373, test_auc = 0.95236, time = 0.04554\n",
      "Epoch: 0250 | train_loss = 0.03365, train_auc = 0.98749, test_loss = 0.03358, test_auc = 0.96061, time = 0.04626\n",
      "Epoch: 0260 | train_loss = 0.03393, train_auc = 0.98761, test_loss = 0.03810, test_auc = 0.95490, time = 0.04536\n",
      "Epoch: 0270 | train_loss = 0.03360, train_auc = 0.98754, test_loss = 0.03149, test_auc = 0.96428, time = 0.04687\n",
      "Epoch: 0280 | train_loss = 0.03099, train_auc = 0.98933, test_loss = 0.03026, test_auc = 0.96474, time = 0.04590\n",
      "Epoch: 0290 | train_loss = 0.03168, train_auc = 0.98861, test_loss = 0.03886, test_auc = 0.92303, time = 0.04656\n",
      "Epoch: 0300 | train_loss = 0.03420, train_auc = 0.98825, test_loss = 0.03373, test_auc = 0.95683, time = 0.04625\n",
      "Epoch: 0310 | train_loss = 0.03149, train_auc = 0.98941, test_loss = 0.02919, test_auc = 0.96783, time = 0.04610\n",
      "Epoch: 0320 | train_loss = 0.03168, train_auc = 0.98922, test_loss = 0.03178, test_auc = 0.96516, time = 0.04614\n",
      "Epoch: 0330 | train_loss = 0.03029, train_auc = 0.99007, test_loss = 0.03442, test_auc = 0.95944, time = 0.04700\n",
      "Epoch: 0340 | train_loss = 0.02917, train_auc = 0.98970, test_loss = 0.02958, test_auc = 0.96708, time = 0.04754\n",
      "Epoch: 0350 | train_loss = 0.02701, train_auc = 0.99057, test_loss = 0.03131, test_auc = 0.96708, time = 0.04729\n",
      "Epoch: 0360 | train_loss = 0.02742, train_auc = 0.99055, test_loss = 0.03055, test_auc = 0.96594, time = 0.04646\n",
      "Epoch: 0370 | train_loss = 0.02726, train_auc = 0.99037, test_loss = 0.03130, test_auc = 0.96455, time = 0.04644\n",
      "Epoch: 0380 | train_loss = 0.03190, train_auc = 0.98940, test_loss = 0.03096, test_auc = 0.96362, time = 0.04591\n",
      "Epoch: 0390 | train_loss = 0.02911, train_auc = 0.99021, test_loss = 0.03027, test_auc = 0.96579, time = 0.04734\n",
      "Epoch: 0400 | train_loss = 0.02672, train_auc = 0.99177, test_loss = 0.03108, test_auc = 0.96608, time = 0.04613\n",
      "Epoch: 0410 | train_loss = 0.02593, train_auc = 0.99163, test_loss = 0.03101, test_auc = 0.96512, time = 0.04595\n",
      "Epoch: 0420 | train_loss = 0.02675, train_auc = 0.99143, test_loss = 0.03076, test_auc = 0.96710, time = 0.04625\n",
      "Epoch: 0430 | train_loss = 0.02734, train_auc = 0.99126, test_loss = 0.03106, test_auc = 0.96971, time = 0.04628\n",
      "Epoch: 0440 | train_loss = 0.02529, train_auc = 0.99212, test_loss = 0.03101, test_auc = 0.96473, time = 0.04769\n",
      "Epoch: 0450 | train_loss = 0.02814, train_auc = 0.99120, test_loss = 0.03252, test_auc = 0.95656, time = 0.04600\n",
      "Epoch: 0460 | train_loss = 0.02822, train_auc = 0.99135, test_loss = 0.02901, test_auc = 0.96275, time = 0.04720\n",
      "Epoch: 0470 | train_loss = 0.02523, train_auc = 0.99231, test_loss = 0.02978, test_auc = 0.96943, time = 0.04635\n",
      "Epoch: 0480 | train_loss = 0.02647, train_auc = 0.99165, test_loss = 0.03066, test_auc = 0.96732, time = 0.04600\n",
      "Epoch: 0490 | train_loss = 0.02357, train_auc = 0.99262, test_loss = 0.02993, test_auc = 0.97057, time = 0.04601\n",
      "Epoch: 0500 | train_loss = 0.02457, train_auc = 0.99130, test_loss = 0.02910, test_auc = 0.96936, time = 0.04650\n",
      "times: 6, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13624, train_auc = 0.52093, test_loss = 0.07280, test_auc = 0.55932, time = 0.81968\n",
      "Epoch: 0010 | train_loss = 0.08319, train_auc = 0.90454, test_loss = 0.05027, test_auc = 0.82649, time = 0.05035\n",
      "Epoch: 0020 | train_loss = 0.07241, train_auc = 0.93173, test_loss = 0.04231, test_auc = 0.88326, time = 0.04750\n",
      "Epoch: 0030 | train_loss = 0.06592, train_auc = 0.94396, test_loss = 0.03924, test_auc = 0.90907, time = 0.04597\n",
      "Epoch: 0040 | train_loss = 0.06222, train_auc = 0.95099, test_loss = 0.03692, test_auc = 0.92886, time = 0.04756\n",
      "Epoch: 0050 | train_loss = 0.07628, train_auc = 0.93212, test_loss = 0.03517, test_auc = 0.94015, time = 0.04669\n",
      "Epoch: 0060 | train_loss = 0.05846, train_auc = 0.95715, test_loss = 0.03511, test_auc = 0.93563, time = 0.04563\n",
      "Epoch: 0070 | train_loss = 0.05592, train_auc = 0.96200, test_loss = 0.03928, test_auc = 0.92728, time = 0.04539\n",
      "Epoch: 0080 | train_loss = 0.05399, train_auc = 0.96474, test_loss = 0.03613, test_auc = 0.93938, time = 0.04503\n",
      "Epoch: 0090 | train_loss = 0.05413, train_auc = 0.96533, test_loss = 0.03929, test_auc = 0.93933, time = 0.04480\n",
      "Epoch: 0100 | train_loss = 0.05143, train_auc = 0.96870, test_loss = 0.03276, test_auc = 0.95390, time = 0.04587\n",
      "Epoch: 0110 | train_loss = 0.05040, train_auc = 0.96981, test_loss = 0.03480, test_auc = 0.95179, time = 0.04534\n",
      "Epoch: 0120 | train_loss = 0.04756, train_auc = 0.97298, test_loss = 0.03475, test_auc = 0.95236, time = 0.04918\n",
      "Epoch: 0130 | train_loss = 0.04809, train_auc = 0.97274, test_loss = 0.03162, test_auc = 0.95588, time = 0.04541\n",
      "Epoch: 0140 | train_loss = 0.04488, train_auc = 0.97582, test_loss = 0.03277, test_auc = 0.95520, time = 0.04555\n",
      "Epoch: 0150 | train_loss = 0.04633, train_auc = 0.97565, test_loss = 0.03500, test_auc = 0.95591, time = 0.04556\n",
      "Epoch: 0160 | train_loss = 0.04290, train_auc = 0.97777, test_loss = 0.03090, test_auc = 0.96050, time = 0.04437\n",
      "Epoch: 0170 | train_loss = 0.04279, train_auc = 0.97786, test_loss = 0.03387, test_auc = 0.95764, time = 0.04528\n",
      "Epoch: 0180 | train_loss = 0.04371, train_auc = 0.97809, test_loss = 0.03400, test_auc = 0.94780, time = 0.04467\n",
      "Epoch: 0190 | train_loss = 0.03969, train_auc = 0.98026, test_loss = 0.03315, test_auc = 0.95188, time = 0.04540\n",
      "Epoch: 0200 | train_loss = 0.03950, train_auc = 0.97985, test_loss = 0.03439, test_auc = 0.95027, time = 0.04546\n",
      "Epoch: 0210 | train_loss = 0.03850, train_auc = 0.98078, test_loss = 0.03103, test_auc = 0.95707, time = 0.04493\n",
      "Epoch: 0220 | train_loss = 0.03993, train_auc = 0.98180, test_loss = 0.03221, test_auc = 0.95547, time = 0.04492\n",
      "Epoch: 0230 | train_loss = 0.04021, train_auc = 0.98141, test_loss = 0.03192, test_auc = 0.96011, time = 0.04757\n",
      "Epoch: 0240 | train_loss = 0.03635, train_auc = 0.98317, test_loss = 0.03185, test_auc = 0.96080, time = 0.04449\n",
      "Epoch: 0250 | train_loss = 0.03596, train_auc = 0.98515, test_loss = 0.03101, test_auc = 0.96265, time = 0.04542\n",
      "Epoch: 0260 | train_loss = 0.03450, train_auc = 0.98703, test_loss = 0.03062, test_auc = 0.96696, time = 0.04533\n",
      "Epoch: 0270 | train_loss = 0.03832, train_auc = 0.98585, test_loss = 0.03220, test_auc = 0.96303, time = 0.04493\n",
      "Epoch: 0280 | train_loss = 0.03350, train_auc = 0.98747, test_loss = 0.03156, test_auc = 0.95726, time = 0.04454\n",
      "Epoch: 0290 | train_loss = 0.03212, train_auc = 0.98803, test_loss = 0.02972, test_auc = 0.96796, time = 0.04524\n",
      "Epoch: 0300 | train_loss = 0.03339, train_auc = 0.98882, test_loss = 0.03225, test_auc = 0.96395, time = 0.04509\n",
      "Epoch: 0310 | train_loss = 0.03128, train_auc = 0.98969, test_loss = 0.03160, test_auc = 0.96219, time = 0.04476\n",
      "Epoch: 0320 | train_loss = 0.03102, train_auc = 0.99022, test_loss = 0.02974, test_auc = 0.96714, time = 0.04474\n",
      "Epoch: 0330 | train_loss = 0.02908, train_auc = 0.99103, test_loss = 0.03046, test_auc = 0.96437, time = 0.04447\n",
      "Epoch: 0340 | train_loss = 0.02819, train_auc = 0.99136, test_loss = 0.03255, test_auc = 0.96095, time = 0.04684\n",
      "Epoch: 0350 | train_loss = 0.02941, train_auc = 0.99152, test_loss = 0.03232, test_auc = 0.96556, time = 0.05077\n",
      "Epoch: 0360 | train_loss = 0.02871, train_auc = 0.99175, test_loss = 0.03427, test_auc = 0.96411, time = 0.04440\n",
      "Epoch: 0370 | train_loss = 0.02965, train_auc = 0.99096, test_loss = 0.03058, test_auc = 0.97102, time = 0.04597\n",
      "Epoch: 0380 | train_loss = 0.02685, train_auc = 0.99185, test_loss = 0.02983, test_auc = 0.97114, time = 0.04642\n",
      "Epoch: 0390 | train_loss = 0.02680, train_auc = 0.99135, test_loss = 0.03100, test_auc = 0.96771, time = 0.04420\n",
      "Epoch: 0400 | train_loss = 0.02644, train_auc = 0.99245, test_loss = 0.03274, test_auc = 0.96808, time = 0.04394\n",
      "Epoch: 0410 | train_loss = 0.02712, train_auc = 0.99238, test_loss = 0.03183, test_auc = 0.96641, time = 0.04420\n",
      "Epoch: 0420 | train_loss = 0.02624, train_auc = 0.99267, test_loss = 0.02867, test_auc = 0.97313, time = 0.04358\n",
      "Epoch: 0430 | train_loss = 0.02529, train_auc = 0.99259, test_loss = 0.02739, test_auc = 0.97129, time = 0.04409\n",
      "Epoch: 0440 | train_loss = 0.02613, train_auc = 0.99274, test_loss = 0.03085, test_auc = 0.97031, time = 0.04374\n",
      "Epoch: 0450 | train_loss = 0.02392, train_auc = 0.99309, test_loss = 0.03477, test_auc = 0.96737, time = 0.04411\n",
      "Epoch: 0460 | train_loss = 0.03031, train_auc = 0.99113, test_loss = 0.03085, test_auc = 0.96709, time = 0.04421\n",
      "Epoch: 0470 | train_loss = 0.02428, train_auc = 0.99316, test_loss = 0.03112, test_auc = 0.97101, time = 0.04434\n",
      "Epoch: 0480 | train_loss = 0.02545, train_auc = 0.99350, test_loss = 0.03112, test_auc = 0.96333, time = 0.04487\n",
      "Epoch: 0490 | train_loss = 0.02697, train_auc = 0.99214, test_loss = 0.02845, test_auc = 0.97241, time = 0.04432\n",
      "Epoch: 0500 | train_loss = 0.02574, train_auc = 0.99334, test_loss = 0.03015, test_auc = 0.96583, time = 0.04610\n",
      "times: 6, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13678, train_auc = 0.51851, test_loss = 0.06532, test_auc = 0.64942, time = 0.81334\n",
      "Epoch: 0010 | train_loss = 0.08426, train_auc = 0.89874, test_loss = 0.04743, test_auc = 0.84386, time = 0.05166\n",
      "Epoch: 0020 | train_loss = 0.07539, train_auc = 0.92274, test_loss = 0.03869, test_auc = 0.92128, time = 0.04743\n",
      "Epoch: 0030 | train_loss = 0.06785, train_auc = 0.94327, test_loss = 0.03830, test_auc = 0.91635, time = 0.04665\n",
      "Epoch: 0040 | train_loss = 0.06413, train_auc = 0.94943, test_loss = 0.03641, test_auc = 0.92605, time = 0.04565\n",
      "Epoch: 0050 | train_loss = 0.06061, train_auc = 0.95521, test_loss = 0.03769, test_auc = 0.92585, time = 0.04534\n",
      "Epoch: 0060 | train_loss = 0.05938, train_auc = 0.95818, test_loss = 0.03680, test_auc = 0.93397, time = 0.04686\n",
      "Epoch: 0070 | train_loss = 0.05824, train_auc = 0.95955, test_loss = 0.03695, test_auc = 0.94705, time = 0.04562\n",
      "Epoch: 0080 | train_loss = 0.05544, train_auc = 0.96425, test_loss = 0.03368, test_auc = 0.95062, time = 0.04519\n",
      "Epoch: 0090 | train_loss = 0.05257, train_auc = 0.96643, test_loss = 0.03440, test_auc = 0.95127, time = 0.04447\n",
      "Epoch: 0100 | train_loss = 0.05306, train_auc = 0.96816, test_loss = 0.03357, test_auc = 0.94827, time = 0.04466\n",
      "Epoch: 0110 | train_loss = 0.05273, train_auc = 0.96897, test_loss = 0.03113, test_auc = 0.95614, time = 0.04461\n",
      "Epoch: 0120 | train_loss = 0.05153, train_auc = 0.96983, test_loss = 0.03264, test_auc = 0.95504, time = 0.04469\n",
      "Epoch: 0130 | train_loss = 0.04817, train_auc = 0.97318, test_loss = 0.03372, test_auc = 0.94731, time = 0.04503\n",
      "Epoch: 0140 | train_loss = 0.04898, train_auc = 0.97352, test_loss = 0.03317, test_auc = 0.95213, time = 0.04545\n",
      "Epoch: 0150 | train_loss = 0.04830, train_auc = 0.97395, test_loss = 0.03366, test_auc = 0.95487, time = 0.04575\n",
      "Epoch: 0160 | train_loss = 0.04394, train_auc = 0.97793, test_loss = 0.03009, test_auc = 0.96216, time = 0.04484\n",
      "Epoch: 0170 | train_loss = 0.04323, train_auc = 0.97841, test_loss = 0.03338, test_auc = 0.95809, time = 0.04443\n",
      "Epoch: 0180 | train_loss = 0.04188, train_auc = 0.98098, test_loss = 0.03381, test_auc = 0.95821, time = 0.04491\n",
      "Epoch: 0190 | train_loss = 0.04198, train_auc = 0.98016, test_loss = 0.03238, test_auc = 0.96387, time = 0.04466\n",
      "Epoch: 0200 | train_loss = 0.03969, train_auc = 0.98253, test_loss = 0.03038, test_auc = 0.96415, time = 0.04544\n",
      "Epoch: 0210 | train_loss = 0.03716, train_auc = 0.98461, test_loss = 0.03549, test_auc = 0.96125, time = 0.04451\n",
      "Epoch: 0220 | train_loss = 0.03729, train_auc = 0.98451, test_loss = 0.03221, test_auc = 0.96566, time = 0.04611\n",
      "Epoch: 0230 | train_loss = 0.03822, train_auc = 0.98475, test_loss = 0.03103, test_auc = 0.96175, time = 0.04450\n",
      "Epoch: 0240 | train_loss = 0.03669, train_auc = 0.98627, test_loss = 0.03207, test_auc = 0.95758, time = 0.04443\n",
      "Epoch: 0250 | train_loss = 0.03560, train_auc = 0.98716, test_loss = 0.03379, test_auc = 0.96375, time = 0.04436\n",
      "Epoch: 0260 | train_loss = 0.03463, train_auc = 0.98699, test_loss = 0.03180, test_auc = 0.96776, time = 0.04566\n",
      "Epoch: 0270 | train_loss = 0.03395, train_auc = 0.98827, test_loss = 0.03185, test_auc = 0.96067, time = 0.04466\n",
      "Epoch: 0280 | train_loss = 0.03254, train_auc = 0.98950, test_loss = 0.03226, test_auc = 0.95697, time = 0.04571\n",
      "Epoch: 0290 | train_loss = 0.03348, train_auc = 0.98890, test_loss = 0.02933, test_auc = 0.96899, time = 0.04566\n",
      "Epoch: 0300 | train_loss = 0.03196, train_auc = 0.99060, test_loss = 0.03494, test_auc = 0.96370, time = 0.04565\n",
      "Epoch: 0310 | train_loss = 0.02972, train_auc = 0.99051, test_loss = 0.03268, test_auc = 0.96633, time = 0.04440\n",
      "Epoch: 0320 | train_loss = 0.03086, train_auc = 0.99078, test_loss = 0.03182, test_auc = 0.96779, time = 0.04436\n",
      "Epoch: 0330 | train_loss = 0.02901, train_auc = 0.99150, test_loss = 0.03033, test_auc = 0.96450, time = 0.04933\n",
      "Epoch: 0340 | train_loss = 0.03053, train_auc = 0.99116, test_loss = 0.02805, test_auc = 0.97097, time = 0.04525\n",
      "Epoch: 0350 | train_loss = 0.02934, train_auc = 0.99207, test_loss = 0.03045, test_auc = 0.96772, time = 0.04483\n",
      "Epoch: 0360 | train_loss = 0.02954, train_auc = 0.99198, test_loss = 0.03201, test_auc = 0.96831, time = 0.04551\n",
      "Epoch: 0370 | train_loss = 0.02793, train_auc = 0.99170, test_loss = 0.02961, test_auc = 0.97198, time = 0.04651\n",
      "Epoch: 0380 | train_loss = 0.02707, train_auc = 0.99162, test_loss = 0.02712, test_auc = 0.97608, time = 0.04593\n",
      "Epoch: 0390 | train_loss = 0.02717, train_auc = 0.99203, test_loss = 0.03070, test_auc = 0.97148, time = 0.04503\n",
      "Epoch: 0400 | train_loss = 0.02866, train_auc = 0.99174, test_loss = 0.03231, test_auc = 0.96810, time = 0.04472\n",
      "Epoch: 0410 | train_loss = 0.02485, train_auc = 0.99335, test_loss = 0.02816, test_auc = 0.97183, time = 0.04522\n",
      "Epoch: 0420 | train_loss = 0.02681, train_auc = 0.99230, test_loss = 0.02894, test_auc = 0.97229, time = 0.04508\n",
      "Epoch: 0430 | train_loss = 0.02739, train_auc = 0.99300, test_loss = 0.02916, test_auc = 0.97125, time = 0.04411\n",
      "Epoch: 0440 | train_loss = 0.02764, train_auc = 0.99202, test_loss = 0.03156, test_auc = 0.96643, time = 0.04483\n",
      "Epoch: 0450 | train_loss = 0.02983, train_auc = 0.99176, test_loss = 0.03073, test_auc = 0.96946, time = 0.04550\n",
      "Epoch: 0460 | train_loss = 0.02407, train_auc = 0.99292, test_loss = 0.02747, test_auc = 0.97444, time = 0.04392\n",
      "Epoch: 0470 | train_loss = 0.02420, train_auc = 0.99350, test_loss = 0.02750, test_auc = 0.97424, time = 0.04427\n",
      "Epoch: 0480 | train_loss = 0.02447, train_auc = 0.99302, test_loss = 0.02930, test_auc = 0.97270, time = 0.04493\n",
      "Epoch: 0490 | train_loss = 0.02419, train_auc = 0.99299, test_loss = 0.02874, test_auc = 0.97321, time = 0.04487\n",
      "Epoch: 0500 | train_loss = 0.02321, train_auc = 0.99412, test_loss = 0.03041, test_auc = 0.96528, time = 0.04451\n",
      "times: 6, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13888, train_auc = 0.50964, test_loss = 0.07441, test_auc = 0.52286, time = 0.84511\n",
      "Epoch: 0010 | train_loss = 0.08413, train_auc = 0.90808, test_loss = 0.05264, test_auc = 0.85530, time = 0.05092\n",
      "Epoch: 0020 | train_loss = 0.07108, train_auc = 0.93488, test_loss = 0.04028, test_auc = 0.90292, time = 0.04890\n",
      "Epoch: 0030 | train_loss = 0.06839, train_auc = 0.94232, test_loss = 0.03864, test_auc = 0.92394, time = 0.04658\n",
      "Epoch: 0040 | train_loss = 0.06260, train_auc = 0.95216, test_loss = 0.03634, test_auc = 0.94106, time = 0.04654\n",
      "Epoch: 0050 | train_loss = 0.06154, train_auc = 0.95445, test_loss = 0.03358, test_auc = 0.94802, time = 0.04508\n",
      "Epoch: 0060 | train_loss = 0.05829, train_auc = 0.96193, test_loss = 0.03285, test_auc = 0.95308, time = 0.04574\n",
      "Epoch: 0070 | train_loss = 0.05415, train_auc = 0.96554, test_loss = 0.03265, test_auc = 0.95258, time = 0.04632\n",
      "Epoch: 0080 | train_loss = 0.05678, train_auc = 0.96768, test_loss = 0.03465, test_auc = 0.94667, time = 0.04564\n",
      "Epoch: 0090 | train_loss = 0.05108, train_auc = 0.97041, test_loss = 0.03417, test_auc = 0.94883, time = 0.04488\n",
      "Epoch: 0100 | train_loss = 0.05008, train_auc = 0.97112, test_loss = 0.03667, test_auc = 0.94520, time = 0.04583\n",
      "Epoch: 0110 | train_loss = 0.04681, train_auc = 0.97496, test_loss = 0.03692, test_auc = 0.94664, time = 0.04477\n",
      "Epoch: 0120 | train_loss = 0.04518, train_auc = 0.97694, test_loss = 0.03549, test_auc = 0.95322, time = 0.04335\n",
      "Epoch: 0130 | train_loss = 0.04629, train_auc = 0.97569, test_loss = 0.03313, test_auc = 0.95709, time = 0.04343\n",
      "Epoch: 0140 | train_loss = 0.04507, train_auc = 0.97732, test_loss = 0.03516, test_auc = 0.94487, time = 0.04369\n",
      "Epoch: 0150 | train_loss = 0.04308, train_auc = 0.98008, test_loss = 0.03205, test_auc = 0.95538, time = 0.04350\n",
      "Epoch: 0160 | train_loss = 0.04254, train_auc = 0.98014, test_loss = 0.03357, test_auc = 0.94742, time = 0.04388\n",
      "Epoch: 0170 | train_loss = 0.04342, train_auc = 0.98185, test_loss = 0.03269, test_auc = 0.96311, time = 0.04518\n",
      "Epoch: 0180 | train_loss = 0.04002, train_auc = 0.98364, test_loss = 0.03153, test_auc = 0.96132, time = 0.04394\n",
      "Epoch: 0190 | train_loss = 0.03722, train_auc = 0.98404, test_loss = 0.02979, test_auc = 0.96561, time = 0.04481\n",
      "Epoch: 0200 | train_loss = 0.03695, train_auc = 0.98603, test_loss = 0.03397, test_auc = 0.96361, time = 0.04627\n",
      "Epoch: 0210 | train_loss = 0.03699, train_auc = 0.98610, test_loss = 0.03365, test_auc = 0.96211, time = 0.04699\n",
      "Epoch: 0220 | train_loss = 0.03851, train_auc = 0.98560, test_loss = 0.03479, test_auc = 0.95188, time = 0.04667\n",
      "Epoch: 0230 | train_loss = 0.03596, train_auc = 0.98714, test_loss = 0.04132, test_auc = 0.94588, time = 0.04486\n",
      "Epoch: 0240 | train_loss = 0.03298, train_auc = 0.98864, test_loss = 0.03229, test_auc = 0.96496, time = 0.04544\n",
      "Epoch: 0250 | train_loss = 0.03408, train_auc = 0.98760, test_loss = 0.03366, test_auc = 0.96145, time = 0.04479\n",
      "Epoch: 0260 | train_loss = 0.03367, train_auc = 0.98892, test_loss = 0.03230, test_auc = 0.96676, time = 0.04403\n",
      "Epoch: 0270 | train_loss = 0.03112, train_auc = 0.99081, test_loss = 0.03368, test_auc = 0.96550, time = 0.04350\n",
      "Epoch: 0280 | train_loss = 0.03327, train_auc = 0.98957, test_loss = 0.03163, test_auc = 0.96612, time = 0.04363\n",
      "Epoch: 0290 | train_loss = 0.03131, train_auc = 0.99051, test_loss = 0.03369, test_auc = 0.96430, time = 0.04744\n",
      "Epoch: 0300 | train_loss = 0.03146, train_auc = 0.99171, test_loss = 0.02975, test_auc = 0.97091, time = 0.04496\n",
      "Epoch: 0310 | train_loss = 0.02990, train_auc = 0.99092, test_loss = 0.03537, test_auc = 0.96348, time = 0.04523\n",
      "Epoch: 0320 | train_loss = 0.03177, train_auc = 0.99186, test_loss = 0.03089, test_auc = 0.96978, time = 0.04422\n",
      "Epoch: 0330 | train_loss = 0.02641, train_auc = 0.99310, test_loss = 0.03328, test_auc = 0.95008, time = 0.04387\n",
      "Epoch: 0340 | train_loss = 0.02867, train_auc = 0.99297, test_loss = 0.03171, test_auc = 0.96941, time = 0.04427\n",
      "Epoch: 0350 | train_loss = 0.02735, train_auc = 0.99340, test_loss = 0.03538, test_auc = 0.94308, time = 0.04413\n",
      "Epoch: 0360 | train_loss = 0.03058, train_auc = 0.99216, test_loss = 0.03474, test_auc = 0.94976, time = 0.04490\n",
      "Epoch: 0370 | train_loss = 0.02545, train_auc = 0.99350, test_loss = 0.03276, test_auc = 0.96748, time = 0.04467\n",
      "Epoch: 0380 | train_loss = 0.02536, train_auc = 0.99379, test_loss = 0.03383, test_auc = 0.95657, time = 0.04465\n",
      "Epoch: 0390 | train_loss = 0.02450, train_auc = 0.99437, test_loss = 0.02940, test_auc = 0.97236, time = 0.04362\n",
      "Epoch: 0400 | train_loss = 0.02601, train_auc = 0.99377, test_loss = 0.03174, test_auc = 0.96963, time = 0.04463\n",
      "Epoch: 0410 | train_loss = 0.02471, train_auc = 0.99379, test_loss = 0.03236, test_auc = 0.97089, time = 0.04396\n",
      "Epoch: 0420 | train_loss = 0.02511, train_auc = 0.99389, test_loss = 0.03001, test_auc = 0.97127, time = 0.04379\n",
      "Epoch: 0430 | train_loss = 0.02231, train_auc = 0.99465, test_loss = 0.03199, test_auc = 0.96833, time = 0.04505\n",
      "Epoch: 0440 | train_loss = 0.02369, train_auc = 0.99445, test_loss = 0.03202, test_auc = 0.96757, time = 0.04470\n",
      "Epoch: 0450 | train_loss = 0.02483, train_auc = 0.99391, test_loss = 0.02972, test_auc = 0.97246, time = 0.04466\n",
      "Epoch: 0460 | train_loss = 0.02192, train_auc = 0.99452, test_loss = 0.02854, test_auc = 0.97096, time = 0.04480\n",
      "Epoch: 0470 | train_loss = 0.02303, train_auc = 0.99466, test_loss = 0.03357, test_auc = 0.96786, time = 0.04456\n",
      "Epoch: 0480 | train_loss = 0.02296, train_auc = 0.99477, test_loss = 0.03309, test_auc = 0.96218, time = 0.04482\n",
      "Epoch: 0490 | train_loss = 0.02269, train_auc = 0.99472, test_loss = 0.02945, test_auc = 0.97225, time = 0.04421\n",
      "Epoch: 0500 | train_loss = 0.02396, train_auc = 0.99442, test_loss = 0.03320, test_auc = 0.97084, time = 0.04397\n",
      "times: 7, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13068, train_auc = 0.60427, test_loss = 0.07086, test_auc = 0.59775, time = 0.81028\n",
      "Epoch: 0010 | train_loss = 0.08077, train_auc = 0.91214, test_loss = 0.04618, test_auc = 0.88394, time = 0.05057\n",
      "Epoch: 0020 | train_loss = 0.07248, train_auc = 0.93408, test_loss = 0.04274, test_auc = 0.87676, time = 0.05088\n",
      "Epoch: 0030 | train_loss = 0.06598, train_auc = 0.94756, test_loss = 0.03833, test_auc = 0.91211, time = 0.04789\n",
      "Epoch: 0040 | train_loss = 0.06276, train_auc = 0.95331, test_loss = 0.03624, test_auc = 0.93176, time = 0.04641\n",
      "Epoch: 0050 | train_loss = 0.06225, train_auc = 0.95514, test_loss = 0.03683, test_auc = 0.93649, time = 0.04618\n",
      "Epoch: 0060 | train_loss = 0.05740, train_auc = 0.96185, test_loss = 0.03440, test_auc = 0.94634, time = 0.04705\n",
      "Epoch: 0070 | train_loss = 0.05531, train_auc = 0.96566, test_loss = 0.03207, test_auc = 0.95038, time = 0.05076\n",
      "Epoch: 0080 | train_loss = 0.05345, train_auc = 0.96828, test_loss = 0.03245, test_auc = 0.94953, time = 0.04493\n",
      "Epoch: 0090 | train_loss = 0.05144, train_auc = 0.97149, test_loss = 0.03167, test_auc = 0.95245, time = 0.04428\n",
      "Epoch: 0100 | train_loss = 0.05007, train_auc = 0.97298, test_loss = 0.03311, test_auc = 0.95119, time = 0.04378\n",
      "Epoch: 0110 | train_loss = 0.04827, train_auc = 0.97577, test_loss = 0.03385, test_auc = 0.95097, time = 0.04357\n",
      "Epoch: 0120 | train_loss = 0.04564, train_auc = 0.97768, test_loss = 0.03289, test_auc = 0.95404, time = 0.04502\n",
      "Epoch: 0130 | train_loss = 0.04375, train_auc = 0.98046, test_loss = 0.03240, test_auc = 0.94792, time = 0.04455\n",
      "Epoch: 0140 | train_loss = 0.04620, train_auc = 0.97770, test_loss = 0.03144, test_auc = 0.95846, time = 0.04450\n",
      "Epoch: 0150 | train_loss = 0.03900, train_auc = 0.98335, test_loss = 0.03216, test_auc = 0.96110, time = 0.04491\n",
      "Epoch: 0160 | train_loss = 0.04210, train_auc = 0.98106, test_loss = 0.03236, test_auc = 0.95620, time = 0.04414\n",
      "Epoch: 0170 | train_loss = 0.04003, train_auc = 0.98282, test_loss = 0.03240, test_auc = 0.95080, time = 0.04689\n",
      "Epoch: 0180 | train_loss = 0.03883, train_auc = 0.98420, test_loss = 0.03176, test_auc = 0.95683, time = 0.04514\n",
      "Epoch: 0190 | train_loss = 0.03699, train_auc = 0.98577, test_loss = 0.03724, test_auc = 0.95509, time = 0.04492\n",
      "Epoch: 0200 | train_loss = 0.03768, train_auc = 0.98627, test_loss = 0.03540, test_auc = 0.95589, time = 0.04560\n",
      "Epoch: 0210 | train_loss = 0.03544, train_auc = 0.98726, test_loss = 0.03150, test_auc = 0.96218, time = 0.04421\n",
      "Epoch: 0220 | train_loss = 0.03684, train_auc = 0.98620, test_loss = 0.03154, test_auc = 0.95748, time = 0.04466\n",
      "Epoch: 0230 | train_loss = 0.03387, train_auc = 0.98850, test_loss = 0.03122, test_auc = 0.96523, time = 0.05025\n",
      "Epoch: 0240 | train_loss = 0.03412, train_auc = 0.98935, test_loss = 0.03441, test_auc = 0.96015, time = 0.04514\n",
      "Epoch: 0250 | train_loss = 0.03011, train_auc = 0.99015, test_loss = 0.03024, test_auc = 0.96429, time = 0.04442\n",
      "Epoch: 0260 | train_loss = 0.03164, train_auc = 0.99009, test_loss = 0.03080, test_auc = 0.96357, time = 0.04372\n",
      "Epoch: 0270 | train_loss = 0.03016, train_auc = 0.99055, test_loss = 0.03439, test_auc = 0.96408, time = 0.04441\n",
      "Epoch: 0280 | train_loss = 0.02893, train_auc = 0.99115, test_loss = 0.03154, test_auc = 0.96326, time = 0.04755\n",
      "Epoch: 0290 | train_loss = 0.02817, train_auc = 0.99154, test_loss = 0.03162, test_auc = 0.96594, time = 0.04653\n",
      "Epoch: 0300 | train_loss = 0.02754, train_auc = 0.99248, test_loss = 0.03496, test_auc = 0.96085, time = 0.04615\n",
      "Epoch: 0310 | train_loss = 0.02884, train_auc = 0.99193, test_loss = 0.03152, test_auc = 0.96711, time = 0.04441\n",
      "Epoch: 0320 | train_loss = 0.02778, train_auc = 0.99243, test_loss = 0.03206, test_auc = 0.96430, time = 0.05149\n",
      "Epoch: 0330 | train_loss = 0.02743, train_auc = 0.99224, test_loss = 0.03416, test_auc = 0.96262, time = 0.04471\n",
      "Epoch: 0340 | train_loss = 0.02596, train_auc = 0.99279, test_loss = 0.03514, test_auc = 0.96711, time = 0.04406\n",
      "Epoch: 0350 | train_loss = 0.02845, train_auc = 0.99299, test_loss = 0.02984, test_auc = 0.96684, time = 0.04713\n",
      "Epoch: 0360 | train_loss = 0.02519, train_auc = 0.99270, test_loss = 0.02963, test_auc = 0.96665, time = 0.05345\n",
      "Epoch: 0370 | train_loss = 0.02560, train_auc = 0.99318, test_loss = 0.03018, test_auc = 0.96831, time = 0.04463\n",
      "Epoch: 0380 | train_loss = 0.02678, train_auc = 0.99336, test_loss = 0.02886, test_auc = 0.96582, time = 0.04561\n",
      "Epoch: 0390 | train_loss = 0.02504, train_auc = 0.99321, test_loss = 0.03039, test_auc = 0.95962, time = 0.04515\n",
      "Epoch: 0400 | train_loss = 0.02353, train_auc = 0.99361, test_loss = 0.03024, test_auc = 0.96432, time = 0.04436\n",
      "Epoch: 0410 | train_loss = 0.02463, train_auc = 0.99289, test_loss = 0.03049, test_auc = 0.96199, time = 0.04416\n",
      "Epoch: 0420 | train_loss = 0.02326, train_auc = 0.99379, test_loss = 0.03061, test_auc = 0.96731, time = 0.04587\n",
      "Epoch: 0430 | train_loss = 0.02571, train_auc = 0.99367, test_loss = 0.02991, test_auc = 0.96971, time = 0.04539\n",
      "Epoch: 0440 | train_loss = 0.02561, train_auc = 0.99316, test_loss = 0.02885, test_auc = 0.96817, time = 0.04492\n",
      "Epoch: 0450 | train_loss = 0.02371, train_auc = 0.99382, test_loss = 0.02773, test_auc = 0.97093, time = 0.04730\n",
      "Epoch: 0460 | train_loss = 0.02299, train_auc = 0.99366, test_loss = 0.03262, test_auc = 0.97033, time = 0.04472\n",
      "Epoch: 0470 | train_loss = 0.02473, train_auc = 0.99343, test_loss = 0.02944, test_auc = 0.97064, time = 0.04472\n",
      "Epoch: 0480 | train_loss = 0.02384, train_auc = 0.99414, test_loss = 0.03235, test_auc = 0.96738, time = 0.04676\n",
      "Epoch: 0490 | train_loss = 0.02287, train_auc = 0.99468, test_loss = 0.03152, test_auc = 0.96890, time = 0.04546\n",
      "Epoch: 0500 | train_loss = 0.02264, train_auc = 0.99475, test_loss = 0.03103, test_auc = 0.96946, time = 0.04624\n",
      "times: 7, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13398, train_auc = 0.54621, test_loss = 0.06601, test_auc = 0.63725, time = 0.79818\n",
      "Epoch: 0010 | train_loss = 0.08417, train_auc = 0.90605, test_loss = 0.04465, test_auc = 0.86232, time = 0.05045\n",
      "Epoch: 0020 | train_loss = 0.07040, train_auc = 0.93628, test_loss = 0.04128, test_auc = 0.88528, time = 0.04930\n",
      "Epoch: 0030 | train_loss = 0.06598, train_auc = 0.94596, test_loss = 0.03969, test_auc = 0.90424, time = 0.04733\n",
      "Epoch: 0040 | train_loss = 0.06653, train_auc = 0.94465, test_loss = 0.03873, test_auc = 0.91952, time = 0.04734\n",
      "Epoch: 0050 | train_loss = 0.06266, train_auc = 0.95174, test_loss = 0.03875, test_auc = 0.90539, time = 0.04752\n",
      "Epoch: 0060 | train_loss = 0.06047, train_auc = 0.95699, test_loss = 0.03692, test_auc = 0.93297, time = 0.04609\n",
      "Epoch: 0070 | train_loss = 0.05727, train_auc = 0.96178, test_loss = 0.03620, test_auc = 0.93718, time = 0.04751\n",
      "Epoch: 0080 | train_loss = 0.05446, train_auc = 0.96537, test_loss = 0.03569, test_auc = 0.94366, time = 0.04544\n",
      "Epoch: 0090 | train_loss = 0.05512, train_auc = 0.96482, test_loss = 0.03372, test_auc = 0.94851, time = 0.04715\n",
      "Epoch: 0100 | train_loss = 0.05292, train_auc = 0.96750, test_loss = 0.03332, test_auc = 0.94666, time = 0.04749\n",
      "Epoch: 0110 | train_loss = 0.04938, train_auc = 0.97183, test_loss = 0.03622, test_auc = 0.95125, time = 0.04566\n",
      "Epoch: 0120 | train_loss = 0.04694, train_auc = 0.97447, test_loss = 0.03324, test_auc = 0.95066, time = 0.04611\n",
      "Epoch: 0130 | train_loss = 0.04547, train_auc = 0.97593, test_loss = 0.03273, test_auc = 0.95540, time = 0.04602\n",
      "Epoch: 0140 | train_loss = 0.04499, train_auc = 0.97675, test_loss = 0.03237, test_auc = 0.95354, time = 0.04528\n",
      "Epoch: 0150 | train_loss = 0.04530, train_auc = 0.97761, test_loss = 0.03396, test_auc = 0.94951, time = 0.04549\n",
      "Epoch: 0160 | train_loss = 0.04196, train_auc = 0.97962, test_loss = 0.03244, test_auc = 0.95927, time = 0.04571\n",
      "Epoch: 0170 | train_loss = 0.04097, train_auc = 0.98031, test_loss = 0.03511, test_auc = 0.95125, time = 0.04602\n",
      "Epoch: 0180 | train_loss = 0.03909, train_auc = 0.98228, test_loss = 0.03379, test_auc = 0.95965, time = 0.04608\n",
      "Epoch: 0190 | train_loss = 0.03903, train_auc = 0.98386, test_loss = 0.03454, test_auc = 0.95660, time = 0.04628\n",
      "Epoch: 0200 | train_loss = 0.03949, train_auc = 0.98340, test_loss = 0.03048, test_auc = 0.96660, time = 0.04605\n",
      "Epoch: 0210 | train_loss = 0.03826, train_auc = 0.98338, test_loss = 0.03184, test_auc = 0.96145, time = 0.04590\n",
      "Epoch: 0220 | train_loss = 0.03500, train_auc = 0.98589, test_loss = 0.03236, test_auc = 0.96386, time = 0.04620\n",
      "Epoch: 0230 | train_loss = 0.03663, train_auc = 0.98526, test_loss = 0.03476, test_auc = 0.96409, time = 0.04648\n",
      "Epoch: 0240 | train_loss = 0.03470, train_auc = 0.98571, test_loss = 0.03294, test_auc = 0.95805, time = 0.04654\n",
      "Epoch: 0250 | train_loss = 0.03401, train_auc = 0.98692, test_loss = 0.02964, test_auc = 0.96718, time = 0.04601\n",
      "Epoch: 0260 | train_loss = 0.03345, train_auc = 0.98664, test_loss = 0.03407, test_auc = 0.96093, time = 0.05525\n",
      "Epoch: 0270 | train_loss = 0.03282, train_auc = 0.98822, test_loss = 0.03024, test_auc = 0.96846, time = 0.04593\n",
      "Epoch: 0280 | train_loss = 0.02988, train_auc = 0.98839, test_loss = 0.03043, test_auc = 0.96789, time = 0.04624\n",
      "Epoch: 0290 | train_loss = 0.03390, train_auc = 0.98805, test_loss = 0.03124, test_auc = 0.96792, time = 0.04779\n",
      "Epoch: 0300 | train_loss = 0.03042, train_auc = 0.98862, test_loss = 0.02917, test_auc = 0.96903, time = 0.04686\n",
      "Epoch: 0310 | train_loss = 0.02977, train_auc = 0.98887, test_loss = 0.03133, test_auc = 0.96717, time = 0.04623\n",
      "Epoch: 0320 | train_loss = 0.03083, train_auc = 0.98952, test_loss = 0.03462, test_auc = 0.96000, time = 0.04616\n",
      "Epoch: 0330 | train_loss = 0.02820, train_auc = 0.99041, test_loss = 0.03061, test_auc = 0.96444, time = 0.04611\n",
      "Epoch: 0340 | train_loss = 0.03158, train_auc = 0.98951, test_loss = 0.02984, test_auc = 0.97069, time = 0.04662\n",
      "Epoch: 0350 | train_loss = 0.02724, train_auc = 0.99057, test_loss = 0.03118, test_auc = 0.96676, time = 0.04655\n",
      "Epoch: 0360 | train_loss = 0.02850, train_auc = 0.99133, test_loss = 0.03026, test_auc = 0.96782, time = 0.04637\n",
      "Epoch: 0370 | train_loss = 0.02930, train_auc = 0.98998, test_loss = 0.03233, test_auc = 0.96911, time = 0.04637\n",
      "Epoch: 0380 | train_loss = 0.02812, train_auc = 0.99083, test_loss = 0.02916, test_auc = 0.97243, time = 0.04594\n",
      "Epoch: 0390 | train_loss = 0.02942, train_auc = 0.98993, test_loss = 0.02904, test_auc = 0.96903, time = 0.04574\n",
      "Epoch: 0400 | train_loss = 0.02913, train_auc = 0.99106, test_loss = 0.02920, test_auc = 0.97145, time = 0.04666\n",
      "Epoch: 0410 | train_loss = 0.02715, train_auc = 0.99267, test_loss = 0.02877, test_auc = 0.97228, time = 0.04581\n",
      "Epoch: 0420 | train_loss = 0.02531, train_auc = 0.99201, test_loss = 0.02943, test_auc = 0.97212, time = 0.04608\n",
      "Epoch: 0430 | train_loss = 0.02686, train_auc = 0.99285, test_loss = 0.02856, test_auc = 0.97378, time = 0.04605\n",
      "Epoch: 0440 | train_loss = 0.02956, train_auc = 0.99086, test_loss = 0.03098, test_auc = 0.96095, time = 0.04624\n",
      "Epoch: 0450 | train_loss = 0.02724, train_auc = 0.99136, test_loss = 0.03033, test_auc = 0.96431, time = 0.04620\n",
      "Epoch: 0460 | train_loss = 0.02760, train_auc = 0.99181, test_loss = 0.02986, test_auc = 0.97310, time = 0.04593\n",
      "Epoch: 0470 | train_loss = 0.02561, train_auc = 0.99332, test_loss = 0.02937, test_auc = 0.96894, time = 0.04567\n",
      "Epoch: 0480 | train_loss = 0.02504, train_auc = 0.99288, test_loss = 0.02970, test_auc = 0.97266, time = 0.04688\n",
      "Epoch: 0490 | train_loss = 0.02498, train_auc = 0.99329, test_loss = 0.02991, test_auc = 0.97212, time = 0.04556\n",
      "Epoch: 0500 | train_loss = 0.02536, train_auc = 0.99257, test_loss = 0.03110, test_auc = 0.97026, time = 0.04866\n",
      "times: 7, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13766, train_auc = 0.51250, test_loss = 0.07135, test_auc = 0.57587, time = 0.79006\n",
      "Epoch: 0010 | train_loss = 0.08504, train_auc = 0.88526, test_loss = 0.05760, test_auc = 0.81115, time = 0.05264\n",
      "Epoch: 0020 | train_loss = 0.07367, train_auc = 0.93213, test_loss = 0.04136, test_auc = 0.89276, time = 0.04912\n",
      "Epoch: 0030 | train_loss = 0.06867, train_auc = 0.93916, test_loss = 0.03679, test_auc = 0.92793, time = 0.04916\n",
      "Epoch: 0040 | train_loss = 0.06399, train_auc = 0.94980, test_loss = 0.03811, test_auc = 0.92537, time = 0.04879\n",
      "Epoch: 0050 | train_loss = 0.06252, train_auc = 0.95503, test_loss = 0.03671, test_auc = 0.93302, time = 0.04710\n",
      "Epoch: 0060 | train_loss = 0.06091, train_auc = 0.95458, test_loss = 0.03691, test_auc = 0.92849, time = 0.04818\n",
      "Epoch: 0070 | train_loss = 0.05739, train_auc = 0.96141, test_loss = 0.03296, test_auc = 0.95003, time = 0.04691\n",
      "Epoch: 0080 | train_loss = 0.05538, train_auc = 0.96482, test_loss = 0.03231, test_auc = 0.95630, time = 0.04748\n",
      "Epoch: 0090 | train_loss = 0.05316, train_auc = 0.96788, test_loss = 0.03172, test_auc = 0.95838, time = 0.04657\n",
      "Epoch: 0100 | train_loss = 0.05132, train_auc = 0.96953, test_loss = 0.03428, test_auc = 0.95408, time = 0.04673\n",
      "Epoch: 0110 | train_loss = 0.05365, train_auc = 0.96839, test_loss = 0.03131, test_auc = 0.96007, time = 0.04631\n",
      "Epoch: 0120 | train_loss = 0.05088, train_auc = 0.97093, test_loss = 0.03124, test_auc = 0.96144, time = 0.04603\n",
      "Epoch: 0130 | train_loss = 0.04883, train_auc = 0.97401, test_loss = 0.03620, test_auc = 0.94145, time = 0.04895\n",
      "Epoch: 0140 | train_loss = 0.04584, train_auc = 0.97675, test_loss = 0.03011, test_auc = 0.96437, time = 0.04783\n",
      "Epoch: 0150 | train_loss = 0.04585, train_auc = 0.97726, test_loss = 0.03169, test_auc = 0.96180, time = 0.05113\n",
      "Epoch: 0160 | train_loss = 0.04466, train_auc = 0.97881, test_loss = 0.02936, test_auc = 0.96456, time = 0.04723\n",
      "Epoch: 0170 | train_loss = 0.04200, train_auc = 0.98013, test_loss = 0.03242, test_auc = 0.95556, time = 0.04785\n",
      "Epoch: 0180 | train_loss = 0.04200, train_auc = 0.98013, test_loss = 0.02978, test_auc = 0.96660, time = 0.04780\n",
      "Epoch: 0190 | train_loss = 0.04044, train_auc = 0.98246, test_loss = 0.03166, test_auc = 0.96470, time = 0.04733\n",
      "Epoch: 0200 | train_loss = 0.04015, train_auc = 0.98167, test_loss = 0.03591, test_auc = 0.94527, time = 0.04650\n",
      "Epoch: 0210 | train_loss = 0.03828, train_auc = 0.98301, test_loss = 0.03597, test_auc = 0.96506, time = 0.04688\n",
      "Epoch: 0220 | train_loss = 0.03986, train_auc = 0.98377, test_loss = 0.03307, test_auc = 0.95894, time = 0.04651\n",
      "Epoch: 0230 | train_loss = 0.03596, train_auc = 0.98620, test_loss = 0.03162, test_auc = 0.96642, time = 0.06101\n",
      "Epoch: 0240 | train_loss = 0.03811, train_auc = 0.98494, test_loss = 0.03578, test_auc = 0.96113, time = 0.04743\n",
      "Epoch: 0250 | train_loss = 0.03557, train_auc = 0.98586, test_loss = 0.03118, test_auc = 0.96812, time = 0.04771\n",
      "Epoch: 0260 | train_loss = 0.03578, train_auc = 0.98662, test_loss = 0.03038, test_auc = 0.96915, time = 0.04682\n",
      "Epoch: 0270 | train_loss = 0.03490, train_auc = 0.98695, test_loss = 0.02755, test_auc = 0.97162, time = 0.04629\n",
      "Epoch: 0280 | train_loss = 0.03175, train_auc = 0.98795, test_loss = 0.03039, test_auc = 0.97041, time = 0.04631\n",
      "Epoch: 0290 | train_loss = 0.03292, train_auc = 0.98842, test_loss = 0.03377, test_auc = 0.97023, time = 0.04596\n",
      "Epoch: 0300 | train_loss = 0.03344, train_auc = 0.98783, test_loss = 0.03394, test_auc = 0.96126, time = 0.04545\n",
      "Epoch: 0310 | train_loss = 0.03323, train_auc = 0.98744, test_loss = 0.03030, test_auc = 0.96920, time = 0.04520\n",
      "Epoch: 0320 | train_loss = 0.03031, train_auc = 0.98906, test_loss = 0.03051, test_auc = 0.97118, time = 0.04628\n",
      "Epoch: 0330 | train_loss = 0.03328, train_auc = 0.98898, test_loss = 0.02912, test_auc = 0.97409, time = 0.04694\n",
      "Epoch: 0340 | train_loss = 0.02929, train_auc = 0.98937, test_loss = 0.02980, test_auc = 0.96860, time = 0.04759\n",
      "Epoch: 0350 | train_loss = 0.02897, train_auc = 0.98984, test_loss = 0.03075, test_auc = 0.97216, time = 0.04783\n",
      "Epoch: 0360 | train_loss = 0.02811, train_auc = 0.98986, test_loss = 0.02778, test_auc = 0.97727, time = 0.04730\n",
      "Epoch: 0370 | train_loss = 0.02882, train_auc = 0.98930, test_loss = 0.02954, test_auc = 0.97124, time = 0.05207\n",
      "Epoch: 0380 | train_loss = 0.02874, train_auc = 0.99037, test_loss = 0.02814, test_auc = 0.97549, time = 0.04672\n",
      "Epoch: 0390 | train_loss = 0.02706, train_auc = 0.99065, test_loss = 0.02985, test_auc = 0.97211, time = 0.04618\n",
      "Epoch: 0400 | train_loss = 0.02753, train_auc = 0.99065, test_loss = 0.02911, test_auc = 0.97214, time = 0.04636\n",
      "Epoch: 0410 | train_loss = 0.03016, train_auc = 0.98969, test_loss = 0.02778, test_auc = 0.97636, time = 0.04927\n",
      "Epoch: 0420 | train_loss = 0.02799, train_auc = 0.99131, test_loss = 0.02964, test_auc = 0.97333, time = 0.04677\n",
      "Epoch: 0430 | train_loss = 0.02753, train_auc = 0.99123, test_loss = 0.02880, test_auc = 0.97496, time = 0.04654\n",
      "Epoch: 0440 | train_loss = 0.02975, train_auc = 0.99107, test_loss = 0.02985, test_auc = 0.97251, time = 0.04709\n",
      "Epoch: 0450 | train_loss = 0.02849, train_auc = 0.99099, test_loss = 0.03246, test_auc = 0.97166, time = 0.04713\n",
      "Epoch: 0460 | train_loss = 0.03011, train_auc = 0.99130, test_loss = 0.02980, test_auc = 0.97640, time = 0.04663\n",
      "Epoch: 0470 | train_loss = 0.02754, train_auc = 0.99230, test_loss = 0.02813, test_auc = 0.97794, time = 0.04691\n",
      "Epoch: 0480 | train_loss = 0.02601, train_auc = 0.99179, test_loss = 0.02870, test_auc = 0.97611, time = 0.04744\n",
      "Epoch: 0490 | train_loss = 0.02803, train_auc = 0.99183, test_loss = 0.02971, test_auc = 0.97573, time = 0.04645\n",
      "Epoch: 0500 | train_loss = 0.02706, train_auc = 0.99212, test_loss = 0.02969, test_auc = 0.97493, time = 0.04872\n",
      "times: 7, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15045, train_auc = 0.39056, test_loss = 0.07810, test_auc = 0.48117, time = 0.82127\n",
      "Epoch: 0010 | train_loss = 0.08041, train_auc = 0.91737, test_loss = 0.04578, test_auc = 0.88228, time = 0.05065\n",
      "Epoch: 0020 | train_loss = 0.07450, train_auc = 0.92980, test_loss = 0.03909, test_auc = 0.90072, time = 0.04900\n",
      "Epoch: 0030 | train_loss = 0.06623, train_auc = 0.94647, test_loss = 0.03775, test_auc = 0.92869, time = 0.04776\n",
      "Epoch: 0040 | train_loss = 0.06245, train_auc = 0.95292, test_loss = 0.03662, test_auc = 0.93814, time = 0.04750\n",
      "Epoch: 0050 | train_loss = 0.06134, train_auc = 0.95661, test_loss = 0.03359, test_auc = 0.95018, time = 0.04800\n",
      "Epoch: 0060 | train_loss = 0.05862, train_auc = 0.95926, test_loss = 0.03258, test_auc = 0.95182, time = 0.04718\n",
      "Epoch: 0070 | train_loss = 0.05471, train_auc = 0.96520, test_loss = 0.03539, test_auc = 0.95276, time = 0.04654\n",
      "Epoch: 0080 | train_loss = 0.05347, train_auc = 0.96739, test_loss = 0.03399, test_auc = 0.95170, time = 0.04562\n",
      "Epoch: 0090 | train_loss = 0.05080, train_auc = 0.97046, test_loss = 0.03631, test_auc = 0.94972, time = 0.04596\n",
      "Epoch: 0100 | train_loss = 0.04942, train_auc = 0.97229, test_loss = 0.03600, test_auc = 0.94985, time = 0.04583\n",
      "Epoch: 0110 | train_loss = 0.04937, train_auc = 0.97353, test_loss = 0.03518, test_auc = 0.94791, time = 0.04541\n",
      "Epoch: 0120 | train_loss = 0.04834, train_auc = 0.97613, test_loss = 0.03487, test_auc = 0.95845, time = 0.04700\n",
      "Epoch: 0130 | train_loss = 0.04374, train_auc = 0.97900, test_loss = 0.03552, test_auc = 0.95610, time = 0.04599\n",
      "Epoch: 0140 | train_loss = 0.04274, train_auc = 0.98011, test_loss = 0.03509, test_auc = 0.94865, time = 0.05210\n",
      "Epoch: 0150 | train_loss = 0.04028, train_auc = 0.98131, test_loss = 0.03069, test_auc = 0.96142, time = 0.04649\n",
      "Epoch: 0160 | train_loss = 0.04163, train_auc = 0.98204, test_loss = 0.03151, test_auc = 0.96016, time = 0.04762\n",
      "Epoch: 0170 | train_loss = 0.04013, train_auc = 0.98294, test_loss = 0.03608, test_auc = 0.94351, time = 0.04648\n",
      "Epoch: 0180 | train_loss = 0.04021, train_auc = 0.98147, test_loss = 0.03220, test_auc = 0.96048, time = 0.04656\n",
      "Epoch: 0190 | train_loss = 0.04018, train_auc = 0.98396, test_loss = 0.03056, test_auc = 0.96140, time = 0.04638\n",
      "Epoch: 0200 | train_loss = 0.03854, train_auc = 0.98450, test_loss = 0.03194, test_auc = 0.96321, time = 0.04639\n",
      "Epoch: 0210 | train_loss = 0.03506, train_auc = 0.98589, test_loss = 0.03457, test_auc = 0.95014, time = 0.04699\n",
      "Epoch: 0220 | train_loss = 0.03583, train_auc = 0.98641, test_loss = 0.03320, test_auc = 0.96454, time = 0.04616\n",
      "Epoch: 0230 | train_loss = 0.03649, train_auc = 0.98559, test_loss = 0.03112, test_auc = 0.96519, time = 0.05053\n",
      "Epoch: 0240 | train_loss = 0.03365, train_auc = 0.98782, test_loss = 0.03409, test_auc = 0.96425, time = 0.04616\n",
      "Epoch: 0250 | train_loss = 0.03397, train_auc = 0.98740, test_loss = 0.03021, test_auc = 0.96719, time = 0.04678\n",
      "Epoch: 0260 | train_loss = 0.03261, train_auc = 0.98822, test_loss = 0.03040, test_auc = 0.96931, time = 0.04638\n",
      "Epoch: 0270 | train_loss = 0.03258, train_auc = 0.98921, test_loss = 0.03512, test_auc = 0.95623, time = 0.04645\n",
      "Epoch: 0280 | train_loss = 0.03307, train_auc = 0.98816, test_loss = 0.03012, test_auc = 0.96793, time = 0.04648\n",
      "Epoch: 0290 | train_loss = 0.03106, train_auc = 0.98943, test_loss = 0.03249, test_auc = 0.96764, time = 0.04668\n",
      "Epoch: 0300 | train_loss = 0.03051, train_auc = 0.98993, test_loss = 0.02954, test_auc = 0.96917, time = 0.05899\n",
      "Epoch: 0310 | train_loss = 0.03054, train_auc = 0.98971, test_loss = 0.03072, test_auc = 0.96781, time = 0.04651\n",
      "Epoch: 0320 | train_loss = 0.02902, train_auc = 0.99015, test_loss = 0.02950, test_auc = 0.97080, time = 0.04742\n",
      "Epoch: 0330 | train_loss = 0.02910, train_auc = 0.99101, test_loss = 0.03230, test_auc = 0.96807, time = 0.04850\n",
      "Epoch: 0340 | train_loss = 0.02453, train_auc = 0.99188, test_loss = 0.03231, test_auc = 0.96839, time = 0.04952\n",
      "Epoch: 0350 | train_loss = 0.03205, train_auc = 0.98977, test_loss = 0.03438, test_auc = 0.96280, time = 0.04683\n",
      "Epoch: 0360 | train_loss = 0.02690, train_auc = 0.99122, test_loss = 0.03274, test_auc = 0.96509, time = 0.04721\n",
      "Epoch: 0370 | train_loss = 0.02691, train_auc = 0.99163, test_loss = 0.02885, test_auc = 0.96966, time = 0.04650\n",
      "Epoch: 0380 | train_loss = 0.03138, train_auc = 0.98997, test_loss = 0.03409, test_auc = 0.95528, time = 0.04744\n",
      "Epoch: 0390 | train_loss = 0.02889, train_auc = 0.99070, test_loss = 0.03494, test_auc = 0.95474, time = 0.04705\n",
      "Epoch: 0400 | train_loss = 0.02793, train_auc = 0.99142, test_loss = 0.03118, test_auc = 0.97067, time = 0.04640\n",
      "Epoch: 0410 | train_loss = 0.02762, train_auc = 0.99113, test_loss = 0.02944, test_auc = 0.97185, time = 0.04683\n",
      "Epoch: 0420 | train_loss = 0.02555, train_auc = 0.99178, test_loss = 0.02903, test_auc = 0.97306, time = 0.04611\n",
      "Epoch: 0430 | train_loss = 0.02650, train_auc = 0.99160, test_loss = 0.02946, test_auc = 0.97108, time = 0.04632\n",
      "Epoch: 0440 | train_loss = 0.02530, train_auc = 0.99172, test_loss = 0.03084, test_auc = 0.97180, time = 0.04832\n",
      "Epoch: 0450 | train_loss = 0.02549, train_auc = 0.99195, test_loss = 0.02979, test_auc = 0.97075, time = 0.04638\n",
      "Epoch: 0460 | train_loss = 0.02502, train_auc = 0.99170, test_loss = 0.02960, test_auc = 0.97160, time = 0.04563\n",
      "Epoch: 0470 | train_loss = 0.02443, train_auc = 0.99222, test_loss = 0.03008, test_auc = 0.97152, time = 0.04529\n",
      "Epoch: 0480 | train_loss = 0.02236, train_auc = 0.99268, test_loss = 0.03025, test_auc = 0.97208, time = 0.04548\n",
      "Epoch: 0490 | train_loss = 0.02501, train_auc = 0.99198, test_loss = 0.03184, test_auc = 0.97000, time = 0.04547\n",
      "Epoch: 0500 | train_loss = 0.02202, train_auc = 0.99300, test_loss = 0.03184, test_auc = 0.97240, time = 0.04555\n",
      "times: 7, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13490, train_auc = 0.55737, test_loss = 0.08216, test_auc = 0.40867, time = 0.84522\n",
      "Epoch: 0010 | train_loss = 0.08303, train_auc = 0.90320, test_loss = 0.04703, test_auc = 0.84838, time = 0.05091\n",
      "Epoch: 0020 | train_loss = 0.07310, train_auc = 0.93384, test_loss = 0.04157, test_auc = 0.87543, time = 0.04721\n",
      "Epoch: 0030 | train_loss = 0.06696, train_auc = 0.94383, test_loss = 0.03867, test_auc = 0.90362, time = 0.05014\n",
      "Epoch: 0040 | train_loss = 0.06340, train_auc = 0.94919, test_loss = 0.03721, test_auc = 0.91804, time = 0.04825\n",
      "Epoch: 0050 | train_loss = 0.06287, train_auc = 0.95212, test_loss = 0.03463, test_auc = 0.94771, time = 0.04702\n",
      "Epoch: 0060 | train_loss = 0.05941, train_auc = 0.95820, test_loss = 0.03400, test_auc = 0.95229, time = 0.04715\n",
      "Epoch: 0070 | train_loss = 0.06067, train_auc = 0.95584, test_loss = 0.03359, test_auc = 0.95011, time = 0.04682\n",
      "Epoch: 0080 | train_loss = 0.05784, train_auc = 0.96314, test_loss = 0.03560, test_auc = 0.95139, time = 0.04669\n",
      "Epoch: 0090 | train_loss = 0.05483, train_auc = 0.96590, test_loss = 0.03370, test_auc = 0.95380, time = 0.05123\n",
      "Epoch: 0100 | train_loss = 0.05170, train_auc = 0.96968, test_loss = 0.03135, test_auc = 0.95936, time = 0.04639\n",
      "Epoch: 0110 | train_loss = 0.05041, train_auc = 0.97131, test_loss = 0.03623, test_auc = 0.95660, time = 0.04756\n",
      "Epoch: 0120 | train_loss = 0.04718, train_auc = 0.97523, test_loss = 0.03371, test_auc = 0.95932, time = 0.04601\n",
      "Epoch: 0130 | train_loss = 0.04678, train_auc = 0.97525, test_loss = 0.03298, test_auc = 0.96001, time = 0.04787\n",
      "Epoch: 0140 | train_loss = 0.04594, train_auc = 0.97711, test_loss = 0.03318, test_auc = 0.95868, time = 0.04576\n",
      "Epoch: 0150 | train_loss = 0.04407, train_auc = 0.97874, test_loss = 0.03405, test_auc = 0.95596, time = 0.04600\n",
      "Epoch: 0160 | train_loss = 0.04342, train_auc = 0.97873, test_loss = 0.02981, test_auc = 0.96726, time = 0.04553\n",
      "Epoch: 0170 | train_loss = 0.04138, train_auc = 0.98044, test_loss = 0.03295, test_auc = 0.96275, time = 0.04528\n",
      "Epoch: 0180 | train_loss = 0.04167, train_auc = 0.98110, test_loss = 0.03081, test_auc = 0.96518, time = 0.04714\n",
      "Epoch: 0190 | train_loss = 0.03985, train_auc = 0.98186, test_loss = 0.03914, test_auc = 0.94417, time = 0.04530\n",
      "Epoch: 0200 | train_loss = 0.03995, train_auc = 0.98320, test_loss = 0.02849, test_auc = 0.96876, time = 0.04506\n",
      "Epoch: 0210 | train_loss = 0.03943, train_auc = 0.98381, test_loss = 0.03420, test_auc = 0.93639, time = 0.04547\n",
      "Epoch: 0220 | train_loss = 0.03370, train_auc = 0.98575, test_loss = 0.02760, test_auc = 0.97072, time = 0.04638\n",
      "Epoch: 0230 | train_loss = 0.03505, train_auc = 0.98662, test_loss = 0.03117, test_auc = 0.96501, time = 0.04579\n",
      "Epoch: 0240 | train_loss = 0.03472, train_auc = 0.98696, test_loss = 0.03114, test_auc = 0.96853, time = 0.04631\n",
      "Epoch: 0250 | train_loss = 0.03532, train_auc = 0.98631, test_loss = 0.03187, test_auc = 0.96982, time = 0.04536\n",
      "Epoch: 0260 | train_loss = 0.03276, train_auc = 0.98844, test_loss = 0.03501, test_auc = 0.95549, time = 0.04821\n",
      "Epoch: 0270 | train_loss = 0.03136, train_auc = 0.98902, test_loss = 0.03357, test_auc = 0.96004, time = 0.04661\n",
      "Epoch: 0280 | train_loss = 0.03204, train_auc = 0.98819, test_loss = 0.03072, test_auc = 0.96757, time = 0.04528\n",
      "Epoch: 0290 | train_loss = 0.03082, train_auc = 0.98882, test_loss = 0.03278, test_auc = 0.95673, time = 0.04552\n",
      "Epoch: 0300 | train_loss = 0.03392, train_auc = 0.98833, test_loss = 0.03336, test_auc = 0.96203, time = 0.04570\n",
      "Epoch: 0310 | train_loss = 0.03033, train_auc = 0.99067, test_loss = 0.02902, test_auc = 0.97358, time = 0.04546\n",
      "Epoch: 0320 | train_loss = 0.02889, train_auc = 0.99110, test_loss = 0.02945, test_auc = 0.97451, time = 0.04577\n",
      "Epoch: 0330 | train_loss = 0.03130, train_auc = 0.99117, test_loss = 0.02845, test_auc = 0.97224, time = 0.04532\n",
      "Epoch: 0340 | train_loss = 0.02937, train_auc = 0.99068, test_loss = 0.03142, test_auc = 0.97069, time = 0.04556\n",
      "Epoch: 0350 | train_loss = 0.02937, train_auc = 0.99057, test_loss = 0.02833, test_auc = 0.97178, time = 0.04529\n",
      "Epoch: 0360 | train_loss = 0.02760, train_auc = 0.99215, test_loss = 0.02751, test_auc = 0.97508, time = 0.04594\n",
      "Epoch: 0370 | train_loss = 0.02775, train_auc = 0.99088, test_loss = 0.03291, test_auc = 0.96665, time = 0.05021\n",
      "Epoch: 0380 | train_loss = 0.02806, train_auc = 0.99213, test_loss = 0.02775, test_auc = 0.97441, time = 0.04761\n",
      "Epoch: 0390 | train_loss = 0.02604, train_auc = 0.99266, test_loss = 0.02662, test_auc = 0.97483, time = 0.04668\n",
      "Epoch: 0400 | train_loss = 0.02514, train_auc = 0.99327, test_loss = 0.03614, test_auc = 0.96736, time = 0.04757\n",
      "Epoch: 0410 | train_loss = 0.02473, train_auc = 0.99318, test_loss = 0.03090, test_auc = 0.96736, time = 0.04947\n",
      "Epoch: 0420 | train_loss = 0.02506, train_auc = 0.99268, test_loss = 0.03100, test_auc = 0.97031, time = 0.04600\n",
      "Epoch: 0430 | train_loss = 0.02712, train_auc = 0.99300, test_loss = 0.03362, test_auc = 0.96973, time = 0.04716\n",
      "Epoch: 0440 | train_loss = 0.02608, train_auc = 0.99267, test_loss = 0.03338, test_auc = 0.95901, time = 0.04674\n",
      "Epoch: 0450 | train_loss = 0.02727, train_auc = 0.99295, test_loss = 0.02900, test_auc = 0.97201, time = 0.04554\n",
      "Epoch: 0460 | train_loss = 0.02592, train_auc = 0.99267, test_loss = 0.02978, test_auc = 0.97187, time = 0.04564\n",
      "Epoch: 0470 | train_loss = 0.02340, train_auc = 0.99390, test_loss = 0.03087, test_auc = 0.97002, time = 0.04635\n",
      "Epoch: 0480 | train_loss = 0.02220, train_auc = 0.99436, test_loss = 0.02846, test_auc = 0.97367, time = 0.04615\n",
      "Epoch: 0490 | train_loss = 0.02268, train_auc = 0.99390, test_loss = 0.02758, test_auc = 0.97563, time = 0.04529\n",
      "Epoch: 0500 | train_loss = 0.02340, train_auc = 0.99432, test_loss = 0.02977, test_auc = 0.97309, time = 0.04497\n",
      "times: 8, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15055, train_auc = 0.36945, test_loss = 0.07743, test_auc = 0.45032, time = 0.78477\n",
      "Epoch: 0010 | train_loss = 0.08578, train_auc = 0.89777, test_loss = 0.05235, test_auc = 0.81531, time = 0.04888\n",
      "Epoch: 0020 | train_loss = 0.07188, train_auc = 0.93709, test_loss = 0.04291, test_auc = 0.87838, time = 0.04743\n",
      "Epoch: 0030 | train_loss = 0.07530, train_auc = 0.92959, test_loss = 0.04016, test_auc = 0.90841, time = 0.04762\n",
      "Epoch: 0040 | train_loss = 0.06190, train_auc = 0.95382, test_loss = 0.03488, test_auc = 0.94133, time = 0.04713\n",
      "Epoch: 0050 | train_loss = 0.06048, train_auc = 0.95853, test_loss = 0.03318, test_auc = 0.94511, time = 0.04453\n",
      "Epoch: 0060 | train_loss = 0.05936, train_auc = 0.96035, test_loss = 0.03510, test_auc = 0.94285, time = 0.04517\n",
      "Epoch: 0070 | train_loss = 0.05916, train_auc = 0.96127, test_loss = 0.03388, test_auc = 0.94787, time = 0.04442\n",
      "Epoch: 0080 | train_loss = 0.05318, train_auc = 0.96862, test_loss = 0.03459, test_auc = 0.95086, time = 0.04391\n",
      "Epoch: 0090 | train_loss = 0.05212, train_auc = 0.96951, test_loss = 0.03485, test_auc = 0.94892, time = 0.04353\n",
      "Epoch: 0100 | train_loss = 0.04860, train_auc = 0.97440, test_loss = 0.03554, test_auc = 0.94588, time = 0.04362\n",
      "Epoch: 0110 | train_loss = 0.04823, train_auc = 0.97542, test_loss = 0.03151, test_auc = 0.95835, time = 0.04388\n",
      "Epoch: 0120 | train_loss = 0.04722, train_auc = 0.97542, test_loss = 0.03461, test_auc = 0.95481, time = 0.04336\n",
      "Epoch: 0130 | train_loss = 0.04468, train_auc = 0.97800, test_loss = 0.03569, test_auc = 0.95332, time = 0.04242\n",
      "Epoch: 0140 | train_loss = 0.04577, train_auc = 0.97769, test_loss = 0.03446, test_auc = 0.95795, time = 0.04283\n",
      "Epoch: 0150 | train_loss = 0.04319, train_auc = 0.98077, test_loss = 0.03051, test_auc = 0.96338, time = 0.04367\n",
      "Epoch: 0160 | train_loss = 0.04035, train_auc = 0.98243, test_loss = 0.03223, test_auc = 0.96165, time = 0.04492\n",
      "Epoch: 0170 | train_loss = 0.04105, train_auc = 0.98327, test_loss = 0.03143, test_auc = 0.96144, time = 0.04501\n",
      "Epoch: 0180 | train_loss = 0.04195, train_auc = 0.98140, test_loss = 0.03273, test_auc = 0.95689, time = 0.04902\n",
      "Epoch: 0190 | train_loss = 0.03798, train_auc = 0.98370, test_loss = 0.03285, test_auc = 0.96003, time = 0.04532\n",
      "Epoch: 0200 | train_loss = 0.03598, train_auc = 0.98682, test_loss = 0.03267, test_auc = 0.96488, time = 0.04676\n",
      "Epoch: 0210 | train_loss = 0.03555, train_auc = 0.98679, test_loss = 0.03360, test_auc = 0.96112, time = 0.04450\n",
      "Epoch: 0220 | train_loss = 0.03767, train_auc = 0.98639, test_loss = 0.03175, test_auc = 0.96767, time = 0.04409\n",
      "Epoch: 0230 | train_loss = 0.03359, train_auc = 0.98840, test_loss = 0.03126, test_auc = 0.96397, time = 0.04424\n",
      "Epoch: 0240 | train_loss = 0.03395, train_auc = 0.98929, test_loss = 0.02970, test_auc = 0.96828, time = 0.04367\n",
      "Epoch: 0250 | train_loss = 0.03307, train_auc = 0.98961, test_loss = 0.03025, test_auc = 0.96696, time = 0.04343\n",
      "Epoch: 0260 | train_loss = 0.03195, train_auc = 0.98908, test_loss = 0.03002, test_auc = 0.96967, time = 0.04305\n",
      "Epoch: 0270 | train_loss = 0.03007, train_auc = 0.99095, test_loss = 0.03239, test_auc = 0.96640, time = 0.04409\n",
      "Epoch: 0280 | train_loss = 0.03109, train_auc = 0.98980, test_loss = 0.03257, test_auc = 0.96939, time = 0.04385\n",
      "Epoch: 0290 | train_loss = 0.02845, train_auc = 0.99098, test_loss = 0.02854, test_auc = 0.97180, time = 0.04445\n",
      "Epoch: 0300 | train_loss = 0.03038, train_auc = 0.99112, test_loss = 0.02889, test_auc = 0.97239, time = 0.04429\n",
      "Epoch: 0310 | train_loss = 0.03003, train_auc = 0.99089, test_loss = 0.03004, test_auc = 0.97252, time = 0.04455\n",
      "Epoch: 0320 | train_loss = 0.03082, train_auc = 0.99060, test_loss = 0.03226, test_auc = 0.96825, time = 0.04422\n",
      "Epoch: 0330 | train_loss = 0.02853, train_auc = 0.99183, test_loss = 0.03342, test_auc = 0.96531, time = 0.04469\n",
      "Epoch: 0340 | train_loss = 0.02758, train_auc = 0.99275, test_loss = 0.02931, test_auc = 0.97236, time = 0.04351\n",
      "Epoch: 0350 | train_loss = 0.02979, train_auc = 0.99193, test_loss = 0.03096, test_auc = 0.97378, time = 0.04348\n",
      "Epoch: 0360 | train_loss = 0.02917, train_auc = 0.99276, test_loss = 0.03656, test_auc = 0.96436, time = 0.04731\n",
      "Epoch: 0370 | train_loss = 0.02637, train_auc = 0.99248, test_loss = 0.03276, test_auc = 0.97065, time = 0.04320\n",
      "Epoch: 0380 | train_loss = 0.02619, train_auc = 0.99376, test_loss = 0.03075, test_auc = 0.97283, time = 0.04910\n",
      "Epoch: 0390 | train_loss = 0.02756, train_auc = 0.99349, test_loss = 0.03246, test_auc = 0.96085, time = 0.04382\n",
      "Epoch: 0400 | train_loss = 0.02626, train_auc = 0.99370, test_loss = 0.02902, test_auc = 0.97430, time = 0.04380\n",
      "Epoch: 0410 | train_loss = 0.02659, train_auc = 0.99347, test_loss = 0.03152, test_auc = 0.96840, time = 0.04405\n",
      "Epoch: 0420 | train_loss = 0.02560, train_auc = 0.99358, test_loss = 0.02862, test_auc = 0.97641, time = 0.04480\n",
      "Epoch: 0430 | train_loss = 0.02651, train_auc = 0.99354, test_loss = 0.03307, test_auc = 0.96987, time = 0.04377\n",
      "Epoch: 0440 | train_loss = 0.02492, train_auc = 0.99334, test_loss = 0.02871, test_auc = 0.97700, time = 0.04498\n",
      "Epoch: 0450 | train_loss = 0.02227, train_auc = 0.99464, test_loss = 0.02923, test_auc = 0.97586, time = 0.04366\n",
      "Epoch: 0460 | train_loss = 0.02519, train_auc = 0.99412, test_loss = 0.02952, test_auc = 0.97456, time = 0.04398\n",
      "Epoch: 0470 | train_loss = 0.02234, train_auc = 0.99473, test_loss = 0.03553, test_auc = 0.95361, time = 0.04347\n",
      "Epoch: 0480 | train_loss = 0.02343, train_auc = 0.99470, test_loss = 0.03206, test_auc = 0.97375, time = 0.04362\n",
      "Epoch: 0490 | train_loss = 0.02242, train_auc = 0.99502, test_loss = 0.03215, test_auc = 0.96870, time = 0.04499\n",
      "Epoch: 0500 | train_loss = 0.02674, train_auc = 0.99435, test_loss = 0.02985, test_auc = 0.97073, time = 0.04365\n",
      "times: 8, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15473, train_auc = 0.34975, test_loss = 0.08663, test_auc = 0.33581, time = 0.80169\n",
      "Epoch: 0010 | train_loss = 0.07945, train_auc = 0.91536, test_loss = 0.05740, test_auc = 0.88845, time = 0.05112\n",
      "Epoch: 0020 | train_loss = 0.07555, train_auc = 0.92849, test_loss = 0.04240, test_auc = 0.91196, time = 0.05081\n",
      "Epoch: 0030 | train_loss = 0.07072, train_auc = 0.93945, test_loss = 0.03858, test_auc = 0.91531, time = 0.04712\n",
      "Epoch: 0040 | train_loss = 0.06204, train_auc = 0.95452, test_loss = 0.03362, test_auc = 0.94379, time = 0.04656\n",
      "Epoch: 0050 | train_loss = 0.06027, train_auc = 0.95887, test_loss = 0.03443, test_auc = 0.94282, time = 0.04686\n",
      "Epoch: 0060 | train_loss = 0.05749, train_auc = 0.96551, test_loss = 0.03511, test_auc = 0.94422, time = 0.04603\n",
      "Epoch: 0070 | train_loss = 0.05464, train_auc = 0.96811, test_loss = 0.03434, test_auc = 0.94270, time = 0.04511\n",
      "Epoch: 0080 | train_loss = 0.05375, train_auc = 0.97013, test_loss = 0.03053, test_auc = 0.95532, time = 0.04515\n",
      "Epoch: 0090 | train_loss = 0.05169, train_auc = 0.97252, test_loss = 0.03255, test_auc = 0.95135, time = 0.04535\n",
      "Epoch: 0100 | train_loss = 0.04714, train_auc = 0.97764, test_loss = 0.03206, test_auc = 0.95525, time = 0.04704\n",
      "Epoch: 0110 | train_loss = 0.04555, train_auc = 0.97967, test_loss = 0.03269, test_auc = 0.95069, time = 0.04518\n",
      "Epoch: 0120 | train_loss = 0.04398, train_auc = 0.98097, test_loss = 0.03072, test_auc = 0.95795, time = 0.04927\n",
      "Epoch: 0130 | train_loss = 0.04302, train_auc = 0.98187, test_loss = 0.03126, test_auc = 0.95863, time = 0.04644\n",
      "Epoch: 0140 | train_loss = 0.04014, train_auc = 0.98374, test_loss = 0.03152, test_auc = 0.95712, time = 0.04735\n",
      "Epoch: 0150 | train_loss = 0.03893, train_auc = 0.98559, test_loss = 0.03534, test_auc = 0.95600, time = 0.04598\n",
      "Epoch: 0160 | train_loss = 0.04102, train_auc = 0.98448, test_loss = 0.03385, test_auc = 0.95176, time = 0.04539\n",
      "Epoch: 0170 | train_loss = 0.03905, train_auc = 0.98554, test_loss = 0.03451, test_auc = 0.95318, time = 0.04563\n",
      "Epoch: 0180 | train_loss = 0.03507, train_auc = 0.98818, test_loss = 0.03078, test_auc = 0.95902, time = 0.04496\n",
      "Epoch: 0190 | train_loss = 0.03643, train_auc = 0.98818, test_loss = 0.03075, test_auc = 0.95922, time = 0.04562\n",
      "Epoch: 0200 | train_loss = 0.03676, train_auc = 0.98731, test_loss = 0.03105, test_auc = 0.95827, time = 0.04591\n",
      "Epoch: 0210 | train_loss = 0.03315, train_auc = 0.98962, test_loss = 0.03266, test_auc = 0.95765, time = 0.04573\n",
      "Epoch: 0220 | train_loss = 0.03388, train_auc = 0.98909, test_loss = 0.03247, test_auc = 0.95537, time = 0.04723\n",
      "Epoch: 0230 | train_loss = 0.03501, train_auc = 0.98829, test_loss = 0.03094, test_auc = 0.96241, time = 0.04593\n",
      "Epoch: 0240 | train_loss = 0.03307, train_auc = 0.98929, test_loss = 0.03072, test_auc = 0.96453, time = 0.04590\n",
      "Epoch: 0250 | train_loss = 0.03282, train_auc = 0.99005, test_loss = 0.03094, test_auc = 0.96199, time = 0.04579\n",
      "Epoch: 0260 | train_loss = 0.03032, train_auc = 0.99029, test_loss = 0.03194, test_auc = 0.96460, time = 0.04544\n",
      "Epoch: 0270 | train_loss = 0.02925, train_auc = 0.99086, test_loss = 0.03038, test_auc = 0.96388, time = 0.04534\n",
      "Epoch: 0280 | train_loss = 0.02865, train_auc = 0.99126, test_loss = 0.03271, test_auc = 0.96389, time = 0.04534\n",
      "Epoch: 0290 | train_loss = 0.03129, train_auc = 0.99059, test_loss = 0.03473, test_auc = 0.96366, time = 0.04534\n",
      "Epoch: 0300 | train_loss = 0.02965, train_auc = 0.99078, test_loss = 0.03296, test_auc = 0.96513, time = 0.04498\n",
      "Epoch: 0310 | train_loss = 0.03070, train_auc = 0.99121, test_loss = 0.03166, test_auc = 0.96751, time = 0.05044\n",
      "Epoch: 0320 | train_loss = 0.02862, train_auc = 0.99269, test_loss = 0.03119, test_auc = 0.96504, time = 0.04483\n",
      "Epoch: 0330 | train_loss = 0.02924, train_auc = 0.99205, test_loss = 0.03015, test_auc = 0.96121, time = 0.04475\n",
      "Epoch: 0340 | train_loss = 0.02936, train_auc = 0.99202, test_loss = 0.03022, test_auc = 0.96439, time = 0.04511\n",
      "Epoch: 0350 | train_loss = 0.02596, train_auc = 0.99290, test_loss = 0.03328, test_auc = 0.96431, time = 0.04441\n",
      "Epoch: 0360 | train_loss = 0.02543, train_auc = 0.99321, test_loss = 0.02996, test_auc = 0.96944, time = 0.04405\n",
      "Epoch: 0370 | train_loss = 0.02410, train_auc = 0.99373, test_loss = 0.03090, test_auc = 0.96808, time = 0.04454\n",
      "Epoch: 0380 | train_loss = 0.02440, train_auc = 0.99295, test_loss = 0.02964, test_auc = 0.96848, time = 0.04490\n",
      "Epoch: 0390 | train_loss = 0.02438, train_auc = 0.99336, test_loss = 0.02984, test_auc = 0.97163, time = 0.04462\n",
      "Epoch: 0400 | train_loss = 0.02650, train_auc = 0.99349, test_loss = 0.02848, test_auc = 0.97056, time = 0.04490\n",
      "Epoch: 0410 | train_loss = 0.02395, train_auc = 0.99408, test_loss = 0.02810, test_auc = 0.97267, time = 0.04493\n",
      "Epoch: 0420 | train_loss = 0.02443, train_auc = 0.99452, test_loss = 0.02758, test_auc = 0.97186, time = 0.04476\n",
      "Epoch: 0430 | train_loss = 0.02332, train_auc = 0.99392, test_loss = 0.02923, test_auc = 0.97102, time = 0.04432\n",
      "Epoch: 0440 | train_loss = 0.02534, train_auc = 0.99405, test_loss = 0.02837, test_auc = 0.97170, time = 0.04436\n",
      "Epoch: 0450 | train_loss = 0.02342, train_auc = 0.99444, test_loss = 0.03049, test_auc = 0.96980, time = 0.04491\n",
      "Epoch: 0460 | train_loss = 0.02470, train_auc = 0.99461, test_loss = 0.02847, test_auc = 0.97136, time = 0.04538\n",
      "Epoch: 0470 | train_loss = 0.02353, train_auc = 0.99430, test_loss = 0.02999, test_auc = 0.96886, time = 0.04479\n",
      "Epoch: 0480 | train_loss = 0.02237, train_auc = 0.99521, test_loss = 0.03019, test_auc = 0.97136, time = 0.04622\n",
      "Epoch: 0490 | train_loss = 0.02116, train_auc = 0.99524, test_loss = 0.02769, test_auc = 0.97259, time = 0.04478\n",
      "Epoch: 0500 | train_loss = 0.02324, train_auc = 0.99479, test_loss = 0.02852, test_auc = 0.96827, time = 0.04377\n",
      "times: 8, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14063, train_auc = 0.47780, test_loss = 0.06726, test_auc = 0.61932, time = 0.79023\n",
      "Epoch: 0010 | train_loss = 0.08107, train_auc = 0.90954, test_loss = 0.04877, test_auc = 0.85811, time = 0.05044\n",
      "Epoch: 0020 | train_loss = 0.07221, train_auc = 0.93279, test_loss = 0.03966, test_auc = 0.89878, time = 0.04701\n",
      "Epoch: 0030 | train_loss = 0.06560, train_auc = 0.94544, test_loss = 0.03681, test_auc = 0.91959, time = 0.04646\n",
      "Epoch: 0040 | train_loss = 0.06245, train_auc = 0.95250, test_loss = 0.03509, test_auc = 0.93846, time = 0.04527\n",
      "Epoch: 0050 | train_loss = 0.06068, train_auc = 0.95816, test_loss = 0.03586, test_auc = 0.94038, time = 0.04500\n",
      "Epoch: 0060 | train_loss = 0.05789, train_auc = 0.96305, test_loss = 0.03338, test_auc = 0.94747, time = 0.05075\n",
      "Epoch: 0070 | train_loss = 0.05498, train_auc = 0.96656, test_loss = 0.03342, test_auc = 0.94770, time = 0.04564\n",
      "Epoch: 0080 | train_loss = 0.05128, train_auc = 0.97210, test_loss = 0.03282, test_auc = 0.95037, time = 0.04707\n",
      "Epoch: 0090 | train_loss = 0.05036, train_auc = 0.97374, test_loss = 0.03263, test_auc = 0.95503, time = 0.04520\n",
      "Epoch: 0100 | train_loss = 0.05220, train_auc = 0.97168, test_loss = 0.03664, test_auc = 0.93902, time = 0.04385\n",
      "Epoch: 0110 | train_loss = 0.04833, train_auc = 0.97540, test_loss = 0.03851, test_auc = 0.94174, time = 0.04366\n",
      "Epoch: 0120 | train_loss = 0.04590, train_auc = 0.97890, test_loss = 0.03624, test_auc = 0.93935, time = 0.04361\n",
      "Epoch: 0130 | train_loss = 0.04404, train_auc = 0.97978, test_loss = 0.03311, test_auc = 0.95728, time = 0.04353\n",
      "Epoch: 0140 | train_loss = 0.04266, train_auc = 0.98191, test_loss = 0.03590, test_auc = 0.95212, time = 0.04365\n",
      "Epoch: 0150 | train_loss = 0.04331, train_auc = 0.98097, test_loss = 0.03331, test_auc = 0.94979, time = 0.04327\n",
      "Epoch: 0160 | train_loss = 0.04342, train_auc = 0.98170, test_loss = 0.03249, test_auc = 0.95670, time = 0.04495\n",
      "Epoch: 0170 | train_loss = 0.04011, train_auc = 0.98439, test_loss = 0.02976, test_auc = 0.96285, time = 0.04368\n",
      "Epoch: 0180 | train_loss = 0.03873, train_auc = 0.98544, test_loss = 0.03128, test_auc = 0.95679, time = 0.04353\n",
      "Epoch: 0190 | train_loss = 0.03618, train_auc = 0.98702, test_loss = 0.03114, test_auc = 0.96297, time = 0.04616\n",
      "Epoch: 0200 | train_loss = 0.03891, train_auc = 0.98585, test_loss = 0.03078, test_auc = 0.96060, time = 0.04467\n",
      "Epoch: 0210 | train_loss = 0.03352, train_auc = 0.98852, test_loss = 0.03224, test_auc = 0.96236, time = 0.04396\n",
      "Epoch: 0220 | train_loss = 0.03170, train_auc = 0.98979, test_loss = 0.02975, test_auc = 0.96697, time = 0.04410\n",
      "Epoch: 0230 | train_loss = 0.03170, train_auc = 0.99009, test_loss = 0.03251, test_auc = 0.96300, time = 0.04315\n",
      "Epoch: 0240 | train_loss = 0.03250, train_auc = 0.99066, test_loss = 0.03622, test_auc = 0.94896, time = 0.04503\n",
      "Epoch: 0250 | train_loss = 0.03265, train_auc = 0.98986, test_loss = 0.02966, test_auc = 0.96557, time = 0.04435\n",
      "Epoch: 0260 | train_loss = 0.03244, train_auc = 0.99035, test_loss = 0.02885, test_auc = 0.96678, time = 0.04400\n",
      "Epoch: 0270 | train_loss = 0.03005, train_auc = 0.99222, test_loss = 0.03225, test_auc = 0.96556, time = 0.04353\n",
      "Epoch: 0280 | train_loss = 0.03237, train_auc = 0.99029, test_loss = 0.02978, test_auc = 0.96645, time = 0.04430\n",
      "Epoch: 0290 | train_loss = 0.03089, train_auc = 0.99172, test_loss = 0.03458, test_auc = 0.95437, time = 0.04426\n",
      "Epoch: 0300 | train_loss = 0.02776, train_auc = 0.99261, test_loss = 0.03053, test_auc = 0.96749, time = 0.04370\n",
      "Epoch: 0310 | train_loss = 0.02937, train_auc = 0.99198, test_loss = 0.03223, test_auc = 0.96503, time = 0.04354\n",
      "Epoch: 0320 | train_loss = 0.02794, train_auc = 0.99302, test_loss = 0.03162, test_auc = 0.96552, time = 0.04344\n",
      "Epoch: 0330 | train_loss = 0.02589, train_auc = 0.99325, test_loss = 0.03183, test_auc = 0.96580, time = 0.04352\n",
      "Epoch: 0340 | train_loss = 0.02731, train_auc = 0.99286, test_loss = 0.02904, test_auc = 0.96756, time = 0.04310\n",
      "Epoch: 0350 | train_loss = 0.02659, train_auc = 0.99293, test_loss = 0.03080, test_auc = 0.96845, time = 0.04388\n",
      "Epoch: 0360 | train_loss = 0.02633, train_auc = 0.99321, test_loss = 0.02926, test_auc = 0.96614, time = 0.04480\n",
      "Epoch: 0370 | train_loss = 0.02649, train_auc = 0.99357, test_loss = 0.03219, test_auc = 0.96420, time = 0.04689\n",
      "Epoch: 0380 | train_loss = 0.02387, train_auc = 0.99414, test_loss = 0.03580, test_auc = 0.96128, time = 0.04446\n",
      "Epoch: 0390 | train_loss = 0.02460, train_auc = 0.99406, test_loss = 0.02838, test_auc = 0.96952, time = 0.04508\n",
      "Epoch: 0400 | train_loss = 0.02590, train_auc = 0.99369, test_loss = 0.03024, test_auc = 0.96740, time = 0.04380\n",
      "Epoch: 0410 | train_loss = 0.02782, train_auc = 0.99323, test_loss = 0.03059, test_auc = 0.96931, time = 0.04400\n",
      "Epoch: 0420 | train_loss = 0.02314, train_auc = 0.99452, test_loss = 0.03075, test_auc = 0.96325, time = 0.04450\n",
      "Epoch: 0430 | train_loss = 0.02442, train_auc = 0.99485, test_loss = 0.02970, test_auc = 0.96812, time = 0.04337\n",
      "Epoch: 0440 | train_loss = 0.02637, train_auc = 0.99347, test_loss = 0.03511, test_auc = 0.96380, time = 0.04519\n",
      "Epoch: 0450 | train_loss = 0.02553, train_auc = 0.99434, test_loss = 0.03010, test_auc = 0.96648, time = 0.04339\n",
      "Epoch: 0460 | train_loss = 0.02257, train_auc = 0.99484, test_loss = 0.03218, test_auc = 0.95921, time = 0.04391\n",
      "Epoch: 0470 | train_loss = 0.02469, train_auc = 0.99385, test_loss = 0.03118, test_auc = 0.96807, time = 0.04496\n",
      "Epoch: 0480 | train_loss = 0.02276, train_auc = 0.99431, test_loss = 0.03331, test_auc = 0.95925, time = 0.04559\n",
      "Epoch: 0490 | train_loss = 0.02467, train_auc = 0.99451, test_loss = 0.03059, test_auc = 0.96775, time = 0.04373\n",
      "Epoch: 0500 | train_loss = 0.02258, train_auc = 0.99476, test_loss = 0.02791, test_auc = 0.97195, time = 0.04660\n",
      "times: 8, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13305, train_auc = 0.57503, test_loss = 0.07455, test_auc = 0.53311, time = 0.81332\n",
      "Epoch: 0010 | train_loss = 0.08235, train_auc = 0.90918, test_loss = 0.04741, test_auc = 0.83256, time = 0.05179\n",
      "Epoch: 0020 | train_loss = 0.07344, train_auc = 0.92385, test_loss = 0.04036, test_auc = 0.90914, time = 0.04859\n",
      "Epoch: 0030 | train_loss = 0.07615, train_auc = 0.92255, test_loss = 0.03817, test_auc = 0.92034, time = 0.04524\n",
      "Epoch: 0040 | train_loss = 0.06409, train_auc = 0.94987, test_loss = 0.03725, test_auc = 0.92718, time = 0.04481\n",
      "Epoch: 0050 | train_loss = 0.06400, train_auc = 0.95062, test_loss = 0.03525, test_auc = 0.93798, time = 0.04522\n",
      "Epoch: 0060 | train_loss = 0.06093, train_auc = 0.95550, test_loss = 0.03651, test_auc = 0.93670, time = 0.04450\n",
      "Epoch: 0070 | train_loss = 0.05780, train_auc = 0.96134, test_loss = 0.03491, test_auc = 0.94271, time = 0.04419\n",
      "Epoch: 0080 | train_loss = 0.05596, train_auc = 0.96289, test_loss = 0.03696, test_auc = 0.94684, time = 0.04404\n",
      "Epoch: 0090 | train_loss = 0.05283, train_auc = 0.96840, test_loss = 0.03466, test_auc = 0.94587, time = 0.04408\n",
      "Epoch: 0100 | train_loss = 0.05275, train_auc = 0.96916, test_loss = 0.03285, test_auc = 0.95541, time = 0.04389\n",
      "Epoch: 0110 | train_loss = 0.04997, train_auc = 0.97436, test_loss = 0.03077, test_auc = 0.96095, time = 0.04383\n",
      "Epoch: 0120 | train_loss = 0.05050, train_auc = 0.97381, test_loss = 0.03495, test_auc = 0.95456, time = 0.04438\n",
      "Epoch: 0130 | train_loss = 0.04779, train_auc = 0.97752, test_loss = 0.03195, test_auc = 0.95815, time = 0.05046\n",
      "Epoch: 0140 | train_loss = 0.04545, train_auc = 0.97976, test_loss = 0.03519, test_auc = 0.95289, time = 0.04517\n",
      "Epoch: 0150 | train_loss = 0.04211, train_auc = 0.98225, test_loss = 0.03137, test_auc = 0.96087, time = 0.04456\n",
      "Epoch: 0160 | train_loss = 0.04261, train_auc = 0.98266, test_loss = 0.03157, test_auc = 0.96024, time = 0.04404\n",
      "Epoch: 0170 | train_loss = 0.04092, train_auc = 0.98431, test_loss = 0.03421, test_auc = 0.95084, time = 0.04358\n",
      "Epoch: 0180 | train_loss = 0.03865, train_auc = 0.98507, test_loss = 0.03291, test_auc = 0.96205, time = 0.04426\n",
      "Epoch: 0190 | train_loss = 0.03740, train_auc = 0.98670, test_loss = 0.03167, test_auc = 0.96316, time = 0.04928\n",
      "Epoch: 0200 | train_loss = 0.03537, train_auc = 0.98711, test_loss = 0.03883, test_auc = 0.96081, time = 0.04430\n",
      "Epoch: 0210 | train_loss = 0.03679, train_auc = 0.98640, test_loss = 0.03161, test_auc = 0.96144, time = 0.04420\n",
      "Epoch: 0220 | train_loss = 0.03237, train_auc = 0.98921, test_loss = 0.03264, test_auc = 0.96002, time = 0.04445\n",
      "Epoch: 0230 | train_loss = 0.03326, train_auc = 0.98880, test_loss = 0.03518, test_auc = 0.96058, time = 0.04386\n",
      "Epoch: 0240 | train_loss = 0.03382, train_auc = 0.99003, test_loss = 0.03174, test_auc = 0.96764, time = 0.04408\n",
      "Epoch: 0250 | train_loss = 0.03049, train_auc = 0.99107, test_loss = 0.03039, test_auc = 0.97176, time = 0.04417\n",
      "Epoch: 0260 | train_loss = 0.03220, train_auc = 0.99062, test_loss = 0.03050, test_auc = 0.96743, time = 0.04378\n",
      "Epoch: 0270 | train_loss = 0.03126, train_auc = 0.99066, test_loss = 0.03502, test_auc = 0.96643, time = 0.04391\n",
      "Epoch: 0280 | train_loss = 0.03021, train_auc = 0.99089, test_loss = 0.02976, test_auc = 0.97052, time = 0.04395\n",
      "Epoch: 0290 | train_loss = 0.03056, train_auc = 0.99153, test_loss = 0.03212, test_auc = 0.97177, time = 0.04367\n",
      "Epoch: 0300 | train_loss = 0.02979, train_auc = 0.99231, test_loss = 0.03279, test_auc = 0.96928, time = 0.04545\n",
      "Epoch: 0310 | train_loss = 0.02744, train_auc = 0.99197, test_loss = 0.02905, test_auc = 0.97423, time = 0.05127\n",
      "Epoch: 0320 | train_loss = 0.02901, train_auc = 0.99174, test_loss = 0.03238, test_auc = 0.96942, time = 0.04515\n",
      "Epoch: 0330 | train_loss = 0.02635, train_auc = 0.99287, test_loss = 0.03111, test_auc = 0.97382, time = 0.04455\n",
      "Epoch: 0340 | train_loss = 0.02907, train_auc = 0.99160, test_loss = 0.02992, test_auc = 0.97139, time = 0.04492\n",
      "Epoch: 0350 | train_loss = 0.02654, train_auc = 0.99278, test_loss = 0.02948, test_auc = 0.97247, time = 0.04436\n",
      "Epoch: 0360 | train_loss = 0.02784, train_auc = 0.99297, test_loss = 0.03171, test_auc = 0.96859, time = 0.04423\n",
      "Epoch: 0370 | train_loss = 0.02432, train_auc = 0.99338, test_loss = 0.03270, test_auc = 0.96620, time = 0.04356\n",
      "Epoch: 0380 | train_loss = 0.02708, train_auc = 0.99302, test_loss = 0.03331, test_auc = 0.95946, time = 0.04441\n",
      "Epoch: 0390 | train_loss = 0.02503, train_auc = 0.99352, test_loss = 0.02989, test_auc = 0.97003, time = 0.04345\n",
      "Epoch: 0400 | train_loss = 0.02478, train_auc = 0.99351, test_loss = 0.02864, test_auc = 0.97412, time = 0.04286\n",
      "Epoch: 0410 | train_loss = 0.02516, train_auc = 0.99387, test_loss = 0.02952, test_auc = 0.97627, time = 0.04660\n",
      "Epoch: 0420 | train_loss = 0.02311, train_auc = 0.99400, test_loss = 0.02850, test_auc = 0.97533, time = 0.04393\n",
      "Epoch: 0430 | train_loss = 0.02282, train_auc = 0.99358, test_loss = 0.03305, test_auc = 0.97026, time = 0.04426\n",
      "Epoch: 0440 | train_loss = 0.02302, train_auc = 0.99366, test_loss = 0.03379, test_auc = 0.95730, time = 0.04430\n",
      "Epoch: 0450 | train_loss = 0.02551, train_auc = 0.99374, test_loss = 0.03337, test_auc = 0.97420, time = 0.04429\n",
      "Epoch: 0460 | train_loss = 0.02427, train_auc = 0.99354, test_loss = 0.02893, test_auc = 0.97650, time = 0.04438\n",
      "Epoch: 0470 | train_loss = 0.02668, train_auc = 0.99357, test_loss = 0.02884, test_auc = 0.97532, time = 0.04499\n",
      "Epoch: 0480 | train_loss = 0.02738, train_auc = 0.99251, test_loss = 0.02860, test_auc = 0.97393, time = 0.04460\n",
      "Epoch: 0490 | train_loss = 0.02454, train_auc = 0.99391, test_loss = 0.02890, test_auc = 0.97677, time = 0.04446\n",
      "Epoch: 0500 | train_loss = 0.02344, train_auc = 0.99354, test_loss = 0.02868, test_auc = 0.97567, time = 0.04526\n",
      "times: 8, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.12913, train_auc = 0.65239, test_loss = 0.07358, test_auc = 0.54853, time = 0.81102\n",
      "Epoch: 0010 | train_loss = 0.08009, train_auc = 0.90562, test_loss = 0.06295, test_auc = 0.79125, time = 0.04965\n",
      "Epoch: 0020 | train_loss = 0.07301, train_auc = 0.93658, test_loss = 0.04178, test_auc = 0.89818, time = 0.04711\n",
      "Epoch: 0030 | train_loss = 0.06470, train_auc = 0.94845, test_loss = 0.03733, test_auc = 0.93270, time = 0.04641\n",
      "Epoch: 0040 | train_loss = 0.06017, train_auc = 0.95601, test_loss = 0.03660, test_auc = 0.93715, time = 0.04576\n",
      "Epoch: 0050 | train_loss = 0.06010, train_auc = 0.95861, test_loss = 0.03400, test_auc = 0.94564, time = 0.04516\n",
      "Epoch: 0060 | train_loss = 0.05680, train_auc = 0.96214, test_loss = 0.03505, test_auc = 0.94486, time = 0.04539\n",
      "Epoch: 0070 | train_loss = 0.05600, train_auc = 0.96403, test_loss = 0.03621, test_auc = 0.93709, time = 0.04740\n",
      "Epoch: 0080 | train_loss = 0.05316, train_auc = 0.96715, test_loss = 0.03292, test_auc = 0.95290, time = 0.04510\n",
      "Epoch: 0090 | train_loss = 0.05135, train_auc = 0.97067, test_loss = 0.03160, test_auc = 0.95798, time = 0.04541\n",
      "Epoch: 0100 | train_loss = 0.05019, train_auc = 0.97102, test_loss = 0.03609, test_auc = 0.94462, time = 0.04517\n",
      "Epoch: 0110 | train_loss = 0.04772, train_auc = 0.97378, test_loss = 0.03457, test_auc = 0.94624, time = 0.04395\n",
      "Epoch: 0120 | train_loss = 0.04717, train_auc = 0.97414, test_loss = 0.03243, test_auc = 0.95678, time = 0.04338\n",
      "Epoch: 0130 | train_loss = 0.04775, train_auc = 0.97594, test_loss = 0.03344, test_auc = 0.96209, time = 0.04435\n",
      "Epoch: 0140 | train_loss = 0.04591, train_auc = 0.97774, test_loss = 0.03278, test_auc = 0.95322, time = 0.05117\n",
      "Epoch: 0150 | train_loss = 0.04346, train_auc = 0.97910, test_loss = 0.03290, test_auc = 0.95809, time = 0.04350\n",
      "Epoch: 0160 | train_loss = 0.04085, train_auc = 0.98167, test_loss = 0.03287, test_auc = 0.96101, time = 0.04406\n",
      "Epoch: 0170 | train_loss = 0.04230, train_auc = 0.98105, test_loss = 0.03640, test_auc = 0.95462, time = 0.04376\n",
      "Epoch: 0180 | train_loss = 0.04053, train_auc = 0.98339, test_loss = 0.03610, test_auc = 0.95936, time = 0.04363\n",
      "Epoch: 0190 | train_loss = 0.03882, train_auc = 0.98544, test_loss = 0.03296, test_auc = 0.96132, time = 0.04403\n",
      "Epoch: 0200 | train_loss = 0.03801, train_auc = 0.98479, test_loss = 0.03214, test_auc = 0.96486, time = 0.04360\n",
      "Epoch: 0210 | train_loss = 0.03482, train_auc = 0.98676, test_loss = 0.03360, test_auc = 0.96476, time = 0.04421\n",
      "Epoch: 0220 | train_loss = 0.03672, train_auc = 0.98617, test_loss = 0.03126, test_auc = 0.96621, time = 0.04414\n",
      "Epoch: 0230 | train_loss = 0.03627, train_auc = 0.98722, test_loss = 0.03285, test_auc = 0.96638, time = 0.04326\n",
      "Epoch: 0240 | train_loss = 0.03510, train_auc = 0.98823, test_loss = 0.03133, test_auc = 0.96360, time = 0.04458\n",
      "Epoch: 0250 | train_loss = 0.03218, train_auc = 0.98915, test_loss = 0.03366, test_auc = 0.96502, time = 0.04506\n",
      "Epoch: 0260 | train_loss = 0.03240, train_auc = 0.98875, test_loss = 0.03297, test_auc = 0.96867, time = 0.04364\n",
      "Epoch: 0270 | train_loss = 0.03160, train_auc = 0.99057, test_loss = 0.03481, test_auc = 0.96214, time = 0.04442\n",
      "Epoch: 0280 | train_loss = 0.03285, train_auc = 0.98959, test_loss = 0.03658, test_auc = 0.96580, time = 0.04417\n",
      "Epoch: 0290 | train_loss = 0.03237, train_auc = 0.99066, test_loss = 0.03252, test_auc = 0.95922, time = 0.04456\n",
      "Epoch: 0300 | train_loss = 0.03152, train_auc = 0.99103, test_loss = 0.03253, test_auc = 0.96796, time = 0.04411\n",
      "Epoch: 0310 | train_loss = 0.02835, train_auc = 0.99194, test_loss = 0.03177, test_auc = 0.97052, time = 0.04435\n",
      "Epoch: 0320 | train_loss = 0.03025, train_auc = 0.99112, test_loss = 0.03473, test_auc = 0.96206, time = 0.04414\n",
      "Epoch: 0330 | train_loss = 0.02942, train_auc = 0.99151, test_loss = 0.03570, test_auc = 0.96183, time = 0.04479\n",
      "Epoch: 0340 | train_loss = 0.02920, train_auc = 0.99236, test_loss = 0.03398, test_auc = 0.96661, time = 0.04495\n",
      "Epoch: 0350 | train_loss = 0.02853, train_auc = 0.99278, test_loss = 0.03067, test_auc = 0.96680, time = 0.04464\n",
      "Epoch: 0360 | train_loss = 0.02491, train_auc = 0.99383, test_loss = 0.02899, test_auc = 0.97183, time = 0.04515\n",
      "Epoch: 0370 | train_loss = 0.02762, train_auc = 0.99349, test_loss = 0.03283, test_auc = 0.96088, time = 0.04482\n",
      "Epoch: 0380 | train_loss = 0.02602, train_auc = 0.99345, test_loss = 0.02977, test_auc = 0.97078, time = 0.05818\n",
      "Epoch: 0390 | train_loss = 0.02391, train_auc = 0.99391, test_loss = 0.03925, test_auc = 0.95623, time = 0.04629\n",
      "Epoch: 0400 | train_loss = 0.02557, train_auc = 0.99447, test_loss = 0.03100, test_auc = 0.97099, time = 0.04801\n",
      "Epoch: 0410 | train_loss = 0.02876, train_auc = 0.99284, test_loss = 0.03068, test_auc = 0.96709, time = 0.06159\n",
      "Epoch: 0420 | train_loss = 0.02480, train_auc = 0.99391, test_loss = 0.03085, test_auc = 0.96751, time = 0.06817\n",
      "Epoch: 0430 | train_loss = 0.02695, train_auc = 0.99373, test_loss = 0.02913, test_auc = 0.97242, time = 0.04696\n",
      "Epoch: 0440 | train_loss = 0.02457, train_auc = 0.99442, test_loss = 0.02982, test_auc = 0.97069, time = 0.04623\n",
      "Epoch: 0450 | train_loss = 0.02322, train_auc = 0.99499, test_loss = 0.03079, test_auc = 0.96896, time = 0.04489\n",
      "Epoch: 0460 | train_loss = 0.02388, train_auc = 0.99487, test_loss = 0.03317, test_auc = 0.96492, time = 0.04578\n",
      "Epoch: 0470 | train_loss = 0.02252, train_auc = 0.99443, test_loss = 0.03053, test_auc = 0.96838, time = 0.04399\n",
      "Epoch: 0480 | train_loss = 0.02437, train_auc = 0.99496, test_loss = 0.02893, test_auc = 0.97304, time = 0.04451\n",
      "Epoch: 0490 | train_loss = 0.02339, train_auc = 0.99465, test_loss = 0.03733, test_auc = 0.95906, time = 0.04468\n",
      "Epoch: 0500 | train_loss = 0.02156, train_auc = 0.99536, test_loss = 0.02916, test_auc = 0.97344, time = 0.04459\n",
      "times: 9, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14125, train_auc = 0.47704, test_loss = 0.07322, test_auc = 0.54764, time = 0.81472\n",
      "Epoch: 0010 | train_loss = 0.08081, train_auc = 0.91222, test_loss = 0.04995, test_auc = 0.84231, time = 0.05008\n",
      "Epoch: 0020 | train_loss = 0.07141, train_auc = 0.93528, test_loss = 0.04188, test_auc = 0.87997, time = 0.04795\n",
      "Epoch: 0030 | train_loss = 0.06546, train_auc = 0.94981, test_loss = 0.03959, test_auc = 0.91349, time = 0.04636\n",
      "Epoch: 0040 | train_loss = 0.05971, train_auc = 0.95869, test_loss = 0.03868, test_auc = 0.91948, time = 0.04512\n",
      "Epoch: 0050 | train_loss = 0.05835, train_auc = 0.96246, test_loss = 0.03798, test_auc = 0.93448, time = 0.04699\n",
      "Epoch: 0060 | train_loss = 0.05997, train_auc = 0.96116, test_loss = 0.04230, test_auc = 0.93968, time = 0.04573\n",
      "Epoch: 0070 | train_loss = 0.05395, train_auc = 0.96941, test_loss = 0.03534, test_auc = 0.94161, time = 0.04557\n",
      "Epoch: 0080 | train_loss = 0.05030, train_auc = 0.97336, test_loss = 0.03396, test_auc = 0.94944, time = 0.04448\n",
      "Epoch: 0090 | train_loss = 0.04844, train_auc = 0.97535, test_loss = 0.03655, test_auc = 0.94850, time = 0.04645\n",
      "Epoch: 0100 | train_loss = 0.04662, train_auc = 0.97753, test_loss = 0.03438, test_auc = 0.94458, time = 0.04457\n",
      "Epoch: 0110 | train_loss = 0.04873, train_auc = 0.97784, test_loss = 0.03244, test_auc = 0.95626, time = 0.04477\n",
      "Epoch: 0120 | train_loss = 0.04454, train_auc = 0.97941, test_loss = 0.03353, test_auc = 0.95493, time = 0.04527\n",
      "Epoch: 0130 | train_loss = 0.04512, train_auc = 0.97995, test_loss = 0.03349, test_auc = 0.95697, time = 0.04524\n",
      "Epoch: 0140 | train_loss = 0.04097, train_auc = 0.98275, test_loss = 0.03249, test_auc = 0.95558, time = 0.04572\n",
      "Epoch: 0150 | train_loss = 0.04253, train_auc = 0.98166, test_loss = 0.03391, test_auc = 0.95809, time = 0.04497\n",
      "Epoch: 0160 | train_loss = 0.03987, train_auc = 0.98391, test_loss = 0.03210, test_auc = 0.95961, time = 0.04479\n",
      "Epoch: 0170 | train_loss = 0.03958, train_auc = 0.98410, test_loss = 0.03071, test_auc = 0.96170, time = 0.04538\n",
      "Epoch: 0180 | train_loss = 0.03654, train_auc = 0.98617, test_loss = 0.03825, test_auc = 0.94027, time = 0.04476\n",
      "Epoch: 0190 | train_loss = 0.03821, train_auc = 0.98482, test_loss = 0.03338, test_auc = 0.94807, time = 0.04509\n",
      "Epoch: 0200 | train_loss = 0.03600, train_auc = 0.98670, test_loss = 0.03468, test_auc = 0.95185, time = 0.04464\n",
      "Epoch: 0210 | train_loss = 0.03537, train_auc = 0.98756, test_loss = 0.03536, test_auc = 0.94398, time = 0.04530\n",
      "Epoch: 0220 | train_loss = 0.03501, train_auc = 0.98772, test_loss = 0.03627, test_auc = 0.95911, time = 0.04509\n",
      "Epoch: 0230 | train_loss = 0.03308, train_auc = 0.98896, test_loss = 0.03214, test_auc = 0.96459, time = 0.04507\n",
      "Epoch: 0240 | train_loss = 0.03070, train_auc = 0.99028, test_loss = 0.03052, test_auc = 0.96847, time = 0.04501\n",
      "Epoch: 0250 | train_loss = 0.03294, train_auc = 0.98956, test_loss = 0.02902, test_auc = 0.96776, time = 0.04563\n",
      "Epoch: 0260 | train_loss = 0.03096, train_auc = 0.99013, test_loss = 0.03732, test_auc = 0.95901, time = 0.04542\n",
      "Epoch: 0270 | train_loss = 0.03238, train_auc = 0.98983, test_loss = 0.03314, test_auc = 0.96119, time = 0.04423\n",
      "Epoch: 0280 | train_loss = 0.03334, train_auc = 0.98944, test_loss = 0.02968, test_auc = 0.96430, time = 0.04431\n",
      "Epoch: 0290 | train_loss = 0.02896, train_auc = 0.99075, test_loss = 0.03079, test_auc = 0.96754, time = 0.04388\n",
      "Epoch: 0300 | train_loss = 0.02933, train_auc = 0.99117, test_loss = 0.03092, test_auc = 0.96472, time = 0.04426\n",
      "Epoch: 0310 | train_loss = 0.02885, train_auc = 0.99098, test_loss = 0.03121, test_auc = 0.96713, time = 0.04419\n",
      "Epoch: 0320 | train_loss = 0.02660, train_auc = 0.99161, test_loss = 0.03160, test_auc = 0.96431, time = 0.04402\n",
      "Epoch: 0330 | train_loss = 0.03023, train_auc = 0.99054, test_loss = 0.03284, test_auc = 0.96363, time = 0.04411\n",
      "Epoch: 0340 | train_loss = 0.02949, train_auc = 0.99152, test_loss = 0.02941, test_auc = 0.96939, time = 0.04435\n",
      "Epoch: 0350 | train_loss = 0.02662, train_auc = 0.99187, test_loss = 0.03172, test_auc = 0.96637, time = 0.04434\n",
      "Epoch: 0360 | train_loss = 0.02827, train_auc = 0.99156, test_loss = 0.03233, test_auc = 0.96733, time = 0.04459\n",
      "Epoch: 0370 | train_loss = 0.02694, train_auc = 0.99142, test_loss = 0.03182, test_auc = 0.96612, time = 0.04456\n",
      "Epoch: 0380 | train_loss = 0.02741, train_auc = 0.99147, test_loss = 0.03530, test_auc = 0.96380, time = 0.04392\n",
      "Epoch: 0390 | train_loss = 0.02639, train_auc = 0.99171, test_loss = 0.02801, test_auc = 0.97113, time = 0.04416\n",
      "Epoch: 0400 | train_loss = 0.02435, train_auc = 0.99211, test_loss = 0.03320, test_auc = 0.96181, time = 0.04531\n",
      "Epoch: 0410 | train_loss = 0.02508, train_auc = 0.99241, test_loss = 0.03121, test_auc = 0.96822, time = 0.04358\n",
      "Epoch: 0420 | train_loss = 0.02618, train_auc = 0.99205, test_loss = 0.02991, test_auc = 0.96861, time = 0.04395\n",
      "Epoch: 0430 | train_loss = 0.02458, train_auc = 0.99264, test_loss = 0.03026, test_auc = 0.97006, time = 0.04392\n",
      "Epoch: 0440 | train_loss = 0.02551, train_auc = 0.99238, test_loss = 0.03016, test_auc = 0.97004, time = 0.04424\n",
      "Epoch: 0450 | train_loss = 0.02293, train_auc = 0.99256, test_loss = 0.03329, test_auc = 0.96784, time = 0.04404\n",
      "Epoch: 0460 | train_loss = 0.02507, train_auc = 0.99218, test_loss = 0.03255, test_auc = 0.96801, time = 0.04479\n",
      "Epoch: 0470 | train_loss = 0.02641, train_auc = 0.99232, test_loss = 0.03101, test_auc = 0.96837, time = 0.04403\n",
      "Epoch: 0480 | train_loss = 0.02433, train_auc = 0.99294, test_loss = 0.03024, test_auc = 0.96865, time = 0.04401\n",
      "Epoch: 0490 | train_loss = 0.02281, train_auc = 0.99227, test_loss = 0.03074, test_auc = 0.96835, time = 0.04463\n",
      "Epoch: 0500 | train_loss = 0.02261, train_auc = 0.99268, test_loss = 0.03157, test_auc = 0.96602, time = 0.04563\n",
      "times: 9, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13350, train_auc = 0.58211, test_loss = 0.07385, test_auc = 0.53145, time = 0.79324\n",
      "Epoch: 0010 | train_loss = 0.08494, train_auc = 0.91055, test_loss = 0.04859, test_auc = 0.84939, time = 0.05025\n",
      "Epoch: 0020 | train_loss = 0.07657, train_auc = 0.92042, test_loss = 0.04243, test_auc = 0.90242, time = 0.04777\n",
      "Epoch: 0030 | train_loss = 0.06955, train_auc = 0.93997, test_loss = 0.03941, test_auc = 0.90856, time = 0.04687\n",
      "Epoch: 0040 | train_loss = 0.06446, train_auc = 0.94901, test_loss = 0.04115, test_auc = 0.93111, time = 0.04636\n",
      "Epoch: 0050 | train_loss = 0.06281, train_auc = 0.95569, test_loss = 0.03700, test_auc = 0.92825, time = 0.04521\n",
      "Epoch: 0060 | train_loss = 0.05720, train_auc = 0.96203, test_loss = 0.03617, test_auc = 0.94108, time = 0.04550\n",
      "Epoch: 0070 | train_loss = 0.05771, train_auc = 0.96283, test_loss = 0.03371, test_auc = 0.94768, time = 0.04858\n",
      "Epoch: 0080 | train_loss = 0.05402, train_auc = 0.96851, test_loss = 0.03499, test_auc = 0.94446, time = 0.04482\n",
      "Epoch: 0090 | train_loss = 0.05177, train_auc = 0.97221, test_loss = 0.03348, test_auc = 0.94922, time = 0.04510\n",
      "Epoch: 0100 | train_loss = 0.05249, train_auc = 0.97204, test_loss = 0.03286, test_auc = 0.95322, time = 0.04463\n",
      "Epoch: 0110 | train_loss = 0.04943, train_auc = 0.97485, test_loss = 0.03173, test_auc = 0.95526, time = 0.04468\n",
      "Epoch: 0120 | train_loss = 0.04849, train_auc = 0.97574, test_loss = 0.03312, test_auc = 0.95571, time = 0.04352\n",
      "Epoch: 0130 | train_loss = 0.04326, train_auc = 0.98059, test_loss = 0.03145, test_auc = 0.95872, time = 0.04536\n",
      "Epoch: 0140 | train_loss = 0.04363, train_auc = 0.97985, test_loss = 0.03141, test_auc = 0.95985, time = 0.04462\n",
      "Epoch: 0150 | train_loss = 0.04371, train_auc = 0.98037, test_loss = 0.03208, test_auc = 0.95741, time = 0.04546\n",
      "Epoch: 0160 | train_loss = 0.04179, train_auc = 0.98336, test_loss = 0.03227, test_auc = 0.95776, time = 0.04521\n",
      "Epoch: 0170 | train_loss = 0.03840, train_auc = 0.98439, test_loss = 0.03360, test_auc = 0.95280, time = 0.04471\n",
      "Epoch: 0180 | train_loss = 0.03959, train_auc = 0.98399, test_loss = 0.03172, test_auc = 0.95732, time = 0.04450\n",
      "Epoch: 0190 | train_loss = 0.03800, train_auc = 0.98517, test_loss = 0.03131, test_auc = 0.96222, time = 0.04487\n",
      "Epoch: 0200 | train_loss = 0.03769, train_auc = 0.98596, test_loss = 0.03226, test_auc = 0.95917, time = 0.04445\n",
      "Epoch: 0210 | train_loss = 0.03479, train_auc = 0.98720, test_loss = 0.03106, test_auc = 0.96124, time = 0.04470\n",
      "Epoch: 0220 | train_loss = 0.03477, train_auc = 0.98758, test_loss = 0.03137, test_auc = 0.96429, time = 0.04499\n",
      "Epoch: 0230 | train_loss = 0.03404, train_auc = 0.98780, test_loss = 0.03349, test_auc = 0.95593, time = 0.04599\n",
      "Epoch: 0240 | train_loss = 0.03236, train_auc = 0.98890, test_loss = 0.03000, test_auc = 0.96499, time = 0.04579\n",
      "Epoch: 0250 | train_loss = 0.03120, train_auc = 0.98989, test_loss = 0.03123, test_auc = 0.96210, time = 0.04617\n",
      "Epoch: 0260 | train_loss = 0.03219, train_auc = 0.98974, test_loss = 0.03052, test_auc = 0.96354, time = 0.04530\n",
      "Epoch: 0270 | train_loss = 0.03024, train_auc = 0.99043, test_loss = 0.03025, test_auc = 0.96767, time = 0.04591\n",
      "Epoch: 0280 | train_loss = 0.03151, train_auc = 0.99016, test_loss = 0.03459, test_auc = 0.95928, time = 0.04732\n",
      "Epoch: 0290 | train_loss = 0.02956, train_auc = 0.99053, test_loss = 0.03088, test_auc = 0.96846, time = 0.04605\n",
      "Epoch: 0300 | train_loss = 0.03071, train_auc = 0.99081, test_loss = 0.03302, test_auc = 0.96298, time = 0.04805\n",
      "Epoch: 0310 | train_loss = 0.02897, train_auc = 0.99143, test_loss = 0.03430, test_auc = 0.96557, time = 0.04618\n",
      "Epoch: 0320 | train_loss = 0.03371, train_auc = 0.98975, test_loss = 0.03440, test_auc = 0.96357, time = 0.04574\n",
      "Epoch: 0330 | train_loss = 0.02934, train_auc = 0.99147, test_loss = 0.03216, test_auc = 0.95475, time = 0.04541\n",
      "Epoch: 0340 | train_loss = 0.02775, train_auc = 0.99185, test_loss = 0.03098, test_auc = 0.96702, time = 0.04569\n",
      "Epoch: 0350 | train_loss = 0.02957, train_auc = 0.99156, test_loss = 0.03090, test_auc = 0.96664, time = 0.04477\n",
      "Epoch: 0360 | train_loss = 0.02477, train_auc = 0.99298, test_loss = 0.03129, test_auc = 0.96514, time = 0.04664\n",
      "Epoch: 0370 | train_loss = 0.02697, train_auc = 0.99191, test_loss = 0.02961, test_auc = 0.96925, time = 0.04559\n",
      "Epoch: 0380 | train_loss = 0.02720, train_auc = 0.99274, test_loss = 0.03334, test_auc = 0.95329, time = 0.04590\n",
      "Epoch: 0390 | train_loss = 0.02654, train_auc = 0.99281, test_loss = 0.03648, test_auc = 0.96786, time = 0.04694\n",
      "Epoch: 0400 | train_loss = 0.02635, train_auc = 0.99284, test_loss = 0.03451, test_auc = 0.96674, time = 0.04714\n",
      "Epoch: 0410 | train_loss = 0.02627, train_auc = 0.99336, test_loss = 0.02910, test_auc = 0.97295, time = 0.04566\n",
      "Epoch: 0420 | train_loss = 0.02491, train_auc = 0.99309, test_loss = 0.03119, test_auc = 0.96115, time = 0.04468\n",
      "Epoch: 0430 | train_loss = 0.02457, train_auc = 0.99353, test_loss = 0.03169, test_auc = 0.97094, time = 0.05954\n",
      "Epoch: 0440 | train_loss = 0.02476, train_auc = 0.99321, test_loss = 0.02902, test_auc = 0.97107, time = 0.04456\n",
      "Epoch: 0450 | train_loss = 0.02326, train_auc = 0.99399, test_loss = 0.02890, test_auc = 0.97047, time = 0.04442\n",
      "Epoch: 0460 | train_loss = 0.02304, train_auc = 0.99369, test_loss = 0.02724, test_auc = 0.97349, time = 0.04694\n",
      "Epoch: 0470 | train_loss = 0.02652, train_auc = 0.99339, test_loss = 0.03399, test_auc = 0.96334, time = 0.04816\n",
      "Epoch: 0480 | train_loss = 0.02105, train_auc = 0.99417, test_loss = 0.03197, test_auc = 0.96744, time = 0.04596\n",
      "Epoch: 0490 | train_loss = 0.02352, train_auc = 0.99384, test_loss = 0.03074, test_auc = 0.96690, time = 0.04577\n",
      "Epoch: 0500 | train_loss = 0.02546, train_auc = 0.99321, test_loss = 0.02967, test_auc = 0.97258, time = 0.04544\n",
      "times: 9, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.12974, train_auc = 0.63085, test_loss = 0.07058, test_auc = 0.58498, time = 0.80089\n",
      "Epoch: 0010 | train_loss = 0.08112, train_auc = 0.91254, test_loss = 0.04782, test_auc = 0.86074, time = 0.05133\n",
      "Epoch: 0020 | train_loss = 0.07092, train_auc = 0.93367, test_loss = 0.03894, test_auc = 0.90722, time = 0.04757\n",
      "Epoch: 0030 | train_loss = 0.06658, train_auc = 0.94512, test_loss = 0.03775, test_auc = 0.91859, time = 0.04550\n",
      "Epoch: 0040 | train_loss = 0.06459, train_auc = 0.95008, test_loss = 0.03434, test_auc = 0.94028, time = 0.04500\n",
      "Epoch: 0050 | train_loss = 0.05996, train_auc = 0.95704, test_loss = 0.03488, test_auc = 0.94356, time = 0.04580\n",
      "Epoch: 0060 | train_loss = 0.05795, train_auc = 0.96079, test_loss = 0.03443, test_auc = 0.93969, time = 0.04486\n",
      "Epoch: 0070 | train_loss = 0.05486, train_auc = 0.96538, test_loss = 0.03200, test_auc = 0.95037, time = 0.04470\n",
      "Epoch: 0080 | train_loss = 0.05337, train_auc = 0.96699, test_loss = 0.03648, test_auc = 0.95246, time = 0.04580\n",
      "Epoch: 0090 | train_loss = 0.05253, train_auc = 0.96986, test_loss = 0.04053, test_auc = 0.94834, time = 0.04434\n",
      "Epoch: 0100 | train_loss = 0.05180, train_auc = 0.96954, test_loss = 0.03156, test_auc = 0.95716, time = 0.04406\n",
      "Epoch: 0110 | train_loss = 0.04840, train_auc = 0.97406, test_loss = 0.03012, test_auc = 0.96011, time = 0.04491\n",
      "Epoch: 0120 | train_loss = 0.04660, train_auc = 0.97663, test_loss = 0.02998, test_auc = 0.96210, time = 0.04572\n",
      "Epoch: 0130 | train_loss = 0.04530, train_auc = 0.97747, test_loss = 0.03356, test_auc = 0.95501, time = 0.04463\n",
      "Epoch: 0140 | train_loss = 0.04476, train_auc = 0.97816, test_loss = 0.03300, test_auc = 0.96031, time = 0.04458\n",
      "Epoch: 0150 | train_loss = 0.04160, train_auc = 0.98084, test_loss = 0.03324, test_auc = 0.95473, time = 0.04570\n",
      "Epoch: 0160 | train_loss = 0.04209, train_auc = 0.98042, test_loss = 0.03021, test_auc = 0.96565, time = 0.04516\n",
      "Epoch: 0170 | train_loss = 0.04048, train_auc = 0.98352, test_loss = 0.03158, test_auc = 0.95839, time = 0.04436\n",
      "Epoch: 0180 | train_loss = 0.03756, train_auc = 0.98576, test_loss = 0.03350, test_auc = 0.96465, time = 0.04437\n",
      "Epoch: 0190 | train_loss = 0.03786, train_auc = 0.98550, test_loss = 0.03170, test_auc = 0.96359, time = 0.04389\n",
      "Epoch: 0200 | train_loss = 0.03878, train_auc = 0.98566, test_loss = 0.03090, test_auc = 0.96506, time = 0.04471\n",
      "Epoch: 0210 | train_loss = 0.03544, train_auc = 0.98824, test_loss = 0.03414, test_auc = 0.96452, time = 0.04423\n",
      "Epoch: 0220 | train_loss = 0.03799, train_auc = 0.98602, test_loss = 0.03588, test_auc = 0.96470, time = 0.04429\n",
      "Epoch: 0230 | train_loss = 0.03622, train_auc = 0.98642, test_loss = 0.03203, test_auc = 0.96972, time = 0.04446\n",
      "Epoch: 0240 | train_loss = 0.03096, train_auc = 0.98894, test_loss = 0.02988, test_auc = 0.96777, time = 0.04535\n",
      "Epoch: 0250 | train_loss = 0.03222, train_auc = 0.98855, test_loss = 0.03196, test_auc = 0.96086, time = 0.04419\n",
      "Epoch: 0260 | train_loss = 0.03256, train_auc = 0.98960, test_loss = 0.02781, test_auc = 0.97358, time = 0.04414\n",
      "Epoch: 0270 | train_loss = 0.03146, train_auc = 0.99032, test_loss = 0.03249, test_auc = 0.96477, time = 0.04404\n",
      "Epoch: 0280 | train_loss = 0.03085, train_auc = 0.99027, test_loss = 0.03577, test_auc = 0.96475, time = 0.04377\n",
      "Epoch: 0290 | train_loss = 0.03084, train_auc = 0.99041, test_loss = 0.03056, test_auc = 0.96861, time = 0.04416\n",
      "Epoch: 0300 | train_loss = 0.02937, train_auc = 0.99220, test_loss = 0.02848, test_auc = 0.97206, time = 0.04396\n",
      "Epoch: 0310 | train_loss = 0.02800, train_auc = 0.99158, test_loss = 0.02997, test_auc = 0.97209, time = 0.04325\n",
      "Epoch: 0320 | train_loss = 0.02802, train_auc = 0.99172, test_loss = 0.03806, test_auc = 0.95165, time = 0.05319\n",
      "Epoch: 0330 | train_loss = 0.02851, train_auc = 0.99044, test_loss = 0.03206, test_auc = 0.96291, time = 0.04338\n",
      "Epoch: 0340 | train_loss = 0.02846, train_auc = 0.99120, test_loss = 0.03335, test_auc = 0.96367, time = 0.04459\n",
      "Epoch: 0350 | train_loss = 0.02672, train_auc = 0.99186, test_loss = 0.03036, test_auc = 0.96957, time = 0.04447\n",
      "Epoch: 0360 | train_loss = 0.02451, train_auc = 0.99248, test_loss = 0.02795, test_auc = 0.97133, time = 0.04592\n",
      "Epoch: 0370 | train_loss = 0.02776, train_auc = 0.99221, test_loss = 0.02914, test_auc = 0.97239, time = 0.04462\n",
      "Epoch: 0380 | train_loss = 0.02864, train_auc = 0.99153, test_loss = 0.02797, test_auc = 0.97211, time = 0.04474\n",
      "Epoch: 0390 | train_loss = 0.02915, train_auc = 0.99135, test_loss = 0.02837, test_auc = 0.97216, time = 0.04499\n",
      "Epoch: 0400 | train_loss = 0.02812, train_auc = 0.99184, test_loss = 0.02812, test_auc = 0.97457, time = 0.04503\n",
      "Epoch: 0410 | train_loss = 0.02508, train_auc = 0.99275, test_loss = 0.02714, test_auc = 0.97497, time = 0.04481\n",
      "Epoch: 0420 | train_loss = 0.02837, train_auc = 0.99184, test_loss = 0.02763, test_auc = 0.97505, time = 0.04442\n",
      "Epoch: 0430 | train_loss = 0.02628, train_auc = 0.99224, test_loss = 0.02964, test_auc = 0.97279, time = 0.04439\n",
      "Epoch: 0440 | train_loss = 0.02644, train_auc = 0.99219, test_loss = 0.03069, test_auc = 0.96996, time = 0.04691\n",
      "Epoch: 0450 | train_loss = 0.02353, train_auc = 0.99363, test_loss = 0.02912, test_auc = 0.97320, time = 0.04386\n",
      "Epoch: 0460 | train_loss = 0.02501, train_auc = 0.99345, test_loss = 0.02603, test_auc = 0.97761, time = 0.04511\n",
      "Epoch: 0470 | train_loss = 0.02519, train_auc = 0.99302, test_loss = 0.02930, test_auc = 0.97393, time = 0.04483\n",
      "Epoch: 0480 | train_loss = 0.02463, train_auc = 0.99332, test_loss = 0.02926, test_auc = 0.97303, time = 0.04513\n",
      "Epoch: 0490 | train_loss = 0.02547, train_auc = 0.99318, test_loss = 0.03261, test_auc = 0.96722, time = 0.04438\n",
      "Epoch: 0500 | train_loss = 0.02348, train_auc = 0.99293, test_loss = 0.03514, test_auc = 0.96985, time = 0.04434\n",
      "times: 9, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14858, train_auc = 0.41730, test_loss = 0.06973, test_auc = 0.59728, time = 0.78611\n",
      "Epoch: 0010 | train_loss = 0.08422, train_auc = 0.90448, test_loss = 0.05088, test_auc = 0.82830, time = 0.05058\n",
      "Epoch: 0020 | train_loss = 0.07377, train_auc = 0.93023, test_loss = 0.04074, test_auc = 0.91015, time = 0.04623\n",
      "Epoch: 0030 | train_loss = 0.06708, train_auc = 0.94538, test_loss = 0.03834, test_auc = 0.92155, time = 0.05258\n",
      "Epoch: 0040 | train_loss = 0.06403, train_auc = 0.95146, test_loss = 0.03593, test_auc = 0.93179, time = 0.04516\n",
      "Epoch: 0050 | train_loss = 0.06210, train_auc = 0.95445, test_loss = 0.03950, test_auc = 0.93381, time = 0.04501\n",
      "Epoch: 0060 | train_loss = 0.05954, train_auc = 0.96091, test_loss = 0.04097, test_auc = 0.93684, time = 0.04457\n",
      "Epoch: 0070 | train_loss = 0.05681, train_auc = 0.96580, test_loss = 0.03473, test_auc = 0.95530, time = 0.04674\n",
      "Epoch: 0080 | train_loss = 0.05160, train_auc = 0.97089, test_loss = 0.03288, test_auc = 0.95483, time = 0.04417\n",
      "Epoch: 0090 | train_loss = 0.05107, train_auc = 0.97308, test_loss = 0.03517, test_auc = 0.95321, time = 0.04394\n",
      "Epoch: 0100 | train_loss = 0.05548, train_auc = 0.97093, test_loss = 0.02995, test_auc = 0.96083, time = 0.04462\n",
      "Epoch: 0110 | train_loss = 0.04964, train_auc = 0.97470, test_loss = 0.03286, test_auc = 0.95925, time = 0.04474\n",
      "Epoch: 0120 | train_loss = 0.04931, train_auc = 0.97691, test_loss = 0.03315, test_auc = 0.95658, time = 0.04621\n",
      "Epoch: 0130 | train_loss = 0.04586, train_auc = 0.97927, test_loss = 0.03213, test_auc = 0.96039, time = 0.04512\n",
      "Epoch: 0140 | train_loss = 0.04160, train_auc = 0.98414, test_loss = 0.03081, test_auc = 0.96357, time = 0.04477\n",
      "Epoch: 0150 | train_loss = 0.04189, train_auc = 0.98353, test_loss = 0.02944, test_auc = 0.96522, time = 0.05509\n",
      "Epoch: 0160 | train_loss = 0.03999, train_auc = 0.98468, test_loss = 0.02938, test_auc = 0.96657, time = 0.04675\n",
      "Epoch: 0170 | train_loss = 0.03812, train_auc = 0.98598, test_loss = 0.02965, test_auc = 0.96458, time = 0.04594\n",
      "Epoch: 0180 | train_loss = 0.03760, train_auc = 0.98634, test_loss = 0.03153, test_auc = 0.96363, time = 0.04424\n",
      "Epoch: 0190 | train_loss = 0.03802, train_auc = 0.98644, test_loss = 0.03142, test_auc = 0.96747, time = 0.04494\n",
      "Epoch: 0200 | train_loss = 0.03611, train_auc = 0.98738, test_loss = 0.03198, test_auc = 0.96484, time = 0.04566\n",
      "Epoch: 0210 | train_loss = 0.03316, train_auc = 0.98866, test_loss = 0.02795, test_auc = 0.97143, time = 0.04657\n",
      "Epoch: 0220 | train_loss = 0.03628, train_auc = 0.98854, test_loss = 0.02882, test_auc = 0.97180, time = 0.04395\n",
      "Epoch: 0230 | train_loss = 0.03250, train_auc = 0.98917, test_loss = 0.02937, test_auc = 0.97003, time = 0.04403\n",
      "Epoch: 0240 | train_loss = 0.03183, train_auc = 0.98992, test_loss = 0.02966, test_auc = 0.96772, time = 0.04390\n",
      "Epoch: 0250 | train_loss = 0.03094, train_auc = 0.99052, test_loss = 0.02963, test_auc = 0.97132, time = 0.04401\n",
      "Epoch: 0260 | train_loss = 0.03307, train_auc = 0.98953, test_loss = 0.03560, test_auc = 0.96446, time = 0.04523\n",
      "Epoch: 0270 | train_loss = 0.03055, train_auc = 0.99063, test_loss = 0.02793, test_auc = 0.97207, time = 0.04370\n",
      "Epoch: 0280 | train_loss = 0.02934, train_auc = 0.99096, test_loss = 0.03153, test_auc = 0.96861, time = 0.04318\n",
      "Epoch: 0290 | train_loss = 0.02946, train_auc = 0.99123, test_loss = 0.02994, test_auc = 0.97061, time = 0.04812\n",
      "Epoch: 0300 | train_loss = 0.03045, train_auc = 0.99156, test_loss = 0.03288, test_auc = 0.96628, time = 0.04314\n",
      "Epoch: 0310 | train_loss = 0.02676, train_auc = 0.99201, test_loss = 0.03658, test_auc = 0.96940, time = 0.04286\n",
      "Epoch: 0320 | train_loss = 0.02875, train_auc = 0.99189, test_loss = 0.03092, test_auc = 0.96663, time = 0.04327\n",
      "Epoch: 0330 | train_loss = 0.02907, train_auc = 0.99170, test_loss = 0.03303, test_auc = 0.96815, time = 0.04415\n",
      "Epoch: 0340 | train_loss = 0.02702, train_auc = 0.99236, test_loss = 0.03002, test_auc = 0.96749, time = 0.05187\n",
      "Epoch: 0350 | train_loss = 0.02556, train_auc = 0.99251, test_loss = 0.03325, test_auc = 0.96930, time = 0.04998\n",
      "Epoch: 0360 | train_loss = 0.02650, train_auc = 0.99200, test_loss = 0.03148, test_auc = 0.97391, time = 0.04392\n",
      "Epoch: 0370 | train_loss = 0.02427, train_auc = 0.99255, test_loss = 0.02958, test_auc = 0.97250, time = 0.04422\n",
      "Epoch: 0380 | train_loss = 0.02352, train_auc = 0.99303, test_loss = 0.02742, test_auc = 0.97351, time = 0.04350\n",
      "Epoch: 0390 | train_loss = 0.02595, train_auc = 0.99257, test_loss = 0.02971, test_auc = 0.97091, time = 0.04438\n",
      "Epoch: 0400 | train_loss = 0.02620, train_auc = 0.99268, test_loss = 0.03326, test_auc = 0.96525, time = 0.04471\n",
      "Epoch: 0410 | train_loss = 0.02484, train_auc = 0.99305, test_loss = 0.03085, test_auc = 0.97069, time = 0.04471\n",
      "Epoch: 0420 | train_loss = 0.02496, train_auc = 0.99286, test_loss = 0.02773, test_auc = 0.97399, time = 0.04390\n",
      "Epoch: 0430 | train_loss = 0.02492, train_auc = 0.99296, test_loss = 0.03253, test_auc = 0.96773, time = 0.04442\n",
      "Epoch: 0440 | train_loss = 0.02565, train_auc = 0.99284, test_loss = 0.02799, test_auc = 0.97342, time = 0.04384\n",
      "Epoch: 0450 | train_loss = 0.02470, train_auc = 0.99326, test_loss = 0.02929, test_auc = 0.97126, time = 0.04406\n",
      "Epoch: 0460 | train_loss = 0.02274, train_auc = 0.99296, test_loss = 0.02861, test_auc = 0.97308, time = 0.04391\n",
      "Epoch: 0470 | train_loss = 0.02276, train_auc = 0.99337, test_loss = 0.02771, test_auc = 0.97345, time = 0.04376\n",
      "Epoch: 0480 | train_loss = 0.02465, train_auc = 0.99302, test_loss = 0.02892, test_auc = 0.97439, time = 0.04414\n",
      "Epoch: 0490 | train_loss = 0.02270, train_auc = 0.99376, test_loss = 0.02908, test_auc = 0.97125, time = 0.04392\n",
      "Epoch: 0500 | train_loss = 0.02359, train_auc = 0.99347, test_loss = 0.02932, test_auc = 0.96954, time = 0.04348\n",
      "times: 9, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDD\n",
      " epoch: 500\n",
      " lr: 0.001\n",
      " Graph units: [256]\n",
      " dense0: 256\n",
      " dense1: 128\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:15: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/miRNAs.xlsx',header=None,names=['id','biomarker'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 878\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14402, train_auc = 0.43259, test_loss = 0.07168, test_auc = 0.57564, time = 0.79657\n",
      "Epoch: 0010 | train_loss = 0.08469, train_auc = 0.91124, test_loss = 0.05379, test_auc = 0.82169, time = 0.05584\n",
      "Epoch: 0020 | train_loss = 0.07223, train_auc = 0.93470, test_loss = 0.04302, test_auc = 0.89001, time = 0.04780\n",
      "Epoch: 0030 | train_loss = 0.06898, train_auc = 0.94080, test_loss = 0.04021, test_auc = 0.90127, time = 0.04809\n",
      "Epoch: 0040 | train_loss = 0.06413, train_auc = 0.95244, test_loss = 0.03820, test_auc = 0.92505, time = 0.04627\n",
      "Epoch: 0050 | train_loss = 0.05947, train_auc = 0.95760, test_loss = 0.03525, test_auc = 0.94118, time = 0.05246\n",
      "Epoch: 0060 | train_loss = 0.05675, train_auc = 0.96316, test_loss = 0.03356, test_auc = 0.94592, time = 0.04547\n",
      "Epoch: 0070 | train_loss = 0.05499, train_auc = 0.96541, test_loss = 0.03343, test_auc = 0.95087, time = 0.04527\n",
      "Epoch: 0080 | train_loss = 0.05794, train_auc = 0.96174, test_loss = 0.03279, test_auc = 0.94932, time = 0.04515\n",
      "Epoch: 0090 | train_loss = 0.05078, train_auc = 0.97084, test_loss = 0.03307, test_auc = 0.95470, time = 0.04508\n",
      "Epoch: 0100 | train_loss = 0.05034, train_auc = 0.97129, test_loss = 0.03198, test_auc = 0.95612, time = 0.04733\n",
      "Epoch: 0110 | train_loss = 0.04687, train_auc = 0.97593, test_loss = 0.03034, test_auc = 0.95957, time = 0.04498\n",
      "Epoch: 0120 | train_loss = 0.04757, train_auc = 0.97590, test_loss = 0.03308, test_auc = 0.95648, time = 0.04475\n",
      "Epoch: 0130 | train_loss = 0.04500, train_auc = 0.97794, test_loss = 0.03278, test_auc = 0.96053, time = 0.04562\n",
      "Epoch: 0140 | train_loss = 0.04514, train_auc = 0.97827, test_loss = 0.03275, test_auc = 0.95925, time = 0.04486\n",
      "Epoch: 0150 | train_loss = 0.04239, train_auc = 0.98114, test_loss = 0.03087, test_auc = 0.96298, time = 0.04434\n",
      "Epoch: 0160 | train_loss = 0.04165, train_auc = 0.98188, test_loss = 0.03179, test_auc = 0.96608, time = 0.04389\n",
      "Epoch: 0170 | train_loss = 0.03974, train_auc = 0.98302, test_loss = 0.03257, test_auc = 0.96456, time = 0.04547\n",
      "Epoch: 0180 | train_loss = 0.03963, train_auc = 0.98380, test_loss = 0.02998, test_auc = 0.96478, time = 0.04531\n",
      "Epoch: 0190 | train_loss = 0.03861, train_auc = 0.98451, test_loss = 0.03258, test_auc = 0.95995, time = 0.04414\n",
      "Epoch: 0200 | train_loss = 0.03882, train_auc = 0.98495, test_loss = 0.03159, test_auc = 0.96475, time = 0.04606\n",
      "Epoch: 0210 | train_loss = 0.03922, train_auc = 0.98539, test_loss = 0.03496, test_auc = 0.95951, time = 0.04405\n",
      "Epoch: 0220 | train_loss = 0.03795, train_auc = 0.98599, test_loss = 0.02939, test_auc = 0.96972, time = 0.04352\n",
      "Epoch: 0230 | train_loss = 0.03682, train_auc = 0.98759, test_loss = 0.02963, test_auc = 0.97037, time = 0.04451\n",
      "Epoch: 0240 | train_loss = 0.03383, train_auc = 0.98877, test_loss = 0.03348, test_auc = 0.96705, time = 0.04806\n",
      "Epoch: 0250 | train_loss = 0.03358, train_auc = 0.98828, test_loss = 0.02839, test_auc = 0.97086, time = 0.04397\n",
      "Epoch: 0260 | train_loss = 0.03335, train_auc = 0.98935, test_loss = 0.02805, test_auc = 0.97279, time = 0.04589\n",
      "Epoch: 0270 | train_loss = 0.03426, train_auc = 0.98892, test_loss = 0.03484, test_auc = 0.96400, time = 0.04692\n",
      "Epoch: 0280 | train_loss = 0.03292, train_auc = 0.98951, test_loss = 0.02977, test_auc = 0.96879, time = 0.04447\n",
      "Epoch: 0290 | train_loss = 0.03247, train_auc = 0.98981, test_loss = 0.03217, test_auc = 0.96533, time = 0.04416\n",
      "Epoch: 0300 | train_loss = 0.03092, train_auc = 0.98956, test_loss = 0.03229, test_auc = 0.96192, time = 0.04365\n",
      "Epoch: 0310 | train_loss = 0.03109, train_auc = 0.99038, test_loss = 0.03014, test_auc = 0.96915, time = 0.04598\n",
      "Epoch: 0320 | train_loss = 0.03153, train_auc = 0.99038, test_loss = 0.02930, test_auc = 0.97144, time = 0.04419\n",
      "Epoch: 0330 | train_loss = 0.02883, train_auc = 0.99098, test_loss = 0.03077, test_auc = 0.96921, time = 0.04480\n",
      "Epoch: 0340 | train_loss = 0.02599, train_auc = 0.99191, test_loss = 0.02995, test_auc = 0.97184, time = 0.04467\n",
      "Epoch: 0350 | train_loss = 0.02803, train_auc = 0.99151, test_loss = 0.02703, test_auc = 0.97509, time = 0.04441\n",
      "Epoch: 0360 | train_loss = 0.02657, train_auc = 0.99186, test_loss = 0.02575, test_auc = 0.97602, time = 0.04528\n",
      "Epoch: 0370 | train_loss = 0.02872, train_auc = 0.99167, test_loss = 0.02948, test_auc = 0.96961, time = 0.04458\n",
      "Epoch: 0380 | train_loss = 0.02522, train_auc = 0.99224, test_loss = 0.03052, test_auc = 0.96716, time = 0.04480\n",
      "Epoch: 0390 | train_loss = 0.02894, train_auc = 0.99185, test_loss = 0.03385, test_auc = 0.94958, time = 0.04474\n",
      "Epoch: 0400 | train_loss = 0.02762, train_auc = 0.99223, test_loss = 0.03022, test_auc = 0.97280, time = 0.04445\n",
      "Epoch: 0410 | train_loss = 0.02802, train_auc = 0.99164, test_loss = 0.03124, test_auc = 0.97025, time = 0.04503\n",
      "Epoch: 0420 | train_loss = 0.02614, train_auc = 0.99250, test_loss = 0.02881, test_auc = 0.97260, time = 0.04467\n",
      "Epoch: 0430 | train_loss = 0.02478, train_auc = 0.99303, test_loss = 0.02948, test_auc = 0.97049, time = 0.04518\n",
      "Epoch: 0440 | train_loss = 0.02535, train_auc = 0.99235, test_loss = 0.02859, test_auc = 0.97317, time = 0.04501\n",
      "Epoch: 0450 | train_loss = 0.02733, train_auc = 0.99216, test_loss = 0.02886, test_auc = 0.97369, time = 0.04490\n",
      "Epoch: 0460 | train_loss = 0.02371, train_auc = 0.99327, test_loss = 0.02905, test_auc = 0.97397, time = 0.04484\n",
      "Epoch: 0470 | train_loss = 0.02483, train_auc = 0.99305, test_loss = 0.02830, test_auc = 0.97329, time = 0.04639\n",
      "Epoch: 0480 | train_loss = 0.02462, train_auc = 0.99321, test_loss = 0.02742, test_auc = 0.97550, time = 0.04543\n",
      "Epoch: 0490 | train_loss = 0.02255, train_auc = 0.99327, test_loss = 0.02705, test_auc = 0.97788, time = 0.04467\n",
      "Epoch: 0500 | train_loss = 0.02652, train_auc = 0.99320, test_loss = 0.02980, test_auc = 0.97085, time = 0.04457\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "from utils import sample\n",
    "from train import train\n",
    "from evaluation import *\n",
    "from tfdeterminism import patch\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Training')\n",
    "    parser.add_argument('--GPU', type=str, default='0')\n",
    "    parser.add_argument('--epoch', type=int, default=500)\n",
    "    parser.add_argument('--hid_units', type=int, default=256, help='number of neurons in GAT')\n",
    "    parser.add_argument('--dense0', type=int, default=256, help='number of neurons in BFN')\n",
    "    parser.add_argument('--dense1', type=int, default=128, help='number of neurons in BFN')\n",
    "    parser.add_argument('--layers', type=int, default=4, help='number of layer aggregator in GAT')\n",
    "    parser.add_argument('--lr', type=float, default=0.001)\n",
    "    parser.add_argument('--attention_drop', type=float, default=0.1)\n",
    "    parser.add_argument('--feedforward_drop', type=float, default=0.1)\n",
    "    parser.add_argument('--dataset', type=str, default='HMDD')\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    patch()\n",
    "    SEED = 1000\n",
    "    tf.set_random_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.GPU\n",
    "\n",
    "    dataset = args.dataset\n",
    "    times = 10\n",
    "    total_KFOLD_test_labels, total_FOLD_test_scores = [], []\n",
    "    KFOLD_test_out_come = []\n",
    "    for i in range(times):\n",
    "        for fold in range(5):\n",
    "            print(\"times: %d, fold: %d\" % (int(i), int(fold)))\n",
    "            train_arr = np.loadtxt(f'data/{dataset}/data_dir/{i}/{fold}/train_arr.txt')\n",
    "            test_arr = np.loadtxt(f'data/{dataset}/data_dir/{i}/{fold}/test_arr.txt')\n",
    "            train_arr = train_arr.astype(np.int64)\n",
    "            test_arr = test_arr.astype(np.int64)\n",
    "            test_labels, scores, test_out_come = train(args, train_arr, test_arr, dataset, i, fold)\n",
    "            total_KFOLD_test_labels.append(test_labels)\n",
    "            total_FOLD_test_scores.append(scores)\n",
    "            KFOLD_test_out_come.append(test_out_come)\n",
    "\n",
    "    print('Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "association_matrix_shape: (383, 495)\n",
      "times: 0 Fold: 0 Test AUC: 0.9787 Test AUPR: 0.9752\n",
      "times: 0 Fold: 1 Test AUC: 0.9745 Test AUPR: 0.9695\n",
      "times: 0 Fold: 2 Test AUC: 0.9734 Test AUPR: 0.9690\n",
      "times: 0 Fold: 3 Test AUC: 0.9763 Test AUPR: 0.9721\n",
      "times: 0 Fold: 4 Test AUC: 0.9772 Test AUPR: 0.9739\n",
      "times: 1 Fold: 0 Test AUC: 0.9753 Test AUPR: 0.9723\n",
      "times: 1 Fold: 1 Test AUC: 0.9805 Test AUPR: 0.9786\n",
      "times: 1 Fold: 2 Test AUC: 0.9768 Test AUPR: 0.9740\n",
      "times: 1 Fold: 3 Test AUC: 0.9771 Test AUPR: 0.9741\n",
      "times: 1 Fold: 4 Test AUC: 0.9688 Test AUPR: 0.9636\n",
      "times: 2 Fold: 0 Test AUC: 0.9763 Test AUPR: 0.9725\n",
      "times: 2 Fold: 1 Test AUC: 0.9792 Test AUPR: 0.9763\n",
      "times: 2 Fold: 2 Test AUC: 0.9757 Test AUPR: 0.9725\n",
      "times: 2 Fold: 3 Test AUC: 0.9763 Test AUPR: 0.9732\n",
      "times: 2 Fold: 4 Test AUC: 0.9758 Test AUPR: 0.9730\n",
      "times: 3 Fold: 0 Test AUC: 0.9717 Test AUPR: 0.9657\n",
      "times: 3 Fold: 1 Test AUC: 0.9701 Test AUPR: 0.9654\n",
      "times: 3 Fold: 2 Test AUC: 0.9752 Test AUPR: 0.9719\n",
      "times: 3 Fold: 3 Test AUC: 0.9792 Test AUPR: 0.9778\n",
      "times: 3 Fold: 4 Test AUC: 0.9774 Test AUPR: 0.9749\n",
      "times: 4 Fold: 0 Test AUC: 0.9753 Test AUPR: 0.9708\n",
      "times: 4 Fold: 1 Test AUC: 0.9722 Test AUPR: 0.9687\n",
      "times: 4 Fold: 2 Test AUC: 0.9754 Test AUPR: 0.9728\n",
      "times: 4 Fold: 3 Test AUC: 0.9771 Test AUPR: 0.9742\n",
      "times: 4 Fold: 4 Test AUC: 0.9783 Test AUPR: 0.9755\n",
      "times: 5 Fold: 0 Test AUC: 0.9773 Test AUPR: 0.9745\n",
      "times: 5 Fold: 1 Test AUC: 0.9768 Test AUPR: 0.9742\n",
      "times: 5 Fold: 2 Test AUC: 0.9762 Test AUPR: 0.9729\n",
      "times: 5 Fold: 3 Test AUC: 0.9703 Test AUPR: 0.9665\n",
      "times: 5 Fold: 4 Test AUC: 0.9776 Test AUPR: 0.9742\n",
      "times: 6 Fold: 0 Test AUC: 0.9738 Test AUPR: 0.9697\n",
      "times: 6 Fold: 1 Test AUC: 0.9717 Test AUPR: 0.9673\n",
      "times: 6 Fold: 2 Test AUC: 0.9740 Test AUPR: 0.9709\n",
      "times: 6 Fold: 3 Test AUC: 0.9769 Test AUPR: 0.9730\n",
      "times: 6 Fold: 4 Test AUC: 0.9764 Test AUPR: 0.9741\n",
      "times: 7 Fold: 0 Test AUC: 0.9723 Test AUPR: 0.9667\n",
      "times: 7 Fold: 1 Test AUC: 0.9753 Test AUPR: 0.9721\n",
      "times: 7 Fold: 2 Test AUC: 0.9791 Test AUPR: 0.9773\n",
      "times: 7 Fold: 3 Test AUC: 0.9755 Test AUPR: 0.9721\n",
      "times: 7 Fold: 4 Test AUC: 0.9786 Test AUPR: 0.9761\n",
      "times: 8 Fold: 0 Test AUC: 0.9783 Test AUPR: 0.9761\n",
      "times: 8 Fold: 1 Test AUC: 0.9733 Test AUPR: 0.9685\n",
      "times: 8 Fold: 2 Test AUC: 0.9726 Test AUPR: 0.9665\n",
      "times: 8 Fold: 3 Test AUC: 0.9776 Test AUPR: 0.9755\n",
      "times: 8 Fold: 4 Test AUC: 0.9743 Test AUPR: 0.9710\n",
      "times: 9 Fold: 0 Test AUC: 0.9726 Test AUPR: 0.9688\n",
      "times: 9 Fold: 1 Test AUC: 0.9751 Test AUPR: 0.9707\n",
      "times: 9 Fold: 2 Test AUC: 0.9776 Test AUPR: 0.9733\n",
      "times: 9 Fold: 3 Test AUC: 0.9762 Test AUPR: 0.9721\n",
      "times: 9 Fold: 4 Test AUC: 0.9780 Test AUPR: 0.9743\n",
      "-AUC mean: 0.97560.0026 \n",
      " -AUPR mean: 0.97210.0034 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1KklEQVR4nO3deXxU1fn48c+TzExCNpYAgqxBQdkRUGxFXHADrUtFgUrVamut2q/9otal/bnVtlpa61L1W7V+tVVAS61SQawiVKooshUEZRGihOULBLKvkzy/P+5NGLJMJiR3hmSe9+s1r8zce+69zw3kPnPOufccUVWMMcbEr4RYB2CMMSa2LBEYY0ycs0RgjDFxzhKBMcbEOUsExhgT5ywRGGNMnLNEYIwxcc4SgYkqEckWkXPqLLtWRP5dp0yFiHStU26NiKiI9Hc/v+iWK3Rfn4nIr0WkY519V4lIkfvaLiL/KyKDwsR4pohUu+ULRWSTiHyvThkRkTtEZIuIlIrI1+6xk+qUO0VEFopInogcEJEVdfdVp3xPEfmTiOx2j/2FiDwgIqlN/GqNOWKWCMzRajswveaDiAwHUhoo9xtVTQe6Ad8DTgU+rHPhXK6qaUBH4BygFFglIsPCHH+Xu00G8N/AcyJyQsj6J4AbgKuBdGASMBF4LSTmbwDvA/8CjgcygR+5ZesRkS7AcqAD8A33vM4FOgHHhYm1QSLia+42Jj5ZIjBHq7/gXGRrXAP8ubHCqlqmqp8CF+NccOt961bVKlX9UlVvwrk4399UEOpYCBwARgCIyEDgJuAqVV2uqkFV3QBcDlwgIme7m88CXlLVR1R1v7uvVap6ZSOHmwkUAjNUNds9/g5VvVVV14lIf7dGVHuBF5GlIvJ99/21IvKhiPxeRHKBX7g1kWEh5bu5NZju7ueLRGStW+4jERkRUvZOEdkZUiua2NTvy7RNlgjM0epjIENEBotIIjANeLmpjVS1EHgXOL2Joq9HUAYRSRCRi4GuwFZ38UQgR1VX1Dn2Djfuc0UkBfgGMK+pY4Q4B3hdVaubsU1d44BtwDHAgzjnOT1k/ZXAv1R1r4icBLwA/BAnef4RmC8iSW7t5xbgZLdmcj6Q3YK4zFHMEoGJhTfcb6B5IpIHPN1IuZpawbnA58DOCPe/C+jSwjLHurGVAn8HZqrqGnddV2B3I9vtdtd3xvn7aqxcQzKbWb4hu1T1SbeWUgrMxkmiNb7jLgOnaeuPqvqJW1t6CSjHaV6rApKAISLiV9VsVf2yhbGZo5QlAhMLl6pqp5oXTjNLQ/6Cc+G6ljDNQg3ohdOU05Iyu9zYMnD6A84OWbcf6NnIdj3d9QeB6jDlGpLbzPIN2VHn8xIgRUTGuZ3so3ASG0A/4LY6SbkPcKyqbgV+gtN8tldE5orIsS2MzRylLBGYo5aqfoXTaTwZp4mjSSKShtPEsqyJopdFUAZVLQfuBIaLyKXu4veBPiJySp1j98H5Nr1YVUtwOn4vjyRu13vAZSLS2N9lsfsztNO8R92Q68RfhdOBPd19veU2n4GTNH4ZmpRVNUVV57jbzlbV8TgJQ4FHmnEupg2xRGCOdtcDZ6tqcbhCbrv2GOANnG/j/9tAmUQRyRKRJ4EzgQciCUBVK4DfAfe6nzcD/wO8IiKnuvsdCvwNeE9V33M3/SlwrXubaaYbw0gRmdvIoR7FqYG8JCL93PK9RORRERmhqvtwmsdmuMe8jsjuJpoNTAWu4lCzEMBzwI1ubUFEJFVELhSRdBE5QUTOdm+HLcNpImtJ34U5ilkiMEc19y6flWGK/FRECnGaVf4MrAK+WSdxfENEioACYCnOxfZkVV3fjFBeAPqKyLfcz7cAz+N0YBcBi9x919YAVPUjnCals4FtInIAeBZY2Mi5HgC+CVQCn7jntRjI51BH9Q+AO9zzHQp81FTgqvoJTm3iWODtkOUr3f39ASd5bsVphgOnf+BhnGauPUB34O6mjmXaJrGJaYwxJr5ZjcAYY+KcJQJjjIlzlgiMMSbOWSIwxpg41+YGperatav2798/1mEYY0ybsmrVqv2q2q2hdW0uEfTv35+VK8PdTWiMMaYuEfmqsXXWNGSMMXHOEoExxsQ5SwTGGBPnLBEYY0ycs0RgjDFxzrNEICIviMheEfmskfUiIk+IyFYRWScio72KxRhjTOO8rBG8CFwQZv0kYKD7ugF4xsNYjDHGNMKz5whU9QN3RqTGXAL8WZ3hTz8WkU4i0lNVWzpVn4kyVaiqgmDQeVVWQnn5oc+h66qrnVdV1aH3dZeF/lQ99Ko5lqqzPvRzQ2XqLquuDl/mSM67PW1zJKIZm/0eYMIEGDKk+ds1JZYPlPXi8Gn1ctxl9RKBiNyAU2ugb9++UQmuvauuhqIiyMuD/HwoLobCQqWwsJq8PKWkBEpKlNJS52d+Phw86GxTUQHl5UJlpfO+5oLtcN7UDG/u/NDan6EO30bqrW8dcmRbHdlmUdYmgjRhiDT3/3wRQ4Y0+HBwi7SJJ4tV9VmcCT0YO3asTaDQCFUlL6+KnTur2b9fycmpZt8+JTcX8vOVAweU/HwhL08oKBCqqiD0Ih16YRYBv7+apKQqAoFqUlOryMgI0rVrNYGAEggofr9TxueDxETF58N9KYEA9ZYnJiqJiYKIkpDgfE5IEPe9kJhI7Xq/PwGfT2rXAyQkJNR+FhFEqH0lJDgXxdBlznlISJn629Vc8EP3EUqayAgNbdOQ0P00J8mEO35TsR1JMjuatzlSR3t8zZGWluHJfmOZCHbiTJRdo7e7zIRRXV1NSUkZmzdXsG1bFZs3K5s3w+7diezb56O0NAGRQ9+2RZS0tCAdOlSRkVFJamqQHj2CdOxYRUZGNenpVaSnV5OWBmlpQno6dO7sIz3dh9/vIyEhgcTERPx+Pz5fEj6fj8TERBISEhCR2p81L2NM2xPLRDAfuMWdv3UckG/9A4errq6mtLSUr74qZsWKStavV7ZuTWLbtg4Eg35E/IhAz55BevasZOjQEjp1Kiczs4JOnaro0qWCzMwqOnRIIhAIEAgESEpKIikpvfaC7vP58Pv9JCYmxvp0jTEx4lkiEJE5OBOEdxWRHOA+wA+gqv+DM2/rZJx5UkuA73kVS1uhqpSUlLBvXxErVpTz0UcJrFuXwu7dKYgIgYDQp0+Q888vpk+fEnr2LKZHjzKSkqrw+XxkZGSQmppKhw6dCQQC+Hw+AoGAfVM3xoTl5V1D05tYr8DNXh2/LSkoKCAnp4B//rOcZctS2bQplerqdBITYejQCs47r4Djjy+gV69CRJyLfmpqKunpnUhJSSElJYWkpCS74Btjjkib6CxujyoqKtizZy9vvVXOO++ksXVrJyCBjh2Vc88t4aSTiunf/yCBQDmJiYmkpKTQuXMv0tLSSE1NtaYcY0yrsUQQZYWFheTk7GHOHB+LFnWiuLgLqanwrW8VceqpRfTosR+oxufz0bFjRzIyjiUzMxOfz/6pjDHesKtLFKgqubm55OYeYM6cRObP705FRYBjjgkyY8YBTjllL9XVZQQCATp27EyXLl3o1KmTfes3xkSFJQKPFRUVkZ2dzZIl1bz+em/27etAly5VTJt2gLFjd1FRUU5KSgbdumXRvXt3u/gbY6LOEoGHduzYwfr1uTz6aG/27EklKUn5znfymDx5L4WFBSQlZdCvX1+6d+9uHb3GmJixROCByspKtm7dysKF1bzwwiBEEpg0qZAZM3IpKsolGEyiT58+9OnTx2oAxpiYs0TQygoLC9m6dTu/+U1n1q/viojw//7f/3HCCQcpLCyic+fOZGVlkZKSEutQjTEGsETQqgoKCli+/CvuvLM/wWCAfv0qeOihPZSXHyAY9NG/f3969eplzUDGmKOKJYJWUlxczOLFO7nnniwSE31MmZLPtGkH2bdvHx07diQrK4v09PRYh2mMMfVYImgFRUVFLFv2FXff3Q+fz8eNN+Zy+un72b+/kM6dOzNo0CACgUCswzTGmAZZImihkpISPvjgK2bOdJLAVVcd5NRTd1NeXk3fvn3p06ePNQUZY45qlghaoKioiDVrtjNzZhY+n48rrsjjvPN2UV2tHH/88XTp0iXWIRpjTJO8nLO4XQsGg2zZso0f/MBJAhddVMAll+whGAySlZVlScAY02ZYIjgCqsqmTZt46KFMfL5Ehgwp48orcygrK6Nv37507do11iEaY0zErGnoCGRnZ7NggbJpUxdAuOeerykvr2TAgAF079491uEZY0yzWI2gmfbt28fnnx/gpZcGAMKTT+6gqKiAHj16WBIwxrRJViNohoqKCnbs2MHPf+4MG/Hd7x4kENhLp06d6du3b6zDM8aYI2I1gmbIyclh9uyOVFT4GTCgggsvzCUQCHDcccfZLaLGmDbLEkGECgoK2Lgxj7ffPhaAX/5yDwcPHqRLly4kJyfHODpjjDlylggioKp8/fXXPPpoP0SEm2/eT0nJQTp27Ej//v1jHZ4xxrSIJYII7Ny5k6VLq9m7N4WuXYOcfnoeIkL//v1tGGljTJtniaAJxcXF5OTs4ZlnjgeEn/1sb22TUEZGRqzDM8aYFrO7hpqQnZ3NnDldEUlg4sQiuncvJBhMsSYhY0y7YTWCMMrKyigqKmbx4mMAuOGGXAoKCujWrRs+n+VQY0z7YIkgjIMHDzJ7djdAOPvsIsrLi0lLS6NXr16xDs0YY1qNJYJGVFdXs3v3Xt5913la+Prr91NWVkbPnj2tg9gY065YImhEfn4+c+akkpCQwGWX5VNcfIBOnTrRo0ePWIdmjDGtyhJBI/bs2cOSJU6z0NSpB0lISLBhJIwx7ZIlggYEg0E2b66ktDTA8OFlVFaW0qFDB1JTU2MdmjHGtDpLBA3Yv38/zz9/DCLC9Ol5FBcXk5mZaeMJGWPaJUsEdagqe/fu5csv0wDo1y+f1NRU6xswxrRbniYCEblARDaJyFYRuauB9X1FZImIrBGRdSIy2ct4IlFZWcnmzVUkJCQwaVJhbW3AnhswxrRXniUCEUkEngImAUOA6SIypE6xnwOvqepJwDTgaa/iiVRRURHvvuvMPHb66UUkJCTY/MPGmHbNyxrBKcBWVd2mqhXAXOCSOmUUqBmwpyOwy8N4InLw4EFWreoMwLHHHiAlJcU6iY0x7ZqXiaAXsCPkc467LNT9wAwRyQEWAj9uaEcicoOIrBSRlfv27fMi1lrbt5dSWurj5JNLqKgo55hjjrFOYmNMuxbrzuLpwIuq2huYDPxFROrFpKrPqupYVR3brVs3z4IJBoMsWpSOiHD22XkkJSWRmZnp2fGMMeZo4GUi2An0Cfnc210W6nrgNQBVXQ4kA109jCmsgoICPvkkHRCGDi0gJSXFOomNMe2el4ngU2CgiGSJSACnM3h+nTJfAxMBRGQwTiLwtu0njNzcEvbvDzB0aBmVleXWN2CMiQueJQJVDQK3AO8An+PcHbRBRB4UkYvdYrcBPxCR/wBzgGtVVb2KqYl4Wb68DJEERo4spaqqirS0tFiEYowxUeVpu4eqLsTpBA5ddm/I+43AaV7GEKnKyko++SRAQoIwZkwRfr+f9PT0WIdljDGeswZwV3FxMdu2dQCEzMwCUlPT8Pv9sQ7LGGM8F+u7ho4aFRUVfP11B44/vpyKinI6duwY65CMMSYqLBG4vvyyCFVh6NAyEhIS6NSpU6xDMsaYqLBE4PrwQxBJoG/fYpKSkujQoUOsQzLGmKiwRIAzLeXq1amICIMG5dO5c2d7mtgYEzcsEeCML/Sf/6SSllZFhw7lpKSkxDokY4yJGksEQG5uFarCSSeVUV1dbYnAGBNXLBEAa9ZUISKMHFlEUlKSPVFsjIkrlgiALVuqERH69i0hLS3N+geMMXEl7hOBqrJliw8QOnUqJhAIxDokY4yJqogTgYi0y4bzsrIySkqUY48NkpAQJCMjo+mNjDGmHWkyEYjIN0VkI/CF+3mkiMR8SsnWUlxczPr1KWRkOM1DSUlJsQ7JGGOiKpIawe+B84FcAFX9DzDBy6CiqbCwGJEEMjPL8fl89iCZMSbuRNQ0pKo76iyq8iCWmFi/3hl6unv3Ujp27EhiYmKsQzLGmKiKJBHsEJFvAioifhG5HWd+gTZPVdm1S0hIEAYOzLfnB4wxcSmSRHAjcDPOxPM7gVHATR7GFDXl5eV89ZVTA+jatdo6io0xcSmS+QhOUNWrQheIyGnAh96EFD2qSl5eMgkJ0KVLqT0/YIyJS5HUCJ6McFmbU15eTk6Oj6QkxefzWdOQMSYuNVojEJFvAN8EuonIzJBVGUC76FEtKytn3z4fQ4Y4tQGrERhj4lG4pqEAkOaWCZ28twCY4mVQ0fJ//1dGfn4mffrkkZycHOtwjDEmJhpNBKr6L+BfIvKiqn4VxZii5tNPnbtge/SosOcHjDFxK5LO4hIRmQUMBWq/Nqvq2Z5FFSX5+UkkJCQwcGAxIjbiqDEmPkXSWfwKzvASWcADQDbwqYcxRUV1dTXbtjl9AmlpFaSnpzexhTHGtE+RJIJMVf0TUKmq/1LV64A2XxsIBoOUlMAxx1Th91fh80VSOTLGmPYnkqtfpftzt4hcCOwCungXUnQUFhayc6ePjIxqEhISrLPYGBO3IkkED4lIR+A2nOcHMoCfeBlUNPj9fgoLfZxwQiXV1U4yMMaYeNRkIlDVt9y3+cBZUPtkcZu2a9du8vN7kpISxOfz2YQ0xpi4Fe6BskTgSpwxhhap6mcichFwD9ABOCk6IXojLy8F1QS6dq3E5/PZw2TGmLgVrkbwJ6APsAJ4QkR2AWOBu1T1jSjE5qnycj8iQufOZTbYnDEmroVLBGOBEapaLSLJwB7gOFXNjU5o3tq9uxRIx+8PkpSUFutwjDEmZsL1kFaoajWAqpYB25qbBETkAhHZJCJbReSuRspcKSIbRWSDiMxuzv5bYutWQSSB3r3LSE21h8mMMfErXI3gRBFZ574X4Dj3swCqqiPC7djtY3gKOBfIAT4VkfmqujGkzEDgbuA0VT0oIt1bcC7NUlHhQwTS0oLWP2CMiWvhEsHgFu77FGCrqm4DEJG5wCXAxpAyPwCeUtWDAKq6t4XHjFhBQQJJSYqI2oT1xpi4Fm7QuZYONNcLCJ3rOAcYV6fMIAAR+RBnaOv7VXVR3R2JyA3ADQB9+/ZtYVjO8BK7dvno1asSEbF5io0xcS3WT1H5gIHAmcB04DkR6VS3kKo+q6pjVXVst27dWnzQyspKSkuF9PRqm4fAGBP3vEwEO3FuP63R210WKgeYr6qVqrod2IyTGDylqhQX+0hKCpKUlGSJwBgT1yJKBCLSQUROaOa+PwUGikiWiASAacD8OmXewKkNICJdcZqKtjXzOM2mCnv2BOjRo4JAIGCJwBgT15pMBCLyLWAtsMj9PEpE6l7Q61HVIHAL8A7wOfCaqm4QkQdF5GK32DtArohsBJYAd0TjOYXS0ipUISmp0gabM8bEvUgGnbsf5w6gpQCqulZEsiLZuaouBBbWWXZvyHsFZrqvqCksrEAkgM9XRUqKPVVsjIlvkTQNVapqfp1l6kUw0VJQ4DQPJSdXW7OQMSbuRVIj2CAi3wES3QfA/gv4yNuwvLVrl5P/unevsOGnjTFxL5Kr4I9x5isuB2bjDEf9Ew9j8lxZGYg4NQIbftoYE+8iqRGcqKo/A37mdTDRUlJSBfhISlKbotIYE/ciqRH8TkQ+F5FfiMgwzyOKgvz8ICAkJVkfgTHGNJkIVPUsnJnJ9gF/FJH1IvJzzyPz0O7dQmKi0rlz0GoExpi4F1FPqaruUdUngBtxnim4N/wWR7fSUiE5uRqfL8HGGTLGxL1IHigbLCL3i8h6nMnrP8IZLqLNKi+HQECtWcgYY4iss/gF4FXgfFXd5XE8UVFRIQQCareOGmMMESQCVf1GNAKJpsJC6NChypqFjDGGMIlARF5T1SvdJqHQJ4kjmqHsaJaXl0BGho0zZIwxEL5GcKv786JoBBJNJSVCt27V+P3+WIdijDEx12gjuarudt/epKpfhb6Am6ITnjfKy4Xk5DY9XJIxxrSaSHpLz21g2aTWDiRaVNXtLLaHyYwxBsL3EfwI55v/ABFZF7IqHfjQ68C8VF6eQCBQbZ3FxhhD+D6C2cDbwK+Bu0KWF6rqAU+j8lAwCJWVQiAQJBBIi3U4xhgTc+ESgapqtojcXHeFiHRpq8mguFhrRx614SWMMabpGsFFwCqc20dDG9QVGOBhXJ4pKXE6iTt0sAfKjDEGwiQCVb3I/RnRtJRtRXGxkwiSk6tjHIkxxhwdIhlr6DQRSXXfzxCRR0Wkr/eheaO4WN2J6+2uIWOMgchuH30GKBGRkcBtwJfAXzyNykMlJYdmJ7O7howxJrJEEFRVBS4B/qCqT+HcQtomlZY6TUN2+6gxxjgiuW2mUETuBr4LnC4iCUCbHZuhvLwmEaglAmOMIbIawVScieuvU9U9OHMRzPI0Kg+VlTmJwO+3PgJjjIHIpqrcA7wCdBSRi4AyVf2z55F5pKzM+RkI2FhDxhgDkd01dCWwArgCuBL4RESmeB2YV8rLnZ+BQLU9R2CMMUTWR/Az4GRV3QsgIt2A94B5XgbmlZpE4PfbVJXGGAOR9REk1CQBV26E2x2VKipAFZKTEywRGGMMkdUIFonIO8Ac9/NUYKF3IXmrrAx8vmr8frtjyBhjILI5i+8QkW8D491Fz6rq370Nyzvl5fYMgTHGhAo3H8FA4LfAccB64HZV3RmtwLxSXu7cOmodxcYY4wh3NXwBeAu4HGcE0iebu3MRuUBENonIVhG5K0y5y0VERWRsc4/RXOXl4PPZyKPGGFMjXNNQuqo+577fJCKrm7NjEUkEnsKZ6jIH+FRE5qvqxjrl0oFbgU+as/8jVdM0ZInAGGMc4RJBsoicxKF5CDqEflbVphLDKcBWVd0GICJzccYr2lin3C+AR4A7mhn7EalpGrI+AmOMcYRLBLuBR0M+7wn5rMDZTey7F7Aj5HMOMC60gIiMBvqo6gIRaTQRiMgNwA0Affu2bARsJxFUWSIwxhhXuIlpzvLywO7gdY8C1zZVVlWfBZ4FGDt2bIvGhrAagTHGHM7LhvKdQJ+Qz73dZTXSgWHAUhHJBk4F5nvdYewkAht51BhjaniZCD4FBopIlogEgGnA/JqVqpqvql1Vtb+q9gc+Bi5W1ZUexlTbNGSdxcYY4/DsaqiqQeAW4B3gc+A1Vd0gIg+KyMVeHbcplZWQmGi3jxpjTI0mnywWZ0Ceq4ABqvqgO19xD1Vd0dS2qrqQOsNRqOq9jZQ9M6KIWygYtERgjDGhIrkaPg18A5jufi7EeT6gTaqqAp8PSwTGGOOKZNC5cao6WkTWAKjqQbfNv00KBgWfz2YnM8aYGpF8La50nxJWqJ2PoNrTqDxkfQTGGHO4SK6GTwB/B7qLyC+BfwO/8jQqDwWDTtOQ1QiMMcYRyTDUr4jIKmAizvASl6rq555H5gFVSwTGGFNXJHcN9QVKgH+ELlPVr70MzAvVboOWz2fTVBpjTI1IOosX4PQPCJAMZAGbgKEexuWJykqnVmCJwBhjDomkaWh46Gd3oLibPIvIQ8EggJKYaE1DxhhTo9m3zrjDT49rsuBRqLLS+WkT0xhjzCGR9BHMDPmYAIwGdnkWkYeCQadpyO+3GoExxtSIpI8gPeR9EKfP4G/ehOOtmhqBNQ0ZY8whYROB+yBZuqreHqV4POX0EVhnsTHGhGq0oVxEfKpaBZwWxXg8VdNZbM8RGGPMIeFqBCtw+gPWish84K9Acc1KVX3d49ha3aEagQ06Z4wxNSLpI0gGcnHmKK55nkCBNpcIap4jsM5iY4w5JFwi6O7eMfQZhxJAjRbNGxwroU1DxhhjHOEuiYlAGocngBptMhGEPllsjDHGES4R7FbVB6MWSRSE9hEYY4xxhOsxbXeN6M5zBIrfH+tIjDHm6BEuEUyMWhRRUlMjsERgjDGHNJoIVPVANAOJhkOJoN1Vdowx5ojF1c30NUNM+P1xddrGGBNWXF0Ra2oEgYDVCIwxpkacJoK4Om1jjAkrrq6IViMwxpj64ioRVFSoO8SEJQJjjKkRV4nAagTGGFNfXCWCigpnaAnrIzDGmEPi6ooYDIKI4vPF1WkbY0xYcXVFrKx0pqlMSLCmIWOMqeFpIhCRC0Rkk4hsFZG7Glg/U0Q2isg6EVksIv28jCcYBJ+v2ialMcaYEJ5dEd35jp8CJgFDgOkiMqROsTXAWFUdAcwDfuNVPACVlUpios1XbIwxobz8anwKsFVVt6lqBTAXuCS0gKouUdUS9+PHQG8P4yEYhMREJTEx0cvDGGNMm+JlIugF7Aj5nOMua8z1wNsNrRCRG0RkpYis3Ldv3xEH5PQRqDUNGWNMiKPiiigiM4CxwKyG1qvqs6o6VlXHduvW7YiPU1MjMMYYc4iXc3XtBPqEfO7tLjuMiJwD/Aw4Q1XLPYyHykpnmkrrIzDGmEO8rBF8CgwUkSwRCQDTgPmhBUTkJOCPwMWqutfDWAAIBpXERCwRGGNMCM8SgaoGgVuAd4DPgddUdYOIPCgiF7vFZgFpwF9FZK2IzG9kd62ishL8fusjMMaYUJ5O466qC4GFdZbdG/L+HC+PX1dNZ7HVCIwx5pC4+mrsPFBmTUPGGBPK0xrB0cZqBLFTWVlJTk4OZWVlsQ7FmHYtOTmZ3r174/f7I94m7hKB3TUUGzk5OaSnp9O/f3/7/RvjEVUlNzeXnJwcsrKyIt4u7pqGrEYQG2VlZWRmZtrv3hgPiQiZmZnNrnnHXSKwPoLYsd+7Md47kr+zuEsEViMwxpjDxV0i8PstERhjTKi4SwRWIzDGmMPFXSLw+ezJ4ngmIsyYMaP2czAYpFu3blx00UWeH/uNN95ARPjiiy9ql2VnZzNs2LDDyt1///389re/BWDPnj1MmzaN4447jjFjxjB58mQ2b95cb9+lpaWcccYZVFVVReV4zbVo0SJOOOEEjj/+eB5++OFGyz3++OMMGzaMoUOH8thjjwGwadMmRo0aVfvKyMioXde/f3+GDx/OqFGjGDt27GH7ysvLY8qUKZx44okMHjyY5cuXR+U8wpVpaN2OHTs466yzGDJkCEOHDuXxxx9v8hwqKiqYMGECwWCwxecEOLcbtaXXmDFj9EiNH1+pt966Q4PB4BHvwxyZjRs3xjoEVVVNTU3VkSNHaklJiaqqLly4UEeOHKkXXnih58e+8sordfz48XrvvffWLtu+fbsOHTr0sHL33Xefzpo1S6urq/XUU0/VZ555pnbd2rVr9YMPPqi37z/84Q/62GOPRe14zREMBnXAgAH65Zdfanl5uY4YMUI3bNhQr9z69et16NChWlxcrJWVlTpx4kTdsmVLvX0dc8wxmp2draqq/fr103379jV43Kuvvlqfe+45VVUtLy/XgwcPNhrjkiVL9JprrmnxeYQr09i6Xbt26apVq1RVtaCgQAcOHFi7TbhzuP/++/Xll19uMNaG/t6AldrIdTWuniOoqRFY01Bs/e53sGlT6+7zhBPgttsiKzt58mQWLFjAlClTmDNnDtOnT2fZsmUAvPzyyzzxxBNUVFQwbtw4nn76aRITE7n00kvZsWMHZWVl3Hrrrdxwww1kZ2czadIkxo8fz0cffUSvXr1488036dChQ71jFhUV8e9//5slS5bwrW99iwceeKDJOJcsWYLf7+fGG2+sXTZy5MgGy77yyivMnj07asdrjhUrVnD88cczYMAAAKZNm8abb77JkCGHT1j4+eefM27cOFJSUgA444wzeP311/npT39aW2bx4sUcd9xx9OsXflbb/Px8PvjgA1588UUAAoEAgUDA8/MIV6axdXfffTc9e/YEID09ncGDB7Nz50569eoV9hwuvfRS7r77bq666qoWnRfEWdOQ80CZ3cYY76ZNm8bcuXMpKytj3bp1jBs3DnAuRK+++ioffvgha9euJTExkVdeeQWAF154gVWrVrFy5UqeeOIJcnNzAdiyZQs333wzGzZsoFOnTvztb39r8JhvvvkmF1xwAYMGDSIzM5NVq1Y1Gednn33GmDFjmixXUVHBtm3b6N+/f1SOB3D66acf1lxT83rvvffqld25cyd9+hwakb53797s3FlvRHqGDRvGsmXLyM3NpaSkhIULF7Jjx47DysydO5fp06fXfhYRzjvvPMaMGcOzzz5bu3z79u1069aN733ve5x00kl8//vfp7i4uN4xx40bx6hRo/j+97/P/Pnza8/jnXfeOaLzCFcmku2zs7NZs2YN48aNa/Ichg0bxqefflovziMRNzUCVaiqshrB0SDSb+5eGTFiBNnZ2cyZM4fJkyfXLl+8eDGrVq3i5JNPBpx29+7duwPwxBNP8Pe//x1w2nS3bNlCjx49yMrKYtSoUQCMGTOG7OzsBo85Z84cbr31VsBJRHPmzGHMmDGN/l9szv/R/fv306lTp6gdD6itQbWmwYMHc+edd3LeeeeRmprKqFGjDptWtqKigvnz5/PrX/+6dtm///1vevXqxd69ezn33HM58cQTa9vOV69ezZNPPsm4ceO49dZbefjhh/nFL35x2DE/+eQTAJYuXcqLL75Y++07FoqKirj88st57LHHyMjIaPIcEhMTCQQCFBYWkp6e3qJjx00iCAadZGAzlBmAiy++mNtvv52lS5fWfrtXVa655prDLjTgXCTee+89li9fTkpKCmeeeWbtk5tJSUm15RITEyktLa13rAMHDvD++++zfv16RISqqipEhFmzZpGZmcnBgwfrlc/KyqJ3797MmzevyXPp0KHDYU+Sen08cGoEhYWF9Zb/9re/5ZxzDh9UuFevXod9s8/JyaFXr4Znrb3++uu5/vrrAbjnnnvo3fvQNOZvv/02o0eP5phjjjls3wDdu3fnsssuY8WKFUyYMIHevXvTu3fv2trelClTwnZSRyKS8whXJty6yspKLr/8cq666iq+/e1vA0R0DuXl5SQnJ7fovCCOmoacznXFFzepz4Rz3XXXcd999zF8+PDaZRMnTmTevHns3evMkXTgwAG++uor8vPz6dy5MykpKXzxxRd8/PHHzTrWvHnz+O53v8tXX31FdnY2O3bsICsri2XLlpGWlkbPnj15//33a4+5aNEixo8fz9lnn015eflhTR7r1q2r9228c+fOVFVV1SYDr48HTo1g7dq19V51kwDAySefzJYtW9i+fTsVFRXMnTuXiy++uF45oPZ3//XXX/P666/zne98p3ZdTX9OjeLi4tpkVFxczD//+c/aO6J69OhBnz592OR2Ri1evLhen0SoM888s8naQCTnEa5MY+tUleuvv57Bgwczc+bM2n01dQ65ubl07dq1WYPLNaqxXuSj9XWkdw3l56uOHFmhv/rV9iPa3rTM0XTXUF1LliypvWto7ty5OnLkSB0+fLiOHj1aly9frmVlZXrBBRfoiSeeqJdccomeccYZumTJknp34MyaNUvvu+++evs/88wz9e233z5s2eOPP6433nijqqpu2LBBzzzzTB05cqSOHDnysDtBdu7cqVdccYUOGDBAhwwZopMnT9bNmzfXO8Z1112n7777btSO11wLFizQgQMH6oABA/Shhx6qXT5p0iTduXNn7efx48fr4MGDdcSIEfree+/VLi8qKtIuXbpoXl5e7bIvv/xSR4wYoSNGjNAhQ4Yctl9V1TVr1uiYMWN0+PDheskll+iBAwfqxXXKKafU/h5CX4sWLTri82isTGPrli1bpoAOHz689vgLFixo8hz++te/6syZMxuMs7l3DYmzvu0YO3asrly5stnbHTgAZ51VyYwZO7njjv6tH5gJ6/PPP2fw4MGxDqPdWr16Nb///e/5y1/+EutQTJR8+9vf5uGHH2bQoEH11jX09yYiq1R1bL3CWNOQMe3C6NGjOeussw57oMy0XxUVFVx66aUNJoEjETeXxZoH8Hy+tlUDMiZS1113XaxDMFESCAS4+uqrW21/cVMjqKx07hqyRGCMMYeLm0RgTUPGGNOwuEkEh2oEsY7EGGOOLnGTCKxGYIwxDYubRFBZ6fxsjWcvjDGmPYmbRFAzxITVCIwx5nBxkwicGoE1DRljTF1xc1mseY4gEIib3HdU27hxY4PDAh+p1NTUsGPJHInrrruOt956i+7du/PZZ59FvF1eXh6zZ8/mpptuanD9/fffT1paGrfffnuj+4ikjDGtJW6uiocSgQ1BfTQoLi4mIyOj1V7NTSpLly7l2muvDVvm2muvZdGiRc0+t7y8PJ5++ulmb2dMrMRhIoibUzYtNGHCBLp06RK2THFxMRdeeCEjR45k2LBhvPrqq9x11118+eWXjBo1ijvuuAOAX/7ylwwaNIjx48fXjiZZV7gyL7/8MqeccgqjRo3ihz/8IVVVVdx111089dRTtWVC5x42pjnipmnI7hoy4MxIVV5eTlFREQcOHKidVOaRRx7h/PPPb/b+Fi1axLHHHsuCBQsAZ4rEcePG8dlnn7F27VoAVq1axdy5c1m7di3BYJDRo0fXmwksXJnQmdP8fj833XQTr7zyClOnTuUnP/kJN998MwCvvfZagzNrGdOUuEkENTUCv9+ahuJZa89INXz4cG677TbuvPNOLrroIk4//fR6E78sW7aMyy67rHYu3obG4g9XprGZ066++mr27t3Lrl272LdvH507dz5sKkRjIuVpIhCRC4DHgUTgeVV9uM76JODPwBggF5iqqtlexFJTI0hKsqYh03oGDRrE6tWrWbhwIT//+c+ZOHFiqw4GBo3PnAZwxRVXMG/ePPbs2cPUqVNb9bgmfnh2VRSRROApYBIwBJguInVv67geOKiqxwO/Bx7xKh6rEZhQkcxIFYldu3aRkpLCjBkzuOOOO1i9ejXp6emHTeM4YcIE3njjDUpLSyksLOQf//hHvf2EK9PYzGkAU6dOZe7cucybN48rrriixedj4pOXNYJTgK2qug1AROYClwAbQ8pcAtzvvp8H/EFERD2YLedQImjtPZsjkZqaSkFBQavuLxI1fQR1NdRHMH36dJYuXcr+/fvp3bs3DzzwQO18ujXWr1/PHXfcQUJCAn6/n2eeeYbMzExOO+00hg0bxqRJk5g1axZTp05l5MiRdO/evbaJB2Dy5Mk8//zzjB49utEyQ4YM4aGHHuK8886juroav9/PU089Rb9+/Rg6dCiFhYX06tWLnj171tvvscceG9HvxcQ3z2YoE5EpwAWq+n3383eBcap6S0iZz9wyOe7nL90y++vs6wbgBoC+ffuOqfk21BwffACzZ+fzq18l0KVL+pGeljlCNkOZMdHT3BnK2kRnsao+CzwLzlSVR7KPCRNgwoSOrRqXMca0B172nO4EQm9h6O0ua7CMiPiAjjidxsYYY6LEy0TwKTBQRLJEJABMA+bXKTMfuMZ9PwV434v+AXN0sH9aY7x3JH9nniUCVQ0CtwDvAJ8Dr6nqBhF5UERqbpL+E5ApIluBmcBdXsVjYis5OZnc3FxLBsZ4SFXJzc0lOTm5Wdt51lnslbFjx+rKlStjHYZppsrKSnJycigrK4t1KMa0a8nJyfTu3Rt/nVsk23xnsWn7/H4/WVlZsQ7DGNMAe8zWGGPinCUCY4yJc5YIjDEmzrW5zmIR2Qc0/9FiR1dgf5Ol2hc75/hg5xwfWnLO/VS1W0Mr2lwiaAkRWdlYr3l7ZeccH+yc44NX52xNQ8YYE+csERhjTJyLt0TwbKwDiAE75/hg5xwfPDnnuOojMMYYU1+81QiMMcbUYYnAGGPiXLtMBCJygYhsEpGtIlJvRFMRSRKRV931n4hI/xiE2aoiOOeZIrJRRNaJyGIR6ReLOFtTU+ccUu5yEVERafO3GkZyziJypftvvUFEZkc7xtYWwf/tviKyRETWuP+/J8ciztYiIi+IyF53BseG1ouIPOH+PtaJyOgWH1RV29ULSAS+BAYAAeA/wJA6ZW4C/sd9Pw14NdZxR+GczwJS3Pc/iodzdsulAx8AHwNjYx13FP6dBwJrgM7u5+6xjjsK5/ws8CP3/RAgO9Zxt/CcJwCjgc8aWT8ZeBsQ4FTgk5Yesz3WCE4BtqrqNlWtAOYCl9Qpcwnwkvt+HjBRRCSKMba2Js9ZVZeoaon78WOcGePaskj+nQF+ATwCtIfxryM55x8AT6nqQQBV3RvlGFtbJOesQIb7viOwK4rxtTpV/QA4EKbIJcCf1fEx0ElEerbkmO0xEfQCdoR8znGXNVhGnQl08oHMqETnjUjOOdT1ON8o2rImz9mtMvdR1QXRDMxDkfw7DwIGiciHIvKxiFwQtei8Eck53w/MEJEcYCHw4+iEFjPN/Xtvks1HEGdEZAYwFjgj1rF4SUQSgEeBa2McSrT5cJqHzsSp9X0gIsNVNS+WQXlsOvCiqv5ORL4B/EVEhqlqdawDayvaY41gJ9An5HNvd1mDZUTEh1OdzI1KdN6I5JwRkXOAnwEXq2p5lGLzSlPnnA4MA5aKSDZOW+r8Nt5hHMm/cw4wX1UrVXU7sBknMbRVkZzz9cBrAKq6HEjGGZytvYro77052mMi+BQYKCJZIhLA6QyeX6fMfOAa9/0U4H11e2HaqCbPWUROAv6IkwTaersxNHHOqpqvql1Vtb+q9sfpF7lYVdvyPKeR/N9+A6c2gIh0xWkq2hbFGFtbJOf8NTARQEQG4ySCfVGNMrrmA1e7dw+dCuSr6u6W7LDdNQ2palBEbgHewbnj4AVV3SAiDwIrVXU+8Cec6uNWnE6ZabGLuOUiPOdZQBrwV7df/GtVvThmQbdQhOfcrkR4zu8A54nIRqAKuENV22xtN8Jzvg14TkT+G6fj+Nq2/MVORObgJPOubr/HfYAfQFX/B6cfZDKwFSgBvtfiY7bh35cxxphW0B6bhowxxjSDJQJjjIlzlgiMMSbOWSIwxpg4Z4nAGGPinCUCc1QSkSoRWRvy6h+mbFErHO9FEdnuHmu1+4Rqc/fxvIgMcd/fU2fdRy2N0d1Pze/lMxH5h4h0aqL8qLY+Gqfxnt0+ao5KIlKkqmmtXTbMPl4E3lLVeSJyHvBbVR3Rgv21OKam9isiLwGbVfWXYcpfizPq6i2tHYtpP6xGYNoEEUlz51FYLSLrRaTeSKMi0lNEPgj5xny6u/w8EVnubvtXEWnqAv0BcLy77Ux3X5+JyE/cZakiskBE/uMun+ouXyoiY0XkYaCDG8cr7roi9+dcEbkwJOYXRWSKiCSKyCwR+dQdY/6HEfxaluMONiYip7jnuEZEPhKRE9wncR8EprqxTHVjf0FEVrhlGxqx1cSbWI+9bS97NfTCeSp2rfv6O85T8Bnuuq44T1XW1GiL3J+3AT9z3yfijDfUFefCnuouvxO4t4HjvQhMcd9fAXwCjAHWA6k4T2VvAE4CLgeeC9m2o/tzKe6cBzUxhZSpifEy4CX3fQBnFMkOwA3Az93lScBKIKuBOItCzu+vwAXu5wzA574/B/ib+/5a4A8h2/8KmOG+74QzFlFqrP+97RXbV7sbYsK0G6WqOqrmg4j4gV+JyASgGueb8DHAnpBtPgVecMu+oaprReQMnMlKPnSH1gjgfJNuyCwR+TnOODXX44xf83dVLXZjeB04HVgE/E5EHsFpTlrWjPN6G3hcRJKAC4APVLXUbY4aISJT3HIdcQaL215n+w4istY9/8+Bd0PKvyQiA3GGWfA3cvzzgItF5Hb3czLQ192XiVOWCExbcRXQDRijqpXijCiaHFpAVT9wE8WFwIsi8ihwEHhXVadHcIw7VHVezQcRmdhQIVXdLM5cB5OBh0Rksao+GMlJqGqZiCwFzgem4ky0As5sUz9W1Xea2EWpqo4SkRSc8XduBp7AmYBniape5nasL21kewEuV9VNkcRr4oP1EZi2oiOw100CZwH15lwWZx7m/1PV54Dncab7+xg4TURq2vxTRWRQhMdcBlwqIikikorTrLNMRI4FSlT1ZZzB/BqaM7bSrZk05FWcgcJqahfgXNR/VLONiAxyj9kgdWab+y/gNjk0lHrNUMTXhhQtxGkiq/EO8GNxq0fijEpr4pwlAtNWvAKMFZH1wNXAFw2UORP4j4iswfm2/biq7sO5MM4RkXU4zUInRnJAVV2N03ewAqfP4HlVXQMMB1a4TTT3AQ81sPmzwLqazuI6/okzMdB76ky/CE7i2gisFmfS8j/SRI3djWUdzsQsvwF+7Z576HZLgCE1ncU4NQe/G9sG97OJc3b7qDHGxDmrERhjTJyzRGCMMXHOEoExxsQ5SwTGGBPnLBEYY0ycs0RgjDFxzhKBMcbEuf8PjA+ALyBO4p8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "statistic_total_AUC(args, total_KFOLD_test_labels, total_FOLD_test_scores, KFOLD_test_out_come)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement of GTGenie on HMDAD in 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow version 1.15.5 has been patched using tfdeterminism version 0.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times: 0, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.17115, train_auc = 0.44055, test_loss = 0.08609, test_auc = 0.52753, time = 0.76369\n",
      "Epoch: 0010 | train_loss = 0.07705, train_auc = 0.97804, test_loss = 0.04909, test_auc = 0.92623, time = 0.01558\n",
      "Epoch: 0020 | train_loss = 0.05404, train_auc = 0.98719, test_loss = 0.04159, test_auc = 0.92920, time = 0.01376\n",
      "Epoch: 0030 | train_loss = 0.03764, train_auc = 0.99139, test_loss = 0.03972, test_auc = 0.94457, time = 0.01430\n",
      "Epoch: 0040 | train_loss = 0.03148, train_auc = 0.99228, test_loss = 0.04125, test_auc = 0.94148, time = 0.01293\n",
      "Epoch: 0050 | train_loss = 0.02557, train_auc = 0.99297, test_loss = 0.04618, test_auc = 0.92006, time = 0.01401\n",
      "Epoch: 0060 | train_loss = 0.02350, train_auc = 0.99208, test_loss = 0.04171, test_auc = 0.93235, time = 0.01302\n",
      "Epoch: 0070 | train_loss = 0.02312, train_auc = 0.99139, test_loss = 0.04186, test_auc = 0.93099, time = 0.01261\n",
      "Epoch: 0080 | train_loss = 0.02302, train_auc = 0.99169, test_loss = 0.04206, test_auc = 0.93568, time = 0.01228\n",
      "Epoch: 0090 | train_loss = 0.02299, train_auc = 0.99181, test_loss = 0.04271, test_auc = 0.94093, time = 0.01276\n",
      "Epoch: 0100 | train_loss = 0.02298, train_auc = 0.99179, test_loss = 0.04268, test_auc = 0.94278, time = 0.01316\n",
      "Epoch: 0110 | train_loss = 0.02298, train_auc = 0.99186, test_loss = 0.04279, test_auc = 0.94259, time = 0.01222\n",
      "Epoch: 0120 | train_loss = 0.02297, train_auc = 0.99195, test_loss = 0.04271, test_auc = 0.94327, time = 0.01278\n",
      "Epoch: 0130 | train_loss = 0.02297, train_auc = 0.99205, test_loss = 0.04254, test_auc = 0.94438, time = 0.01264\n",
      "Epoch: 0140 | train_loss = 0.02296, train_auc = 0.99216, test_loss = 0.04253, test_auc = 0.94173, time = 0.01272\n",
      "Epoch: 0150 | train_loss = 0.01904, train_auc = 0.99377, test_loss = 0.03920, test_auc = 0.94309, time = 0.01226\n",
      "Epoch: 0160 | train_loss = 0.01879, train_auc = 0.99415, test_loss = 0.04169, test_auc = 0.94679, time = 0.01231\n",
      "Epoch: 0170 | train_loss = 0.01877, train_auc = 0.99418, test_loss = 0.04376, test_auc = 0.94006, time = 0.01337\n",
      "Epoch: 0180 | train_loss = 0.01876, train_auc = 0.99424, test_loss = 0.04394, test_auc = 0.94438, time = 0.01826\n",
      "Epoch: 0190 | train_loss = 0.01876, train_auc = 0.99427, test_loss = 0.04396, test_auc = 0.94321, time = 0.01305\n",
      "Epoch: 0200 | train_loss = 0.01875, train_auc = 0.99429, test_loss = 0.04389, test_auc = 0.93907, time = 0.01276\n",
      "Epoch: 0210 | train_loss = 0.01875, train_auc = 0.99431, test_loss = 0.04385, test_auc = 0.93938, time = 0.01224\n",
      "Epoch: 0220 | train_loss = 0.01875, train_auc = 0.99429, test_loss = 0.04381, test_auc = 0.94333, time = 0.01221\n",
      "Epoch: 0230 | train_loss = 0.01875, train_auc = 0.99427, test_loss = 0.04380, test_auc = 0.93994, time = 0.01233\n",
      "Epoch: 0240 | train_loss = 0.01875, train_auc = 0.99433, test_loss = 0.04380, test_auc = 0.93969, time = 0.01235\n",
      "Epoch: 0250 | train_loss = 0.01875, train_auc = 0.99433, test_loss = 0.04380, test_auc = 0.93975, time = 0.01259\n",
      "Epoch: 0260 | train_loss = 0.01875, train_auc = 0.99435, test_loss = 0.04379, test_auc = 0.94321, time = 0.01306\n",
      "Epoch: 0270 | train_loss = 0.01875, train_auc = 0.99435, test_loss = 0.04379, test_auc = 0.93969, time = 0.01809\n",
      "Epoch: 0280 | train_loss = 0.01875, train_auc = 0.99436, test_loss = 0.04379, test_auc = 0.93951, time = 0.01246\n",
      "Epoch: 0290 | train_loss = 0.01875, train_auc = 0.99434, test_loss = 0.04379, test_auc = 0.93981, time = 0.01237\n",
      "Epoch: 0300 | train_loss = 0.01875, train_auc = 0.99436, test_loss = 0.04379, test_auc = 0.93963, time = 0.01225\n",
      "times: 0, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15201, train_auc = 0.59184, test_loss = 0.09513, test_auc = 0.39790, time = 0.76798\n",
      "Epoch: 0010 | train_loss = 0.07400, train_auc = 0.97317, test_loss = 0.05420, test_auc = 0.85809, time = 0.01506\n",
      "Epoch: 0020 | train_loss = 0.05170, train_auc = 0.98402, test_loss = 0.05779, test_auc = 0.80926, time = 0.01357\n",
      "Epoch: 0030 | train_loss = 0.03881, train_auc = 0.98955, test_loss = 0.04323, test_auc = 0.92784, time = 0.01336\n",
      "Epoch: 0040 | train_loss = 0.02963, train_auc = 0.99073, test_loss = 0.04251, test_auc = 0.93759, time = 0.01603\n",
      "Epoch: 0050 | train_loss = 0.02414, train_auc = 0.99164, test_loss = 0.04658, test_auc = 0.92901, time = 0.01270\n",
      "Epoch: 0060 | train_loss = 0.02187, train_auc = 0.99207, test_loss = 0.03237, test_auc = 0.96321, time = 0.01363\n",
      "Epoch: 0070 | train_loss = 0.02121, train_auc = 0.99225, test_loss = 0.03560, test_auc = 0.94630, time = 0.01252\n",
      "Epoch: 0080 | train_loss = 0.02104, train_auc = 0.99238, test_loss = 0.03277, test_auc = 0.95407, time = 0.01303\n",
      "Epoch: 0090 | train_loss = 0.02100, train_auc = 0.99242, test_loss = 0.03348, test_auc = 0.95272, time = 0.01259\n",
      "Epoch: 0100 | train_loss = 0.02094, train_auc = 0.99280, test_loss = 0.03417, test_auc = 0.95358, time = 0.01300\n",
      "Epoch: 0110 | train_loss = 0.01890, train_auc = 0.99307, test_loss = 0.03551, test_auc = 0.96469, time = 0.01311\n",
      "Epoch: 0120 | train_loss = 0.01884, train_auc = 0.99297, test_loss = 0.03129, test_auc = 0.94802, time = 0.01313\n",
      "Epoch: 0130 | train_loss = 0.01879, train_auc = 0.99292, test_loss = 0.03096, test_auc = 0.96259, time = 0.01239\n",
      "Epoch: 0140 | train_loss = 0.01877, train_auc = 0.99295, test_loss = 0.03234, test_auc = 0.95383, time = 0.01309\n",
      "Epoch: 0150 | train_loss = 0.01876, train_auc = 0.99292, test_loss = 0.03364, test_auc = 0.94840, time = 0.01233\n",
      "Epoch: 0160 | train_loss = 0.01876, train_auc = 0.99292, test_loss = 0.03362, test_auc = 0.94883, time = 0.01267\n",
      "Epoch: 0170 | train_loss = 0.01876, train_auc = 0.99292, test_loss = 0.03334, test_auc = 0.95111, time = 0.01272\n",
      "Epoch: 0180 | train_loss = 0.01876, train_auc = 0.99293, test_loss = 0.03321, test_auc = 0.95204, time = 0.01325\n",
      "Epoch: 0190 | train_loss = 0.01875, train_auc = 0.99291, test_loss = 0.03316, test_auc = 0.95222, time = 0.01283\n",
      "Epoch: 0200 | train_loss = 0.01875, train_auc = 0.99291, test_loss = 0.03315, test_auc = 0.95259, time = 0.01242\n",
      "Epoch: 0210 | train_loss = 0.01875, train_auc = 0.99292, test_loss = 0.03313, test_auc = 0.95259, time = 0.01214\n",
      "Epoch: 0220 | train_loss = 0.01875, train_auc = 0.99289, test_loss = 0.03311, test_auc = 0.95315, time = 0.01270\n",
      "Epoch: 0230 | train_loss = 0.01875, train_auc = 0.99292, test_loss = 0.03310, test_auc = 0.95364, time = 0.01251\n",
      "Epoch: 0240 | train_loss = 0.01875, train_auc = 0.99292, test_loss = 0.03308, test_auc = 0.95414, time = 0.01203\n",
      "Epoch: 0250 | train_loss = 0.01875, train_auc = 0.99295, test_loss = 0.03306, test_auc = 0.95414, time = 0.01243\n",
      "Epoch: 0260 | train_loss = 0.01875, train_auc = 0.99292, test_loss = 0.03304, test_auc = 0.95426, time = 0.01208\n",
      "Epoch: 0270 | train_loss = 0.01875, train_auc = 0.99293, test_loss = 0.03302, test_auc = 0.95432, time = 0.01230\n",
      "Epoch: 0280 | train_loss = 0.01875, train_auc = 0.99292, test_loss = 0.03300, test_auc = 0.95451, time = 0.01286\n",
      "Epoch: 0290 | train_loss = 0.01875, train_auc = 0.99294, test_loss = 0.03299, test_auc = 0.95451, time = 0.01243\n",
      "Epoch: 0300 | train_loss = 0.01875, train_auc = 0.99289, test_loss = 0.03297, test_auc = 0.95463, time = 0.01226\n",
      "times: 0, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14086, train_auc = 0.59746, test_loss = 0.08690, test_auc = 0.52722, time = 0.76867\n",
      "Epoch: 0010 | train_loss = 0.06868, train_auc = 0.96907, test_loss = 0.04605, test_auc = 0.93278, time = 0.01532\n",
      "Epoch: 0020 | train_loss = 0.04714, train_auc = 0.99235, test_loss = 0.04389, test_auc = 0.94049, time = 0.01353\n",
      "Epoch: 0030 | train_loss = 0.03270, train_auc = 0.99667, test_loss = 0.03764, test_auc = 0.95852, time = 0.01350\n",
      "Epoch: 0040 | train_loss = 0.02691, train_auc = 0.99618, test_loss = 0.04177, test_auc = 0.92432, time = 0.01383\n",
      "Epoch: 0050 | train_loss = 0.02161, train_auc = 0.99703, test_loss = 0.03806, test_auc = 0.95420, time = 0.01293\n",
      "Epoch: 0060 | train_loss = 0.01641, train_auc = 0.99738, test_loss = 0.03448, test_auc = 0.96284, time = 0.01242\n",
      "Epoch: 0070 | train_loss = 0.01452, train_auc = 0.99743, test_loss = 0.04154, test_auc = 0.94123, time = 0.01254\n",
      "Epoch: 0080 | train_loss = 0.01371, train_auc = 0.99742, test_loss = 0.03882, test_auc = 0.94741, time = 0.01726\n",
      "Epoch: 0090 | train_loss = 0.01342, train_auc = 0.99752, test_loss = 0.03852, test_auc = 0.94889, time = 0.01261\n",
      "Epoch: 0100 | train_loss = 0.01335, train_auc = 0.99749, test_loss = 0.03816, test_auc = 0.95210, time = 0.01299\n",
      "Epoch: 0110 | train_loss = 0.01331, train_auc = 0.99749, test_loss = 0.03772, test_auc = 0.95654, time = 0.01227\n",
      "Epoch: 0120 | train_loss = 0.01329, train_auc = 0.99748, test_loss = 0.03814, test_auc = 0.95531, time = 0.01234\n",
      "Epoch: 0130 | train_loss = 0.01329, train_auc = 0.99746, test_loss = 0.03862, test_auc = 0.95290, time = 0.01304\n",
      "Epoch: 0140 | train_loss = 0.01328, train_auc = 0.99748, test_loss = 0.03879, test_auc = 0.95265, time = 0.01236\n",
      "Epoch: 0150 | train_loss = 0.01328, train_auc = 0.99750, test_loss = 0.03889, test_auc = 0.95302, time = 0.01259\n",
      "Epoch: 0160 | train_loss = 0.01327, train_auc = 0.99749, test_loss = 0.03893, test_auc = 0.95340, time = 0.01292\n",
      "Epoch: 0170 | train_loss = 0.01327, train_auc = 0.99750, test_loss = 0.03895, test_auc = 0.95352, time = 0.01241\n",
      "Epoch: 0180 | train_loss = 0.01327, train_auc = 0.99750, test_loss = 0.03897, test_auc = 0.95377, time = 0.01251\n",
      "Epoch: 0190 | train_loss = 0.01327, train_auc = 0.99749, test_loss = 0.03898, test_auc = 0.95401, time = 0.01263\n",
      "Epoch: 0200 | train_loss = 0.01327, train_auc = 0.99748, test_loss = 0.03900, test_auc = 0.95426, time = 0.01250\n",
      "Epoch: 0210 | train_loss = 0.01327, train_auc = 0.99749, test_loss = 0.03901, test_auc = 0.95426, time = 0.01250\n",
      "Epoch: 0220 | train_loss = 0.01327, train_auc = 0.99749, test_loss = 0.03902, test_auc = 0.95414, time = 0.01251\n",
      "Epoch: 0230 | train_loss = 0.01327, train_auc = 0.99749, test_loss = 0.03902, test_auc = 0.95414, time = 0.01859\n",
      "Epoch: 0240 | train_loss = 0.01326, train_auc = 0.99750, test_loss = 0.03902, test_auc = 0.95438, time = 0.01247\n",
      "Epoch: 0250 | train_loss = 0.01326, train_auc = 0.99748, test_loss = 0.03902, test_auc = 0.95451, time = 0.01244\n",
      "Epoch: 0260 | train_loss = 0.01326, train_auc = 0.99750, test_loss = 0.03902, test_auc = 0.95463, time = 0.01231\n",
      "Epoch: 0270 | train_loss = 0.01326, train_auc = 0.99748, test_loss = 0.03902, test_auc = 0.95463, time = 0.01234\n",
      "Epoch: 0280 | train_loss = 0.01326, train_auc = 0.99748, test_loss = 0.03902, test_auc = 0.95457, time = 0.01259\n",
      "Epoch: 0290 | train_loss = 0.01326, train_auc = 0.99749, test_loss = 0.03902, test_auc = 0.95438, time = 0.01258\n",
      "Epoch: 0300 | train_loss = 0.01326, train_auc = 0.99748, test_loss = 0.03902, test_auc = 0.95420, time = 0.01246\n",
      "times: 0, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.16131, train_auc = 0.58409, test_loss = 0.10220, test_auc = 0.32926, time = 0.76008\n",
      "Epoch: 0010 | train_loss = 0.08915, train_auc = 0.94670, test_loss = 0.04046, test_auc = 0.93975, time = 0.01494\n",
      "Epoch: 0020 | train_loss = 0.05539, train_auc = 0.97954, test_loss = 0.03685, test_auc = 0.95333, time = 0.01313\n",
      "Epoch: 0030 | train_loss = 0.04855, train_auc = 0.98478, test_loss = 0.04045, test_auc = 0.93383, time = 0.01301\n",
      "Epoch: 0040 | train_loss = 0.04475, train_auc = 0.98541, test_loss = 0.03984, test_auc = 0.93932, time = 0.01235\n",
      "Epoch: 0050 | train_loss = 0.03986, train_auc = 0.99006, test_loss = 0.03729, test_auc = 0.95704, time = 0.01250\n",
      "Epoch: 0060 | train_loss = 0.03816, train_auc = 0.99057, test_loss = 0.04159, test_auc = 0.94228, time = 0.01228\n",
      "Epoch: 0070 | train_loss = 0.03391, train_auc = 0.99197, test_loss = 0.04078, test_auc = 0.95704, time = 0.01235\n",
      "Epoch: 0080 | train_loss = 0.03301, train_auc = 0.99203, test_loss = 0.04065, test_auc = 0.94525, time = 0.01240\n",
      "Epoch: 0090 | train_loss = 0.03264, train_auc = 0.99204, test_loss = 0.04275, test_auc = 0.94160, time = 0.01257\n",
      "Epoch: 0100 | train_loss = 0.03254, train_auc = 0.99216, test_loss = 0.04403, test_auc = 0.93346, time = 0.01222\n",
      "Epoch: 0110 | train_loss = 0.03251, train_auc = 0.99234, test_loss = 0.04495, test_auc = 0.92556, time = 0.01217\n",
      "Epoch: 0120 | train_loss = 0.02726, train_auc = 0.99478, test_loss = 0.05243, test_auc = 0.87568, time = 0.01252\n",
      "Epoch: 0130 | train_loss = 0.02906, train_auc = 0.99367, test_loss = 0.04531, test_auc = 0.91963, time = 0.01211\n",
      "Epoch: 0140 | train_loss = 0.02881, train_auc = 0.99240, test_loss = 0.04153, test_auc = 0.94895, time = 0.01208\n",
      "Epoch: 0150 | train_loss = 0.02824, train_auc = 0.99051, test_loss = 0.04006, test_auc = 0.94802, time = 0.01233\n",
      "Epoch: 0160 | train_loss = 0.02815, train_auc = 0.99047, test_loss = 0.04456, test_auc = 0.93333, time = 0.01228\n",
      "Epoch: 0170 | train_loss = 0.02807, train_auc = 0.99090, test_loss = 0.04469, test_auc = 0.92148, time = 0.01219\n",
      "Epoch: 0180 | train_loss = 0.02657, train_auc = 0.99238, test_loss = 0.04424, test_auc = 0.91741, time = 0.01220\n",
      "Epoch: 0190 | train_loss = 0.02370, train_auc = 0.99304, test_loss = 0.04136, test_auc = 0.94617, time = 0.01238\n",
      "Epoch: 0200 | train_loss = 0.02310, train_auc = 0.99314, test_loss = 0.04118, test_auc = 0.95272, time = 0.01248\n",
      "Epoch: 0210 | train_loss = 0.02299, train_auc = 0.99423, test_loss = 0.03782, test_auc = 0.96031, time = 0.01227\n",
      "Epoch: 0220 | train_loss = 0.02297, train_auc = 0.99318, test_loss = 0.03836, test_auc = 0.96043, time = 0.01233\n",
      "Epoch: 0230 | train_loss = 0.02296, train_auc = 0.99318, test_loss = 0.03871, test_auc = 0.95568, time = 0.01216\n",
      "Epoch: 0240 | train_loss = 0.02296, train_auc = 0.99420, test_loss = 0.03933, test_auc = 0.95154, time = 0.01243\n",
      "Epoch: 0250 | train_loss = 0.02296, train_auc = 0.99321, test_loss = 0.03965, test_auc = 0.95000, time = 0.01280\n",
      "Epoch: 0260 | train_loss = 0.02296, train_auc = 0.99317, test_loss = 0.03981, test_auc = 0.94864, time = 0.01257\n",
      "Epoch: 0270 | train_loss = 0.02296, train_auc = 0.99319, test_loss = 0.03977, test_auc = 0.94840, time = 0.01195\n",
      "Epoch: 0280 | train_loss = 0.02296, train_auc = 0.99323, test_loss = 0.03975, test_auc = 0.94833, time = 0.01222\n",
      "Epoch: 0290 | train_loss = 0.02296, train_auc = 0.99427, test_loss = 0.03977, test_auc = 0.94840, time = 0.01347\n",
      "Epoch: 0300 | train_loss = 0.02296, train_auc = 0.99327, test_loss = 0.03984, test_auc = 0.94778, time = 0.01300\n",
      "times: 0, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.17056, train_auc = 0.37118, test_loss = 0.08790, test_auc = 0.53333, time = 0.74657\n",
      "Epoch: 0010 | train_loss = 0.07611, train_auc = 0.92504, test_loss = 0.05405, test_auc = 0.89222, time = 0.01507\n",
      "Epoch: 0020 | train_loss = 0.05700, train_auc = 0.94924, test_loss = 0.04361, test_auc = 0.93846, time = 0.01323\n",
      "Epoch: 0030 | train_loss = 0.03989, train_auc = 0.98799, test_loss = 0.05845, test_auc = 0.70346, time = 0.01262\n",
      "Epoch: 0040 | train_loss = 0.03288, train_auc = 0.98842, test_loss = 0.03233, test_auc = 0.97000, time = 0.01206\n",
      "Epoch: 0050 | train_loss = 0.02881, train_auc = 0.99085, test_loss = 0.03140, test_auc = 0.96049, time = 0.01202\n",
      "Epoch: 0060 | train_loss = 0.02697, train_auc = 0.99078, test_loss = 0.03123, test_auc = 0.97185, time = 0.01198\n",
      "Epoch: 0070 | train_loss = 0.02609, train_auc = 0.99122, test_loss = 0.06494, test_auc = 0.69568, time = 0.01232\n",
      "Epoch: 0080 | train_loss = 0.02499, train_auc = 0.99080, test_loss = 0.06549, test_auc = 0.60765, time = 0.01210\n",
      "Epoch: 0090 | train_loss = 0.02488, train_auc = 0.99019, test_loss = 0.06509, test_auc = 0.71222, time = 0.01197\n",
      "Epoch: 0100 | train_loss = 0.02484, train_auc = 0.99036, test_loss = 0.05871, test_auc = 0.83160, time = 0.01209\n",
      "Epoch: 0110 | train_loss = 0.02482, train_auc = 0.99040, test_loss = 0.04966, test_auc = 0.86827, time = 0.01193\n",
      "Epoch: 0120 | train_loss = 0.02481, train_auc = 0.99042, test_loss = 0.04624, test_auc = 0.87815, time = 0.01204\n",
      "Epoch: 0130 | train_loss = 0.02481, train_auc = 0.99049, test_loss = 0.04676, test_auc = 0.87741, time = 0.01205\n",
      "Epoch: 0140 | train_loss = 0.02481, train_auc = 0.99053, test_loss = 0.04606, test_auc = 0.88049, time = 0.01192\n",
      "Epoch: 0150 | train_loss = 0.02481, train_auc = 0.99062, test_loss = 0.04530, test_auc = 0.88840, time = 0.01201\n",
      "Epoch: 0160 | train_loss = 0.02480, train_auc = 0.99078, test_loss = 0.04490, test_auc = 0.89840, time = 0.01233\n",
      "Epoch: 0170 | train_loss = 0.02480, train_auc = 0.99082, test_loss = 0.04450, test_auc = 0.90877, time = 0.01239\n",
      "Epoch: 0180 | train_loss = 0.02480, train_auc = 0.99090, test_loss = 0.04424, test_auc = 0.91321, time = 0.01239\n",
      "Epoch: 0190 | train_loss = 0.02480, train_auc = 0.99100, test_loss = 0.04408, test_auc = 0.91580, time = 0.01189\n",
      "Epoch: 0200 | train_loss = 0.02480, train_auc = 0.99105, test_loss = 0.04379, test_auc = 0.92049, time = 0.01192\n",
      "Epoch: 0210 | train_loss = 0.02480, train_auc = 0.99115, test_loss = 0.04350, test_auc = 0.92457, time = 0.01226\n",
      "Epoch: 0220 | train_loss = 0.02480, train_auc = 0.99122, test_loss = 0.04298, test_auc = 0.92889, time = 0.01178\n",
      "Epoch: 0230 | train_loss = 0.02480, train_auc = 0.99166, test_loss = 0.03666, test_auc = 0.94321, time = 0.01181\n",
      "Epoch: 0240 | train_loss = 0.02924, train_auc = 0.99071, test_loss = 0.05061, test_auc = 0.88778, time = 0.01222\n",
      "Epoch: 0250 | train_loss = 0.02355, train_auc = 0.99048, test_loss = 0.04508, test_auc = 0.94512, time = 0.01198\n",
      "Epoch: 0260 | train_loss = 0.02306, train_auc = 0.99077, test_loss = 0.04188, test_auc = 0.93747, time = 0.01196\n",
      "Epoch: 0270 | train_loss = 0.02300, train_auc = 0.99080, test_loss = 0.04224, test_auc = 0.93870, time = 0.01190\n",
      "Epoch: 0280 | train_loss = 0.02297, train_auc = 0.98998, test_loss = 0.04334, test_auc = 0.91858, time = 0.01205\n",
      "Epoch: 0290 | train_loss = 0.02296, train_auc = 0.99004, test_loss = 0.04315, test_auc = 0.91117, time = 0.01214\n",
      "Epoch: 0300 | train_loss = 0.02296, train_auc = 0.99009, test_loss = 0.04340, test_auc = 0.90685, time = 0.01219\n",
      "times: 1, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15525, train_auc = 0.56168, test_loss = 0.10235, test_auc = 0.32827, time = 0.78860\n",
      "Epoch: 0010 | train_loss = 0.07838, train_auc = 0.93009, test_loss = 0.05967, test_auc = 0.90963, time = 0.01533\n",
      "Epoch: 0020 | train_loss = 0.04964, train_auc = 0.98152, test_loss = 0.05885, test_auc = 0.85037, time = 0.01324\n",
      "Epoch: 0030 | train_loss = 0.03973, train_auc = 0.98584, test_loss = 0.04023, test_auc = 0.95679, time = 0.01341\n",
      "Epoch: 0040 | train_loss = 0.03417, train_auc = 0.98759, test_loss = 0.04049, test_auc = 0.95654, time = 0.01248\n",
      "Epoch: 0050 | train_loss = 0.03290, train_auc = 0.98953, test_loss = 0.04041, test_auc = 0.94926, time = 0.01194\n",
      "Epoch: 0060 | train_loss = 0.03135, train_auc = 0.99114, test_loss = 0.04113, test_auc = 0.94901, time = 0.01202\n",
      "Epoch: 0070 | train_loss = 0.02986, train_auc = 0.99065, test_loss = 0.04228, test_auc = 0.95549, time = 0.01205\n",
      "Epoch: 0080 | train_loss = 0.02836, train_auc = 0.98966, test_loss = 0.04231, test_auc = 0.94142, time = 0.01201\n",
      "Epoch: 0090 | train_loss = 0.02821, train_auc = 0.98962, test_loss = 0.03877, test_auc = 0.95747, time = 0.01226\n",
      "Epoch: 0100 | train_loss = 0.02816, train_auc = 0.98970, test_loss = 0.03877, test_auc = 0.95870, time = 0.01291\n",
      "Epoch: 0110 | train_loss = 0.02815, train_auc = 0.98875, test_loss = 0.03801, test_auc = 0.96012, time = 0.01239\n",
      "Epoch: 0120 | train_loss = 0.02814, train_auc = 0.98879, test_loss = 0.03702, test_auc = 0.96185, time = 0.01248\n",
      "Epoch: 0130 | train_loss = 0.02813, train_auc = 0.98989, test_loss = 0.03670, test_auc = 0.96247, time = 0.01390\n",
      "Epoch: 0140 | train_loss = 0.02813, train_auc = 0.98888, test_loss = 0.03675, test_auc = 0.96228, time = 0.01254\n",
      "Epoch: 0150 | train_loss = 0.02813, train_auc = 0.98886, test_loss = 0.03683, test_auc = 0.96296, time = 0.01259\n",
      "Epoch: 0160 | train_loss = 0.02813, train_auc = 0.98890, test_loss = 0.03668, test_auc = 0.96358, time = 0.01255\n",
      "Epoch: 0170 | train_loss = 0.02813, train_auc = 0.98890, test_loss = 0.03656, test_auc = 0.96370, time = 0.01312\n",
      "Epoch: 0180 | train_loss = 0.02812, train_auc = 0.98993, test_loss = 0.03653, test_auc = 0.96364, time = 0.01260\n",
      "Epoch: 0190 | train_loss = 0.02812, train_auc = 0.98895, test_loss = 0.03649, test_auc = 0.96395, time = 0.01377\n",
      "Epoch: 0200 | train_loss = 0.02812, train_auc = 0.98894, test_loss = 0.03647, test_auc = 0.96407, time = 0.01222\n",
      "Epoch: 0210 | train_loss = 0.02812, train_auc = 0.98894, test_loss = 0.03645, test_auc = 0.96395, time = 0.01260\n",
      "Epoch: 0220 | train_loss = 0.02812, train_auc = 0.99002, test_loss = 0.03643, test_auc = 0.96395, time = 0.01252\n",
      "Epoch: 0230 | train_loss = 0.02812, train_auc = 0.98999, test_loss = 0.03641, test_auc = 0.96383, time = 0.01257\n",
      "Epoch: 0240 | train_loss = 0.02812, train_auc = 0.98996, test_loss = 0.03640, test_auc = 0.96395, time = 0.01235\n",
      "Epoch: 0250 | train_loss = 0.02812, train_auc = 0.99000, test_loss = 0.03638, test_auc = 0.96370, time = 0.01273\n",
      "Epoch: 0260 | train_loss = 0.02812, train_auc = 0.98893, test_loss = 0.03637, test_auc = 0.96377, time = 0.01245\n",
      "Epoch: 0270 | train_loss = 0.02812, train_auc = 0.99000, test_loss = 0.03636, test_auc = 0.96414, time = 0.01186\n",
      "Epoch: 0280 | train_loss = 0.02812, train_auc = 0.98899, test_loss = 0.03635, test_auc = 0.96432, time = 0.01228\n",
      "Epoch: 0290 | train_loss = 0.02812, train_auc = 0.99003, test_loss = 0.03634, test_auc = 0.96444, time = 0.01261\n",
      "Epoch: 0300 | train_loss = 0.02812, train_auc = 0.99005, test_loss = 0.03633, test_auc = 0.96451, time = 0.01231\n",
      "times: 1, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.16522, train_auc = 0.46095, test_loss = 0.10601, test_auc = 0.29074, time = 0.81135\n",
      "Epoch: 0010 | train_loss = 0.06762, train_auc = 0.98076, test_loss = 0.05266, test_auc = 0.91494, time = 0.01581\n",
      "Epoch: 0020 | train_loss = 0.05060, train_auc = 0.97900, test_loss = 0.05285, test_auc = 0.88407, time = 0.01349\n",
      "Epoch: 0030 | train_loss = 0.04154, train_auc = 0.98730, test_loss = 0.03702, test_auc = 0.96383, time = 0.01344\n",
      "Epoch: 0040 | train_loss = 0.03369, train_auc = 0.99236, test_loss = 0.03568, test_auc = 0.96698, time = 0.01228\n",
      "Epoch: 0050 | train_loss = 0.02548, train_auc = 0.99397, test_loss = 0.03371, test_auc = 0.96469, time = 0.01260\n",
      "Epoch: 0060 | train_loss = 0.02160, train_auc = 0.99453, test_loss = 0.03364, test_auc = 0.97173, time = 0.01239\n",
      "Epoch: 0070 | train_loss = 0.02107, train_auc = 0.99401, test_loss = 0.03454, test_auc = 0.96346, time = 0.01336\n",
      "Epoch: 0080 | train_loss = 0.02100, train_auc = 0.99405, test_loss = 0.03628, test_auc = 0.96309, time = 0.01346\n",
      "Epoch: 0090 | train_loss = 0.02098, train_auc = 0.99405, test_loss = 0.03643, test_auc = 0.96370, time = 0.01250\n",
      "Epoch: 0100 | train_loss = 0.02097, train_auc = 0.99408, test_loss = 0.03574, test_auc = 0.96432, time = 0.01277\n",
      "Epoch: 0110 | train_loss = 0.02097, train_auc = 0.99307, test_loss = 0.03557, test_auc = 0.96519, time = 0.01250\n",
      "Epoch: 0120 | train_loss = 0.02097, train_auc = 0.99411, test_loss = 0.03599, test_auc = 0.96407, time = 0.01271\n",
      "Epoch: 0130 | train_loss = 0.02097, train_auc = 0.99312, test_loss = 0.03603, test_auc = 0.96432, time = 0.01258\n",
      "Epoch: 0140 | train_loss = 0.02096, train_auc = 0.99311, test_loss = 0.03591, test_auc = 0.96444, time = 0.01260\n",
      "Epoch: 0150 | train_loss = 0.02096, train_auc = 0.99414, test_loss = 0.03586, test_auc = 0.96457, time = 0.01251\n",
      "Epoch: 0160 | train_loss = 0.02096, train_auc = 0.99315, test_loss = 0.03579, test_auc = 0.96469, time = 0.01222\n",
      "Epoch: 0170 | train_loss = 0.02096, train_auc = 0.99314, test_loss = 0.03571, test_auc = 0.96444, time = 0.01248\n",
      "Epoch: 0180 | train_loss = 0.02096, train_auc = 0.99319, test_loss = 0.03565, test_auc = 0.96457, time = 0.01268\n",
      "Epoch: 0190 | train_loss = 0.02096, train_auc = 0.99424, test_loss = 0.03561, test_auc = 0.96444, time = 0.01436\n",
      "Epoch: 0200 | train_loss = 0.02096, train_auc = 0.99326, test_loss = 0.03557, test_auc = 0.96457, time = 0.01269\n",
      "Epoch: 0210 | train_loss = 0.02096, train_auc = 0.99309, test_loss = 0.03555, test_auc = 0.96457, time = 0.01259\n",
      "Epoch: 0220 | train_loss = 0.02096, train_auc = 0.99323, test_loss = 0.03559, test_auc = 0.96457, time = 0.01234\n",
      "Epoch: 0230 | train_loss = 0.02096, train_auc = 0.99323, test_loss = 0.03566, test_auc = 0.96469, time = 0.01251\n",
      "Epoch: 0240 | train_loss = 0.02096, train_auc = 0.99323, test_loss = 0.03568, test_auc = 0.96494, time = 0.01253\n",
      "Epoch: 0250 | train_loss = 0.02096, train_auc = 0.99319, test_loss = 0.03566, test_auc = 0.96506, time = 0.01257\n",
      "Epoch: 0260 | train_loss = 0.02096, train_auc = 0.99331, test_loss = 0.03566, test_auc = 0.96506, time = 0.01260\n",
      "Epoch: 0270 | train_loss = 0.02096, train_auc = 0.99323, test_loss = 0.03565, test_auc = 0.96469, time = 0.01233\n",
      "Epoch: 0280 | train_loss = 0.02096, train_auc = 0.99232, test_loss = 0.03559, test_auc = 0.96531, time = 0.01263\n",
      "Epoch: 0290 | train_loss = 0.02095, train_auc = 0.99254, test_loss = 0.03555, test_auc = 0.96519, time = 0.01208\n",
      "Epoch: 0300 | train_loss = 0.02096, train_auc = 0.99341, test_loss = 0.03780, test_auc = 0.96111, time = 0.01250\n",
      "times: 1, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.18356, train_auc = 0.31819, test_loss = 0.07137, test_auc = 0.67617, time = 0.79169\n",
      "Epoch: 0010 | train_loss = 0.07533, train_auc = 0.95777, test_loss = 0.05791, test_auc = 0.87037, time = 0.01513\n",
      "Epoch: 0020 | train_loss = 0.05191, train_auc = 0.97890, test_loss = 0.04109, test_auc = 0.93852, time = 0.01411\n",
      "Epoch: 0030 | train_loss = 0.04311, train_auc = 0.98368, test_loss = 0.03919, test_auc = 0.95654, time = 0.01276\n",
      "Epoch: 0040 | train_loss = 0.03952, train_auc = 0.98586, test_loss = 0.03945, test_auc = 0.95630, time = 0.01290\n",
      "Epoch: 0050 | train_loss = 0.03566, train_auc = 0.98736, test_loss = 0.03899, test_auc = 0.96074, time = 0.01207\n",
      "Epoch: 0060 | train_loss = 0.03197, train_auc = 0.98794, test_loss = 0.04001, test_auc = 0.94840, time = 0.01256\n",
      "Epoch: 0070 | train_loss = 0.03128, train_auc = 0.98780, test_loss = 0.03971, test_auc = 0.94512, time = 0.01256\n",
      "Epoch: 0080 | train_loss = 0.03116, train_auc = 0.98792, test_loss = 0.04017, test_auc = 0.94568, time = 0.01232\n",
      "Epoch: 0090 | train_loss = 0.03112, train_auc = 0.98777, test_loss = 0.04102, test_auc = 0.94704, time = 0.01271\n",
      "Epoch: 0100 | train_loss = 0.03102, train_auc = 0.98803, test_loss = 0.04069, test_auc = 0.94914, time = 0.01261\n",
      "Epoch: 0110 | train_loss = 0.03013, train_auc = 0.98882, test_loss = 0.03949, test_auc = 0.96160, time = 0.01284\n",
      "Epoch: 0120 | train_loss = 0.02986, train_auc = 0.98741, test_loss = 0.04056, test_auc = 0.95525, time = 0.01308\n",
      "Epoch: 0130 | train_loss = 0.02969, train_auc = 0.98728, test_loss = 0.04102, test_auc = 0.95728, time = 0.01261\n",
      "Epoch: 0140 | train_loss = 0.02966, train_auc = 0.98723, test_loss = 0.04214, test_auc = 0.94815, time = 0.01252\n",
      "Epoch: 0150 | train_loss = 0.02965, train_auc = 0.98729, test_loss = 0.04212, test_auc = 0.94852, time = 0.01224\n",
      "Epoch: 0160 | train_loss = 0.02965, train_auc = 0.98726, test_loss = 0.04227, test_auc = 0.94778, time = 0.01201\n",
      "Epoch: 0170 | train_loss = 0.02964, train_auc = 0.98725, test_loss = 0.04236, test_auc = 0.94765, time = 0.01210\n",
      "Epoch: 0180 | train_loss = 0.02964, train_auc = 0.98629, test_loss = 0.04242, test_auc = 0.94778, time = 0.01217\n",
      "Epoch: 0190 | train_loss = 0.02964, train_auc = 0.98728, test_loss = 0.04247, test_auc = 0.94802, time = 0.01226\n",
      "Epoch: 0200 | train_loss = 0.02964, train_auc = 0.98628, test_loss = 0.04249, test_auc = 0.94802, time = 0.01409\n",
      "Epoch: 0210 | train_loss = 0.02964, train_auc = 0.98731, test_loss = 0.04251, test_auc = 0.94790, time = 0.01283\n",
      "Epoch: 0220 | train_loss = 0.02964, train_auc = 0.98633, test_loss = 0.04254, test_auc = 0.94802, time = 0.01259\n",
      "Epoch: 0230 | train_loss = 0.02964, train_auc = 0.98733, test_loss = 0.04257, test_auc = 0.94802, time = 0.01242\n",
      "Epoch: 0240 | train_loss = 0.02964, train_auc = 0.98629, test_loss = 0.04260, test_auc = 0.94778, time = 0.01257\n",
      "Epoch: 0250 | train_loss = 0.02964, train_auc = 0.98633, test_loss = 0.04261, test_auc = 0.94790, time = 0.01240\n",
      "Epoch: 0260 | train_loss = 0.02964, train_auc = 0.98730, test_loss = 0.04262, test_auc = 0.94778, time = 0.01238\n",
      "Epoch: 0270 | train_loss = 0.02964, train_auc = 0.98730, test_loss = 0.04263, test_auc = 0.94753, time = 0.01254\n",
      "Epoch: 0280 | train_loss = 0.02964, train_auc = 0.98634, test_loss = 0.04264, test_auc = 0.94753, time = 0.01216\n",
      "Epoch: 0290 | train_loss = 0.02964, train_auc = 0.98640, test_loss = 0.04264, test_auc = 0.94765, time = 0.01237\n",
      "Epoch: 0300 | train_loss = 0.02964, train_auc = 0.98633, test_loss = 0.04265, test_auc = 0.94753, time = 0.01303\n",
      "times: 1, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.16642, train_auc = 0.46326, test_loss = 0.07866, test_auc = 0.62636, time = 0.79282\n",
      "Epoch: 0010 | train_loss = 0.06726, train_auc = 0.96836, test_loss = 0.04963, test_auc = 0.90796, time = 0.01563\n",
      "Epoch: 0020 | train_loss = 0.05615, train_auc = 0.97516, test_loss = 0.04564, test_auc = 0.90049, time = 0.01358\n",
      "Epoch: 0030 | train_loss = 0.04591, train_auc = 0.98137, test_loss = 0.04264, test_auc = 0.93642, time = 0.01306\n",
      "Epoch: 0040 | train_loss = 0.04318, train_auc = 0.98394, test_loss = 0.04223, test_auc = 0.93469, time = 0.01286\n",
      "Epoch: 0050 | train_loss = 0.03643, train_auc = 0.98531, test_loss = 0.04335, test_auc = 0.91574, time = 0.01224\n",
      "Epoch: 0060 | train_loss = 0.03200, train_auc = 0.98853, test_loss = 0.04202, test_auc = 0.93321, time = 0.01207\n",
      "Epoch: 0070 | train_loss = 0.02869, train_auc = 0.98825, test_loss = 0.03983, test_auc = 0.92062, time = 0.01200\n",
      "Epoch: 0080 | train_loss = 0.02835, train_auc = 0.98924, test_loss = 0.04429, test_auc = 0.90784, time = 0.01254\n",
      "Epoch: 0090 | train_loss = 0.02821, train_auc = 0.98848, test_loss = 0.04408, test_auc = 0.90506, time = 0.01193\n",
      "Epoch: 0100 | train_loss = 0.02816, train_auc = 0.98944, test_loss = 0.04516, test_auc = 0.89753, time = 0.01236\n",
      "Epoch: 0110 | train_loss = 0.02814, train_auc = 0.98867, test_loss = 0.04362, test_auc = 0.91296, time = 0.01178\n",
      "Epoch: 0120 | train_loss = 0.02813, train_auc = 0.98867, test_loss = 0.04300, test_auc = 0.91790, time = 0.01213\n",
      "Epoch: 0130 | train_loss = 0.02813, train_auc = 0.98768, test_loss = 0.04296, test_auc = 0.91846, time = 0.01272\n",
      "Epoch: 0140 | train_loss = 0.02813, train_auc = 0.98762, test_loss = 0.04293, test_auc = 0.91895, time = 0.01304\n",
      "Epoch: 0150 | train_loss = 0.02812, train_auc = 0.98760, test_loss = 0.04303, test_auc = 0.91944, time = 0.01183\n",
      "Epoch: 0160 | train_loss = 0.02812, train_auc = 0.98764, test_loss = 0.04306, test_auc = 0.92179, time = 0.01211\n",
      "Epoch: 0170 | train_loss = 0.02812, train_auc = 0.98766, test_loss = 0.04305, test_auc = 0.92241, time = 0.01211\n",
      "Epoch: 0180 | train_loss = 0.02812, train_auc = 0.98769, test_loss = 0.04306, test_auc = 0.92290, time = 0.01280\n",
      "Epoch: 0190 | train_loss = 0.02812, train_auc = 0.98768, test_loss = 0.04306, test_auc = 0.92062, time = 0.01196\n",
      "Epoch: 0200 | train_loss = 0.02812, train_auc = 0.98769, test_loss = 0.04306, test_auc = 0.92506, time = 0.01192\n",
      "Epoch: 0210 | train_loss = 0.02812, train_auc = 0.98772, test_loss = 0.04306, test_auc = 0.92222, time = 0.01190\n",
      "Epoch: 0220 | train_loss = 0.02812, train_auc = 0.98767, test_loss = 0.04306, test_auc = 0.92648, time = 0.01226\n",
      "Epoch: 0230 | train_loss = 0.02812, train_auc = 0.98769, test_loss = 0.04307, test_auc = 0.92358, time = 0.01229\n",
      "Epoch: 0240 | train_loss = 0.02812, train_auc = 0.98767, test_loss = 0.04307, test_auc = 0.92340, time = 0.01287\n",
      "Epoch: 0250 | train_loss = 0.02812, train_auc = 0.98769, test_loss = 0.04307, test_auc = 0.92747, time = 0.01258\n",
      "Epoch: 0260 | train_loss = 0.02812, train_auc = 0.98770, test_loss = 0.04308, test_auc = 0.92451, time = 0.01247\n",
      "Epoch: 0270 | train_loss = 0.02812, train_auc = 0.98768, test_loss = 0.04308, test_auc = 0.92500, time = 0.01244\n",
      "Epoch: 0280 | train_loss = 0.02812, train_auc = 0.98772, test_loss = 0.04308, test_auc = 0.92519, time = 0.01207\n",
      "Epoch: 0290 | train_loss = 0.02812, train_auc = 0.98773, test_loss = 0.04309, test_auc = 0.92580, time = 0.01195\n",
      "Epoch: 0300 | train_loss = 0.02812, train_auc = 0.98774, test_loss = 0.04309, test_auc = 0.92580, time = 0.01292\n",
      "times: 1, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15663, train_auc = 0.53721, test_loss = 0.08486, test_auc = 0.54500, time = 0.95336\n",
      "Epoch: 0010 | train_loss = 0.06524, train_auc = 0.97495, test_loss = 0.05428, test_auc = 0.92722, time = 0.01550\n",
      "Epoch: 0020 | train_loss = 0.04646, train_auc = 0.98448, test_loss = 0.03779, test_auc = 0.95593, time = 0.01471\n",
      "Epoch: 0030 | train_loss = 0.03525, train_auc = 0.98972, test_loss = 0.03662, test_auc = 0.95432, time = 0.01362\n",
      "Epoch: 0040 | train_loss = 0.02921, train_auc = 0.99064, test_loss = 0.03638, test_auc = 0.95772, time = 0.01309\n",
      "Epoch: 0050 | train_loss = 0.02708, train_auc = 0.98850, test_loss = 0.03840, test_auc = 0.94636, time = 0.01411\n",
      "Epoch: 0060 | train_loss = 0.02666, train_auc = 0.98904, test_loss = 0.03545, test_auc = 0.94747, time = 0.01292\n",
      "Epoch: 0070 | train_loss = 0.02515, train_auc = 0.98766, test_loss = 0.03740, test_auc = 0.94957, time = 0.01357\n",
      "Epoch: 0080 | train_loss = 0.02487, train_auc = 0.98967, test_loss = 0.04013, test_auc = 0.93938, time = 0.01288\n",
      "Epoch: 0090 | train_loss = 0.02483, train_auc = 0.98997, test_loss = 0.03699, test_auc = 0.94580, time = 0.01277\n",
      "Epoch: 0100 | train_loss = 0.02482, train_auc = 0.98984, test_loss = 0.03580, test_auc = 0.95086, time = 0.01295\n",
      "Epoch: 0110 | train_loss = 0.02481, train_auc = 0.98970, test_loss = 0.03582, test_auc = 0.95123, time = 0.01298\n",
      "Epoch: 0120 | train_loss = 0.02481, train_auc = 0.98976, test_loss = 0.03625, test_auc = 0.95191, time = 0.01250\n",
      "Epoch: 0130 | train_loss = 0.02480, train_auc = 0.98980, test_loss = 0.03652, test_auc = 0.95185, time = 0.01250\n",
      "Epoch: 0140 | train_loss = 0.02480, train_auc = 0.98984, test_loss = 0.03642, test_auc = 0.95241, time = 0.01237\n",
      "Epoch: 0150 | train_loss = 0.02480, train_auc = 0.98975, test_loss = 0.03652, test_auc = 0.95247, time = 0.01268\n",
      "Epoch: 0160 | train_loss = 0.02480, train_auc = 0.98979, test_loss = 0.03660, test_auc = 0.95284, time = 0.01253\n",
      "Epoch: 0170 | train_loss = 0.02480, train_auc = 0.98981, test_loss = 0.03670, test_auc = 0.95358, time = 0.01254\n",
      "Epoch: 0180 | train_loss = 0.02480, train_auc = 0.98977, test_loss = 0.03679, test_auc = 0.95364, time = 0.01230\n",
      "Epoch: 0190 | train_loss = 0.02480, train_auc = 0.98983, test_loss = 0.03687, test_auc = 0.95377, time = 0.01312\n",
      "Epoch: 0200 | train_loss = 0.02480, train_auc = 0.98979, test_loss = 0.03695, test_auc = 0.95383, time = 0.01397\n",
      "Epoch: 0210 | train_loss = 0.02480, train_auc = 0.98982, test_loss = 0.03705, test_auc = 0.95401, time = 0.01333\n",
      "Epoch: 0220 | train_loss = 0.02480, train_auc = 0.98983, test_loss = 0.03714, test_auc = 0.95420, time = 0.01316\n",
      "Epoch: 0230 | train_loss = 0.02480, train_auc = 0.98981, test_loss = 0.03723, test_auc = 0.95420, time = 0.01269\n",
      "Epoch: 0240 | train_loss = 0.02480, train_auc = 0.98988, test_loss = 0.03732, test_auc = 0.95500, time = 0.01241\n",
      "Epoch: 0250 | train_loss = 0.02480, train_auc = 0.98987, test_loss = 0.03741, test_auc = 0.95549, time = 0.01229\n",
      "Epoch: 0260 | train_loss = 0.02480, train_auc = 0.98985, test_loss = 0.03750, test_auc = 0.95543, time = 0.01305\n",
      "Epoch: 0270 | train_loss = 0.02480, train_auc = 0.98986, test_loss = 0.03758, test_auc = 0.95605, time = 0.01285\n",
      "Epoch: 0280 | train_loss = 0.02480, train_auc = 0.98976, test_loss = 0.03765, test_auc = 0.95580, time = 0.01255\n",
      "Epoch: 0290 | train_loss = 0.02480, train_auc = 0.98988, test_loss = 0.03770, test_auc = 0.95568, time = 0.01276\n",
      "Epoch: 0300 | train_loss = 0.02480, train_auc = 0.98973, test_loss = 0.03775, test_auc = 0.95605, time = 0.01246\n",
      "times: 2, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.17738, train_auc = 0.44282, test_loss = 0.08568, test_auc = 0.50222, time = 0.78074\n",
      "Epoch: 0010 | train_loss = 0.06636, train_auc = 0.98239, test_loss = 0.04935, test_auc = 0.90926, time = 0.01503\n",
      "Epoch: 0020 | train_loss = 0.04575, train_auc = 0.99103, test_loss = 0.04396, test_auc = 0.93963, time = 0.01517\n",
      "Epoch: 0030 | train_loss = 0.03682, train_auc = 0.99255, test_loss = 0.04056, test_auc = 0.95407, time = 0.01535\n",
      "Epoch: 0040 | train_loss = 0.02667, train_auc = 0.99524, test_loss = 0.04138, test_auc = 0.94667, time = 0.01385\n",
      "Epoch: 0050 | train_loss = 0.02414, train_auc = 0.99502, test_loss = 0.04369, test_auc = 0.93765, time = 0.01293\n",
      "Epoch: 0060 | train_loss = 0.02318, train_auc = 0.99566, test_loss = 0.03941, test_auc = 0.95235, time = 0.01378\n",
      "Epoch: 0070 | train_loss = 0.01730, train_auc = 0.99751, test_loss = 0.03861, test_auc = 0.94975, time = 0.01232\n",
      "Epoch: 0080 | train_loss = 0.01398, train_auc = 0.99750, test_loss = 0.04088, test_auc = 0.93704, time = 0.01275\n",
      "Epoch: 0090 | train_loss = 0.01338, train_auc = 0.99642, test_loss = 0.04018, test_auc = 0.95136, time = 0.01247\n",
      "Epoch: 0100 | train_loss = 0.01330, train_auc = 0.99743, test_loss = 0.03809, test_auc = 0.95840, time = 0.01344\n",
      "Epoch: 0110 | train_loss = 0.01328, train_auc = 0.99647, test_loss = 0.03936, test_auc = 0.95364, time = 0.01251\n",
      "Epoch: 0120 | train_loss = 0.01327, train_auc = 0.99650, test_loss = 0.04023, test_auc = 0.94488, time = 0.01230\n",
      "Epoch: 0130 | train_loss = 0.01326, train_auc = 0.99757, test_loss = 0.04036, test_auc = 0.94315, time = 0.01273\n",
      "Epoch: 0140 | train_loss = 0.01326, train_auc = 0.99754, test_loss = 0.04039, test_auc = 0.94222, time = 0.01241\n",
      "Epoch: 0150 | train_loss = 0.01326, train_auc = 0.99652, test_loss = 0.04039, test_auc = 0.94272, time = 0.01248\n",
      "Epoch: 0160 | train_loss = 0.01326, train_auc = 0.99760, test_loss = 0.04043, test_auc = 0.94290, time = 0.01248\n",
      "Epoch: 0170 | train_loss = 0.01326, train_auc = 0.99652, test_loss = 0.04046, test_auc = 0.94296, time = 0.01237\n",
      "Epoch: 0180 | train_loss = 0.01326, train_auc = 0.99758, test_loss = 0.04049, test_auc = 0.94290, time = 0.01246\n",
      "Epoch: 0190 | train_loss = 0.01326, train_auc = 0.99760, test_loss = 0.04053, test_auc = 0.94278, time = 0.01248\n",
      "Epoch: 0200 | train_loss = 0.01326, train_auc = 0.99651, test_loss = 0.04057, test_auc = 0.94290, time = 0.01256\n",
      "Epoch: 0210 | train_loss = 0.01326, train_auc = 0.99652, test_loss = 0.04061, test_auc = 0.94315, time = 0.01256\n",
      "Epoch: 0220 | train_loss = 0.01326, train_auc = 0.99650, test_loss = 0.04064, test_auc = 0.94333, time = 0.01266\n",
      "Epoch: 0230 | train_loss = 0.01326, train_auc = 0.99651, test_loss = 0.04067, test_auc = 0.94327, time = 0.01301\n",
      "Epoch: 0240 | train_loss = 0.01326, train_auc = 0.99759, test_loss = 0.04070, test_auc = 0.94327, time = 0.01264\n",
      "Epoch: 0250 | train_loss = 0.01326, train_auc = 0.99652, test_loss = 0.04072, test_auc = 0.94333, time = 0.01265\n",
      "Epoch: 0260 | train_loss = 0.01326, train_auc = 0.99652, test_loss = 0.04075, test_auc = 0.94321, time = 0.01334\n",
      "Epoch: 0270 | train_loss = 0.01326, train_auc = 0.99653, test_loss = 0.04077, test_auc = 0.94315, time = 0.01313\n",
      "Epoch: 0280 | train_loss = 0.01326, train_auc = 0.99652, test_loss = 0.04079, test_auc = 0.94333, time = 0.01251\n",
      "Epoch: 0290 | train_loss = 0.01326, train_auc = 0.99653, test_loss = 0.04081, test_auc = 0.94309, time = 0.01251\n",
      "Epoch: 0300 | train_loss = 0.01326, train_auc = 0.99653, test_loss = 0.04083, test_auc = 0.94333, time = 0.01377\n",
      "times: 2, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14981, train_auc = 0.62073, test_loss = 0.10856, test_auc = 0.23840, time = 0.78107\n",
      "Epoch: 0010 | train_loss = 0.05743, train_auc = 0.97327, test_loss = 0.06496, test_auc = 0.89235, time = 0.01565\n",
      "Epoch: 0020 | train_loss = 0.03200, train_auc = 0.99725, test_loss = 0.04369, test_auc = 0.94352, time = 0.01417\n",
      "Epoch: 0030 | train_loss = 0.01886, train_auc = 0.99646, test_loss = 0.05382, test_auc = 0.90383, time = 0.01434\n",
      "Epoch: 0040 | train_loss = 0.01813, train_auc = 0.99676, test_loss = 0.04531, test_auc = 0.92259, time = 0.01316\n",
      "Epoch: 0050 | train_loss = 0.01658, train_auc = 0.99674, test_loss = 0.04072, test_auc = 0.95395, time = 0.01275\n",
      "Epoch: 0060 | train_loss = 0.01636, train_auc = 0.99584, test_loss = 0.03946, test_auc = 0.95519, time = 0.01272\n",
      "Epoch: 0070 | train_loss = 0.01629, train_auc = 0.99585, test_loss = 0.03957, test_auc = 0.95111, time = 0.01439\n",
      "Epoch: 0080 | train_loss = 0.01627, train_auc = 0.99593, test_loss = 0.03860, test_auc = 0.95420, time = 0.01228\n",
      "Epoch: 0090 | train_loss = 0.01626, train_auc = 0.99596, test_loss = 0.03806, test_auc = 0.95654, time = 0.01242\n",
      "Epoch: 0100 | train_loss = 0.01626, train_auc = 0.99594, test_loss = 0.03827, test_auc = 0.95617, time = 0.01271\n",
      "Epoch: 0110 | train_loss = 0.01625, train_auc = 0.99595, test_loss = 0.03838, test_auc = 0.95556, time = 0.01271\n",
      "Epoch: 0120 | train_loss = 0.01625, train_auc = 0.99596, test_loss = 0.03867, test_auc = 0.95481, time = 0.01284\n",
      "Epoch: 0130 | train_loss = 0.01625, train_auc = 0.99596, test_loss = 0.03884, test_auc = 0.95407, time = 0.01403\n",
      "Epoch: 0140 | train_loss = 0.01625, train_auc = 0.99596, test_loss = 0.03886, test_auc = 0.95383, time = 0.01279\n",
      "Epoch: 0150 | train_loss = 0.01624, train_auc = 0.99596, test_loss = 0.03866, test_auc = 0.95395, time = 0.01258\n",
      "Epoch: 0160 | train_loss = 0.01624, train_auc = 0.99596, test_loss = 0.03857, test_auc = 0.95432, time = 0.01256\n",
      "Epoch: 0170 | train_loss = 0.01624, train_auc = 0.99598, test_loss = 0.03857, test_auc = 0.95432, time = 0.01284\n",
      "Epoch: 0180 | train_loss = 0.01624, train_auc = 0.99598, test_loss = 0.03855, test_auc = 0.95444, time = 0.01277\n",
      "Epoch: 0190 | train_loss = 0.01624, train_auc = 0.99598, test_loss = 0.03853, test_auc = 0.95457, time = 0.01262\n",
      "Epoch: 0200 | train_loss = 0.01624, train_auc = 0.99597, test_loss = 0.03855, test_auc = 0.95444, time = 0.01218\n",
      "Epoch: 0210 | train_loss = 0.01624, train_auc = 0.99597, test_loss = 0.03860, test_auc = 0.95457, time = 0.01251\n",
      "Epoch: 0220 | train_loss = 0.01624, train_auc = 0.99597, test_loss = 0.03865, test_auc = 0.95457, time = 0.01273\n",
      "Epoch: 0230 | train_loss = 0.01624, train_auc = 0.99597, test_loss = 0.03870, test_auc = 0.95444, time = 0.01221\n",
      "Epoch: 0240 | train_loss = 0.01624, train_auc = 0.99597, test_loss = 0.03873, test_auc = 0.95444, time = 0.01244\n",
      "Epoch: 0250 | train_loss = 0.01624, train_auc = 0.99597, test_loss = 0.03876, test_auc = 0.95426, time = 0.01305\n",
      "Epoch: 0260 | train_loss = 0.01624, train_auc = 0.99600, test_loss = 0.03878, test_auc = 0.95395, time = 0.01303\n",
      "Epoch: 0270 | train_loss = 0.01624, train_auc = 0.99599, test_loss = 0.03881, test_auc = 0.95395, time = 0.01271\n",
      "Epoch: 0280 | train_loss = 0.01624, train_auc = 0.99598, test_loss = 0.03883, test_auc = 0.95383, time = 0.01266\n",
      "Epoch: 0290 | train_loss = 0.01624, train_auc = 0.99599, test_loss = 0.03885, test_auc = 0.95395, time = 0.01454\n",
      "Epoch: 0300 | train_loss = 0.01624, train_auc = 0.99598, test_loss = 0.03887, test_auc = 0.95395, time = 0.01369\n",
      "times: 2, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.17573, train_auc = 0.38853, test_loss = 0.08890, test_auc = 0.50556, time = 0.78589\n",
      "Epoch: 0010 | train_loss = 0.07730, train_auc = 0.94772, test_loss = 0.05250, test_auc = 0.92827, time = 0.01532\n",
      "Epoch: 0020 | train_loss = 0.04688, train_auc = 0.98836, test_loss = 0.03839, test_auc = 0.96593, time = 0.01415\n",
      "Epoch: 0030 | train_loss = 0.03181, train_auc = 0.99446, test_loss = 0.03398, test_auc = 0.97926, time = 0.01347\n",
      "Epoch: 0040 | train_loss = 0.02373, train_auc = 0.99495, test_loss = 0.05351, test_auc = 0.94321, time = 0.01392\n",
      "Epoch: 0050 | train_loss = 0.02019, train_auc = 0.99316, test_loss = 0.05147, test_auc = 0.94543, time = 0.01285\n",
      "Epoch: 0060 | train_loss = 0.01915, train_auc = 0.99310, test_loss = 0.02963, test_auc = 0.96796, time = 0.01264\n",
      "Epoch: 0070 | train_loss = 0.01886, train_auc = 0.99274, test_loss = 0.02940, test_auc = 0.96235, time = 0.01269\n",
      "Epoch: 0080 | train_loss = 0.01880, train_auc = 0.99253, test_loss = 0.03083, test_auc = 0.96235, time = 0.01317\n",
      "Epoch: 0090 | train_loss = 0.01878, train_auc = 0.99313, test_loss = 0.03217, test_auc = 0.96358, time = 0.01250\n",
      "Epoch: 0100 | train_loss = 0.01877, train_auc = 0.99325, test_loss = 0.03276, test_auc = 0.96235, time = 0.01290\n",
      "Epoch: 0110 | train_loss = 0.01877, train_auc = 0.99317, test_loss = 0.03310, test_auc = 0.96111, time = 0.01287\n",
      "Epoch: 0120 | train_loss = 0.01876, train_auc = 0.99322, test_loss = 0.03330, test_auc = 0.96080, time = 0.01227\n",
      "Epoch: 0130 | train_loss = 0.01876, train_auc = 0.99244, test_loss = 0.03345, test_auc = 0.96074, time = 0.01236\n",
      "Epoch: 0140 | train_loss = 0.01876, train_auc = 0.99340, test_loss = 0.03347, test_auc = 0.96074, time = 0.01235\n",
      "Epoch: 0150 | train_loss = 0.01876, train_auc = 0.99336, test_loss = 0.03345, test_auc = 0.96086, time = 0.01241\n",
      "Epoch: 0160 | train_loss = 0.01876, train_auc = 0.99244, test_loss = 0.03342, test_auc = 0.96074, time = 0.01224\n",
      "Epoch: 0170 | train_loss = 0.01876, train_auc = 0.99338, test_loss = 0.03339, test_auc = 0.96093, time = 0.01243\n",
      "Epoch: 0180 | train_loss = 0.01875, train_auc = 0.99248, test_loss = 0.03338, test_auc = 0.96086, time = 0.01232\n",
      "Epoch: 0190 | train_loss = 0.01875, train_auc = 0.99341, test_loss = 0.03337, test_auc = 0.96099, time = 0.01256\n",
      "Epoch: 0200 | train_loss = 0.01875, train_auc = 0.99253, test_loss = 0.03336, test_auc = 0.96093, time = 0.01306\n",
      "Epoch: 0210 | train_loss = 0.01875, train_auc = 0.99253, test_loss = 0.03335, test_auc = 0.96056, time = 0.01296\n",
      "Epoch: 0220 | train_loss = 0.01875, train_auc = 0.99256, test_loss = 0.03334, test_auc = 0.96043, time = 0.01234\n",
      "Epoch: 0230 | train_loss = 0.01875, train_auc = 0.99256, test_loss = 0.03332, test_auc = 0.96037, time = 0.01261\n",
      "Epoch: 0240 | train_loss = 0.01875, train_auc = 0.99252, test_loss = 0.03331, test_auc = 0.96043, time = 0.01249\n",
      "Epoch: 0250 | train_loss = 0.01875, train_auc = 0.99253, test_loss = 0.03330, test_auc = 0.96025, time = 0.01221\n",
      "Epoch: 0260 | train_loss = 0.01875, train_auc = 0.99255, test_loss = 0.03329, test_auc = 0.96006, time = 0.01337\n",
      "Epoch: 0270 | train_loss = 0.01875, train_auc = 0.99255, test_loss = 0.03328, test_auc = 0.96006, time = 0.01255\n",
      "Epoch: 0280 | train_loss = 0.01875, train_auc = 0.99256, test_loss = 0.03328, test_auc = 0.95994, time = 0.01262\n",
      "Epoch: 0290 | train_loss = 0.01875, train_auc = 0.99258, test_loss = 0.03327, test_auc = 0.95963, time = 0.01245\n",
      "Epoch: 0300 | train_loss = 0.01875, train_auc = 0.99258, test_loss = 0.03326, test_auc = 0.95951, time = 0.01269\n",
      "times: 2, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.16968, train_auc = 0.37563, test_loss = 0.08115, test_auc = 0.56562, time = 0.77186\n",
      "Epoch: 0010 | train_loss = 0.06159, train_auc = 0.98718, test_loss = 0.03631, test_auc = 0.95210, time = 0.01506\n",
      "Epoch: 0020 | train_loss = 0.04021, train_auc = 0.99549, test_loss = 0.03519, test_auc = 0.97160, time = 0.01310\n",
      "Epoch: 0030 | train_loss = 0.02486, train_auc = 0.99894, test_loss = 0.03490, test_auc = 0.95358, time = 0.01353\n",
      "Epoch: 0040 | train_loss = 0.01183, train_auc = 0.99921, test_loss = 0.03222, test_auc = 0.97062, time = 0.01294\n",
      "Epoch: 0050 | train_loss = 0.00973, train_auc = 0.99912, test_loss = 0.03784, test_auc = 0.95543, time = 0.01219\n",
      "Epoch: 0060 | train_loss = 0.01011, train_auc = 0.99851, test_loss = 0.03736, test_auc = 0.96191, time = 0.01281\n",
      "Epoch: 0070 | train_loss = 0.00966, train_auc = 0.99875, test_loss = 0.03578, test_auc = 0.96914, time = 0.01270\n",
      "Epoch: 0080 | train_loss = 0.00949, train_auc = 0.99852, test_loss = 0.03712, test_auc = 0.96333, time = 0.01314\n",
      "Epoch: 0090 | train_loss = 0.00941, train_auc = 0.99855, test_loss = 0.03634, test_auc = 0.96506, time = 0.01311\n",
      "Epoch: 0100 | train_loss = 0.00940, train_auc = 0.99848, test_loss = 0.03610, test_auc = 0.96444, time = 0.01231\n",
      "Epoch: 0110 | train_loss = 0.00939, train_auc = 0.99850, test_loss = 0.03627, test_auc = 0.96506, time = 0.01260\n",
      "Epoch: 0120 | train_loss = 0.00939, train_auc = 0.99856, test_loss = 0.03620, test_auc = 0.96420, time = 0.01280\n",
      "Epoch: 0130 | train_loss = 0.00938, train_auc = 0.99851, test_loss = 0.03613, test_auc = 0.96321, time = 0.01331\n",
      "Epoch: 0140 | train_loss = 0.00938, train_auc = 0.99851, test_loss = 0.03609, test_auc = 0.96321, time = 0.01243\n",
      "Epoch: 0150 | train_loss = 0.00938, train_auc = 0.99852, test_loss = 0.03608, test_auc = 0.96333, time = 0.01325\n",
      "Epoch: 0160 | train_loss = 0.00938, train_auc = 0.99860, test_loss = 0.03609, test_auc = 0.96383, time = 0.01280\n",
      "Epoch: 0170 | train_loss = 0.00938, train_auc = 0.99855, test_loss = 0.03609, test_auc = 0.96420, time = 0.01246\n",
      "Epoch: 0180 | train_loss = 0.00938, train_auc = 0.99863, test_loss = 0.03611, test_auc = 0.96444, time = 0.01237\n",
      "Epoch: 0190 | train_loss = 0.00938, train_auc = 0.99789, test_loss = 0.03614, test_auc = 0.96444, time = 0.01248\n",
      "Epoch: 0200 | train_loss = 0.00938, train_auc = 0.99789, test_loss = 0.03617, test_auc = 0.96457, time = 0.01271\n",
      "Epoch: 0210 | train_loss = 0.00938, train_auc = 0.99865, test_loss = 0.03620, test_auc = 0.96469, time = 0.01246\n",
      "Epoch: 0220 | train_loss = 0.00938, train_auc = 0.99791, test_loss = 0.03624, test_auc = 0.96444, time = 0.01274\n",
      "Epoch: 0230 | train_loss = 0.00938, train_auc = 0.99866, test_loss = 0.03627, test_auc = 0.96457, time = 0.01236\n",
      "Epoch: 0240 | train_loss = 0.00938, train_auc = 0.99791, test_loss = 0.03630, test_auc = 0.96444, time = 0.01331\n",
      "Epoch: 0250 | train_loss = 0.00938, train_auc = 0.99871, test_loss = 0.03633, test_auc = 0.96420, time = 0.01221\n",
      "Epoch: 0260 | train_loss = 0.00938, train_auc = 0.99870, test_loss = 0.03636, test_auc = 0.96432, time = 0.01328\n",
      "Epoch: 0270 | train_loss = 0.00938, train_auc = 0.99875, test_loss = 0.03639, test_auc = 0.96457, time = 0.01235\n",
      "Epoch: 0280 | train_loss = 0.00938, train_auc = 0.99792, test_loss = 0.03642, test_auc = 0.96469, time = 0.01300\n",
      "Epoch: 0290 | train_loss = 0.00938, train_auc = 0.99876, test_loss = 0.03645, test_auc = 0.96481, time = 0.01244\n",
      "Epoch: 0300 | train_loss = 0.00938, train_auc = 0.99793, test_loss = 0.03648, test_auc = 0.96469, time = 0.01242\n",
      "times: 2, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.16868, train_auc = 0.42735, test_loss = 0.09466, test_auc = 0.44914, time = 0.77992\n",
      "Epoch: 0010 | train_loss = 0.06412, train_auc = 0.98160, test_loss = 0.07289, test_auc = 0.83630, time = 0.01552\n",
      "Epoch: 0020 | train_loss = 0.04273, train_auc = 0.99368, test_loss = 0.03813, test_auc = 0.95000, time = 0.01404\n",
      "Epoch: 0030 | train_loss = 0.02939, train_auc = 0.99620, test_loss = 0.03826, test_auc = 0.94691, time = 0.01538\n",
      "Epoch: 0040 | train_loss = 0.02076, train_auc = 0.99545, test_loss = 0.04161, test_auc = 0.94821, time = 0.01299\n",
      "Epoch: 0050 | train_loss = 0.01907, train_auc = 0.99556, test_loss = 0.04090, test_auc = 0.94265, time = 0.01297\n",
      "Epoch: 0060 | train_loss = 0.01887, train_auc = 0.99485, test_loss = 0.03809, test_auc = 0.94870, time = 0.01558\n",
      "Epoch: 0070 | train_loss = 0.01879, train_auc = 0.99511, test_loss = 0.03800, test_auc = 0.93420, time = 0.01351\n",
      "Epoch: 0080 | train_loss = 0.01674, train_auc = 0.99526, test_loss = 0.04092, test_auc = 0.94012, time = 0.01318\n",
      "Epoch: 0090 | train_loss = 0.01642, train_auc = 0.99650, test_loss = 0.03951, test_auc = 0.96667, time = 0.01317\n",
      "Epoch: 0100 | train_loss = 0.01633, train_auc = 0.99551, test_loss = 0.03804, test_auc = 0.96710, time = 0.01280\n",
      "Epoch: 0110 | train_loss = 0.01627, train_auc = 0.99552, test_loss = 0.03791, test_auc = 0.95827, time = 0.01332\n",
      "Epoch: 0120 | train_loss = 0.01626, train_auc = 0.99555, test_loss = 0.03766, test_auc = 0.95136, time = 0.01273\n",
      "Epoch: 0130 | train_loss = 0.01625, train_auc = 0.99562, test_loss = 0.03806, test_auc = 0.94852, time = 0.01248\n",
      "Epoch: 0140 | train_loss = 0.01625, train_auc = 0.99563, test_loss = 0.03776, test_auc = 0.95136, time = 0.01256\n",
      "Epoch: 0150 | train_loss = 0.01625, train_auc = 0.99564, test_loss = 0.03757, test_auc = 0.95191, time = 0.01292\n",
      "Epoch: 0160 | train_loss = 0.01625, train_auc = 0.99461, test_loss = 0.03749, test_auc = 0.95216, time = 0.01249\n",
      "Epoch: 0170 | train_loss = 0.01624, train_auc = 0.99463, test_loss = 0.03743, test_auc = 0.95272, time = 0.01270\n",
      "Epoch: 0180 | train_loss = 0.01624, train_auc = 0.99462, test_loss = 0.03736, test_auc = 0.95086, time = 0.01271\n",
      "Epoch: 0190 | train_loss = 0.01624, train_auc = 0.99463, test_loss = 0.03728, test_auc = 0.95364, time = 0.01308\n",
      "Epoch: 0200 | train_loss = 0.01624, train_auc = 0.99566, test_loss = 0.03722, test_auc = 0.95407, time = 0.01258\n",
      "Epoch: 0210 | train_loss = 0.01624, train_auc = 0.99463, test_loss = 0.03718, test_auc = 0.95148, time = 0.01246\n",
      "Epoch: 0220 | train_loss = 0.01624, train_auc = 0.99462, test_loss = 0.03714, test_auc = 0.95179, time = 0.01256\n",
      "Epoch: 0230 | train_loss = 0.01624, train_auc = 0.99464, test_loss = 0.03710, test_auc = 0.95235, time = 0.01248\n",
      "Epoch: 0240 | train_loss = 0.01624, train_auc = 0.99466, test_loss = 0.03707, test_auc = 0.95481, time = 0.01279\n",
      "Epoch: 0250 | train_loss = 0.01624, train_auc = 0.99565, test_loss = 0.03704, test_auc = 0.95340, time = 0.01262\n",
      "Epoch: 0260 | train_loss = 0.01624, train_auc = 0.99465, test_loss = 0.03701, test_auc = 0.95327, time = 0.01242\n",
      "Epoch: 0270 | train_loss = 0.01624, train_auc = 0.99464, test_loss = 0.03698, test_auc = 0.95377, time = 0.01276\n",
      "Epoch: 0280 | train_loss = 0.01624, train_auc = 0.99464, test_loss = 0.03696, test_auc = 0.95562, time = 0.01297\n",
      "Epoch: 0290 | train_loss = 0.01624, train_auc = 0.99465, test_loss = 0.03693, test_auc = 0.95358, time = 0.01237\n",
      "Epoch: 0300 | train_loss = 0.01624, train_auc = 0.99469, test_loss = 0.03691, test_auc = 0.95333, time = 0.01223\n",
      "times: 3, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.16071, train_auc = 0.41349, test_loss = 0.09324, test_auc = 0.42840, time = 0.77375\n",
      "Epoch: 0010 | train_loss = 0.06668, train_auc = 0.96976, test_loss = 0.04289, test_auc = 0.92074, time = 0.01526\n",
      "Epoch: 0020 | train_loss = 0.04572, train_auc = 0.98491, test_loss = 0.05476, test_auc = 0.88556, time = 0.01395\n",
      "Epoch: 0030 | train_loss = 0.03471, train_auc = 0.98507, test_loss = 0.03900, test_auc = 0.94747, time = 0.01303\n",
      "Epoch: 0040 | train_loss = 0.02872, train_auc = 0.98992, test_loss = 0.04940, test_auc = 0.92296, time = 0.01366\n",
      "Epoch: 0050 | train_loss = 0.02459, train_auc = 0.99515, test_loss = 0.05834, test_auc = 0.89006, time = 0.01280\n",
      "Epoch: 0060 | train_loss = 0.02050, train_auc = 0.99535, test_loss = 0.04589, test_auc = 0.92543, time = 0.01315\n",
      "Epoch: 0070 | train_loss = 0.01932, train_auc = 0.99600, test_loss = 0.05960, test_auc = 0.85074, time = 0.01364\n",
      "Epoch: 0080 | train_loss = 0.01583, train_auc = 0.99748, test_loss = 0.06054, test_auc = 0.86636, time = 0.01327\n",
      "Epoch: 0090 | train_loss = 0.01358, train_auc = 0.99738, test_loss = 0.03988, test_auc = 0.94852, time = 0.01271\n",
      "Epoch: 0100 | train_loss = 0.01335, train_auc = 0.99753, test_loss = 0.04095, test_auc = 0.94796, time = 0.01274\n",
      "Epoch: 0110 | train_loss = 0.01329, train_auc = 0.99763, test_loss = 0.04049, test_auc = 0.94568, time = 0.01235\n",
      "Epoch: 0120 | train_loss = 0.01328, train_auc = 0.99770, test_loss = 0.04018, test_auc = 0.93395, time = 0.01283\n",
      "Epoch: 0130 | train_loss = 0.01327, train_auc = 0.99775, test_loss = 0.04033, test_auc = 0.93198, time = 0.01299\n",
      "Epoch: 0140 | train_loss = 0.01327, train_auc = 0.99784, test_loss = 0.03976, test_auc = 0.93333, time = 0.01199\n",
      "Epoch: 0150 | train_loss = 0.01321, train_auc = 0.99808, test_loss = 0.04227, test_auc = 0.92963, time = 0.01225\n",
      "Epoch: 0160 | train_loss = 0.01046, train_auc = 0.99818, test_loss = 0.04179, test_auc = 0.94204, time = 0.01458\n",
      "Epoch: 0170 | train_loss = 0.01017, train_auc = 0.99808, test_loss = 0.05400, test_auc = 0.91333, time = 0.01305\n",
      "Epoch: 0180 | train_loss = 0.00954, train_auc = 0.99804, test_loss = 0.06104, test_auc = 0.72790, time = 0.01538\n",
      "Epoch: 0190 | train_loss = 0.00942, train_auc = 0.99800, test_loss = 0.06019, test_auc = 0.71210, time = 0.01319\n",
      "Epoch: 0200 | train_loss = 0.00939, train_auc = 0.99804, test_loss = 0.06070, test_auc = 0.71006, time = 0.01282\n",
      "Epoch: 0210 | train_loss = 0.00938, train_auc = 0.99804, test_loss = 0.06127, test_auc = 0.71191, time = 0.01270\n",
      "Epoch: 0220 | train_loss = 0.00938, train_auc = 0.99807, test_loss = 0.06150, test_auc = 0.71630, time = 0.01253\n",
      "Epoch: 0230 | train_loss = 0.00938, train_auc = 0.99808, test_loss = 0.06162, test_auc = 0.72037, time = 0.01280\n",
      "Epoch: 0240 | train_loss = 0.00938, train_auc = 0.99807, test_loss = 0.06171, test_auc = 0.72191, time = 0.01272\n",
      "Epoch: 0250 | train_loss = 0.00938, train_auc = 0.99807, test_loss = 0.06177, test_auc = 0.72414, time = 0.01284\n",
      "Epoch: 0260 | train_loss = 0.00938, train_auc = 0.99809, test_loss = 0.06180, test_auc = 0.72525, time = 0.01267\n",
      "Epoch: 0270 | train_loss = 0.00938, train_auc = 0.99809, test_loss = 0.06182, test_auc = 0.72759, time = 0.01313\n",
      "Epoch: 0280 | train_loss = 0.00938, train_auc = 0.99810, test_loss = 0.06184, test_auc = 0.72889, time = 0.01281\n",
      "Epoch: 0290 | train_loss = 0.00937, train_auc = 0.99810, test_loss = 0.06185, test_auc = 0.72994, time = 0.01236\n",
      "Epoch: 0300 | train_loss = 0.00937, train_auc = 0.99811, test_loss = 0.06186, test_auc = 0.73123, time = 0.01235\n",
      "times: 3, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.18147, train_auc = 0.33811, test_loss = 0.06950, test_auc = 0.69512, time = 0.79536\n",
      "Epoch: 0010 | train_loss = 0.06696, train_auc = 0.97747, test_loss = 0.04289, test_auc = 0.95938, time = 0.01552\n",
      "Epoch: 0020 | train_loss = 0.04486, train_auc = 0.98910, test_loss = 0.03610, test_auc = 0.94432, time = 0.01530\n",
      "Epoch: 0030 | train_loss = 0.03165, train_auc = 0.99165, test_loss = 0.02918, test_auc = 0.96691, time = 0.01311\n",
      "Epoch: 0040 | train_loss = 0.02787, train_auc = 0.99193, test_loss = 0.03168, test_auc = 0.96370, time = 0.01215\n",
      "Epoch: 0050 | train_loss = 0.02104, train_auc = 0.99317, test_loss = 0.03726, test_auc = 0.94043, time = 0.01213\n",
      "Epoch: 0060 | train_loss = 0.01892, train_auc = 0.99457, test_loss = 0.04959, test_auc = 0.92593, time = 0.01244\n",
      "Epoch: 0070 | train_loss = 0.01640, train_auc = 0.99465, test_loss = 0.03288, test_auc = 0.94827, time = 0.01203\n",
      "Epoch: 0080 | train_loss = 0.01628, train_auc = 0.99457, test_loss = 0.03100, test_auc = 0.95877, time = 0.01241\n",
      "Epoch: 0090 | train_loss = 0.01626, train_auc = 0.99478, test_loss = 0.03067, test_auc = 0.96346, time = 0.01258\n",
      "Epoch: 0100 | train_loss = 0.01625, train_auc = 0.99514, test_loss = 0.03032, test_auc = 0.96383, time = 0.01247\n",
      "Epoch: 0110 | train_loss = 0.01624, train_auc = 0.99522, test_loss = 0.03055, test_auc = 0.96432, time = 0.01247\n",
      "Epoch: 0120 | train_loss = 0.01624, train_auc = 0.99526, test_loss = 0.03062, test_auc = 0.96426, time = 0.01249\n",
      "Epoch: 0130 | train_loss = 0.01624, train_auc = 0.99527, test_loss = 0.03054, test_auc = 0.96309, time = 0.01238\n",
      "Epoch: 0140 | train_loss = 0.01624, train_auc = 0.99528, test_loss = 0.03056, test_auc = 0.96321, time = 0.01802\n",
      "Epoch: 0150 | train_loss = 0.01624, train_auc = 0.99528, test_loss = 0.03057, test_auc = 0.96463, time = 0.01236\n",
      "Epoch: 0160 | train_loss = 0.01624, train_auc = 0.99532, test_loss = 0.03055, test_auc = 0.96302, time = 0.01229\n",
      "Epoch: 0170 | train_loss = 0.01624, train_auc = 0.99529, test_loss = 0.03055, test_auc = 0.96457, time = 0.01256\n",
      "Epoch: 0180 | train_loss = 0.01624, train_auc = 0.99531, test_loss = 0.03054, test_auc = 0.96327, time = 0.01216\n",
      "Epoch: 0190 | train_loss = 0.01624, train_auc = 0.99534, test_loss = 0.03053, test_auc = 0.96475, time = 0.01192\n",
      "Epoch: 0200 | train_loss = 0.01624, train_auc = 0.99535, test_loss = 0.03053, test_auc = 0.96358, time = 0.01191\n",
      "Epoch: 0210 | train_loss = 0.01624, train_auc = 0.99531, test_loss = 0.03052, test_auc = 0.96340, time = 0.01247\n",
      "Epoch: 0220 | train_loss = 0.01624, train_auc = 0.99533, test_loss = 0.03052, test_auc = 0.96352, time = 0.01207\n",
      "Epoch: 0230 | train_loss = 0.01624, train_auc = 0.99532, test_loss = 0.03051, test_auc = 0.96389, time = 0.01205\n",
      "Epoch: 0240 | train_loss = 0.01624, train_auc = 0.99533, test_loss = 0.03051, test_auc = 0.96352, time = 0.01220\n",
      "Epoch: 0250 | train_loss = 0.01623, train_auc = 0.99536, test_loss = 0.03051, test_auc = 0.96352, time = 0.01247\n",
      "Epoch: 0260 | train_loss = 0.01623, train_auc = 0.99535, test_loss = 0.03051, test_auc = 0.96370, time = 0.01282\n",
      "Epoch: 0270 | train_loss = 0.01623, train_auc = 0.99535, test_loss = 0.03051, test_auc = 0.96377, time = 0.01216\n",
      "Epoch: 0280 | train_loss = 0.01623, train_auc = 0.99534, test_loss = 0.03051, test_auc = 0.96377, time = 0.01203\n",
      "Epoch: 0290 | train_loss = 0.01623, train_auc = 0.99534, test_loss = 0.03051, test_auc = 0.96377, time = 0.01214\n",
      "Epoch: 0300 | train_loss = 0.01623, train_auc = 0.99534, test_loss = 0.03051, test_auc = 0.96377, time = 0.01225\n",
      "times: 3, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15044, train_auc = 0.57287, test_loss = 0.06822, test_auc = 0.70389, time = 0.75099\n",
      "Epoch: 0010 | train_loss = 0.06592, train_auc = 0.97276, test_loss = 0.05839, test_auc = 0.90253, time = 0.01493\n",
      "Epoch: 0020 | train_loss = 0.04325, train_auc = 0.98836, test_loss = 0.04755, test_auc = 0.93370, time = 0.01362\n",
      "Epoch: 0030 | train_loss = 0.03307, train_auc = 0.98806, test_loss = 0.04410, test_auc = 0.94642, time = 0.01295\n",
      "Epoch: 0040 | train_loss = 0.02742, train_auc = 0.98835, test_loss = 0.04334, test_auc = 0.94901, time = 0.01241\n",
      "Epoch: 0050 | train_loss = 0.02769, train_auc = 0.98664, test_loss = 0.03661, test_auc = 0.96901, time = 0.01241\n",
      "Epoch: 0060 | train_loss = 0.02786, train_auc = 0.98833, test_loss = 0.04210, test_auc = 0.96019, time = 0.01264\n",
      "Epoch: 0070 | train_loss = 0.02698, train_auc = 0.98733, test_loss = 0.03703, test_auc = 0.95796, time = 0.01307\n",
      "Epoch: 0080 | train_loss = 0.02664, train_auc = 0.98641, test_loss = 0.03883, test_auc = 0.96093, time = 0.01246\n",
      "Epoch: 0090 | train_loss = 0.02656, train_auc = 0.98562, test_loss = 0.03972, test_auc = 0.95716, time = 0.01273\n",
      "Epoch: 0100 | train_loss = 0.02654, train_auc = 0.98571, test_loss = 0.04046, test_auc = 0.95667, time = 0.01315\n",
      "Epoch: 0110 | train_loss = 0.02653, train_auc = 0.98574, test_loss = 0.03992, test_auc = 0.95827, time = 0.01233\n",
      "Epoch: 0120 | train_loss = 0.02652, train_auc = 0.98577, test_loss = 0.03956, test_auc = 0.95975, time = 0.01265\n",
      "Epoch: 0130 | train_loss = 0.02652, train_auc = 0.98674, test_loss = 0.03941, test_auc = 0.96000, time = 0.01227\n",
      "Epoch: 0140 | train_loss = 0.02652, train_auc = 0.98580, test_loss = 0.03944, test_auc = 0.96037, time = 0.01232\n",
      "Epoch: 0150 | train_loss = 0.02652, train_auc = 0.98577, test_loss = 0.03947, test_auc = 0.95988, time = 0.01254\n",
      "Epoch: 0160 | train_loss = 0.02652, train_auc = 0.98577, test_loss = 0.03951, test_auc = 0.95975, time = 0.01331\n",
      "Epoch: 0170 | train_loss = 0.02652, train_auc = 0.98577, test_loss = 0.03953, test_auc = 0.96000, time = 0.01308\n",
      "Epoch: 0180 | train_loss = 0.02651, train_auc = 0.98577, test_loss = 0.03950, test_auc = 0.95975, time = 0.01289\n",
      "Epoch: 0190 | train_loss = 0.02651, train_auc = 0.98583, test_loss = 0.03948, test_auc = 0.96012, time = 0.01254\n",
      "Epoch: 0200 | train_loss = 0.02651, train_auc = 0.98580, test_loss = 0.03946, test_auc = 0.96025, time = 0.01263\n",
      "Epoch: 0210 | train_loss = 0.02651, train_auc = 0.98583, test_loss = 0.03944, test_auc = 0.96037, time = 0.01240\n",
      "Epoch: 0220 | train_loss = 0.02651, train_auc = 0.98583, test_loss = 0.03941, test_auc = 0.96037, time = 0.01264\n",
      "Epoch: 0230 | train_loss = 0.02651, train_auc = 0.98580, test_loss = 0.03939, test_auc = 0.96037, time = 0.01207\n",
      "Epoch: 0240 | train_loss = 0.02651, train_auc = 0.98580, test_loss = 0.03936, test_auc = 0.96049, time = 0.01227\n",
      "Epoch: 0250 | train_loss = 0.02651, train_auc = 0.98583, test_loss = 0.03933, test_auc = 0.96062, time = 0.01270\n",
      "Epoch: 0260 | train_loss = 0.02651, train_auc = 0.98583, test_loss = 0.03931, test_auc = 0.96062, time = 0.01799\n",
      "Epoch: 0270 | train_loss = 0.02651, train_auc = 0.98583, test_loss = 0.03928, test_auc = 0.96056, time = 0.01291\n",
      "Epoch: 0280 | train_loss = 0.02651, train_auc = 0.98586, test_loss = 0.03926, test_auc = 0.96056, time = 0.01270\n",
      "Epoch: 0290 | train_loss = 0.02651, train_auc = 0.98586, test_loss = 0.03923, test_auc = 0.96074, time = 0.01325\n",
      "Epoch: 0300 | train_loss = 0.02651, train_auc = 0.98586, test_loss = 0.03921, test_auc = 0.96037, time = 0.01307\n",
      "times: 3, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14845, train_auc = 0.64697, test_loss = 0.07246, test_auc = 0.67525, time = 0.76853\n",
      "Epoch: 0010 | train_loss = 0.07221, train_auc = 0.95304, test_loss = 0.05859, test_auc = 0.89549, time = 0.01597\n",
      "Epoch: 0020 | train_loss = 0.04870, train_auc = 0.98275, test_loss = 0.04641, test_auc = 0.94012, time = 0.01413\n",
      "Epoch: 0030 | train_loss = 0.03591, train_auc = 0.98500, test_loss = 0.04003, test_auc = 0.94259, time = 0.01511\n",
      "Epoch: 0040 | train_loss = 0.03297, train_auc = 0.98604, test_loss = 0.03967, test_auc = 0.94870, time = 0.01326\n",
      "Epoch: 0050 | train_loss = 0.03025, train_auc = 0.98474, test_loss = 0.04033, test_auc = 0.94901, time = 0.01591\n",
      "Epoch: 0060 | train_loss = 0.02984, train_auc = 0.98604, test_loss = 0.04155, test_auc = 0.95426, time = 0.01278\n",
      "Epoch: 0070 | train_loss = 0.02973, train_auc = 0.98487, test_loss = 0.04145, test_auc = 0.96019, time = 0.01275\n",
      "Epoch: 0080 | train_loss = 0.02969, train_auc = 0.98498, test_loss = 0.04084, test_auc = 0.96623, time = 0.01251\n",
      "Epoch: 0090 | train_loss = 0.02967, train_auc = 0.98515, test_loss = 0.04044, test_auc = 0.96630, time = 0.01457\n",
      "Epoch: 0100 | train_loss = 0.02967, train_auc = 0.98522, test_loss = 0.04071, test_auc = 0.96562, time = 0.01274\n",
      "Epoch: 0110 | train_loss = 0.02966, train_auc = 0.98517, test_loss = 0.04065, test_auc = 0.96636, time = 0.01273\n",
      "Epoch: 0120 | train_loss = 0.02966, train_auc = 0.98512, test_loss = 0.04061, test_auc = 0.96623, time = 0.01476\n",
      "Epoch: 0130 | train_loss = 0.02965, train_auc = 0.98525, test_loss = 0.04066, test_auc = 0.96593, time = 0.01300\n",
      "Epoch: 0140 | train_loss = 0.02965, train_auc = 0.98519, test_loss = 0.04057, test_auc = 0.96580, time = 0.01252\n",
      "Epoch: 0150 | train_loss = 0.02965, train_auc = 0.98525, test_loss = 0.04064, test_auc = 0.96580, time = 0.01277\n",
      "Epoch: 0160 | train_loss = 0.02965, train_auc = 0.98524, test_loss = 0.04066, test_auc = 0.96599, time = 0.01262\n",
      "Epoch: 0170 | train_loss = 0.02965, train_auc = 0.98518, test_loss = 0.04068, test_auc = 0.96586, time = 0.01238\n",
      "Epoch: 0180 | train_loss = 0.02965, train_auc = 0.98522, test_loss = 0.04071, test_auc = 0.96599, time = 0.01300\n",
      "Epoch: 0190 | train_loss = 0.02965, train_auc = 0.98522, test_loss = 0.04073, test_auc = 0.96605, time = 0.01238\n",
      "Epoch: 0200 | train_loss = 0.02964, train_auc = 0.98524, test_loss = 0.04076, test_auc = 0.96623, time = 0.01256\n",
      "Epoch: 0210 | train_loss = 0.02964, train_auc = 0.98519, test_loss = 0.04078, test_auc = 0.96648, time = 0.01246\n",
      "Epoch: 0220 | train_loss = 0.02964, train_auc = 0.98519, test_loss = 0.04080, test_auc = 0.96667, time = 0.01219\n",
      "Epoch: 0230 | train_loss = 0.02964, train_auc = 0.98527, test_loss = 0.04082, test_auc = 0.96648, time = 0.01258\n",
      "Epoch: 0240 | train_loss = 0.02964, train_auc = 0.98521, test_loss = 0.04084, test_auc = 0.96623, time = 0.01261\n",
      "Epoch: 0250 | train_loss = 0.02964, train_auc = 0.98526, test_loss = 0.04086, test_auc = 0.96630, time = 0.01244\n",
      "Epoch: 0260 | train_loss = 0.02964, train_auc = 0.98519, test_loss = 0.04088, test_auc = 0.96636, time = 0.01262\n",
      "Epoch: 0270 | train_loss = 0.02964, train_auc = 0.98523, test_loss = 0.04089, test_auc = 0.96648, time = 0.01248\n",
      "Epoch: 0280 | train_loss = 0.02964, train_auc = 0.98523, test_loss = 0.04091, test_auc = 0.96636, time = 0.01229\n",
      "Epoch: 0290 | train_loss = 0.02964, train_auc = 0.98524, test_loss = 0.04092, test_auc = 0.96636, time = 0.01214\n",
      "Epoch: 0300 | train_loss = 0.02964, train_auc = 0.98525, test_loss = 0.04093, test_auc = 0.96642, time = 0.01245\n",
      "times: 3, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15774, train_auc = 0.57468, test_loss = 0.08537, test_auc = 0.54407, time = 0.75099\n",
      "Epoch: 0010 | train_loss = 0.09089, train_auc = 0.94314, test_loss = 0.05680, test_auc = 0.89519, time = 0.01505\n",
      "Epoch: 0020 | train_loss = 0.05211, train_auc = 0.98261, test_loss = 0.06257, test_auc = 0.64117, time = 0.01309\n",
      "Epoch: 0030 | train_loss = 0.03574, train_auc = 0.98795, test_loss = 0.03849, test_auc = 0.90852, time = 0.01302\n",
      "Epoch: 0040 | train_loss = 0.02515, train_auc = 0.98764, test_loss = 0.03660, test_auc = 0.93475, time = 0.01240\n",
      "Epoch: 0050 | train_loss = 0.02340, train_auc = 0.98831, test_loss = 0.03456, test_auc = 0.94210, time = 0.01248\n",
      "Epoch: 0060 | train_loss = 0.02310, train_auc = 0.98969, test_loss = 0.03513, test_auc = 0.93926, time = 0.01245\n",
      "Epoch: 0070 | train_loss = 0.02302, train_auc = 0.99001, test_loss = 0.03523, test_auc = 0.94111, time = 0.01221\n",
      "Epoch: 0080 | train_loss = 0.02300, train_auc = 0.99013, test_loss = 0.03551, test_auc = 0.94068, time = 0.01218\n",
      "Epoch: 0090 | train_loss = 0.02299, train_auc = 0.99026, test_loss = 0.03562, test_auc = 0.94037, time = 0.01206\n",
      "Epoch: 0100 | train_loss = 0.02298, train_auc = 0.99028, test_loss = 0.03531, test_auc = 0.94012, time = 0.01233\n",
      "Epoch: 0110 | train_loss = 0.02298, train_auc = 0.99033, test_loss = 0.03523, test_auc = 0.93673, time = 0.01262\n",
      "Epoch: 0120 | train_loss = 0.02297, train_auc = 0.99030, test_loss = 0.03526, test_auc = 0.93679, time = 0.01264\n",
      "Epoch: 0130 | train_loss = 0.02297, train_auc = 0.99030, test_loss = 0.03524, test_auc = 0.93691, time = 0.01221\n",
      "Epoch: 0140 | train_loss = 0.02297, train_auc = 0.99037, test_loss = 0.03526, test_auc = 0.94049, time = 0.01212\n",
      "Epoch: 0150 | train_loss = 0.02297, train_auc = 0.99035, test_loss = 0.03527, test_auc = 0.93722, time = 0.01239\n",
      "Epoch: 0160 | train_loss = 0.02297, train_auc = 0.99038, test_loss = 0.03525, test_auc = 0.93772, time = 0.01307\n",
      "Epoch: 0170 | train_loss = 0.02297, train_auc = 0.99038, test_loss = 0.03525, test_auc = 0.93827, time = 0.01260\n",
      "Epoch: 0180 | train_loss = 0.02297, train_auc = 0.99038, test_loss = 0.03524, test_auc = 0.93827, time = 0.01251\n",
      "Epoch: 0190 | train_loss = 0.02297, train_auc = 0.99041, test_loss = 0.03523, test_auc = 0.93846, time = 0.01286\n",
      "Epoch: 0200 | train_loss = 0.02296, train_auc = 0.99043, test_loss = 0.03523, test_auc = 0.93852, time = 0.01226\n",
      "Epoch: 0210 | train_loss = 0.02296, train_auc = 0.99048, test_loss = 0.03523, test_auc = 0.93809, time = 0.01232\n",
      "Epoch: 0220 | train_loss = 0.02296, train_auc = 0.99044, test_loss = 0.03523, test_auc = 0.93858, time = 0.01250\n",
      "Epoch: 0230 | train_loss = 0.02296, train_auc = 0.99047, test_loss = 0.03523, test_auc = 0.93858, time = 0.01328\n",
      "Epoch: 0240 | train_loss = 0.02296, train_auc = 0.99060, test_loss = 0.03520, test_auc = 0.93877, time = 0.01371\n",
      "Epoch: 0250 | train_loss = 0.03101, train_auc = 0.98963, test_loss = 0.05231, test_auc = 0.81685, time = 0.01252\n",
      "Epoch: 0260 | train_loss = 0.02527, train_auc = 0.99113, test_loss = 0.03456, test_auc = 0.93105, time = 0.01252\n",
      "Epoch: 0270 | train_loss = 0.02151, train_auc = 0.99340, test_loss = 0.03065, test_auc = 0.95901, time = 0.01239\n",
      "Epoch: 0280 | train_loss = 0.02104, train_auc = 0.99117, test_loss = 0.03174, test_auc = 0.94568, time = 0.01272\n",
      "Epoch: 0290 | train_loss = 0.02099, train_auc = 0.99117, test_loss = 0.03129, test_auc = 0.94543, time = 0.01268\n",
      "Epoch: 0300 | train_loss = 0.02097, train_auc = 0.99128, test_loss = 0.03080, test_auc = 0.94556, time = 0.01237\n",
      "times: 4, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15985, train_auc = 0.53601, test_loss = 0.05925, test_auc = 0.77463, time = 0.76869\n",
      "Epoch: 0010 | train_loss = 0.06982, train_auc = 0.95402, test_loss = 0.05190, test_auc = 0.88037, time = 0.01576\n",
      "Epoch: 0020 | train_loss = 0.04873, train_auc = 0.98462, test_loss = 0.04095, test_auc = 0.91265, time = 0.01473\n",
      "Epoch: 0030 | train_loss = 0.03367, train_auc = 0.98974, test_loss = 0.04029, test_auc = 0.92914, time = 0.01332\n",
      "Epoch: 0040 | train_loss = 0.02785, train_auc = 0.99045, test_loss = 0.04053, test_auc = 0.94111, time = 0.01379\n",
      "Epoch: 0050 | train_loss = 0.02680, train_auc = 0.99089, test_loss = 0.04116, test_auc = 0.93457, time = 0.01255\n",
      "Epoch: 0060 | train_loss = 0.02353, train_auc = 0.99158, test_loss = 0.04482, test_auc = 0.92877, time = 0.01272\n",
      "Epoch: 0070 | train_loss = 0.02321, train_auc = 0.99164, test_loss = 0.04298, test_auc = 0.92235, time = 0.01260\n",
      "Epoch: 0080 | train_loss = 0.02302, train_auc = 0.99210, test_loss = 0.04280, test_auc = 0.93235, time = 0.01194\n",
      "Epoch: 0090 | train_loss = 0.01990, train_auc = 0.99285, test_loss = 0.04187, test_auc = 0.93160, time = 0.01210\n",
      "Epoch: 0100 | train_loss = 0.01961, train_auc = 0.99270, test_loss = 0.04241, test_auc = 0.91210, time = 0.01245\n",
      "Epoch: 0110 | train_loss = 0.01903, train_auc = 0.99272, test_loss = 0.04510, test_auc = 0.89691, time = 0.01263\n",
      "Epoch: 0120 | train_loss = 0.01882, train_auc = 0.99275, test_loss = 0.04301, test_auc = 0.91086, time = 0.01217\n",
      "Epoch: 0130 | train_loss = 0.01878, train_auc = 0.99284, test_loss = 0.04161, test_auc = 0.92475, time = 0.01237\n",
      "Epoch: 0140 | train_loss = 0.01877, train_auc = 0.99284, test_loss = 0.04157, test_auc = 0.92870, time = 0.01198\n",
      "Epoch: 0150 | train_loss = 0.01876, train_auc = 0.99284, test_loss = 0.04145, test_auc = 0.93025, time = 0.01309\n",
      "Epoch: 0160 | train_loss = 0.01876, train_auc = 0.99285, test_loss = 0.04133, test_auc = 0.93037, time = 0.01283\n",
      "Epoch: 0170 | train_loss = 0.01876, train_auc = 0.99284, test_loss = 0.04125, test_auc = 0.93043, time = 0.01269\n",
      "Epoch: 0180 | train_loss = 0.01875, train_auc = 0.99284, test_loss = 0.04122, test_auc = 0.93049, time = 0.01206\n",
      "Epoch: 0190 | train_loss = 0.01875, train_auc = 0.99285, test_loss = 0.04121, test_auc = 0.93123, time = 0.01237\n",
      "Epoch: 0200 | train_loss = 0.01875, train_auc = 0.99282, test_loss = 0.04123, test_auc = 0.93191, time = 0.01318\n",
      "Epoch: 0210 | train_loss = 0.01875, train_auc = 0.99285, test_loss = 0.04126, test_auc = 0.93253, time = 0.01240\n",
      "Epoch: 0220 | train_loss = 0.01875, train_auc = 0.99285, test_loss = 0.04127, test_auc = 0.93210, time = 0.01243\n",
      "Epoch: 0230 | train_loss = 0.01875, train_auc = 0.99287, test_loss = 0.04128, test_auc = 0.93259, time = 0.01223\n",
      "Epoch: 0240 | train_loss = 0.01875, train_auc = 0.99290, test_loss = 0.04129, test_auc = 0.93315, time = 0.01255\n",
      "Epoch: 0250 | train_loss = 0.01875, train_auc = 0.99287, test_loss = 0.04130, test_auc = 0.93315, time = 0.01280\n",
      "Epoch: 0260 | train_loss = 0.01875, train_auc = 0.99285, test_loss = 0.04130, test_auc = 0.93265, time = 0.01210\n",
      "Epoch: 0270 | train_loss = 0.01875, train_auc = 0.99287, test_loss = 0.04130, test_auc = 0.93346, time = 0.01648\n",
      "Epoch: 0280 | train_loss = 0.01875, train_auc = 0.99287, test_loss = 0.04131, test_auc = 0.93272, time = 0.01258\n",
      "Epoch: 0290 | train_loss = 0.01875, train_auc = 0.99289, test_loss = 0.04131, test_auc = 0.93364, time = 0.01249\n",
      "Epoch: 0300 | train_loss = 0.01875, train_auc = 0.99290, test_loss = 0.04131, test_auc = 0.93352, time = 0.01284\n",
      "times: 4, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.17192, train_auc = 0.38940, test_loss = 0.09324, test_auc = 0.44457, time = 0.75347\n",
      "Epoch: 0010 | train_loss = 0.06811, train_auc = 0.97625, test_loss = 0.05267, test_auc = 0.84160, time = 0.01555\n",
      "Epoch: 0020 | train_loss = 0.04837, train_auc = 0.98071, test_loss = 0.04234, test_auc = 0.94716, time = 0.01361\n",
      "Epoch: 0030 | train_loss = 0.04003, train_auc = 0.98106, test_loss = 0.04048, test_auc = 0.94321, time = 0.01298\n",
      "Epoch: 0040 | train_loss = 0.03617, train_auc = 0.98093, test_loss = 0.03800, test_auc = 0.94475, time = 0.01260\n",
      "Epoch: 0050 | train_loss = 0.03506, train_auc = 0.98144, test_loss = 0.03516, test_auc = 0.94809, time = 0.01246\n",
      "Epoch: 0060 | train_loss = 0.03141, train_auc = 0.98007, test_loss = 0.04088, test_auc = 0.91543, time = 0.01253\n",
      "Epoch: 0070 | train_loss = 0.02990, train_auc = 0.98389, test_loss = 0.04023, test_auc = 0.94414, time = 0.01228\n",
      "Epoch: 0080 | train_loss = 0.02973, train_auc = 0.98518, test_loss = 0.03924, test_auc = 0.93642, time = 0.01211\n",
      "Epoch: 0090 | train_loss = 0.02968, train_auc = 0.98560, test_loss = 0.03883, test_auc = 0.93710, time = 0.01236\n",
      "Epoch: 0100 | train_loss = 0.02965, train_auc = 0.98487, test_loss = 0.03875, test_auc = 0.92617, time = 0.01266\n",
      "Epoch: 0110 | train_loss = 0.02848, train_auc = 0.98630, test_loss = 0.06234, test_auc = 0.73074, time = 0.01228\n",
      "Epoch: 0120 | train_loss = 0.02822, train_auc = 0.98637, test_loss = 0.03844, test_auc = 0.92241, time = 0.01478\n",
      "Epoch: 0130 | train_loss = 0.02817, train_auc = 0.98638, test_loss = 0.03689, test_auc = 0.92728, time = 0.01222\n",
      "Epoch: 0140 | train_loss = 0.02814, train_auc = 0.98679, test_loss = 0.03699, test_auc = 0.93735, time = 0.01223\n",
      "Epoch: 0150 | train_loss = 0.02813, train_auc = 0.98686, test_loss = 0.03764, test_auc = 0.93519, time = 0.01292\n",
      "Epoch: 0160 | train_loss = 0.02663, train_auc = 0.98727, test_loss = 0.03700, test_auc = 0.92580, time = 0.01263\n",
      "Epoch: 0170 | train_loss = 0.02658, train_auc = 0.98702, test_loss = 0.03812, test_auc = 0.91475, time = 0.01233\n",
      "Epoch: 0180 | train_loss = 0.02653, train_auc = 0.98704, test_loss = 0.03774, test_auc = 0.92444, time = 0.01250\n",
      "Epoch: 0190 | train_loss = 0.02652, train_auc = 0.98704, test_loss = 0.03746, test_auc = 0.92889, time = 0.01244\n",
      "Epoch: 0200 | train_loss = 0.02651, train_auc = 0.98706, test_loss = 0.03757, test_auc = 0.92864, time = 0.01233\n",
      "Epoch: 0210 | train_loss = 0.02651, train_auc = 0.98694, test_loss = 0.03759, test_auc = 0.93068, time = 0.01240\n",
      "Epoch: 0220 | train_loss = 0.02651, train_auc = 0.98693, test_loss = 0.03749, test_auc = 0.93315, time = 0.01290\n",
      "Epoch: 0230 | train_loss = 0.02651, train_auc = 0.98691, test_loss = 0.03745, test_auc = 0.93765, time = 0.01232\n",
      "Epoch: 0240 | train_loss = 0.02651, train_auc = 0.98694, test_loss = 0.03746, test_auc = 0.93562, time = 0.01245\n",
      "Epoch: 0250 | train_loss = 0.02651, train_auc = 0.98688, test_loss = 0.03747, test_auc = 0.93605, time = 0.01219\n",
      "Epoch: 0260 | train_loss = 0.02651, train_auc = 0.98696, test_loss = 0.03748, test_auc = 0.93648, time = 0.01267\n",
      "Epoch: 0270 | train_loss = 0.02651, train_auc = 0.98696, test_loss = 0.03749, test_auc = 0.93877, time = 0.01239\n",
      "Epoch: 0280 | train_loss = 0.02651, train_auc = 0.98696, test_loss = 0.03750, test_auc = 0.93642, time = 0.01210\n",
      "Epoch: 0290 | train_loss = 0.02651, train_auc = 0.98696, test_loss = 0.03752, test_auc = 0.93469, time = 0.01311\n",
      "Epoch: 0300 | train_loss = 0.02651, train_auc = 0.98699, test_loss = 0.03753, test_auc = 0.93488, time = 0.01211\n",
      "times: 4, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.18118, train_auc = 0.32294, test_loss = 0.08936, test_auc = 0.49451, time = 0.78307\n",
      "Epoch: 0010 | train_loss = 0.06696, train_auc = 0.96617, test_loss = 0.04387, test_auc = 0.93963, time = 0.01562\n",
      "Epoch: 0020 | train_loss = 0.04938, train_auc = 0.98691, test_loss = 0.03502, test_auc = 0.96741, time = 0.01395\n",
      "Epoch: 0030 | train_loss = 0.03932, train_auc = 0.98841, test_loss = 0.03460, test_auc = 0.97210, time = 0.01353\n",
      "Epoch: 0040 | train_loss = 0.03247, train_auc = 0.98927, test_loss = 0.03687, test_auc = 0.96383, time = 0.01310\n",
      "Epoch: 0050 | train_loss = 0.03013, train_auc = 0.98885, test_loss = 0.03765, test_auc = 0.96481, time = 0.01301\n",
      "Epoch: 0060 | train_loss = 0.02842, train_auc = 0.98929, test_loss = 0.03933, test_auc = 0.96370, time = 0.01361\n",
      "Epoch: 0070 | train_loss = 0.02825, train_auc = 0.98745, test_loss = 0.04016, test_auc = 0.96333, time = 0.01296\n",
      "Epoch: 0080 | train_loss = 0.02820, train_auc = 0.98727, test_loss = 0.03853, test_auc = 0.96716, time = 0.01301\n",
      "Epoch: 0090 | train_loss = 0.02816, train_auc = 0.98835, test_loss = 0.03813, test_auc = 0.96704, time = 0.01242\n",
      "Epoch: 0100 | train_loss = 0.02814, train_auc = 0.98947, test_loss = 0.03811, test_auc = 0.96469, time = 0.01286\n",
      "Epoch: 0110 | train_loss = 0.02814, train_auc = 0.98853, test_loss = 0.03841, test_auc = 0.96722, time = 0.01260\n",
      "Epoch: 0120 | train_loss = 0.02813, train_auc = 0.98758, test_loss = 0.03861, test_auc = 0.96556, time = 0.01381\n",
      "Epoch: 0130 | train_loss = 0.02813, train_auc = 0.98862, test_loss = 0.03872, test_auc = 0.96426, time = 0.01276\n",
      "Epoch: 0140 | train_loss = 0.02813, train_auc = 0.98858, test_loss = 0.03884, test_auc = 0.96358, time = 0.01267\n",
      "Epoch: 0150 | train_loss = 0.02812, train_auc = 0.98862, test_loss = 0.03896, test_auc = 0.96340, time = 0.01318\n",
      "Epoch: 0160 | train_loss = 0.02812, train_auc = 0.98860, test_loss = 0.03901, test_auc = 0.96296, time = 0.01285\n",
      "Epoch: 0170 | train_loss = 0.02812, train_auc = 0.98867, test_loss = 0.03903, test_auc = 0.96327, time = 0.01271\n",
      "Epoch: 0180 | train_loss = 0.02812, train_auc = 0.98873, test_loss = 0.03906, test_auc = 0.95926, time = 0.01253\n",
      "Epoch: 0190 | train_loss = 0.02812, train_auc = 0.98865, test_loss = 0.03908, test_auc = 0.95926, time = 0.01251\n",
      "Epoch: 0200 | train_loss = 0.02812, train_auc = 0.98867, test_loss = 0.03908, test_auc = 0.96340, time = 0.01249\n",
      "Epoch: 0210 | train_loss = 0.02812, train_auc = 0.98867, test_loss = 0.03907, test_auc = 0.95914, time = 0.01252\n",
      "Epoch: 0220 | train_loss = 0.02812, train_auc = 0.98884, test_loss = 0.03903, test_auc = 0.95901, time = 0.01248\n",
      "Epoch: 0230 | train_loss = 0.04125, train_auc = 0.98814, test_loss = 0.03351, test_auc = 0.96747, time = 0.01224\n",
      "Epoch: 0240 | train_loss = 0.03531, train_auc = 0.99058, test_loss = 0.04894, test_auc = 0.92068, time = 0.01305\n",
      "Epoch: 0250 | train_loss = 0.02716, train_auc = 0.99017, test_loss = 0.04055, test_auc = 0.96469, time = 0.01238\n",
      "Epoch: 0260 | train_loss = 0.02668, train_auc = 0.98868, test_loss = 0.03586, test_auc = 0.96173, time = 0.01227\n",
      "Epoch: 0270 | train_loss = 0.02655, train_auc = 0.98863, test_loss = 0.03451, test_auc = 0.96420, time = 0.01315\n",
      "Epoch: 0280 | train_loss = 0.02653, train_auc = 0.98931, test_loss = 0.03429, test_auc = 0.96654, time = 0.01270\n",
      "Epoch: 0290 | train_loss = 0.02652, train_auc = 0.98931, test_loss = 0.03502, test_auc = 0.95870, time = 0.01255\n",
      "Epoch: 0300 | train_loss = 0.02651, train_auc = 0.98913, test_loss = 0.03545, test_auc = 0.95895, time = 0.01262\n",
      "times: 4, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.16742, train_auc = 0.41719, test_loss = 0.06998, test_auc = 0.69111, time = 0.78447\n",
      "Epoch: 0010 | train_loss = 0.07657, train_auc = 0.95116, test_loss = 0.04981, test_auc = 0.92543, time = 0.01535\n",
      "Epoch: 0020 | train_loss = 0.04797, train_auc = 0.98772, test_loss = 0.03817, test_auc = 0.94512, time = 0.01354\n",
      "Epoch: 0030 | train_loss = 0.03350, train_auc = 0.99247, test_loss = 0.03043, test_auc = 0.96395, time = 0.01310\n",
      "Epoch: 0040 | train_loss = 0.02626, train_auc = 0.99304, test_loss = 0.03387, test_auc = 0.95691, time = 0.01259\n",
      "Epoch: 0050 | train_loss = 0.02415, train_auc = 0.99329, test_loss = 0.03517, test_auc = 0.93864, time = 0.01261\n",
      "Epoch: 0060 | train_loss = 0.02165, train_auc = 0.99381, test_loss = 0.04274, test_auc = 0.92580, time = 0.01795\n",
      "Epoch: 0070 | train_loss = 0.02117, train_auc = 0.99423, test_loss = 0.03922, test_auc = 0.92951, time = 0.01227\n",
      "Epoch: 0080 | train_loss = 0.02105, train_auc = 0.99462, test_loss = 0.03667, test_auc = 0.94000, time = 0.01233\n",
      "Epoch: 0090 | train_loss = 0.02100, train_auc = 0.99479, test_loss = 0.03672, test_auc = 0.94432, time = 0.01269\n",
      "Epoch: 0100 | train_loss = 0.01929, train_auc = 0.99533, test_loss = 0.03558, test_auc = 0.94543, time = 0.01235\n",
      "Epoch: 0110 | train_loss = 0.01925, train_auc = 0.99357, test_loss = 0.03512, test_auc = 0.96074, time = 0.01249\n",
      "Epoch: 0120 | train_loss = 0.01889, train_auc = 0.99378, test_loss = 0.03280, test_auc = 0.96815, time = 0.01252\n",
      "Epoch: 0130 | train_loss = 0.01880, train_auc = 0.99375, test_loss = 0.03247, test_auc = 0.96975, time = 0.01260\n",
      "Epoch: 0140 | train_loss = 0.01877, train_auc = 0.99375, test_loss = 0.03097, test_auc = 0.96988, time = 0.01280\n",
      "Epoch: 0150 | train_loss = 0.01877, train_auc = 0.99372, test_loss = 0.03093, test_auc = 0.96975, time = 0.01250\n",
      "Epoch: 0160 | train_loss = 0.01876, train_auc = 0.99374, test_loss = 0.03153, test_auc = 0.96988, time = 0.01235\n",
      "Epoch: 0170 | train_loss = 0.01876, train_auc = 0.99374, test_loss = 0.03193, test_auc = 0.96951, time = 0.01245\n",
      "Epoch: 0180 | train_loss = 0.01876, train_auc = 0.99385, test_loss = 0.03221, test_auc = 0.96926, time = 0.01238\n",
      "Epoch: 0190 | train_loss = 0.01875, train_auc = 0.99384, test_loss = 0.03250, test_auc = 0.96864, time = 0.01246\n",
      "Epoch: 0200 | train_loss = 0.01875, train_auc = 0.99382, test_loss = 0.03272, test_auc = 0.96864, time = 0.01239\n",
      "Epoch: 0210 | train_loss = 0.01875, train_auc = 0.99383, test_loss = 0.03291, test_auc = 0.96809, time = 0.01239\n",
      "Epoch: 0220 | train_loss = 0.01875, train_auc = 0.99384, test_loss = 0.03304, test_auc = 0.96765, time = 0.01229\n",
      "Epoch: 0230 | train_loss = 0.01875, train_auc = 0.99387, test_loss = 0.03314, test_auc = 0.96765, time = 0.01239\n",
      "Epoch: 0240 | train_loss = 0.01875, train_auc = 0.99389, test_loss = 0.03323, test_auc = 0.96753, time = 0.01202\n",
      "Epoch: 0250 | train_loss = 0.01875, train_auc = 0.99385, test_loss = 0.03332, test_auc = 0.96753, time = 0.01208\n",
      "Epoch: 0260 | train_loss = 0.01875, train_auc = 0.99387, test_loss = 0.03339, test_auc = 0.96741, time = 0.01208\n",
      "Epoch: 0270 | train_loss = 0.01875, train_auc = 0.99386, test_loss = 0.03346, test_auc = 0.96728, time = 0.01228\n",
      "Epoch: 0280 | train_loss = 0.01875, train_auc = 0.99390, test_loss = 0.03352, test_auc = 0.96704, time = 0.01255\n",
      "Epoch: 0290 | train_loss = 0.01875, train_auc = 0.99389, test_loss = 0.03357, test_auc = 0.96704, time = 0.01246\n",
      "Epoch: 0300 | train_loss = 0.01875, train_auc = 0.99384, test_loss = 0.03362, test_auc = 0.96704, time = 0.01216\n",
      "times: 4, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15423, train_auc = 0.57684, test_loss = 0.10379, test_auc = 0.31765, time = 0.78755\n",
      "Epoch: 0010 | train_loss = 0.05515, train_auc = 0.98925, test_loss = 0.06553, test_auc = 0.87815, time = 0.01555\n",
      "Epoch: 0020 | train_loss = 0.03109, train_auc = 0.99591, test_loss = 0.04340, test_auc = 0.95309, time = 0.01368\n",
      "Epoch: 0030 | train_loss = 0.01864, train_auc = 0.99670, test_loss = 0.04432, test_auc = 0.94759, time = 0.01343\n",
      "Epoch: 0040 | train_loss = 0.01656, train_auc = 0.99680, test_loss = 0.03915, test_auc = 0.94673, time = 0.01251\n",
      "Epoch: 0050 | train_loss = 0.01633, train_auc = 0.99583, test_loss = 0.03677, test_auc = 0.95315, time = 0.01222\n",
      "Epoch: 0060 | train_loss = 0.01628, train_auc = 0.99582, test_loss = 0.03736, test_auc = 0.95796, time = 0.01216\n",
      "Epoch: 0070 | train_loss = 0.01626, train_auc = 0.99583, test_loss = 0.03738, test_auc = 0.95772, time = 0.01231\n",
      "Epoch: 0080 | train_loss = 0.01625, train_auc = 0.99586, test_loss = 0.03725, test_auc = 0.95975, time = 0.01219\n",
      "Epoch: 0090 | train_loss = 0.01625, train_auc = 0.99588, test_loss = 0.03733, test_auc = 0.95889, time = 0.01230\n",
      "Epoch: 0100 | train_loss = 0.01624, train_auc = 0.99588, test_loss = 0.03747, test_auc = 0.95827, time = 0.01229\n",
      "Epoch: 0110 | train_loss = 0.01624, train_auc = 0.99589, test_loss = 0.03765, test_auc = 0.95827, time = 0.01223\n",
      "Epoch: 0120 | train_loss = 0.01624, train_auc = 0.99588, test_loss = 0.03775, test_auc = 0.95840, time = 0.01241\n",
      "Epoch: 0130 | train_loss = 0.01624, train_auc = 0.99586, test_loss = 0.03781, test_auc = 0.95889, time = 0.01220\n",
      "Epoch: 0140 | train_loss = 0.01624, train_auc = 0.99584, test_loss = 0.03786, test_auc = 0.95901, time = 0.01225\n",
      "Epoch: 0150 | train_loss = 0.01624, train_auc = 0.99586, test_loss = 0.03791, test_auc = 0.95907, time = 0.01226\n",
      "Epoch: 0160 | train_loss = 0.01624, train_auc = 0.99586, test_loss = 0.03795, test_auc = 0.95920, time = 0.01228\n",
      "Epoch: 0170 | train_loss = 0.01624, train_auc = 0.99584, test_loss = 0.03799, test_auc = 0.95944, time = 0.01214\n",
      "Epoch: 0180 | train_loss = 0.01624, train_auc = 0.99585, test_loss = 0.03803, test_auc = 0.95957, time = 0.01227\n",
      "Epoch: 0190 | train_loss = 0.01624, train_auc = 0.99585, test_loss = 0.03806, test_auc = 0.95969, time = 0.01214\n",
      "Epoch: 0200 | train_loss = 0.01624, train_auc = 0.99586, test_loss = 0.03809, test_auc = 0.95988, time = 0.01213\n",
      "Epoch: 0210 | train_loss = 0.01624, train_auc = 0.99587, test_loss = 0.03812, test_auc = 0.95981, time = 0.01220\n",
      "Epoch: 0220 | train_loss = 0.01624, train_auc = 0.99587, test_loss = 0.03815, test_auc = 0.95981, time = 0.01208\n",
      "Epoch: 0230 | train_loss = 0.01624, train_auc = 0.99585, test_loss = 0.03818, test_auc = 0.96012, time = 0.01270\n",
      "Epoch: 0240 | train_loss = 0.01624, train_auc = 0.99586, test_loss = 0.03820, test_auc = 0.96012, time = 0.01222\n",
      "Epoch: 0250 | train_loss = 0.01624, train_auc = 0.99585, test_loss = 0.03822, test_auc = 0.96031, time = 0.01220\n",
      "Epoch: 0260 | train_loss = 0.01624, train_auc = 0.99585, test_loss = 0.03824, test_auc = 0.96031, time = 0.01237\n",
      "Epoch: 0270 | train_loss = 0.01624, train_auc = 0.99587, test_loss = 0.03826, test_auc = 0.96062, time = 0.01253\n",
      "Epoch: 0280 | train_loss = 0.01624, train_auc = 0.99585, test_loss = 0.03828, test_auc = 0.96056, time = 0.01281\n",
      "Epoch: 0290 | train_loss = 0.01623, train_auc = 0.99586, test_loss = 0.03830, test_auc = 0.96099, time = 0.01206\n",
      "Epoch: 0300 | train_loss = 0.01623, train_auc = 0.99586, test_loss = 0.03832, test_auc = 0.96105, time = 0.01234\n",
      "times: 5, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14295, train_auc = 0.63975, test_loss = 0.07840, test_auc = 0.59056, time = 0.88857\n",
      "Epoch: 0010 | train_loss = 0.06737, train_auc = 0.96066, test_loss = 0.07284, test_auc = 0.80778, time = 0.01565\n",
      "Epoch: 0020 | train_loss = 0.04603, train_auc = 0.98031, test_loss = 0.04526, test_auc = 0.93086, time = 0.01326\n",
      "Epoch: 0030 | train_loss = 0.03699, train_auc = 0.98288, test_loss = 0.04093, test_auc = 0.94728, time = 0.01329\n",
      "Epoch: 0040 | train_loss = 0.03323, train_auc = 0.98469, test_loss = 0.04192, test_auc = 0.95321, time = 0.01316\n",
      "Epoch: 0050 | train_loss = 0.03138, train_auc = 0.98575, test_loss = 0.04671, test_auc = 0.93210, time = 0.01275\n",
      "Epoch: 0060 | train_loss = 0.03002, train_auc = 0.98608, test_loss = 0.04583, test_auc = 0.93370, time = 0.01269\n",
      "Epoch: 0070 | train_loss = 0.02964, train_auc = 0.98319, test_loss = 0.04000, test_auc = 0.95136, time = 0.01211\n",
      "Epoch: 0080 | train_loss = 0.02852, train_auc = 0.98446, test_loss = 0.04100, test_auc = 0.95160, time = 0.01279\n",
      "Epoch: 0090 | train_loss = 0.02822, train_auc = 0.98600, test_loss = 0.04294, test_auc = 0.95284, time = 0.01205\n",
      "Epoch: 0100 | train_loss = 0.02816, train_auc = 0.98701, test_loss = 0.04281, test_auc = 0.95148, time = 0.01246\n",
      "Epoch: 0110 | train_loss = 0.02814, train_auc = 0.98636, test_loss = 0.04262, test_auc = 0.95272, time = 0.01232\n",
      "Epoch: 0120 | train_loss = 0.02813, train_auc = 0.98633, test_loss = 0.04258, test_auc = 0.95111, time = 0.01249\n",
      "Epoch: 0130 | train_loss = 0.02813, train_auc = 0.98635, test_loss = 0.04252, test_auc = 0.95241, time = 0.01235\n",
      "Epoch: 0140 | train_loss = 0.02813, train_auc = 0.98656, test_loss = 0.04246, test_auc = 0.95414, time = 0.01236\n",
      "Epoch: 0150 | train_loss = 0.02813, train_auc = 0.98663, test_loss = 0.04260, test_auc = 0.95426, time = 0.01253\n",
      "Epoch: 0160 | train_loss = 0.02812, train_auc = 0.98667, test_loss = 0.04274, test_auc = 0.95469, time = 0.01280\n",
      "Epoch: 0170 | train_loss = 0.02812, train_auc = 0.98666, test_loss = 0.04280, test_auc = 0.95494, time = 0.01274\n",
      "Epoch: 0180 | train_loss = 0.02812, train_auc = 0.98661, test_loss = 0.04282, test_auc = 0.95093, time = 0.01259\n",
      "Epoch: 0190 | train_loss = 0.02812, train_auc = 0.98666, test_loss = 0.04284, test_auc = 0.95167, time = 0.01263\n",
      "Epoch: 0200 | train_loss = 0.02812, train_auc = 0.98672, test_loss = 0.04283, test_auc = 0.95191, time = 0.01225\n",
      "Epoch: 0210 | train_loss = 0.02812, train_auc = 0.98667, test_loss = 0.04284, test_auc = 0.95191, time = 0.01247\n",
      "Epoch: 0220 | train_loss = 0.02812, train_auc = 0.98679, test_loss = 0.04283, test_auc = 0.95568, time = 0.01222\n",
      "Epoch: 0230 | train_loss = 0.02812, train_auc = 0.98680, test_loss = 0.04283, test_auc = 0.95191, time = 0.01207\n",
      "Epoch: 0240 | train_loss = 0.02812, train_auc = 0.98686, test_loss = 0.04283, test_auc = 0.95204, time = 0.01207\n",
      "Epoch: 0250 | train_loss = 0.02812, train_auc = 0.98682, test_loss = 0.04283, test_auc = 0.95191, time = 0.01195\n",
      "Epoch: 0260 | train_loss = 0.02812, train_auc = 0.98684, test_loss = 0.04284, test_auc = 0.95216, time = 0.01241\n",
      "Epoch: 0270 | train_loss = 0.02812, train_auc = 0.98590, test_loss = 0.04284, test_auc = 0.95210, time = 0.01227\n",
      "Epoch: 0280 | train_loss = 0.02812, train_auc = 0.98596, test_loss = 0.04284, test_auc = 0.95216, time = 0.01220\n",
      "Epoch: 0290 | train_loss = 0.02812, train_auc = 0.98694, test_loss = 0.04285, test_auc = 0.95216, time = 0.01223\n",
      "Epoch: 0300 | train_loss = 0.02812, train_auc = 0.98595, test_loss = 0.04285, test_auc = 0.95222, time = 0.01244\n",
      "times: 5, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.17139, train_auc = 0.39356, test_loss = 0.08008, test_auc = 0.60136, time = 0.78212\n",
      "Epoch: 0010 | train_loss = 0.07356, train_auc = 0.97163, test_loss = 0.07357, test_auc = 0.82074, time = 0.01597\n",
      "Epoch: 0020 | train_loss = 0.04982, train_auc = 0.98465, test_loss = 0.05675, test_auc = 0.90914, time = 0.01367\n",
      "Epoch: 0030 | train_loss = 0.03965, train_auc = 0.98701, test_loss = 0.03659, test_auc = 0.95358, time = 0.02010\n",
      "Epoch: 0040 | train_loss = 0.03375, train_auc = 0.98782, test_loss = 0.03455, test_auc = 0.95593, time = 0.01374\n",
      "Epoch: 0050 | train_loss = 0.03181, train_auc = 0.98724, test_loss = 0.03574, test_auc = 0.95272, time = 0.01543\n",
      "Epoch: 0060 | train_loss = 0.03047, train_auc = 0.98812, test_loss = 0.04505, test_auc = 0.93253, time = 0.01312\n",
      "Epoch: 0070 | train_loss = 0.03012, train_auc = 0.98826, test_loss = 0.03864, test_auc = 0.94901, time = 0.01286\n",
      "Epoch: 0080 | train_loss = 0.02985, train_auc = 0.98735, test_loss = 0.03874, test_auc = 0.94951, time = 0.01261\n",
      "Epoch: 0090 | train_loss = 0.02974, train_auc = 0.98763, test_loss = 0.04067, test_auc = 0.94605, time = 0.01211\n",
      "Epoch: 0100 | train_loss = 0.02970, train_auc = 0.98737, test_loss = 0.04242, test_auc = 0.95031, time = 0.01247\n",
      "Epoch: 0110 | train_loss = 0.02968, train_auc = 0.98758, test_loss = 0.04065, test_auc = 0.94901, time = 0.01253\n",
      "Epoch: 0120 | train_loss = 0.02967, train_auc = 0.98758, test_loss = 0.04061, test_auc = 0.95284, time = 0.01196\n",
      "Epoch: 0130 | train_loss = 0.02966, train_auc = 0.98764, test_loss = 0.04007, test_auc = 0.94988, time = 0.01275\n",
      "Epoch: 0140 | train_loss = 0.02966, train_auc = 0.98762, test_loss = 0.03978, test_auc = 0.95037, time = 0.01255\n",
      "Epoch: 0150 | train_loss = 0.02966, train_auc = 0.98672, test_loss = 0.04058, test_auc = 0.94938, time = 0.01287\n",
      "Epoch: 0160 | train_loss = 0.02965, train_auc = 0.98776, test_loss = 0.04059, test_auc = 0.94951, time = 0.01251\n",
      "Epoch: 0170 | train_loss = 0.02965, train_auc = 0.98777, test_loss = 0.04055, test_auc = 0.94957, time = 0.01231\n",
      "Epoch: 0180 | train_loss = 0.02965, train_auc = 0.98679, test_loss = 0.04037, test_auc = 0.94963, time = 0.01245\n",
      "Epoch: 0190 | train_loss = 0.02964, train_auc = 0.98691, test_loss = 0.03963, test_auc = 0.95000, time = 0.01252\n",
      "Epoch: 0200 | train_loss = 0.02909, train_auc = 0.98804, test_loss = 0.04377, test_auc = 0.90735, time = 0.01253\n",
      "Epoch: 0210 | train_loss = 0.02839, train_auc = 0.98805, test_loss = 0.04410, test_auc = 0.94167, time = 0.01200\n",
      "Epoch: 0220 | train_loss = 0.02820, train_auc = 0.98820, test_loss = 0.03987, test_auc = 0.94617, time = 0.01232\n",
      "Epoch: 0230 | train_loss = 0.02814, train_auc = 0.98835, test_loss = 0.03871, test_auc = 0.94840, time = 0.01230\n",
      "Epoch: 0240 | train_loss = 0.02810, train_auc = 0.98862, test_loss = 0.03819, test_auc = 0.94963, time = 0.01247\n",
      "Epoch: 0250 | train_loss = 0.02670, train_auc = 0.98949, test_loss = 0.04134, test_auc = 0.94074, time = 0.01216\n",
      "Epoch: 0260 | train_loss = 0.02656, train_auc = 0.98852, test_loss = 0.04105, test_auc = 0.94660, time = 0.01232\n",
      "Epoch: 0270 | train_loss = 0.02653, train_auc = 0.98859, test_loss = 0.04139, test_auc = 0.94352, time = 0.01196\n",
      "Epoch: 0280 | train_loss = 0.02652, train_auc = 0.98761, test_loss = 0.04050, test_auc = 0.94840, time = 0.01227\n",
      "Epoch: 0290 | train_loss = 0.02652, train_auc = 0.98758, test_loss = 0.03994, test_auc = 0.94981, time = 0.01253\n",
      "Epoch: 0300 | train_loss = 0.02651, train_auc = 0.98764, test_loss = 0.03993, test_auc = 0.95068, time = 0.01229\n",
      "times: 5, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15370, train_auc = 0.55224, test_loss = 0.08419, test_auc = 0.57210, time = 0.77478\n",
      "Epoch: 0010 | train_loss = 0.06676, train_auc = 0.97195, test_loss = 0.03851, test_auc = 0.95383, time = 0.01505\n",
      "Epoch: 0020 | train_loss = 0.04176, train_auc = 0.99291, test_loss = 0.03941, test_auc = 0.96370, time = 0.01487\n",
      "Epoch: 0030 | train_loss = 0.02776, train_auc = 0.99632, test_loss = 0.03746, test_auc = 0.94691, time = 0.01380\n",
      "Epoch: 0040 | train_loss = 0.01885, train_auc = 0.99627, test_loss = 0.03946, test_auc = 0.94333, time = 0.01276\n",
      "Epoch: 0050 | train_loss = 0.01674, train_auc = 0.99642, test_loss = 0.04068, test_auc = 0.94031, time = 0.01270\n",
      "Epoch: 0060 | train_loss = 0.01635, train_auc = 0.99552, test_loss = 0.04132, test_auc = 0.95321, time = 0.01227\n",
      "Epoch: 0070 | train_loss = 0.01628, train_auc = 0.99553, test_loss = 0.04114, test_auc = 0.95630, time = 0.01239\n",
      "Epoch: 0080 | train_loss = 0.01627, train_auc = 0.99461, test_loss = 0.04139, test_auc = 0.95630, time = 0.01263\n",
      "Epoch: 0090 | train_loss = 0.01626, train_auc = 0.99559, test_loss = 0.04137, test_auc = 0.95593, time = 0.01276\n",
      "Epoch: 0100 | train_loss = 0.01625, train_auc = 0.99459, test_loss = 0.04129, test_auc = 0.95543, time = 0.01190\n",
      "Epoch: 0110 | train_loss = 0.01625, train_auc = 0.99458, test_loss = 0.04128, test_auc = 0.95531, time = 0.01222\n",
      "Epoch: 0120 | train_loss = 0.01625, train_auc = 0.99462, test_loss = 0.04133, test_auc = 0.95531, time = 0.01249\n",
      "Epoch: 0130 | train_loss = 0.01624, train_auc = 0.99459, test_loss = 0.04136, test_auc = 0.95531, time = 0.01214\n",
      "Epoch: 0140 | train_loss = 0.01624, train_auc = 0.99459, test_loss = 0.04135, test_auc = 0.95556, time = 0.01230\n",
      "Epoch: 0150 | train_loss = 0.01624, train_auc = 0.99462, test_loss = 0.04131, test_auc = 0.95556, time = 0.01226\n",
      "Epoch: 0160 | train_loss = 0.01624, train_auc = 0.99562, test_loss = 0.04131, test_auc = 0.95543, time = 0.01265\n",
      "Epoch: 0170 | train_loss = 0.01624, train_auc = 0.99462, test_loss = 0.04130, test_auc = 0.95556, time = 0.01219\n",
      "Epoch: 0180 | train_loss = 0.01624, train_auc = 0.99563, test_loss = 0.04128, test_auc = 0.95568, time = 0.01252\n",
      "Epoch: 0190 | train_loss = 0.01624, train_auc = 0.99462, test_loss = 0.04126, test_auc = 0.95568, time = 0.01299\n",
      "Epoch: 0200 | train_loss = 0.01624, train_auc = 0.99462, test_loss = 0.04125, test_auc = 0.95543, time = 0.01235\n",
      "Epoch: 0210 | train_loss = 0.01624, train_auc = 0.99463, test_loss = 0.04123, test_auc = 0.95543, time = 0.01242\n",
      "Epoch: 0220 | train_loss = 0.01624, train_auc = 0.99463, test_loss = 0.04121, test_auc = 0.95543, time = 0.01226\n",
      "Epoch: 0230 | train_loss = 0.01624, train_auc = 0.99461, test_loss = 0.04119, test_auc = 0.95543, time = 0.01510\n",
      "Epoch: 0240 | train_loss = 0.01624, train_auc = 0.99463, test_loss = 0.04117, test_auc = 0.95531, time = 0.01228\n",
      "Epoch: 0250 | train_loss = 0.01624, train_auc = 0.99566, test_loss = 0.04115, test_auc = 0.95531, time = 0.01226\n",
      "Epoch: 0260 | train_loss = 0.01624, train_auc = 0.99464, test_loss = 0.04112, test_auc = 0.95531, time = 0.01213\n",
      "Epoch: 0270 | train_loss = 0.01624, train_auc = 0.99564, test_loss = 0.04110, test_auc = 0.95531, time = 0.01618\n",
      "Epoch: 0280 | train_loss = 0.01624, train_auc = 0.99464, test_loss = 0.04107, test_auc = 0.95531, time = 0.01304\n",
      "Epoch: 0290 | train_loss = 0.01624, train_auc = 0.99464, test_loss = 0.04105, test_auc = 0.95556, time = 0.01248\n",
      "Epoch: 0300 | train_loss = 0.01624, train_auc = 0.99463, test_loss = 0.04103, test_auc = 0.95556, time = 0.01194\n",
      "times: 5, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.16926, train_auc = 0.42556, test_loss = 0.07835, test_auc = 0.62099, time = 0.77014\n",
      "Epoch: 0010 | train_loss = 0.06669, train_auc = 0.98153, test_loss = 0.04486, test_auc = 0.91309, time = 0.01687\n",
      "Epoch: 0020 | train_loss = 0.04313, train_auc = 0.99077, test_loss = 0.04919, test_auc = 0.91438, time = 0.01463\n",
      "Epoch: 0030 | train_loss = 0.03235, train_auc = 0.99258, test_loss = 0.04913, test_auc = 0.91802, time = 0.01371\n",
      "Epoch: 0040 | train_loss = 0.02234, train_auc = 0.99398, test_loss = 0.04779, test_auc = 0.90944, time = 0.01253\n",
      "Epoch: 0050 | train_loss = 0.01807, train_auc = 0.99735, test_loss = 0.04745, test_auc = 0.91654, time = 0.01277\n",
      "Epoch: 0060 | train_loss = 0.01427, train_auc = 0.99738, test_loss = 0.04196, test_auc = 0.92426, time = 0.01258\n",
      "Epoch: 0070 | train_loss = 0.01357, train_auc = 0.99733, test_loss = 0.04430, test_auc = 0.92179, time = 0.01276\n",
      "Epoch: 0080 | train_loss = 0.01338, train_auc = 0.99741, test_loss = 0.04378, test_auc = 0.92494, time = 0.01258\n",
      "Epoch: 0090 | train_loss = 0.01333, train_auc = 0.99747, test_loss = 0.04606, test_auc = 0.92519, time = 0.01256\n",
      "Epoch: 0100 | train_loss = 0.01330, train_auc = 0.99647, test_loss = 0.04552, test_auc = 0.92654, time = 0.01274\n",
      "Epoch: 0110 | train_loss = 0.01329, train_auc = 0.99647, test_loss = 0.04564, test_auc = 0.92395, time = 0.01278\n",
      "Epoch: 0120 | train_loss = 0.01328, train_auc = 0.99647, test_loss = 0.04577, test_auc = 0.92370, time = 0.01295\n",
      "Epoch: 0130 | train_loss = 0.01328, train_auc = 0.99647, test_loss = 0.04566, test_auc = 0.92457, time = 0.01596\n",
      "Epoch: 0140 | train_loss = 0.01327, train_auc = 0.99648, test_loss = 0.04568, test_auc = 0.92407, time = 0.01244\n",
      "Epoch: 0150 | train_loss = 0.01327, train_auc = 0.99647, test_loss = 0.04552, test_auc = 0.92420, time = 0.01263\n",
      "Epoch: 0160 | train_loss = 0.01327, train_auc = 0.99647, test_loss = 0.04548, test_auc = 0.92407, time = 0.01217\n",
      "Epoch: 0170 | train_loss = 0.01327, train_auc = 0.99647, test_loss = 0.04573, test_auc = 0.92364, time = 0.01242\n",
      "Epoch: 0180 | train_loss = 0.01327, train_auc = 0.99648, test_loss = 0.04588, test_auc = 0.92364, time = 0.01268\n",
      "Epoch: 0190 | train_loss = 0.01327, train_auc = 0.99647, test_loss = 0.04593, test_auc = 0.92364, time = 0.01310\n",
      "Epoch: 0200 | train_loss = 0.01326, train_auc = 0.99647, test_loss = 0.04604, test_auc = 0.92315, time = 0.01276\n",
      "Epoch: 0210 | train_loss = 0.01326, train_auc = 0.99650, test_loss = 0.04620, test_auc = 0.92290, time = 0.01212\n",
      "Epoch: 0220 | train_loss = 0.01326, train_auc = 0.99649, test_loss = 0.04626, test_auc = 0.92198, time = 0.01259\n",
      "Epoch: 0230 | train_loss = 0.01326, train_auc = 0.99648, test_loss = 0.04709, test_auc = 0.92080, time = 0.01267\n",
      "Epoch: 0240 | train_loss = 0.01326, train_auc = 0.99650, test_loss = 0.04745, test_auc = 0.92056, time = 0.01301\n",
      "Epoch: 0250 | train_loss = 0.01326, train_auc = 0.99650, test_loss = 0.04752, test_auc = 0.92031, time = 0.01261\n",
      "Epoch: 0260 | train_loss = 0.01326, train_auc = 0.99650, test_loss = 0.04748, test_auc = 0.92019, time = 0.01218\n",
      "Epoch: 0270 | train_loss = 0.01326, train_auc = 0.99650, test_loss = 0.04746, test_auc = 0.91994, time = 0.01254\n",
      "Epoch: 0280 | train_loss = 0.01326, train_auc = 0.99649, test_loss = 0.04740, test_auc = 0.91994, time = 0.01323\n",
      "Epoch: 0290 | train_loss = 0.01326, train_auc = 0.99650, test_loss = 0.04737, test_auc = 0.91994, time = 0.01250\n",
      "Epoch: 0300 | train_loss = 0.01326, train_auc = 0.99651, test_loss = 0.04735, test_auc = 0.92006, time = 0.01370\n",
      "times: 5, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15387, train_auc = 0.59921, test_loss = 0.08323, test_auc = 0.57222, time = 0.74621\n",
      "Epoch: 0010 | train_loss = 0.07928, train_auc = 0.95517, test_loss = 0.05727, test_auc = 0.87580, time = 0.01499\n",
      "Epoch: 0020 | train_loss = 0.05544, train_auc = 0.98184, test_loss = 0.04816, test_auc = 0.87099, time = 0.01342\n",
      "Epoch: 0030 | train_loss = 0.04666, train_auc = 0.98082, test_loss = 0.06342, test_auc = 0.74284, time = 0.01236\n",
      "Epoch: 0040 | train_loss = 0.04257, train_auc = 0.98033, test_loss = 0.04205, test_auc = 0.94043, time = 0.02174\n",
      "Epoch: 0050 | train_loss = 0.04079, train_auc = 0.98010, test_loss = 0.03855, test_auc = 0.94204, time = 0.01225\n",
      "Epoch: 0060 | train_loss = 0.03997, train_auc = 0.98007, test_loss = 0.04073, test_auc = 0.93228, time = 0.01261\n",
      "Epoch: 0070 | train_loss = 0.03985, train_auc = 0.97941, test_loss = 0.04077, test_auc = 0.93765, time = 0.01261\n",
      "Epoch: 0080 | train_loss = 0.03980, train_auc = 0.98061, test_loss = 0.04016, test_auc = 0.93815, time = 0.01196\n",
      "Epoch: 0090 | train_loss = 0.03880, train_auc = 0.98024, test_loss = 0.04210, test_auc = 0.93506, time = 0.01214\n",
      "Epoch: 0100 | train_loss = 0.03704, train_auc = 0.98183, test_loss = 0.04314, test_auc = 0.91056, time = 0.01250\n",
      "Epoch: 0110 | train_loss = 0.03661, train_auc = 0.98088, test_loss = 0.04122, test_auc = 0.93599, time = 0.01226\n",
      "Epoch: 0120 | train_loss = 0.03639, train_auc = 0.98194, test_loss = 0.04035, test_auc = 0.94025, time = 0.01227\n",
      "Epoch: 0130 | train_loss = 0.03635, train_auc = 0.98104, test_loss = 0.04063, test_auc = 0.94173, time = 0.01238\n",
      "Epoch: 0140 | train_loss = 0.03632, train_auc = 0.98094, test_loss = 0.04023, test_auc = 0.94173, time = 0.01203\n",
      "Epoch: 0150 | train_loss = 0.03630, train_auc = 0.98100, test_loss = 0.04006, test_auc = 0.94247, time = 0.01193\n",
      "Epoch: 0160 | train_loss = 0.03554, train_auc = 0.98147, test_loss = 0.03925, test_auc = 0.94179, time = 0.01229\n",
      "Epoch: 0170 | train_loss = 0.03510, train_auc = 0.98257, test_loss = 0.04128, test_auc = 0.94191, time = 0.01216\n",
      "Epoch: 0180 | train_loss = 0.03405, train_auc = 0.98363, test_loss = 0.04269, test_auc = 0.93630, time = 0.01215\n",
      "Epoch: 0190 | train_loss = 0.03383, train_auc = 0.98312, test_loss = 0.04293, test_auc = 0.93914, time = 0.01211\n",
      "Epoch: 0200 | train_loss = 0.03296, train_auc = 0.98530, test_loss = 0.04267, test_auc = 0.93852, time = 0.01209\n",
      "Epoch: 0210 | train_loss = 0.03254, train_auc = 0.98532, test_loss = 0.04021, test_auc = 0.94821, time = 0.01204\n",
      "Epoch: 0220 | train_loss = 0.03250, train_auc = 0.98515, test_loss = 0.04007, test_auc = 0.94796, time = 0.01185\n",
      "Epoch: 0230 | train_loss = 0.03248, train_auc = 0.98323, test_loss = 0.04013, test_auc = 0.94444, time = 0.01196\n",
      "Epoch: 0240 | train_loss = 0.03247, train_auc = 0.98326, test_loss = 0.03992, test_auc = 0.94568, time = 0.01209\n",
      "Epoch: 0250 | train_loss = 0.03247, train_auc = 0.98325, test_loss = 0.03973, test_auc = 0.94617, time = 0.01211\n",
      "Epoch: 0260 | train_loss = 0.03247, train_auc = 0.98441, test_loss = 0.03967, test_auc = 0.94568, time = 0.01253\n",
      "Epoch: 0270 | train_loss = 0.03247, train_auc = 0.98328, test_loss = 0.03966, test_auc = 0.94543, time = 0.01217\n",
      "Epoch: 0280 | train_loss = 0.03247, train_auc = 0.98338, test_loss = 0.03968, test_auc = 0.94556, time = 0.01249\n",
      "Epoch: 0290 | train_loss = 0.03247, train_auc = 0.98344, test_loss = 0.03974, test_auc = 0.94580, time = 0.01241\n",
      "Epoch: 0300 | train_loss = 0.03247, train_auc = 0.98340, test_loss = 0.03982, test_auc = 0.94568, time = 0.01255\n",
      "times: 6, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13356, train_auc = 0.76038, test_loss = 0.06073, test_auc = 0.77556, time = 0.76171\n",
      "Epoch: 0010 | train_loss = 0.07228, train_auc = 0.96266, test_loss = 0.04872, test_auc = 0.91951, time = 0.01556\n",
      "Epoch: 0020 | train_loss = 0.05165, train_auc = 0.98118, test_loss = 0.04400, test_auc = 0.93444, time = 0.01662\n",
      "Epoch: 0030 | train_loss = 0.03437, train_auc = 0.98798, test_loss = 0.06255, test_auc = 0.78568, time = 0.01383\n",
      "Epoch: 0040 | train_loss = 0.02651, train_auc = 0.98991, test_loss = 0.06536, test_auc = 0.62951, time = 0.01382\n",
      "Epoch: 0050 | train_loss = 0.02349, train_auc = 0.99077, test_loss = 0.06148, test_auc = 0.65741, time = 0.01274\n",
      "Epoch: 0060 | train_loss = 0.02123, train_auc = 0.98931, test_loss = 0.06389, test_auc = 0.65284, time = 0.01732\n",
      "Epoch: 0070 | train_loss = 0.02109, train_auc = 0.99103, test_loss = 0.06355, test_auc = 0.74494, time = 0.01297\n",
      "Epoch: 0080 | train_loss = 0.02101, train_auc = 0.99115, test_loss = 0.06294, test_auc = 0.72123, time = 0.01260\n",
      "Epoch: 0090 | train_loss = 0.02099, train_auc = 0.99118, test_loss = 0.06251, test_auc = 0.75654, time = 0.01230\n",
      "Epoch: 0100 | train_loss = 0.02098, train_auc = 0.99126, test_loss = 0.06228, test_auc = 0.77568, time = 0.01261\n",
      "Epoch: 0110 | train_loss = 0.02097, train_auc = 0.99122, test_loss = 0.06210, test_auc = 0.78753, time = 0.01235\n",
      "Epoch: 0120 | train_loss = 0.02097, train_auc = 0.99128, test_loss = 0.06194, test_auc = 0.79926, time = 0.01244\n",
      "Epoch: 0130 | train_loss = 0.02097, train_auc = 0.99124, test_loss = 0.06175, test_auc = 0.81469, time = 0.01294\n",
      "Epoch: 0140 | train_loss = 0.02097, train_auc = 0.99134, test_loss = 0.06155, test_auc = 0.82920, time = 0.01282\n",
      "Epoch: 0150 | train_loss = 0.02097, train_auc = 0.99126, test_loss = 0.06134, test_auc = 0.83963, time = 0.01324\n",
      "Epoch: 0160 | train_loss = 0.02097, train_auc = 0.99132, test_loss = 0.06115, test_auc = 0.84617, time = 0.01412\n",
      "Epoch: 0170 | train_loss = 0.02096, train_auc = 0.99132, test_loss = 0.06095, test_auc = 0.85198, time = 0.01250\n",
      "Epoch: 0180 | train_loss = 0.02096, train_auc = 0.99132, test_loss = 0.06074, test_auc = 0.85716, time = 0.01241\n",
      "Epoch: 0190 | train_loss = 0.02096, train_auc = 0.99130, test_loss = 0.06050, test_auc = 0.86123, time = 0.01252\n",
      "Epoch: 0200 | train_loss = 0.02096, train_auc = 0.99132, test_loss = 0.06024, test_auc = 0.86617, time = 0.01320\n",
      "Epoch: 0210 | train_loss = 0.02096, train_auc = 0.99136, test_loss = 0.05995, test_auc = 0.87019, time = 0.01259\n",
      "Epoch: 0220 | train_loss = 0.02096, train_auc = 0.99140, test_loss = 0.05964, test_auc = 0.87321, time = 0.01273\n",
      "Epoch: 0230 | train_loss = 0.02096, train_auc = 0.99140, test_loss = 0.05929, test_auc = 0.87475, time = 0.01332\n",
      "Epoch: 0240 | train_loss = 0.02096, train_auc = 0.99138, test_loss = 0.05891, test_auc = 0.87617, time = 0.01298\n",
      "Epoch: 0250 | train_loss = 0.02096, train_auc = 0.99136, test_loss = 0.05850, test_auc = 0.87759, time = 0.01251\n",
      "Epoch: 0260 | train_loss = 0.02096, train_auc = 0.99140, test_loss = 0.05806, test_auc = 0.87765, time = 0.01258\n",
      "Epoch: 0270 | train_loss = 0.02096, train_auc = 0.99144, test_loss = 0.05759, test_auc = 0.87858, time = 0.01259\n",
      "Epoch: 0280 | train_loss = 0.02096, train_auc = 0.99145, test_loss = 0.05710, test_auc = 0.87963, time = 0.01245\n",
      "Epoch: 0290 | train_loss = 0.02096, train_auc = 0.99142, test_loss = 0.05659, test_auc = 0.88068, time = 0.01239\n",
      "Epoch: 0300 | train_loss = 0.02096, train_auc = 0.99142, test_loss = 0.05607, test_auc = 0.88352, time = 0.01254\n",
      "times: 6, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14136, train_auc = 0.65902, test_loss = 0.06285, test_auc = 0.75543, time = 0.75430\n",
      "Epoch: 0010 | train_loss = 0.06060, train_auc = 0.97276, test_loss = 0.05142, test_auc = 0.89840, time = 0.01519\n",
      "Epoch: 0020 | train_loss = 0.03894, train_auc = 0.98980, test_loss = 0.03661, test_auc = 0.94753, time = 0.01494\n",
      "Epoch: 0030 | train_loss = 0.02821, train_auc = 0.99161, test_loss = 0.03450, test_auc = 0.95796, time = 0.01361\n",
      "Epoch: 0040 | train_loss = 0.02284, train_auc = 0.99191, test_loss = 0.03325, test_auc = 0.96037, time = 0.01272\n",
      "Epoch: 0050 | train_loss = 0.02125, train_auc = 0.99206, test_loss = 0.03123, test_auc = 0.95080, time = 0.01272\n",
      "Epoch: 0060 | train_loss = 0.02107, train_auc = 0.99109, test_loss = 0.03195, test_auc = 0.94852, time = 0.01354\n",
      "Epoch: 0070 | train_loss = 0.02100, train_auc = 0.99113, test_loss = 0.03277, test_auc = 0.94889, time = 0.01243\n",
      "Epoch: 0080 | train_loss = 0.02098, train_auc = 0.99115, test_loss = 0.03328, test_auc = 0.94914, time = 0.01252\n",
      "Epoch: 0090 | train_loss = 0.02098, train_auc = 0.99220, test_loss = 0.03350, test_auc = 0.94870, time = 0.01225\n",
      "Epoch: 0100 | train_loss = 0.02097, train_auc = 0.99113, test_loss = 0.03348, test_auc = 0.94802, time = 0.01987\n",
      "Epoch: 0110 | train_loss = 0.02097, train_auc = 0.99113, test_loss = 0.03358, test_auc = 0.94741, time = 0.01271\n",
      "Epoch: 0120 | train_loss = 0.02097, train_auc = 0.99117, test_loss = 0.03358, test_auc = 0.95123, time = 0.01230\n",
      "Epoch: 0130 | train_loss = 0.02097, train_auc = 0.99118, test_loss = 0.03356, test_auc = 0.94716, time = 0.01249\n",
      "Epoch: 0140 | train_loss = 0.02097, train_auc = 0.99117, test_loss = 0.03353, test_auc = 0.94691, time = 0.01230\n",
      "Epoch: 0150 | train_loss = 0.02097, train_auc = 0.99220, test_loss = 0.03351, test_auc = 0.94679, time = 0.01258\n",
      "Epoch: 0160 | train_loss = 0.02096, train_auc = 0.99117, test_loss = 0.03349, test_auc = 0.94654, time = 0.01280\n",
      "Epoch: 0170 | train_loss = 0.02096, train_auc = 0.99115, test_loss = 0.03348, test_auc = 0.94642, time = 0.01277\n",
      "Epoch: 0180 | train_loss = 0.02096, train_auc = 0.99117, test_loss = 0.03347, test_auc = 0.94593, time = 0.01245\n",
      "Epoch: 0190 | train_loss = 0.02096, train_auc = 0.99118, test_loss = 0.03346, test_auc = 0.94617, time = 0.01230\n",
      "Epoch: 0200 | train_loss = 0.02096, train_auc = 0.99117, test_loss = 0.03344, test_auc = 0.94580, time = 0.01380\n",
      "Epoch: 0210 | train_loss = 0.02096, train_auc = 0.99115, test_loss = 0.03343, test_auc = 0.94586, time = 0.01257\n",
      "Epoch: 0220 | train_loss = 0.02096, train_auc = 0.99117, test_loss = 0.03342, test_auc = 0.94654, time = 0.01226\n",
      "Epoch: 0230 | train_loss = 0.02096, train_auc = 0.99117, test_loss = 0.03341, test_auc = 0.94630, time = 0.01267\n",
      "Epoch: 0240 | train_loss = 0.02096, train_auc = 0.99120, test_loss = 0.03340, test_auc = 0.94667, time = 0.01282\n",
      "Epoch: 0250 | train_loss = 0.02096, train_auc = 0.99218, test_loss = 0.03339, test_auc = 0.94630, time = 0.01243\n",
      "Epoch: 0260 | train_loss = 0.02096, train_auc = 0.99117, test_loss = 0.03338, test_auc = 0.94611, time = 0.01249\n",
      "Epoch: 0270 | train_loss = 0.02096, train_auc = 0.99120, test_loss = 0.03337, test_auc = 0.94611, time = 0.01245\n",
      "Epoch: 0280 | train_loss = 0.02096, train_auc = 0.99118, test_loss = 0.03336, test_auc = 0.94636, time = 0.01250\n",
      "Epoch: 0290 | train_loss = 0.02096, train_auc = 0.99120, test_loss = 0.03335, test_auc = 0.94617, time = 0.01224\n",
      "Epoch: 0300 | train_loss = 0.02096, train_auc = 0.99117, test_loss = 0.03334, test_auc = 0.94642, time = 0.01227\n",
      "times: 6, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.16809, train_auc = 0.40439, test_loss = 0.08622, test_auc = 0.55080, time = 0.80051\n",
      "Epoch: 0010 | train_loss = 0.06997, train_auc = 0.97334, test_loss = 0.04127, test_auc = 0.95407, time = 0.01557\n",
      "Epoch: 0020 | train_loss = 0.05450, train_auc = 0.98006, test_loss = 0.02573, test_auc = 0.97772, time = 0.01420\n",
      "Epoch: 0030 | train_loss = 0.04025, train_auc = 0.98718, test_loss = 0.02314, test_auc = 0.97840, time = 0.01334\n",
      "Epoch: 0040 | train_loss = 0.03208, train_auc = 0.98749, test_loss = 0.02898, test_auc = 0.97549, time = 0.01281\n",
      "Epoch: 0050 | train_loss = 0.02947, train_auc = 0.98767, test_loss = 0.03324, test_auc = 0.97154, time = 0.01375\n",
      "Epoch: 0060 | train_loss = 0.02792, train_auc = 0.99094, test_loss = 0.03239, test_auc = 0.97414, time = 0.01272\n",
      "Epoch: 0070 | train_loss = 0.02520, train_auc = 0.98887, test_loss = 0.02966, test_auc = 0.97235, time = 0.01336\n",
      "Epoch: 0080 | train_loss = 0.02335, train_auc = 0.99166, test_loss = 0.03151, test_auc = 0.96951, time = 0.01333\n",
      "Epoch: 0090 | train_loss = 0.02310, train_auc = 0.99106, test_loss = 0.02945, test_auc = 0.96790, time = 0.01270\n",
      "Epoch: 0100 | train_loss = 0.02302, train_auc = 0.99107, test_loss = 0.02887, test_auc = 0.97037, time = 0.01279\n",
      "Epoch: 0110 | train_loss = 0.02299, train_auc = 0.99098, test_loss = 0.02844, test_auc = 0.97025, time = 0.01283\n",
      "Epoch: 0120 | train_loss = 0.02298, train_auc = 0.99093, test_loss = 0.02905, test_auc = 0.97099, time = 0.01279\n",
      "Epoch: 0130 | train_loss = 0.02297, train_auc = 0.99084, test_loss = 0.02929, test_auc = 0.96975, time = 0.01230\n",
      "Epoch: 0140 | train_loss = 0.02297, train_auc = 0.99086, test_loss = 0.02955, test_auc = 0.97025, time = 0.01231\n",
      "Epoch: 0150 | train_loss = 0.02297, train_auc = 0.99085, test_loss = 0.02966, test_auc = 0.96938, time = 0.01619\n",
      "Epoch: 0160 | train_loss = 0.02297, train_auc = 0.99081, test_loss = 0.02967, test_auc = 0.96852, time = 0.01255\n",
      "Epoch: 0170 | train_loss = 0.02297, train_auc = 0.99084, test_loss = 0.02972, test_auc = 0.96790, time = 0.01264\n",
      "Epoch: 0180 | train_loss = 0.02297, train_auc = 0.99078, test_loss = 0.02976, test_auc = 0.96765, time = 0.01235\n",
      "Epoch: 0190 | train_loss = 0.02296, train_auc = 0.99083, test_loss = 0.02979, test_auc = 0.96741, time = 0.01231\n",
      "Epoch: 0200 | train_loss = 0.02296, train_auc = 0.99069, test_loss = 0.02979, test_auc = 0.96741, time = 0.01205\n",
      "Epoch: 0210 | train_loss = 0.02296, train_auc = 0.99072, test_loss = 0.02978, test_auc = 0.96741, time = 0.01210\n",
      "Epoch: 0220 | train_loss = 0.02296, train_auc = 0.99069, test_loss = 0.02979, test_auc = 0.96691, time = 0.01221\n",
      "Epoch: 0230 | train_loss = 0.02296, train_auc = 0.99066, test_loss = 0.02980, test_auc = 0.96691, time = 0.01247\n",
      "Epoch: 0240 | train_loss = 0.02296, train_auc = 0.99074, test_loss = 0.02980, test_auc = 0.96617, time = 0.01200\n",
      "Epoch: 0250 | train_loss = 0.02296, train_auc = 0.98975, test_loss = 0.02980, test_auc = 0.96617, time = 0.01198\n",
      "Epoch: 0260 | train_loss = 0.02296, train_auc = 0.98981, test_loss = 0.02981, test_auc = 0.96593, time = 0.01399\n",
      "Epoch: 0270 | train_loss = 0.02296, train_auc = 0.98982, test_loss = 0.02982, test_auc = 0.96617, time = 0.01248\n",
      "Epoch: 0280 | train_loss = 0.02296, train_auc = 0.98975, test_loss = 0.02983, test_auc = 0.96568, time = 0.01316\n",
      "Epoch: 0290 | train_loss = 0.02296, train_auc = 0.99062, test_loss = 0.02985, test_auc = 0.96519, time = 0.01265\n",
      "Epoch: 0300 | train_loss = 0.02296, train_auc = 0.98970, test_loss = 0.02986, test_auc = 0.96506, time = 0.01240\n",
      "times: 6, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14950, train_auc = 0.58769, test_loss = 0.10314, test_auc = 0.32204, time = 0.75653\n",
      "Epoch: 0010 | train_loss = 0.06652, train_auc = 0.97812, test_loss = 0.06102, test_auc = 0.90012, time = 0.01480\n",
      "Epoch: 0020 | train_loss = 0.04614, train_auc = 0.97818, test_loss = 0.03895, test_auc = 0.95623, time = 0.01532\n",
      "Epoch: 0030 | train_loss = 0.03943, train_auc = 0.98146, test_loss = 0.03337, test_auc = 0.97383, time = 0.01315\n",
      "Epoch: 0040 | train_loss = 0.03501, train_auc = 0.98349, test_loss = 0.03488, test_auc = 0.96975, time = 0.01262\n",
      "Epoch: 0050 | train_loss = 0.03287, train_auc = 0.98319, test_loss = 0.04003, test_auc = 0.94370, time = 0.01269\n",
      "Epoch: 0060 | train_loss = 0.03137, train_auc = 0.98286, test_loss = 0.03513, test_auc = 0.97543, time = 0.01255\n",
      "Epoch: 0070 | train_loss = 0.03121, train_auc = 0.98255, test_loss = 0.03607, test_auc = 0.97506, time = 0.01235\n",
      "Epoch: 0080 | train_loss = 0.03115, train_auc = 0.98188, test_loss = 0.03557, test_auc = 0.97543, time = 0.01342\n",
      "Epoch: 0090 | train_loss = 0.03113, train_auc = 0.98200, test_loss = 0.03542, test_auc = 0.97407, time = 0.01365\n",
      "Epoch: 0100 | train_loss = 0.03112, train_auc = 0.98204, test_loss = 0.03514, test_auc = 0.97395, time = 0.01246\n",
      "Epoch: 0110 | train_loss = 0.03111, train_auc = 0.98295, test_loss = 0.03510, test_auc = 0.97358, time = 0.01386\n",
      "Epoch: 0120 | train_loss = 0.03111, train_auc = 0.98284, test_loss = 0.03516, test_auc = 0.97370, time = 0.01542\n",
      "Epoch: 0130 | train_loss = 0.03110, train_auc = 0.98279, test_loss = 0.03515, test_auc = 0.97364, time = 0.01331\n",
      "Epoch: 0140 | train_loss = 0.03110, train_auc = 0.98283, test_loss = 0.03508, test_auc = 0.97370, time = 0.01253\n",
      "Epoch: 0150 | train_loss = 0.03110, train_auc = 0.98284, test_loss = 0.03506, test_auc = 0.97370, time = 0.01251\n",
      "Epoch: 0160 | train_loss = 0.03110, train_auc = 0.98284, test_loss = 0.03508, test_auc = 0.97401, time = 0.01260\n",
      "Epoch: 0170 | train_loss = 0.03110, train_auc = 0.98281, test_loss = 0.03508, test_auc = 0.97389, time = 0.01252\n",
      "Epoch: 0180 | train_loss = 0.03110, train_auc = 0.98286, test_loss = 0.03508, test_auc = 0.97420, time = 0.01383\n",
      "Epoch: 0190 | train_loss = 0.03109, train_auc = 0.98278, test_loss = 0.03509, test_auc = 0.97414, time = 0.01271\n",
      "Epoch: 0200 | train_loss = 0.03109, train_auc = 0.98287, test_loss = 0.03509, test_auc = 0.97414, time = 0.01226\n",
      "Epoch: 0210 | train_loss = 0.03109, train_auc = 0.98285, test_loss = 0.03509, test_auc = 0.97414, time = 0.01280\n",
      "Epoch: 0220 | train_loss = 0.03109, train_auc = 0.98287, test_loss = 0.03510, test_auc = 0.97438, time = 0.01321\n",
      "Epoch: 0230 | train_loss = 0.03109, train_auc = 0.98289, test_loss = 0.03510, test_auc = 0.97444, time = 0.01267\n",
      "Epoch: 0240 | train_loss = 0.03109, train_auc = 0.98302, test_loss = 0.03510, test_auc = 0.97414, time = 0.01339\n",
      "Epoch: 0250 | train_loss = 0.03109, train_auc = 0.98299, test_loss = 0.03511, test_auc = 0.97451, time = 0.01252\n",
      "Epoch: 0260 | train_loss = 0.03109, train_auc = 0.98292, test_loss = 0.03511, test_auc = 0.97432, time = 0.01322\n",
      "Epoch: 0270 | train_loss = 0.03109, train_auc = 0.98301, test_loss = 0.03511, test_auc = 0.97438, time = 0.01256\n",
      "Epoch: 0280 | train_loss = 0.03109, train_auc = 0.98306, test_loss = 0.03511, test_auc = 0.97444, time = 0.01331\n",
      "Epoch: 0290 | train_loss = 0.03109, train_auc = 0.98217, test_loss = 0.03512, test_auc = 0.97444, time = 0.01280\n",
      "Epoch: 0300 | train_loss = 0.03109, train_auc = 0.98301, test_loss = 0.03512, test_auc = 0.97444, time = 0.01265\n",
      "times: 6, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.16171, train_auc = 0.47319, test_loss = 0.10393, test_auc = 0.31938, time = 0.76932\n",
      "Epoch: 0010 | train_loss = 0.07579, train_auc = 0.96070, test_loss = 0.04839, test_auc = 0.92123, time = 0.01700\n",
      "Epoch: 0020 | train_loss = 0.05113, train_auc = 0.98716, test_loss = 0.03746, test_auc = 0.95037, time = 0.01320\n",
      "Epoch: 0030 | train_loss = 0.04335, train_auc = 0.98996, test_loss = 0.03481, test_auc = 0.96136, time = 0.01450\n",
      "Epoch: 0040 | train_loss = 0.03672, train_auc = 0.99061, test_loss = 0.03261, test_auc = 0.97210, time = 0.01258\n",
      "Epoch: 0050 | train_loss = 0.02931, train_auc = 0.99127, test_loss = 0.03366, test_auc = 0.97049, time = 0.01330\n",
      "Epoch: 0060 | train_loss = 0.02341, train_auc = 0.99179, test_loss = 0.03371, test_auc = 0.97025, time = 0.01298\n",
      "Epoch: 0070 | train_loss = 0.02188, train_auc = 0.99181, test_loss = 0.03852, test_auc = 0.96284, time = 0.01223\n",
      "Epoch: 0080 | train_loss = 0.02131, train_auc = 0.99186, test_loss = 0.03701, test_auc = 0.95975, time = 0.01220\n",
      "Epoch: 0090 | train_loss = 0.02108, train_auc = 0.99193, test_loss = 0.03683, test_auc = 0.96346, time = 0.01252\n",
      "Epoch: 0100 | train_loss = 0.02103, train_auc = 0.99204, test_loss = 0.03604, test_auc = 0.96679, time = 0.01237\n",
      "Epoch: 0110 | train_loss = 0.02101, train_auc = 0.99199, test_loss = 0.03434, test_auc = 0.97025, time = 0.01235\n",
      "Epoch: 0120 | train_loss = 0.02100, train_auc = 0.99202, test_loss = 0.03419, test_auc = 0.97049, time = 0.01248\n",
      "Epoch: 0130 | train_loss = 0.02099, train_auc = 0.99197, test_loss = 0.03404, test_auc = 0.97099, time = 0.01280\n",
      "Epoch: 0140 | train_loss = 0.02098, train_auc = 0.99201, test_loss = 0.03385, test_auc = 0.97148, time = 0.01212\n",
      "Epoch: 0150 | train_loss = 0.02098, train_auc = 0.99200, test_loss = 0.03385, test_auc = 0.97173, time = 0.01217\n",
      "Epoch: 0160 | train_loss = 0.02098, train_auc = 0.99203, test_loss = 0.03392, test_auc = 0.97160, time = 0.01246\n",
      "Epoch: 0170 | train_loss = 0.02098, train_auc = 0.99204, test_loss = 0.03408, test_auc = 0.97136, time = 0.01270\n",
      "Epoch: 0180 | train_loss = 0.02097, train_auc = 0.99206, test_loss = 0.03423, test_auc = 0.97099, time = 0.01294\n",
      "Epoch: 0190 | train_loss = 0.02097, train_auc = 0.99202, test_loss = 0.03433, test_auc = 0.97123, time = 0.01268\n",
      "Epoch: 0200 | train_loss = 0.02097, train_auc = 0.99202, test_loss = 0.03437, test_auc = 0.97123, time = 0.01242\n",
      "Epoch: 0210 | train_loss = 0.02097, train_auc = 0.99204, test_loss = 0.03451, test_auc = 0.97111, time = 0.01253\n",
      "Epoch: 0220 | train_loss = 0.02097, train_auc = 0.99205, test_loss = 0.03458, test_auc = 0.97086, time = 0.01257\n",
      "Epoch: 0230 | train_loss = 0.02097, train_auc = 0.99204, test_loss = 0.03467, test_auc = 0.97074, time = 0.01241\n",
      "Epoch: 0240 | train_loss = 0.02097, train_auc = 0.99204, test_loss = 0.03473, test_auc = 0.97062, time = 0.01238\n",
      "Epoch: 0250 | train_loss = 0.02097, train_auc = 0.99210, test_loss = 0.03480, test_auc = 0.97049, time = 0.01308\n",
      "Epoch: 0260 | train_loss = 0.02096, train_auc = 0.99205, test_loss = 0.03486, test_auc = 0.97025, time = 0.01248\n",
      "Epoch: 0270 | train_loss = 0.02096, train_auc = 0.99207, test_loss = 0.03491, test_auc = 0.97012, time = 0.01228\n",
      "Epoch: 0280 | train_loss = 0.02096, train_auc = 0.99205, test_loss = 0.03496, test_auc = 0.97012, time = 0.01239\n",
      "Epoch: 0290 | train_loss = 0.02096, train_auc = 0.99202, test_loss = 0.03501, test_auc = 0.97012, time = 0.01213\n",
      "Epoch: 0300 | train_loss = 0.02096, train_auc = 0.99207, test_loss = 0.03507, test_auc = 0.97012, time = 0.01791\n",
      "times: 7, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14863, train_auc = 0.59224, test_loss = 0.10159, test_auc = 0.34370, time = 0.77426\n",
      "Epoch: 0010 | train_loss = 0.07167, train_auc = 0.96671, test_loss = 0.05967, test_auc = 0.85148, time = 0.01505\n",
      "Epoch: 0020 | train_loss = 0.04420, train_auc = 0.99139, test_loss = 0.03175, test_auc = 0.97173, time = 0.01516\n",
      "Epoch: 0030 | train_loss = 0.02779, train_auc = 0.99514, test_loss = 0.03205, test_auc = 0.97494, time = 0.01345\n",
      "Epoch: 0040 | train_loss = 0.02031, train_auc = 0.99449, test_loss = 0.03028, test_auc = 0.97840, time = 0.01286\n",
      "Epoch: 0050 | train_loss = 0.01913, train_auc = 0.99540, test_loss = 0.03623, test_auc = 0.96519, time = 0.01238\n",
      "Epoch: 0060 | train_loss = 0.01889, train_auc = 0.99356, test_loss = 0.03162, test_auc = 0.97148, time = 0.01220\n",
      "Epoch: 0070 | train_loss = 0.01881, train_auc = 0.99363, test_loss = 0.03101, test_auc = 0.97716, time = 0.01265\n",
      "Epoch: 0080 | train_loss = 0.01879, train_auc = 0.99365, test_loss = 0.03105, test_auc = 0.97469, time = 0.01277\n",
      "Epoch: 0090 | train_loss = 0.01878, train_auc = 0.99362, test_loss = 0.03153, test_auc = 0.97457, time = 0.01249\n",
      "Epoch: 0100 | train_loss = 0.01878, train_auc = 0.99368, test_loss = 0.03175, test_auc = 0.97556, time = 0.01217\n",
      "Epoch: 0110 | train_loss = 0.01877, train_auc = 0.99365, test_loss = 0.03187, test_auc = 0.97469, time = 0.01217\n",
      "Epoch: 0120 | train_loss = 0.01877, train_auc = 0.99368, test_loss = 0.03187, test_auc = 0.97469, time = 0.01261\n",
      "Epoch: 0130 | train_loss = 0.01877, train_auc = 0.99367, test_loss = 0.03186, test_auc = 0.97494, time = 0.01303\n",
      "Epoch: 0140 | train_loss = 0.01876, train_auc = 0.99367, test_loss = 0.03180, test_auc = 0.97481, time = 0.01293\n",
      "Epoch: 0150 | train_loss = 0.01876, train_auc = 0.99368, test_loss = 0.03186, test_auc = 0.97481, time = 0.01239\n",
      "Epoch: 0160 | train_loss = 0.01876, train_auc = 0.99367, test_loss = 0.03184, test_auc = 0.97457, time = 0.01243\n",
      "Epoch: 0170 | train_loss = 0.01876, train_auc = 0.99368, test_loss = 0.03187, test_auc = 0.97469, time = 0.01237\n",
      "Epoch: 0180 | train_loss = 0.01876, train_auc = 0.99367, test_loss = 0.03188, test_auc = 0.97481, time = 0.01235\n",
      "Epoch: 0190 | train_loss = 0.01876, train_auc = 0.99368, test_loss = 0.03189, test_auc = 0.97506, time = 0.01259\n",
      "Epoch: 0200 | train_loss = 0.01876, train_auc = 0.99368, test_loss = 0.03189, test_auc = 0.97506, time = 0.01243\n",
      "Epoch: 0210 | train_loss = 0.01875, train_auc = 0.99368, test_loss = 0.03190, test_auc = 0.97506, time = 0.01281\n",
      "Epoch: 0220 | train_loss = 0.01875, train_auc = 0.99367, test_loss = 0.03191, test_auc = 0.97506, time = 0.01232\n",
      "Epoch: 0230 | train_loss = 0.01875, train_auc = 0.99367, test_loss = 0.03191, test_auc = 0.97519, time = 0.01257\n",
      "Epoch: 0240 | train_loss = 0.01875, train_auc = 0.99370, test_loss = 0.03192, test_auc = 0.97531, time = 0.01271\n",
      "Epoch: 0250 | train_loss = 0.01875, train_auc = 0.99368, test_loss = 0.03193, test_auc = 0.97531, time = 0.01700\n",
      "Epoch: 0260 | train_loss = 0.01875, train_auc = 0.99368, test_loss = 0.03193, test_auc = 0.97531, time = 0.01239\n",
      "Epoch: 0270 | train_loss = 0.01875, train_auc = 0.99368, test_loss = 0.03194, test_auc = 0.97506, time = 0.01277\n",
      "Epoch: 0280 | train_loss = 0.01875, train_auc = 0.99368, test_loss = 0.03195, test_auc = 0.97494, time = 0.01241\n",
      "Epoch: 0290 | train_loss = 0.01875, train_auc = 0.99371, test_loss = 0.03195, test_auc = 0.97494, time = 0.01711\n",
      "Epoch: 0300 | train_loss = 0.01875, train_auc = 0.99372, test_loss = 0.03195, test_auc = 0.97481, time = 0.01297\n",
      "times: 7, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13444, train_auc = 0.71941, test_loss = 0.07991, test_auc = 0.60432, time = 0.77124\n",
      "Epoch: 0010 | train_loss = 0.07163, train_auc = 0.97419, test_loss = 0.06323, test_auc = 0.93296, time = 0.01516\n",
      "Epoch: 0020 | train_loss = 0.04267, train_auc = 0.99392, test_loss = 0.03634, test_auc = 0.96728, time = 0.01525\n",
      "Epoch: 0030 | train_loss = 0.03139, train_auc = 0.99516, test_loss = 0.02926, test_auc = 0.97420, time = 0.01324\n",
      "Epoch: 0040 | train_loss = 0.02001, train_auc = 0.99758, test_loss = 0.03204, test_auc = 0.96395, time = 0.01221\n",
      "Epoch: 0050 | train_loss = 0.01544, train_auc = 0.99804, test_loss = 0.03202, test_auc = 0.97667, time = 0.01207\n",
      "Epoch: 0060 | train_loss = 0.01067, train_auc = 0.99808, test_loss = 0.03195, test_auc = 0.97173, time = 0.01226\n",
      "Epoch: 0070 | train_loss = 0.00968, train_auc = 0.99808, test_loss = 0.02535, test_auc = 0.97957, time = 0.01195\n",
      "Epoch: 0080 | train_loss = 0.00945, train_auc = 0.99811, test_loss = 0.02343, test_auc = 0.98216, time = 0.01230\n",
      "Epoch: 0090 | train_loss = 0.00941, train_auc = 0.99812, test_loss = 0.02243, test_auc = 0.98278, time = 0.01232\n",
      "Epoch: 0100 | train_loss = 0.00939, train_auc = 0.99813, test_loss = 0.02242, test_auc = 0.98241, time = 0.01212\n",
      "Epoch: 0110 | train_loss = 0.00939, train_auc = 0.99812, test_loss = 0.02215, test_auc = 0.98253, time = 0.01207\n",
      "Epoch: 0120 | train_loss = 0.00938, train_auc = 0.99812, test_loss = 0.02211, test_auc = 0.98241, time = 0.01230\n",
      "Epoch: 0130 | train_loss = 0.00938, train_auc = 0.99813, test_loss = 0.02209, test_auc = 0.98241, time = 0.01295\n",
      "Epoch: 0140 | train_loss = 0.00938, train_auc = 0.99812, test_loss = 0.02204, test_auc = 0.98253, time = 0.01315\n",
      "Epoch: 0150 | train_loss = 0.00938, train_auc = 0.99812, test_loss = 0.02204, test_auc = 0.98253, time = 0.01208\n",
      "Epoch: 0160 | train_loss = 0.00938, train_auc = 0.99812, test_loss = 0.02204, test_auc = 0.98253, time = 0.01295\n",
      "Epoch: 0170 | train_loss = 0.00938, train_auc = 0.99813, test_loss = 0.02204, test_auc = 0.98253, time = 0.01225\n",
      "Epoch: 0180 | train_loss = 0.00938, train_auc = 0.99813, test_loss = 0.02203, test_auc = 0.98253, time = 0.01322\n",
      "Epoch: 0190 | train_loss = 0.00938, train_auc = 0.99813, test_loss = 0.02202, test_auc = 0.98265, time = 0.01248\n",
      "Epoch: 0200 | train_loss = 0.00938, train_auc = 0.99813, test_loss = 0.02202, test_auc = 0.98265, time = 0.01307\n",
      "Epoch: 0210 | train_loss = 0.00938, train_auc = 0.99813, test_loss = 0.02202, test_auc = 0.98265, time = 0.01245\n",
      "Epoch: 0220 | train_loss = 0.00938, train_auc = 0.99813, test_loss = 0.02202, test_auc = 0.98265, time = 0.01981\n",
      "Epoch: 0230 | train_loss = 0.00938, train_auc = 0.99814, test_loss = 0.02202, test_auc = 0.98265, time = 0.01284\n",
      "Epoch: 0240 | train_loss = 0.00938, train_auc = 0.99813, test_loss = 0.02203, test_auc = 0.98272, time = 0.01338\n",
      "Epoch: 0250 | train_loss = 0.00938, train_auc = 0.99813, test_loss = 0.02203, test_auc = 0.98265, time = 0.01233\n",
      "Epoch: 0260 | train_loss = 0.00938, train_auc = 0.99814, test_loss = 0.02204, test_auc = 0.98265, time = 0.01247\n",
      "Epoch: 0270 | train_loss = 0.00938, train_auc = 0.99814, test_loss = 0.02204, test_auc = 0.98272, time = 0.01240\n",
      "Epoch: 0280 | train_loss = 0.00938, train_auc = 0.99814, test_loss = 0.02205, test_auc = 0.98272, time = 0.01384\n",
      "Epoch: 0290 | train_loss = 0.00938, train_auc = 0.99814, test_loss = 0.02205, test_auc = 0.98272, time = 0.01350\n",
      "Epoch: 0300 | train_loss = 0.00938, train_auc = 0.99814, test_loss = 0.02206, test_auc = 0.98272, time = 0.01219\n",
      "times: 7, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14602, train_auc = 0.69040, test_loss = 0.08840, test_auc = 0.50012, time = 0.75437\n",
      "Epoch: 0010 | train_loss = 0.08491, train_auc = 0.93789, test_loss = 0.05245, test_auc = 0.85191, time = 0.01512\n",
      "Epoch: 0020 | train_loss = 0.05372, train_auc = 0.97815, test_loss = 0.06650, test_auc = 0.74556, time = 0.01432\n",
      "Epoch: 0030 | train_loss = 0.05461, train_auc = 0.98448, test_loss = 0.04063, test_auc = 0.95833, time = 0.01317\n",
      "Epoch: 0040 | train_loss = 0.04289, train_auc = 0.98620, test_loss = 0.04237, test_auc = 0.94907, time = 0.01251\n",
      "Epoch: 0050 | train_loss = 0.03645, train_auc = 0.98894, test_loss = 0.04270, test_auc = 0.94537, time = 0.01191\n",
      "Epoch: 0060 | train_loss = 0.03339, train_auc = 0.98958, test_loss = 0.04080, test_auc = 0.95093, time = 0.01250\n",
      "Epoch: 0070 | train_loss = 0.03033, train_auc = 0.99231, test_loss = 0.03876, test_auc = 0.95833, time = 0.01236\n",
      "Epoch: 0080 | train_loss = 0.02564, train_auc = 0.99186, test_loss = 0.03639, test_auc = 0.96432, time = 0.01200\n",
      "Epoch: 0090 | train_loss = 0.02501, train_auc = 0.99186, test_loss = 0.03899, test_auc = 0.96377, time = 0.01187\n",
      "Epoch: 0100 | train_loss = 0.02489, train_auc = 0.99220, test_loss = 0.03958, test_auc = 0.96253, time = 0.01233\n",
      "Epoch: 0110 | train_loss = 0.02485, train_auc = 0.99224, test_loss = 0.03938, test_auc = 0.96191, time = 0.01265\n",
      "Epoch: 0120 | train_loss = 0.02483, train_auc = 0.99230, test_loss = 0.03942, test_auc = 0.96210, time = 0.01255\n",
      "Epoch: 0130 | train_loss = 0.02482, train_auc = 0.99230, test_loss = 0.03988, test_auc = 0.96198, time = 0.01251\n",
      "Epoch: 0140 | train_loss = 0.02481, train_auc = 0.99228, test_loss = 0.03989, test_auc = 0.96191, time = 0.01309\n",
      "Epoch: 0150 | train_loss = 0.02481, train_auc = 0.99231, test_loss = 0.04005, test_auc = 0.96198, time = 0.01212\n",
      "Epoch: 0160 | train_loss = 0.02481, train_auc = 0.99233, test_loss = 0.04014, test_auc = 0.96160, time = 0.01272\n",
      "Epoch: 0170 | train_loss = 0.02481, train_auc = 0.99233, test_loss = 0.04020, test_auc = 0.96148, time = 0.01192\n",
      "Epoch: 0180 | train_loss = 0.02481, train_auc = 0.99237, test_loss = 0.04024, test_auc = 0.96154, time = 0.01231\n",
      "Epoch: 0190 | train_loss = 0.02481, train_auc = 0.99239, test_loss = 0.04028, test_auc = 0.96167, time = 0.01258\n",
      "Epoch: 0200 | train_loss = 0.02480, train_auc = 0.99239, test_loss = 0.04031, test_auc = 0.96179, time = 0.01227\n",
      "Epoch: 0210 | train_loss = 0.02480, train_auc = 0.99242, test_loss = 0.04032, test_auc = 0.96191, time = 0.01256\n",
      "Epoch: 0220 | train_loss = 0.02480, train_auc = 0.99240, test_loss = 0.04034, test_auc = 0.96204, time = 0.01271\n",
      "Epoch: 0230 | train_loss = 0.02480, train_auc = 0.99240, test_loss = 0.04035, test_auc = 0.96198, time = 0.01204\n",
      "Epoch: 0240 | train_loss = 0.02480, train_auc = 0.99241, test_loss = 0.04036, test_auc = 0.96222, time = 0.01230\n",
      "Epoch: 0250 | train_loss = 0.02480, train_auc = 0.99240, test_loss = 0.04037, test_auc = 0.96235, time = 0.01224\n",
      "Epoch: 0260 | train_loss = 0.02480, train_auc = 0.99243, test_loss = 0.04038, test_auc = 0.96228, time = 0.01252\n",
      "Epoch: 0270 | train_loss = 0.02480, train_auc = 0.99242, test_loss = 0.04039, test_auc = 0.96228, time = 0.01230\n",
      "Epoch: 0280 | train_loss = 0.02480, train_auc = 0.99244, test_loss = 0.04040, test_auc = 0.96241, time = 0.01240\n",
      "Epoch: 0290 | train_loss = 0.02480, train_auc = 0.99243, test_loss = 0.04041, test_auc = 0.96241, time = 0.01206\n",
      "Epoch: 0300 | train_loss = 0.02480, train_auc = 0.99241, test_loss = 0.04042, test_auc = 0.96259, time = 0.01209\n",
      "times: 7, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.16277, train_auc = 0.45763, test_loss = 0.06947, test_auc = 0.69037, time = 0.77661\n",
      "Epoch: 0010 | train_loss = 0.06649, train_auc = 0.97930, test_loss = 0.05133, test_auc = 0.87802, time = 0.01583\n",
      "Epoch: 0020 | train_loss = 0.04148, train_auc = 0.99488, test_loss = 0.03472, test_auc = 0.94809, time = 0.01399\n",
      "Epoch: 0030 | train_loss = 0.02527, train_auc = 0.99666, test_loss = 0.03656, test_auc = 0.93642, time = 0.01347\n",
      "Epoch: 0040 | train_loss = 0.01962, train_auc = 0.99773, test_loss = 0.04853, test_auc = 0.91519, time = 0.01382\n",
      "Epoch: 0050 | train_loss = 0.01663, train_auc = 0.99867, test_loss = 0.04109, test_auc = 0.92006, time = 0.01329\n",
      "Epoch: 0060 | train_loss = 0.01341, train_auc = 1.00000, test_loss = 0.04214, test_auc = 0.92556, time = 0.01509\n",
      "Epoch: 0070 | train_loss = 0.00337, train_auc = 1.00000, test_loss = 0.04548, test_auc = 0.90914, time = 0.01222\n",
      "Epoch: 0080 | train_loss = 0.00194, train_auc = 1.00000, test_loss = 0.04248, test_auc = 0.93111, time = 0.01304\n",
      "Epoch: 0090 | train_loss = 0.00072, train_auc = 1.00000, test_loss = 0.04152, test_auc = 0.94136, time = 0.01247\n",
      "Epoch: 0100 | train_loss = 0.00031, train_auc = 1.00000, test_loss = 0.04262, test_auc = 0.93556, time = 0.01294\n",
      "Epoch: 0110 | train_loss = 0.00018, train_auc = 1.00000, test_loss = 0.04419, test_auc = 0.93241, time = 0.01208\n",
      "Epoch: 0120 | train_loss = 0.00013, train_auc = 1.00000, test_loss = 0.04427, test_auc = 0.93389, time = 0.01249\n",
      "Epoch: 0130 | train_loss = 0.00010, train_auc = 1.00000, test_loss = 0.04430, test_auc = 0.93309, time = 0.01223\n",
      "Epoch: 0140 | train_loss = 0.00008, train_auc = 1.00000, test_loss = 0.04433, test_auc = 0.93210, time = 0.01233\n",
      "Epoch: 0150 | train_loss = 0.00007, train_auc = 1.00000, test_loss = 0.04433, test_auc = 0.93333, time = 0.01220\n",
      "Epoch: 0160 | train_loss = 0.00006, train_auc = 1.00000, test_loss = 0.04431, test_auc = 0.93296, time = 0.01223\n",
      "Epoch: 0170 | train_loss = 0.00006, train_auc = 1.00000, test_loss = 0.04429, test_auc = 0.93346, time = 0.01225\n",
      "Epoch: 0180 | train_loss = 0.00005, train_auc = 1.00000, test_loss = 0.04428, test_auc = 0.93370, time = 0.01210\n",
      "Epoch: 0190 | train_loss = 0.00005, train_auc = 1.00000, test_loss = 0.04428, test_auc = 0.93333, time = 0.01198\n",
      "Epoch: 0200 | train_loss = 0.00004, train_auc = 1.00000, test_loss = 0.04428, test_auc = 0.93407, time = 0.01261\n",
      "Epoch: 0210 | train_loss = 0.00004, train_auc = 1.00000, test_loss = 0.04429, test_auc = 0.93346, time = 0.01309\n",
      "Epoch: 0220 | train_loss = 0.00004, train_auc = 1.00000, test_loss = 0.04430, test_auc = 0.93475, time = 0.01258\n",
      "Epoch: 0230 | train_loss = 0.00003, train_auc = 1.00000, test_loss = 0.04432, test_auc = 0.93494, time = 0.01197\n",
      "Epoch: 0240 | train_loss = 0.00003, train_auc = 1.00000, test_loss = 0.04434, test_auc = 0.93531, time = 0.01240\n",
      "Epoch: 0250 | train_loss = 0.00003, train_auc = 1.00000, test_loss = 0.04436, test_auc = 0.93463, time = 0.01225\n",
      "Epoch: 0260 | train_loss = 0.00003, train_auc = 1.00000, test_loss = 0.04438, test_auc = 0.93469, time = 0.01222\n",
      "Epoch: 0270 | train_loss = 0.00003, train_auc = 1.00000, test_loss = 0.04440, test_auc = 0.93494, time = 0.01255\n",
      "Epoch: 0280 | train_loss = 0.00003, train_auc = 1.00000, test_loss = 0.04442, test_auc = 0.93457, time = 0.01221\n",
      "Epoch: 0290 | train_loss = 0.00002, train_auc = 1.00000, test_loss = 0.04444, test_auc = 0.93457, time = 0.01213\n",
      "Epoch: 0300 | train_loss = 0.00002, train_auc = 1.00000, test_loss = 0.04447, test_auc = 0.93543, time = 0.01213\n",
      "times: 7, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.17008, train_auc = 0.40824, test_loss = 0.09633, test_auc = 0.41722, time = 0.75613\n",
      "Epoch: 0010 | train_loss = 0.07046, train_auc = 0.97718, test_loss = 0.04156, test_auc = 0.93562, time = 0.01527\n",
      "Epoch: 0020 | train_loss = 0.05028, train_auc = 0.98241, test_loss = 0.06130, test_auc = 0.89772, time = 0.01755\n",
      "Epoch: 0030 | train_loss = 0.03607, train_auc = 0.98284, test_loss = 0.05182, test_auc = 0.90654, time = 0.01354\n",
      "Epoch: 0040 | train_loss = 0.02969, train_auc = 0.98545, test_loss = 0.06053, test_auc = 0.66309, time = 0.01283\n",
      "Epoch: 0050 | train_loss = 0.02695, train_auc = 0.98679, test_loss = 0.06038, test_auc = 0.82395, time = 0.01277\n",
      "Epoch: 0060 | train_loss = 0.02661, train_auc = 0.98735, test_loss = 0.05953, test_auc = 0.82531, time = 0.01347\n",
      "Epoch: 0070 | train_loss = 0.02655, train_auc = 0.98805, test_loss = 0.05527, test_auc = 0.92710, time = 0.01273\n",
      "Epoch: 0080 | train_loss = 0.02653, train_auc = 0.98873, test_loss = 0.05063, test_auc = 0.93574, time = 0.01284\n",
      "Epoch: 0090 | train_loss = 0.02651, train_auc = 0.98885, test_loss = 0.05553, test_auc = 0.92475, time = 0.01269\n",
      "Epoch: 0100 | train_loss = 0.02500, train_auc = 0.98729, test_loss = 0.06095, test_auc = 0.72914, time = 0.01330\n",
      "Epoch: 0110 | train_loss = 0.02489, train_auc = 0.98721, test_loss = 0.05433, test_auc = 0.92877, time = 0.01285\n",
      "Epoch: 0120 | train_loss = 0.02483, train_auc = 0.98840, test_loss = 0.04367, test_auc = 0.94481, time = 0.01267\n",
      "Epoch: 0130 | train_loss = 0.02482, train_auc = 0.98840, test_loss = 0.04795, test_auc = 0.94370, time = 0.01267\n",
      "Epoch: 0140 | train_loss = 0.02481, train_auc = 0.98845, test_loss = 0.04772, test_auc = 0.94753, time = 0.01274\n",
      "Epoch: 0150 | train_loss = 0.02481, train_auc = 0.98849, test_loss = 0.05107, test_auc = 0.94062, time = 0.01303\n",
      "Epoch: 0160 | train_loss = 0.02480, train_auc = 0.98851, test_loss = 0.05124, test_auc = 0.94074, time = 0.01249\n",
      "Epoch: 0170 | train_loss = 0.02480, train_auc = 0.98854, test_loss = 0.05053, test_auc = 0.94210, time = 0.01261\n",
      "Epoch: 0180 | train_loss = 0.02480, train_auc = 0.98857, test_loss = 0.04988, test_auc = 0.94247, time = 0.01233\n",
      "Epoch: 0190 | train_loss = 0.02480, train_auc = 0.98858, test_loss = 0.04925, test_auc = 0.94407, time = 0.01293\n",
      "Epoch: 0200 | train_loss = 0.02480, train_auc = 0.98855, test_loss = 0.04844, test_auc = 0.94506, time = 0.01283\n",
      "Epoch: 0210 | train_loss = 0.02480, train_auc = 0.98857, test_loss = 0.04746, test_auc = 0.94568, time = 0.01264\n",
      "Epoch: 0220 | train_loss = 0.02480, train_auc = 0.98856, test_loss = 0.04650, test_auc = 0.94728, time = 0.01254\n",
      "Epoch: 0230 | train_loss = 0.02480, train_auc = 0.98860, test_loss = 0.04568, test_auc = 0.94840, time = 0.01303\n",
      "Epoch: 0240 | train_loss = 0.02480, train_auc = 0.98863, test_loss = 0.04492, test_auc = 0.94914, time = 0.01271\n",
      "Epoch: 0250 | train_loss = 0.02480, train_auc = 0.98863, test_loss = 0.04418, test_auc = 0.94963, time = 0.01229\n",
      "Epoch: 0260 | train_loss = 0.02480, train_auc = 0.98863, test_loss = 0.04347, test_auc = 0.95012, time = 0.01312\n",
      "Epoch: 0270 | train_loss = 0.02480, train_auc = 0.98867, test_loss = 0.04279, test_auc = 0.95056, time = 0.01251\n",
      "Epoch: 0280 | train_loss = 0.02480, train_auc = 0.98862, test_loss = 0.04213, test_auc = 0.95136, time = 0.01285\n",
      "Epoch: 0290 | train_loss = 0.02480, train_auc = 0.98867, test_loss = 0.04149, test_auc = 0.95142, time = 0.01280\n",
      "Epoch: 0300 | train_loss = 0.02480, train_auc = 0.98863, test_loss = 0.04088, test_auc = 0.95167, time = 0.01258\n",
      "times: 8, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.17241, train_auc = 0.37808, test_loss = 0.10049, test_auc = 0.35568, time = 0.78129\n",
      "Epoch: 0010 | train_loss = 0.06130, train_auc = 0.98145, test_loss = 0.04908, test_auc = 0.90512, time = 0.01556\n",
      "Epoch: 0020 | train_loss = 0.04409, train_auc = 0.98670, test_loss = 0.04558, test_auc = 0.93556, time = 0.01325\n",
      "Epoch: 0030 | train_loss = 0.03909, train_auc = 0.98787, test_loss = 0.03935, test_auc = 0.95802, time = 0.01298\n",
      "Epoch: 0040 | train_loss = 0.03487, train_auc = 0.98727, test_loss = 0.03789, test_auc = 0.95975, time = 0.01227\n",
      "Epoch: 0050 | train_loss = 0.03265, train_auc = 0.98784, test_loss = 0.03789, test_auc = 0.94840, time = 0.01248\n",
      "Epoch: 0060 | train_loss = 0.03036, train_auc = 0.98801, test_loss = 0.04121, test_auc = 0.93704, time = 0.01269\n",
      "Epoch: 0070 | train_loss = 0.02988, train_auc = 0.98937, test_loss = 0.04027, test_auc = 0.94864, time = 0.01191\n",
      "Epoch: 0080 | train_loss = 0.02972, train_auc = 0.98856, test_loss = 0.04110, test_auc = 0.94247, time = 0.01215\n",
      "Epoch: 0090 | train_loss = 0.02968, train_auc = 0.98866, test_loss = 0.04077, test_auc = 0.94543, time = 0.01263\n",
      "Epoch: 0100 | train_loss = 0.02967, train_auc = 0.98877, test_loss = 0.04061, test_auc = 0.94278, time = 0.01218\n",
      "Epoch: 0110 | train_loss = 0.02966, train_auc = 0.98880, test_loss = 0.04091, test_auc = 0.94438, time = 0.01240\n",
      "Epoch: 0120 | train_loss = 0.02965, train_auc = 0.98874, test_loss = 0.04110, test_auc = 0.94426, time = 0.01211\n",
      "Epoch: 0130 | train_loss = 0.02965, train_auc = 0.98875, test_loss = 0.04130, test_auc = 0.94370, time = 0.01187\n",
      "Epoch: 0140 | train_loss = 0.02965, train_auc = 0.98885, test_loss = 0.04143, test_auc = 0.94315, time = 0.01256\n",
      "Epoch: 0150 | train_loss = 0.02965, train_auc = 0.98882, test_loss = 0.04152, test_auc = 0.94253, time = 0.01226\n",
      "Epoch: 0160 | train_loss = 0.02965, train_auc = 0.98878, test_loss = 0.04158, test_auc = 0.94198, time = 0.01234\n",
      "Epoch: 0170 | train_loss = 0.02964, train_auc = 0.98881, test_loss = 0.04165, test_auc = 0.94198, time = 0.01215\n",
      "Epoch: 0180 | train_loss = 0.02964, train_auc = 0.98873, test_loss = 0.04171, test_auc = 0.94210, time = 0.01235\n",
      "Epoch: 0190 | train_loss = 0.02964, train_auc = 0.98876, test_loss = 0.04176, test_auc = 0.94191, time = 0.01392\n",
      "Epoch: 0200 | train_loss = 0.02964, train_auc = 0.98873, test_loss = 0.04181, test_auc = 0.94216, time = 0.01217\n",
      "Epoch: 0210 | train_loss = 0.02964, train_auc = 0.98878, test_loss = 0.04186, test_auc = 0.94198, time = 0.01244\n",
      "Epoch: 0220 | train_loss = 0.02964, train_auc = 0.98879, test_loss = 0.04191, test_auc = 0.94179, time = 0.01248\n",
      "Epoch: 0230 | train_loss = 0.02964, train_auc = 0.98880, test_loss = 0.04196, test_auc = 0.94148, time = 0.01202\n",
      "Epoch: 0240 | train_loss = 0.02964, train_auc = 0.98880, test_loss = 0.04201, test_auc = 0.94173, time = 0.01315\n",
      "Epoch: 0250 | train_loss = 0.02964, train_auc = 0.98882, test_loss = 0.04205, test_auc = 0.94198, time = 0.01996\n",
      "Epoch: 0260 | train_loss = 0.02964, train_auc = 0.98883, test_loss = 0.04210, test_auc = 0.94210, time = 0.01210\n",
      "Epoch: 0270 | train_loss = 0.02964, train_auc = 0.98885, test_loss = 0.04214, test_auc = 0.94241, time = 0.01205\n",
      "Epoch: 0280 | train_loss = 0.02964, train_auc = 0.98887, test_loss = 0.04219, test_auc = 0.94247, time = 0.01222\n",
      "Epoch: 0290 | train_loss = 0.02964, train_auc = 0.98882, test_loss = 0.04224, test_auc = 0.94284, time = 0.01208\n",
      "Epoch: 0300 | train_loss = 0.02964, train_auc = 0.98887, test_loss = 0.04229, test_auc = 0.94278, time = 0.01200\n",
      "times: 8, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.15044, train_auc = 0.53316, test_loss = 0.06950, test_auc = 0.69012, time = 0.78755\n",
      "Epoch: 0010 | train_loss = 0.06284, train_auc = 0.98897, test_loss = 0.05836, test_auc = 0.88296, time = 0.01535\n",
      "Epoch: 0020 | train_loss = 0.04112, train_auc = 0.99437, test_loss = 0.03645, test_auc = 0.95469, time = 0.01483\n",
      "Epoch: 0030 | train_loss = 0.02986, train_auc = 0.99636, test_loss = 0.03539, test_auc = 0.96432, time = 0.01360\n",
      "Epoch: 0040 | train_loss = 0.02267, train_auc = 0.99725, test_loss = 0.03702, test_auc = 0.97580, time = 0.01301\n",
      "Epoch: 0050 | train_loss = 0.02123, train_auc = 0.99756, test_loss = 0.03429, test_auc = 0.96864, time = 0.01283\n",
      "Epoch: 0060 | train_loss = 0.02079, train_auc = 0.99804, test_loss = 0.03242, test_auc = 0.97691, time = 0.01260\n",
      "Epoch: 0070 | train_loss = 0.01680, train_auc = 0.99834, test_loss = 0.03236, test_auc = 0.97840, time = 0.01260\n",
      "Epoch: 0080 | train_loss = 0.01633, train_auc = 0.99844, test_loss = 0.03519, test_auc = 0.97593, time = 0.01251\n",
      "Epoch: 0090 | train_loss = 0.01629, train_auc = 0.99835, test_loss = 0.03280, test_auc = 0.97926, time = 0.01250\n",
      "Epoch: 0100 | train_loss = 0.01627, train_auc = 0.99849, test_loss = 0.03254, test_auc = 0.98062, time = 0.01235\n",
      "Epoch: 0110 | train_loss = 0.01626, train_auc = 0.99853, test_loss = 0.03266, test_auc = 0.98074, time = 0.01247\n",
      "Epoch: 0120 | train_loss = 0.01625, train_auc = 0.99848, test_loss = 0.03216, test_auc = 0.98086, time = 0.01251\n",
      "Epoch: 0130 | train_loss = 0.01625, train_auc = 0.99851, test_loss = 0.03170, test_auc = 0.98160, time = 0.01299\n",
      "Epoch: 0140 | train_loss = 0.01625, train_auc = 0.99848, test_loss = 0.03157, test_auc = 0.98173, time = 0.01244\n",
      "Epoch: 0150 | train_loss = 0.01624, train_auc = 0.99847, test_loss = 0.03150, test_auc = 0.98185, time = 0.01318\n",
      "Epoch: 0160 | train_loss = 0.01624, train_auc = 0.99847, test_loss = 0.03141, test_auc = 0.98210, time = 0.01327\n",
      "Epoch: 0170 | train_loss = 0.01624, train_auc = 0.99847, test_loss = 0.03132, test_auc = 0.98235, time = 0.01258\n",
      "Epoch: 0180 | train_loss = 0.01624, train_auc = 0.99847, test_loss = 0.03124, test_auc = 0.98235, time = 0.01317\n",
      "Epoch: 0190 | train_loss = 0.01624, train_auc = 0.99849, test_loss = 0.03118, test_auc = 0.98272, time = 0.01224\n",
      "Epoch: 0200 | train_loss = 0.01624, train_auc = 0.99847, test_loss = 0.03114, test_auc = 0.98272, time = 0.01247\n",
      "Epoch: 0210 | train_loss = 0.01624, train_auc = 0.99847, test_loss = 0.03109, test_auc = 0.98284, time = 0.01308\n",
      "Epoch: 0220 | train_loss = 0.01624, train_auc = 0.99846, test_loss = 0.03105, test_auc = 0.98272, time = 0.01247\n",
      "Epoch: 0230 | train_loss = 0.01624, train_auc = 0.99846, test_loss = 0.03102, test_auc = 0.98284, time = 0.01252\n",
      "Epoch: 0240 | train_loss = 0.01624, train_auc = 0.99846, test_loss = 0.03098, test_auc = 0.98284, time = 0.01277\n",
      "Epoch: 0250 | train_loss = 0.01624, train_auc = 0.99845, test_loss = 0.03095, test_auc = 0.98296, time = 0.01258\n",
      "Epoch: 0260 | train_loss = 0.01624, train_auc = 0.99846, test_loss = 0.03093, test_auc = 0.98296, time = 0.01282\n",
      "Epoch: 0270 | train_loss = 0.01624, train_auc = 0.99845, test_loss = 0.03091, test_auc = 0.98296, time = 0.01271\n",
      "Epoch: 0280 | train_loss = 0.01624, train_auc = 0.99846, test_loss = 0.03088, test_auc = 0.98296, time = 0.01228\n",
      "Epoch: 0290 | train_loss = 0.01624, train_auc = 0.99847, test_loss = 0.03087, test_auc = 0.98296, time = 0.01220\n",
      "Epoch: 0300 | train_loss = 0.01624, train_auc = 0.99846, test_loss = 0.03085, test_auc = 0.98296, time = 0.01240\n",
      "times: 8, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13237, train_auc = 0.72026, test_loss = 0.10265, test_auc = 0.33333, time = 0.77634\n",
      "Epoch: 0010 | train_loss = 0.06160, train_auc = 0.98723, test_loss = 0.04112, test_auc = 0.95302, time = 0.01523\n",
      "Epoch: 0020 | train_loss = 0.03825, train_auc = 0.99576, test_loss = 0.03490, test_auc = 0.97377, time = 0.01625\n",
      "Epoch: 0030 | train_loss = 0.02417, train_auc = 0.99711, test_loss = 0.03648, test_auc = 0.96111, time = 0.01873\n",
      "Epoch: 0040 | train_loss = 0.01959, train_auc = 0.99713, test_loss = 0.03504, test_auc = 0.96648, time = 0.01358\n",
      "Epoch: 0050 | train_loss = 0.01894, train_auc = 0.99696, test_loss = 0.03710, test_auc = 0.96512, time = 0.01288\n",
      "Epoch: 0060 | train_loss = 0.01882, train_auc = 0.99605, test_loss = 0.03833, test_auc = 0.95840, time = 0.01257\n",
      "Epoch: 0070 | train_loss = 0.01879, train_auc = 0.99599, test_loss = 0.03809, test_auc = 0.95784, time = 0.01223\n",
      "Epoch: 0080 | train_loss = 0.01877, train_auc = 0.99596, test_loss = 0.03823, test_auc = 0.96019, time = 0.01295\n",
      "Epoch: 0090 | train_loss = 0.01876, train_auc = 0.99595, test_loss = 0.03844, test_auc = 0.96154, time = 0.01220\n",
      "Epoch: 0100 | train_loss = 0.01876, train_auc = 0.99686, test_loss = 0.03855, test_auc = 0.95846, time = 0.01303\n",
      "Epoch: 0110 | train_loss = 0.01876, train_auc = 0.99594, test_loss = 0.03859, test_auc = 0.95815, time = 0.01266\n",
      "Epoch: 0120 | train_loss = 0.01876, train_auc = 0.99593, test_loss = 0.03860, test_auc = 0.95790, time = 0.01274\n",
      "Epoch: 0130 | train_loss = 0.01876, train_auc = 0.99595, test_loss = 0.03859, test_auc = 0.95790, time = 0.01239\n",
      "Epoch: 0140 | train_loss = 0.01876, train_auc = 0.99685, test_loss = 0.03855, test_auc = 0.95802, time = 0.01216\n",
      "Epoch: 0150 | train_loss = 0.01875, train_auc = 0.99594, test_loss = 0.03850, test_auc = 0.95778, time = 0.01219\n",
      "Epoch: 0160 | train_loss = 0.01875, train_auc = 0.99600, test_loss = 0.03847, test_auc = 0.95790, time = 0.01217\n",
      "Epoch: 0170 | train_loss = 0.01875, train_auc = 0.99505, test_loss = 0.03845, test_auc = 0.96136, time = 0.01210\n",
      "Epoch: 0180 | train_loss = 0.01875, train_auc = 0.99598, test_loss = 0.03843, test_auc = 0.95802, time = 0.01251\n",
      "Epoch: 0190 | train_loss = 0.01875, train_auc = 0.99599, test_loss = 0.03840, test_auc = 0.96173, time = 0.01223\n",
      "Epoch: 0200 | train_loss = 0.01875, train_auc = 0.99606, test_loss = 0.03837, test_auc = 0.95846, time = 0.01229\n",
      "Epoch: 0210 | train_loss = 0.01875, train_auc = 0.99607, test_loss = 0.03836, test_auc = 0.95840, time = 0.01180\n",
      "Epoch: 0220 | train_loss = 0.01875, train_auc = 0.99611, test_loss = 0.03834, test_auc = 0.95852, time = 0.01190\n",
      "Epoch: 0230 | train_loss = 0.01875, train_auc = 0.99610, test_loss = 0.03834, test_auc = 0.95858, time = 0.01185\n",
      "Epoch: 0240 | train_loss = 0.01875, train_auc = 0.99610, test_loss = 0.03833, test_auc = 0.95864, time = 0.01225\n",
      "Epoch: 0250 | train_loss = 0.01875, train_auc = 0.99616, test_loss = 0.03833, test_auc = 0.95858, time = 0.01225\n",
      "Epoch: 0260 | train_loss = 0.01875, train_auc = 0.99518, test_loss = 0.03833, test_auc = 0.95852, time = 0.01225\n",
      "Epoch: 0270 | train_loss = 0.01875, train_auc = 0.99523, test_loss = 0.03833, test_auc = 0.95864, time = 0.01221\n",
      "Epoch: 0280 | train_loss = 0.01875, train_auc = 0.99525, test_loss = 0.03833, test_auc = 0.95858, time = 0.01230\n",
      "Epoch: 0290 | train_loss = 0.01875, train_auc = 0.99525, test_loss = 0.03834, test_auc = 0.95864, time = 0.01213\n",
      "Epoch: 0300 | train_loss = 0.01875, train_auc = 0.99528, test_loss = 0.03834, test_auc = 0.95895, time = 0.01266\n",
      "times: 8, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.18851, train_auc = 0.27525, test_loss = 0.06950, test_auc = 0.68981, time = 0.79720\n",
      "Epoch: 0010 | train_loss = 0.06510, train_auc = 0.98245, test_loss = 0.05493, test_auc = 0.88901, time = 0.01565\n",
      "Epoch: 0020 | train_loss = 0.04365, train_auc = 0.99355, test_loss = 0.03581, test_auc = 0.97006, time = 0.01373\n",
      "Epoch: 0030 | train_loss = 0.02983, train_auc = 0.99704, test_loss = 0.06186, test_auc = 0.81988, time = 0.01282\n",
      "Epoch: 0040 | train_loss = 0.02165, train_auc = 0.99793, test_loss = 0.03932, test_auc = 0.93370, time = 0.01273\n",
      "Epoch: 0050 | train_loss = 0.01515, train_auc = 0.99924, test_loss = 0.03791, test_auc = 0.95679, time = 0.01887\n",
      "Epoch: 0060 | train_loss = 0.01064, train_auc = 0.99924, test_loss = 0.03828, test_auc = 0.94370, time = 0.01343\n",
      "Epoch: 0070 | train_loss = 0.00961, train_auc = 0.99942, test_loss = 0.04046, test_auc = 0.93673, time = 0.01300\n",
      "Epoch: 0080 | train_loss = 0.00945, train_auc = 0.99926, test_loss = 0.04081, test_auc = 0.93778, time = 0.01295\n",
      "Epoch: 0090 | train_loss = 0.00942, train_auc = 0.99922, test_loss = 0.04140, test_auc = 0.93673, time = 0.01274\n",
      "Epoch: 0100 | train_loss = 0.00940, train_auc = 0.99924, test_loss = 0.04135, test_auc = 0.93802, time = 0.01302\n",
      "Epoch: 0110 | train_loss = 0.00939, train_auc = 0.99928, test_loss = 0.04105, test_auc = 0.93975, time = 0.01318\n",
      "Epoch: 0120 | train_loss = 0.00939, train_auc = 0.99928, test_loss = 0.04123, test_auc = 0.94037, time = 0.01287\n",
      "Epoch: 0130 | train_loss = 0.00939, train_auc = 0.99927, test_loss = 0.04105, test_auc = 0.94265, time = 0.01288\n",
      "Epoch: 0140 | train_loss = 0.00938, train_auc = 0.99927, test_loss = 0.04090, test_auc = 0.94432, time = 0.01248\n",
      "Epoch: 0150 | train_loss = 0.00938, train_auc = 0.99922, test_loss = 0.04086, test_auc = 0.94475, time = 0.01251\n",
      "Epoch: 0160 | train_loss = 0.00938, train_auc = 0.99923, test_loss = 0.04079, test_auc = 0.94599, time = 0.01244\n",
      "Epoch: 0170 | train_loss = 0.00938, train_auc = 0.99922, test_loss = 0.04077, test_auc = 0.94698, time = 0.01258\n",
      "Epoch: 0180 | train_loss = 0.00938, train_auc = 0.99926, test_loss = 0.04071, test_auc = 0.94716, time = 0.01282\n",
      "Epoch: 0190 | train_loss = 0.00938, train_auc = 0.99924, test_loss = 0.04065, test_auc = 0.94747, time = 0.01345\n",
      "Epoch: 0200 | train_loss = 0.00938, train_auc = 0.99920, test_loss = 0.04062, test_auc = 0.94833, time = 0.01271\n",
      "Epoch: 0210 | train_loss = 0.00938, train_auc = 0.99924, test_loss = 0.04059, test_auc = 0.94914, time = 0.01546\n",
      "Epoch: 0220 | train_loss = 0.00938, train_auc = 0.99921, test_loss = 0.04056, test_auc = 0.94926, time = 0.01247\n",
      "Epoch: 0230 | train_loss = 0.00938, train_auc = 0.99821, test_loss = 0.04053, test_auc = 0.95000, time = 0.01260\n",
      "Epoch: 0240 | train_loss = 0.00938, train_auc = 0.99925, test_loss = 0.04051, test_auc = 0.95037, time = 0.01252\n",
      "Epoch: 0250 | train_loss = 0.00938, train_auc = 0.99920, test_loss = 0.04049, test_auc = 0.95074, time = 0.01286\n",
      "Epoch: 0260 | train_loss = 0.00938, train_auc = 0.99924, test_loss = 0.04047, test_auc = 0.95068, time = 0.01270\n",
      "Epoch: 0270 | train_loss = 0.00938, train_auc = 0.99927, test_loss = 0.04045, test_auc = 0.95093, time = 0.01242\n",
      "Epoch: 0280 | train_loss = 0.00938, train_auc = 0.99821, test_loss = 0.04044, test_auc = 0.95111, time = 0.01223\n",
      "Epoch: 0290 | train_loss = 0.00938, train_auc = 0.99822, test_loss = 0.04042, test_auc = 0.95136, time = 0.01278\n",
      "Epoch: 0300 | train_loss = 0.00938, train_auc = 0.99822, test_loss = 0.04040, test_auc = 0.95136, time = 0.01522\n",
      "times: 8, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.13928, train_auc = 0.70294, test_loss = 0.06424, test_auc = 0.73889, time = 0.77845\n",
      "Epoch: 0010 | train_loss = 0.06683, train_auc = 0.97665, test_loss = 0.04843, test_auc = 0.90019, time = 0.01568\n",
      "Epoch: 0020 | train_loss = 0.05793, train_auc = 0.97945, test_loss = 0.04966, test_auc = 0.92617, time = 0.01538\n",
      "Epoch: 0030 | train_loss = 0.04378, train_auc = 0.98868, test_loss = 0.03923, test_auc = 0.94790, time = 0.01377\n",
      "Epoch: 0040 | train_loss = 0.03598, train_auc = 0.98999, test_loss = 0.03820, test_auc = 0.96352, time = 0.01260\n",
      "Epoch: 0050 | train_loss = 0.03067, train_auc = 0.99120, test_loss = 0.03250, test_auc = 0.96111, time = 0.01253\n",
      "Epoch: 0060 | train_loss = 0.02770, train_auc = 0.99164, test_loss = 0.03690, test_auc = 0.94932, time = 0.01253\n",
      "Epoch: 0070 | train_loss = 0.02532, train_auc = 0.99327, test_loss = 0.03505, test_auc = 0.95531, time = 0.01258\n",
      "Epoch: 0080 | train_loss = 0.02197, train_auc = 0.99527, test_loss = 0.03468, test_auc = 0.95630, time = 0.01334\n",
      "Epoch: 0090 | train_loss = 0.01932, train_auc = 0.99578, test_loss = 0.03511, test_auc = 0.96265, time = 0.01248\n",
      "Epoch: 0100 | train_loss = 0.01891, train_auc = 0.99576, test_loss = 0.03531, test_auc = 0.94951, time = 0.01220\n",
      "Epoch: 0110 | train_loss = 0.01883, train_auc = 0.99561, test_loss = 0.03498, test_auc = 0.95062, time = 0.01305\n",
      "Epoch: 0120 | train_loss = 0.01879, train_auc = 0.99561, test_loss = 0.03546, test_auc = 0.94802, time = 0.01296\n",
      "Epoch: 0130 | train_loss = 0.01878, train_auc = 0.99562, test_loss = 0.03566, test_auc = 0.94778, time = 0.01222\n",
      "Epoch: 0140 | train_loss = 0.01877, train_auc = 0.99567, test_loss = 0.03583, test_auc = 0.94778, time = 0.01258\n",
      "Epoch: 0150 | train_loss = 0.01877, train_auc = 0.99566, test_loss = 0.03601, test_auc = 0.94728, time = 0.01280\n",
      "Epoch: 0160 | train_loss = 0.01876, train_auc = 0.99564, test_loss = 0.03606, test_auc = 0.94679, time = 0.01229\n",
      "Epoch: 0170 | train_loss = 0.01876, train_auc = 0.99567, test_loss = 0.03606, test_auc = 0.94704, time = 0.01221\n",
      "Epoch: 0180 | train_loss = 0.01876, train_auc = 0.99570, test_loss = 0.03603, test_auc = 0.95012, time = 0.01254\n",
      "Epoch: 0190 | train_loss = 0.01876, train_auc = 0.99573, test_loss = 0.03601, test_auc = 0.94741, time = 0.01250\n",
      "Epoch: 0200 | train_loss = 0.01876, train_auc = 0.99583, test_loss = 0.03597, test_auc = 0.95093, time = 0.01247\n",
      "Epoch: 0210 | train_loss = 0.01875, train_auc = 0.99603, test_loss = 0.03589, test_auc = 0.94765, time = 0.01259\n",
      "Epoch: 0220 | train_loss = 0.01875, train_auc = 0.99678, test_loss = 0.03574, test_auc = 0.94877, time = 0.01272\n",
      "Epoch: 0230 | train_loss = 0.01968, train_auc = 0.99760, test_loss = 0.03572, test_auc = 0.94963, time = 0.01255\n",
      "Epoch: 0240 | train_loss = 0.02031, train_auc = 0.99800, test_loss = 0.03795, test_auc = 0.95074, time = 0.01217\n",
      "Epoch: 0250 | train_loss = 0.01717, train_auc = 0.99660, test_loss = 0.03652, test_auc = 0.96778, time = 0.01216\n",
      "Epoch: 0260 | train_loss = 0.01635, train_auc = 0.99740, test_loss = 0.03544, test_auc = 0.97710, time = 0.01219\n",
      "Epoch: 0270 | train_loss = 0.01396, train_auc = 0.99890, test_loss = 0.03400, test_auc = 0.96660, time = 0.01283\n",
      "Epoch: 0280 | train_loss = 0.01341, train_auc = 0.99927, test_loss = 0.03753, test_auc = 0.96370, time = 0.01223\n",
      "Epoch: 0290 | train_loss = 0.01329, train_auc = 0.99907, test_loss = 0.03678, test_auc = 0.96117, time = 0.01192\n",
      "Epoch: 0300 | train_loss = 0.01327, train_auc = 0.99910, test_loss = 0.03622, test_auc = 0.96179, time = 0.01270\n",
      "times: 9, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.16042, train_auc = 0.45278, test_loss = 0.06079, test_auc = 0.76648, time = 0.77169\n",
      "Epoch: 0010 | train_loss = 0.08535, train_auc = 0.90236, test_loss = 0.05063, test_auc = 0.90599, time = 0.01518\n",
      "Epoch: 0020 | train_loss = 0.05378, train_auc = 0.97782, test_loss = 0.04148, test_auc = 0.94975, time = 0.01386\n",
      "Epoch: 0030 | train_loss = 0.04299, train_auc = 0.98304, test_loss = 0.03677, test_auc = 0.95728, time = 0.01263\n",
      "Epoch: 0040 | train_loss = 0.03655, train_auc = 0.98410, test_loss = 0.03215, test_auc = 0.97191, time = 0.01251\n",
      "Epoch: 0050 | train_loss = 0.03571, train_auc = 0.98466, test_loss = 0.03121, test_auc = 0.97444, time = 0.01209\n",
      "Epoch: 0060 | train_loss = 0.03299, train_auc = 0.98437, test_loss = 0.02756, test_auc = 0.97698, time = 0.01250\n",
      "Epoch: 0070 | train_loss = 0.03262, train_auc = 0.98584, test_loss = 0.03114, test_auc = 0.97438, time = 0.01225\n",
      "Epoch: 0080 | train_loss = 0.03253, train_auc = 0.98480, test_loss = 0.03110, test_auc = 0.97247, time = 0.01334\n",
      "Epoch: 0090 | train_loss = 0.03415, train_auc = 0.98303, test_loss = 0.03790, test_auc = 0.91852, time = 0.01313\n",
      "Epoch: 0100 | train_loss = 0.03141, train_auc = 0.98575, test_loss = 0.03107, test_auc = 0.96846, time = 0.01218\n",
      "Epoch: 0110 | train_loss = 0.02985, train_auc = 0.98626, test_loss = 0.03246, test_auc = 0.96401, time = 0.01231\n",
      "Epoch: 0120 | train_loss = 0.02971, train_auc = 0.98630, test_loss = 0.03177, test_auc = 0.97142, time = 0.01262\n",
      "Epoch: 0130 | train_loss = 0.02967, train_auc = 0.98637, test_loss = 0.02979, test_auc = 0.97568, time = 0.01345\n",
      "Epoch: 0140 | train_loss = 0.02965, train_auc = 0.98643, test_loss = 0.02947, test_auc = 0.97586, time = 0.01280\n",
      "Epoch: 0150 | train_loss = 0.02964, train_auc = 0.98654, test_loss = 0.02961, test_auc = 0.97519, time = 0.01226\n",
      "Epoch: 0160 | train_loss = 0.02829, train_auc = 0.98672, test_loss = 0.02946, test_auc = 0.97519, time = 0.01253\n",
      "Epoch: 0170 | train_loss = 0.02816, train_auc = 0.98674, test_loss = 0.02970, test_auc = 0.97574, time = 0.01214\n",
      "Epoch: 0180 | train_loss = 0.02813, train_auc = 0.98678, test_loss = 0.03048, test_auc = 0.97562, time = 0.01241\n",
      "Epoch: 0190 | train_loss = 0.02813, train_auc = 0.98684, test_loss = 0.02988, test_auc = 0.97568, time = 0.01230\n",
      "Epoch: 0200 | train_loss = 0.02812, train_auc = 0.98686, test_loss = 0.02973, test_auc = 0.97531, time = 0.01306\n",
      "Epoch: 0210 | train_loss = 0.02812, train_auc = 0.98689, test_loss = 0.02973, test_auc = 0.97531, time = 0.01279\n",
      "Epoch: 0220 | train_loss = 0.02812, train_auc = 0.98692, test_loss = 0.02965, test_auc = 0.97593, time = 0.01226\n",
      "Epoch: 0230 | train_loss = 0.02812, train_auc = 0.98692, test_loss = 0.02956, test_auc = 0.97593, time = 0.01250\n",
      "Epoch: 0240 | train_loss = 0.02812, train_auc = 0.98692, test_loss = 0.02952, test_auc = 0.97617, time = 0.01246\n",
      "Epoch: 0250 | train_loss = 0.02812, train_auc = 0.98690, test_loss = 0.02949, test_auc = 0.97617, time = 0.01272\n",
      "Epoch: 0260 | train_loss = 0.02812, train_auc = 0.98694, test_loss = 0.02944, test_auc = 0.97617, time = 0.01221\n",
      "Epoch: 0270 | train_loss = 0.02812, train_auc = 0.98694, test_loss = 0.02940, test_auc = 0.97617, time = 0.01244\n",
      "Epoch: 0280 | train_loss = 0.02812, train_auc = 0.98695, test_loss = 0.02936, test_auc = 0.97617, time = 0.01323\n",
      "Epoch: 0290 | train_loss = 0.02812, train_auc = 0.98693, test_loss = 0.02933, test_auc = 0.97605, time = 0.01279\n",
      "Epoch: 0300 | train_loss = 0.02812, train_auc = 0.98695, test_loss = 0.02930, test_auc = 0.97605, time = 0.01255\n",
      "times: 9, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.18119, train_auc = 0.28975, test_loss = 0.08735, test_auc = 0.51123, time = 0.77427\n",
      "Epoch: 0010 | train_loss = 0.06739, train_auc = 0.95972, test_loss = 0.05361, test_auc = 0.86352, time = 0.01526\n",
      "Epoch: 0020 | train_loss = 0.04506, train_auc = 0.98241, test_loss = 0.04916, test_auc = 0.91191, time = 0.01526\n",
      "Epoch: 0030 | train_loss = 0.03314, train_auc = 0.99336, test_loss = 0.04334, test_auc = 0.90920, time = 0.01283\n",
      "Epoch: 0040 | train_loss = 0.02524, train_auc = 0.99376, test_loss = 0.04407, test_auc = 0.91019, time = 0.01366\n",
      "Epoch: 0050 | train_loss = 0.02212, train_auc = 0.99302, test_loss = 0.04426, test_auc = 0.92932, time = 0.01258\n",
      "Epoch: 0060 | train_loss = 0.01999, train_auc = 0.99472, test_loss = 0.04297, test_auc = 0.92802, time = 0.01260\n",
      "Epoch: 0070 | train_loss = 0.01908, train_auc = 0.99490, test_loss = 0.04786, test_auc = 0.91395, time = 0.01247\n",
      "Epoch: 0080 | train_loss = 0.01882, train_auc = 0.99430, test_loss = 0.04490, test_auc = 0.92778, time = 0.01284\n",
      "Epoch: 0090 | train_loss = 0.01646, train_auc = 0.99529, test_loss = 0.04490, test_auc = 0.93062, time = 0.01271\n",
      "Epoch: 0100 | train_loss = 0.01632, train_auc = 0.99432, test_loss = 0.04711, test_auc = 0.92043, time = 0.01268\n",
      "Epoch: 0110 | train_loss = 0.01628, train_auc = 0.99434, test_loss = 0.04534, test_auc = 0.93494, time = 0.01240\n",
      "Epoch: 0120 | train_loss = 0.01626, train_auc = 0.99438, test_loss = 0.04568, test_auc = 0.93531, time = 0.01245\n",
      "Epoch: 0130 | train_loss = 0.01625, train_auc = 0.99439, test_loss = 0.04577, test_auc = 0.93469, time = 0.01231\n",
      "Epoch: 0140 | train_loss = 0.01624, train_auc = 0.99439, test_loss = 0.04610, test_auc = 0.93309, time = 0.01247\n",
      "Epoch: 0150 | train_loss = 0.01624, train_auc = 0.99441, test_loss = 0.04622, test_auc = 0.93370, time = 0.01236\n",
      "Epoch: 0160 | train_loss = 0.01624, train_auc = 0.99441, test_loss = 0.04630, test_auc = 0.93284, time = 0.01283\n",
      "Epoch: 0170 | train_loss = 0.01624, train_auc = 0.99441, test_loss = 0.04632, test_auc = 0.93259, time = 0.01259\n",
      "Epoch: 0180 | train_loss = 0.01624, train_auc = 0.99441, test_loss = 0.04637, test_auc = 0.93259, time = 0.01308\n",
      "Epoch: 0190 | train_loss = 0.01624, train_auc = 0.99441, test_loss = 0.04640, test_auc = 0.93247, time = 0.01272\n",
      "Epoch: 0200 | train_loss = 0.01624, train_auc = 0.99441, test_loss = 0.04643, test_auc = 0.93198, time = 0.01253\n",
      "Epoch: 0210 | train_loss = 0.01624, train_auc = 0.99441, test_loss = 0.04647, test_auc = 0.93185, time = 0.01299\n",
      "Epoch: 0220 | train_loss = 0.01624, train_auc = 0.99442, test_loss = 0.04650, test_auc = 0.93160, time = 0.01274\n",
      "Epoch: 0230 | train_loss = 0.01624, train_auc = 0.99442, test_loss = 0.04654, test_auc = 0.93167, time = 0.01227\n",
      "Epoch: 0240 | train_loss = 0.01624, train_auc = 0.99442, test_loss = 0.04658, test_auc = 0.93160, time = 0.01265\n",
      "Epoch: 0250 | train_loss = 0.01624, train_auc = 0.99442, test_loss = 0.04661, test_auc = 0.93136, time = 0.01278\n",
      "Epoch: 0260 | train_loss = 0.01624, train_auc = 0.99442, test_loss = 0.04665, test_auc = 0.93099, time = 0.01288\n",
      "Epoch: 0270 | train_loss = 0.01624, train_auc = 0.99441, test_loss = 0.04669, test_auc = 0.93111, time = 0.01244\n",
      "Epoch: 0280 | train_loss = 0.01624, train_auc = 0.99442, test_loss = 0.04672, test_auc = 0.93080, time = 0.01282\n",
      "Epoch: 0290 | train_loss = 0.01623, train_auc = 0.99444, test_loss = 0.04676, test_auc = 0.93086, time = 0.01297\n",
      "Epoch: 0300 | train_loss = 0.01623, train_auc = 0.99441, test_loss = 0.04680, test_auc = 0.93056, time = 0.01230\n",
      "times: 9, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.12946, train_auc = 0.71815, test_loss = 0.08440, test_auc = 0.56179, time = 0.77925\n",
      "Epoch: 0010 | train_loss = 0.05976, train_auc = 0.98587, test_loss = 0.07055, test_auc = 0.84722, time = 0.01538\n",
      "Epoch: 0020 | train_loss = 0.03670, train_auc = 0.99201, test_loss = 0.05271, test_auc = 0.90901, time = 0.01374\n",
      "Epoch: 0030 | train_loss = 0.02892, train_auc = 0.98976, test_loss = 0.04386, test_auc = 0.93704, time = 0.01275\n",
      "Epoch: 0040 | train_loss = 0.02677, train_auc = 0.99318, test_loss = 0.04588, test_auc = 0.91790, time = 0.01310\n",
      "Epoch: 0050 | train_loss = 0.02362, train_auc = 0.99225, test_loss = 0.04510, test_auc = 0.93969, time = 0.01284\n",
      "Epoch: 0060 | train_loss = 0.02315, train_auc = 0.99241, test_loss = 0.04227, test_auc = 0.94981, time = 0.01290\n",
      "Epoch: 0070 | train_loss = 0.02304, train_auc = 0.99251, test_loss = 0.04116, test_auc = 0.94691, time = 0.01237\n",
      "Epoch: 0080 | train_loss = 0.02300, train_auc = 0.99257, test_loss = 0.04158, test_auc = 0.94630, time = 0.01238\n",
      "Epoch: 0090 | train_loss = 0.02299, train_auc = 0.99263, test_loss = 0.04151, test_auc = 0.94568, time = 0.01223\n",
      "Epoch: 0100 | train_loss = 0.02298, train_auc = 0.99267, test_loss = 0.04145, test_auc = 0.94599, time = 0.01281\n",
      "Epoch: 0110 | train_loss = 0.02298, train_auc = 0.99271, test_loss = 0.04149, test_auc = 0.94611, time = 0.01215\n",
      "Epoch: 0120 | train_loss = 0.02297, train_auc = 0.99270, test_loss = 0.04155, test_auc = 0.94586, time = 0.01303\n",
      "Epoch: 0130 | train_loss = 0.02297, train_auc = 0.99275, test_loss = 0.04162, test_auc = 0.94599, time = 0.01226\n",
      "Epoch: 0140 | train_loss = 0.02297, train_auc = 0.99277, test_loss = 0.04166, test_auc = 0.94605, time = 0.01253\n",
      "Epoch: 0150 | train_loss = 0.02297, train_auc = 0.99284, test_loss = 0.04168, test_auc = 0.94574, time = 0.01246\n",
      "Epoch: 0160 | train_loss = 0.02297, train_auc = 0.99282, test_loss = 0.04171, test_auc = 0.94593, time = 0.01263\n",
      "Epoch: 0170 | train_loss = 0.02297, train_auc = 0.99279, test_loss = 0.04173, test_auc = 0.94580, time = 0.01222\n",
      "Epoch: 0180 | train_loss = 0.02297, train_auc = 0.99285, test_loss = 0.04176, test_auc = 0.94537, time = 0.01242\n",
      "Epoch: 0190 | train_loss = 0.02297, train_auc = 0.99288, test_loss = 0.04178, test_auc = 0.94525, time = 0.01310\n",
      "Epoch: 0200 | train_loss = 0.02296, train_auc = 0.99289, test_loss = 0.04180, test_auc = 0.94481, time = 0.01238\n",
      "Epoch: 0210 | train_loss = 0.02296, train_auc = 0.99288, test_loss = 0.04182, test_auc = 0.94444, time = 0.01338\n",
      "Epoch: 0220 | train_loss = 0.02296, train_auc = 0.99294, test_loss = 0.04184, test_auc = 0.94469, time = 0.01202\n",
      "Epoch: 0230 | train_loss = 0.02296, train_auc = 0.99298, test_loss = 0.04186, test_auc = 0.94432, time = 0.01268\n",
      "Epoch: 0240 | train_loss = 0.02296, train_auc = 0.99298, test_loss = 0.04188, test_auc = 0.94414, time = 0.01209\n",
      "Epoch: 0250 | train_loss = 0.02296, train_auc = 0.99294, test_loss = 0.04190, test_auc = 0.94451, time = 0.01220\n",
      "Epoch: 0260 | train_loss = 0.02296, train_auc = 0.99295, test_loss = 0.04191, test_auc = 0.94426, time = 0.01209\n",
      "Epoch: 0270 | train_loss = 0.02296, train_auc = 0.99295, test_loss = 0.04193, test_auc = 0.94383, time = 0.01211\n",
      "Epoch: 0280 | train_loss = 0.02296, train_auc = 0.99293, test_loss = 0.04196, test_auc = 0.94370, time = 0.01234\n",
      "Epoch: 0290 | train_loss = 0.02296, train_auc = 0.99296, test_loss = 0.04198, test_auc = 0.94352, time = 0.01226\n",
      "Epoch: 0300 | train_loss = 0.02296, train_auc = 0.99299, test_loss = 0.04200, test_auc = 0.94346, time = 0.01249\n",
      "times: 9, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.14854, train_auc = 0.62419, test_loss = 0.08232, test_auc = 0.56901, time = 0.76287\n",
      "Epoch: 0010 | train_loss = 0.08037, train_auc = 0.94790, test_loss = 0.06995, test_auc = 0.81630, time = 0.01500\n",
      "Epoch: 0020 | train_loss = 0.04941, train_auc = 0.98485, test_loss = 0.04056, test_auc = 0.92988, time = 0.01338\n",
      "Epoch: 0030 | train_loss = 0.03540, train_auc = 0.98842, test_loss = 0.03686, test_auc = 0.94259, time = 0.01334\n",
      "Epoch: 0040 | train_loss = 0.02797, train_auc = 0.98724, test_loss = 0.03850, test_auc = 0.93901, time = 0.01234\n",
      "Epoch: 0050 | train_loss = 0.02693, train_auc = 0.98736, test_loss = 0.03737, test_auc = 0.94759, time = 0.01224\n",
      "Epoch: 0060 | train_loss = 0.02664, train_auc = 0.98751, test_loss = 0.03624, test_auc = 0.95716, time = 0.01218\n",
      "Epoch: 0070 | train_loss = 0.02657, train_auc = 0.98765, test_loss = 0.03569, test_auc = 0.95407, time = 0.01251\n",
      "Epoch: 0080 | train_loss = 0.02655, train_auc = 0.98679, test_loss = 0.03567, test_auc = 0.95099, time = 0.01243\n",
      "Epoch: 0090 | train_loss = 0.02654, train_auc = 0.98583, test_loss = 0.03572, test_auc = 0.95111, time = 0.01215\n",
      "Epoch: 0100 | train_loss = 0.02653, train_auc = 0.98583, test_loss = 0.03580, test_auc = 0.95111, time = 0.01240\n",
      "Epoch: 0110 | train_loss = 0.02653, train_auc = 0.98580, test_loss = 0.03581, test_auc = 0.95099, time = 0.01244\n",
      "Epoch: 0120 | train_loss = 0.02653, train_auc = 0.98586, test_loss = 0.03581, test_auc = 0.95099, time = 0.01230\n",
      "Epoch: 0130 | train_loss = 0.02652, train_auc = 0.98586, test_loss = 0.03587, test_auc = 0.95099, time = 0.01262\n",
      "Epoch: 0140 | train_loss = 0.02652, train_auc = 0.98580, test_loss = 0.03587, test_auc = 0.95123, time = 0.01999\n",
      "Epoch: 0150 | train_loss = 0.02652, train_auc = 0.98586, test_loss = 0.03592, test_auc = 0.95148, time = 0.01219\n",
      "Epoch: 0160 | train_loss = 0.02652, train_auc = 0.98586, test_loss = 0.03594, test_auc = 0.95136, time = 0.01242\n",
      "Epoch: 0170 | train_loss = 0.02652, train_auc = 0.98583, test_loss = 0.03596, test_auc = 0.95160, time = 0.01424\n",
      "Epoch: 0180 | train_loss = 0.02652, train_auc = 0.98583, test_loss = 0.03598, test_auc = 0.95123, time = 0.01263\n",
      "Epoch: 0190 | train_loss = 0.02652, train_auc = 0.98580, test_loss = 0.03600, test_auc = 0.95123, time = 0.01252\n",
      "Epoch: 0200 | train_loss = 0.02652, train_auc = 0.98583, test_loss = 0.03601, test_auc = 0.95123, time = 0.01275\n",
      "Epoch: 0210 | train_loss = 0.02652, train_auc = 0.98586, test_loss = 0.03603, test_auc = 0.95136, time = 0.01221\n",
      "Epoch: 0220 | train_loss = 0.02651, train_auc = 0.98590, test_loss = 0.03604, test_auc = 0.95136, time = 0.01245\n",
      "Epoch: 0230 | train_loss = 0.02651, train_auc = 0.98586, test_loss = 0.03605, test_auc = 0.95167, time = 0.01217\n",
      "Epoch: 0240 | train_loss = 0.02651, train_auc = 0.98590, test_loss = 0.03606, test_auc = 0.95148, time = 0.01309\n",
      "Epoch: 0250 | train_loss = 0.02651, train_auc = 0.98590, test_loss = 0.03607, test_auc = 0.95130, time = 0.01264\n",
      "Epoch: 0260 | train_loss = 0.02651, train_auc = 0.98593, test_loss = 0.03608, test_auc = 0.95123, time = 0.01246\n",
      "Epoch: 0270 | train_loss = 0.02651, train_auc = 0.98590, test_loss = 0.03609, test_auc = 0.95142, time = 0.01241\n",
      "Epoch: 0280 | train_loss = 0.02651, train_auc = 0.98593, test_loss = 0.03610, test_auc = 0.95117, time = 0.01286\n",
      "Epoch: 0290 | train_loss = 0.02651, train_auc = 0.98593, test_loss = 0.03611, test_auc = 0.95111, time = 0.01238\n",
      "Epoch: 0300 | train_loss = 0.02651, train_auc = 0.98596, test_loss = 0.03612, test_auc = 0.95130, time = 0.01265\n",
      "times: 9, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: HMDAD\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.0\n",
      " feedforward_drop:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:17: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/'+dataset+'/microbes.xlsx',header=None,names=['id','microbe'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 331\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.18127, train_auc = 0.30792, test_loss = 0.07695, test_auc = 0.64364, time = 0.78640\n",
      "Epoch: 0010 | train_loss = 0.06285, train_auc = 0.97580, test_loss = 0.04288, test_auc = 0.93568, time = 0.01591\n",
      "Epoch: 0020 | train_loss = 0.04643, train_auc = 0.98294, test_loss = 0.03731, test_auc = 0.96432, time = 0.01408\n",
      "Epoch: 0030 | train_loss = 0.03856, train_auc = 0.98596, test_loss = 0.04090, test_auc = 0.95481, time = 0.01345\n",
      "Epoch: 0040 | train_loss = 0.03621, train_auc = 0.98492, test_loss = 0.03887, test_auc = 0.94901, time = 0.01318\n",
      "Epoch: 0050 | train_loss = 0.03290, train_auc = 0.98724, test_loss = 0.03728, test_auc = 0.96074, time = 0.01315\n",
      "Epoch: 0060 | train_loss = 0.03258, train_auc = 0.98715, test_loss = 0.03569, test_auc = 0.96840, time = 0.01227\n",
      "Epoch: 0070 | train_loss = 0.03252, train_auc = 0.98732, test_loss = 0.03437, test_auc = 0.97049, time = 0.01352\n",
      "Epoch: 0080 | train_loss = 0.03248, train_auc = 0.98764, test_loss = 0.03416, test_auc = 0.97012, time = 0.01764\n",
      "Epoch: 0090 | train_loss = 0.03137, train_auc = 0.98848, test_loss = 0.03629, test_auc = 0.97037, time = 0.01267\n",
      "Epoch: 0100 | train_loss = 0.03021, train_auc = 0.99102, test_loss = 0.03913, test_auc = 0.95778, time = 0.01247\n",
      "Epoch: 0110 | train_loss = 0.02837, train_auc = 0.99108, test_loss = 0.03474, test_auc = 0.97086, time = 0.01258\n",
      "Epoch: 0120 | train_loss = 0.02665, train_auc = 0.99205, test_loss = 0.03455, test_auc = 0.97037, time = 0.01242\n",
      "Epoch: 0130 | train_loss = 0.02655, train_auc = 0.98909, test_loss = 0.03363, test_auc = 0.97173, time = 0.01207\n",
      "Epoch: 0140 | train_loss = 0.02653, train_auc = 0.99037, test_loss = 0.03217, test_auc = 0.97111, time = 0.01253\n",
      "Epoch: 0150 | train_loss = 0.02652, train_auc = 0.99044, test_loss = 0.03240, test_auc = 0.97185, time = 0.01224\n",
      "Epoch: 0160 | train_loss = 0.02652, train_auc = 0.99040, test_loss = 0.03265, test_auc = 0.97111, time = 0.01332\n",
      "Epoch: 0170 | train_loss = 0.02651, train_auc = 0.99042, test_loss = 0.03277, test_auc = 0.97111, time = 0.01246\n",
      "Epoch: 0180 | train_loss = 0.02651, train_auc = 0.99145, test_loss = 0.03273, test_auc = 0.97086, time = 0.01235\n",
      "Epoch: 0190 | train_loss = 0.02651, train_auc = 0.99047, test_loss = 0.03270, test_auc = 0.97086, time = 0.01244\n",
      "Epoch: 0200 | train_loss = 0.02651, train_auc = 0.99147, test_loss = 0.03268, test_auc = 0.97062, time = 0.01236\n",
      "Epoch: 0210 | train_loss = 0.02651, train_auc = 0.98933, test_loss = 0.03268, test_auc = 0.97074, time = 0.01253\n",
      "Epoch: 0220 | train_loss = 0.02651, train_auc = 0.99150, test_loss = 0.03270, test_auc = 0.97074, time = 0.01253\n",
      "Epoch: 0230 | train_loss = 0.02651, train_auc = 0.99137, test_loss = 0.03272, test_auc = 0.97062, time = 0.01444\n",
      "Epoch: 0240 | train_loss = 0.02651, train_auc = 0.99037, test_loss = 0.03273, test_auc = 0.97049, time = 0.01322\n",
      "Epoch: 0250 | train_loss = 0.02651, train_auc = 0.99051, test_loss = 0.03276, test_auc = 0.97037, time = 0.01214\n",
      "Epoch: 0260 | train_loss = 0.02651, train_auc = 0.99052, test_loss = 0.03279, test_auc = 0.97062, time = 0.01218\n",
      "Epoch: 0270 | train_loss = 0.02651, train_auc = 0.99043, test_loss = 0.03283, test_auc = 0.97049, time = 0.01221\n",
      "Epoch: 0280 | train_loss = 0.02651, train_auc = 0.99055, test_loss = 0.03289, test_auc = 0.97062, time = 0.01214\n",
      "Epoch: 0290 | train_loss = 0.02651, train_auc = 0.99047, test_loss = 0.03296, test_auc = 0.97049, time = 0.01240\n",
      "Epoch: 0300 | train_loss = 0.02651, train_auc = 0.99044, test_loss = 0.03301, test_auc = 0.97037, time = 0.01230\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "from utils import sample\n",
    "from train import train\n",
    "from evaluation import *\n",
    "from tfdeterminism import patch\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Training')\n",
    "    parser.add_argument('--GPU', type=str, default='0')\n",
    "    parser.add_argument('--epoch', type=int, default=300)\n",
    "    parser.add_argument('--hid_units', type=int, default=64, help='number of neurons in GAT')\n",
    "    parser.add_argument('--dense0', type=int, default=64, help='number of neurons in BFN')\n",
    "    parser.add_argument('--dense1', type=int, default=32, help='number of neurons in BFN')\n",
    "    parser.add_argument('--layers', type=int, default=4, help='number of layer aggregator in GAT')\n",
    "    parser.add_argument('--lr', type=float, default=0.003)\n",
    "    parser.add_argument('--attention_drop', type=float, default=0.0)\n",
    "    parser.add_argument('--feedforward_drop', type=float, default=0.0)\n",
    "    parser.add_argument('--dataset', type=str, default='HMDAD')\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    patch()\n",
    "    SEED = 1000\n",
    "    tf.set_random_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.GPU\n",
    "\n",
    "    dataset = args.dataset\n",
    "    times = 10\n",
    "    total_KFOLD_test_labels, total_FOLD_test_scores = [], []\n",
    "    KFOLD_test_out_come = []\n",
    "    for i in range(times):\n",
    "        for fold in range(5):\n",
    "            print(\"times: %d, fold: %d\" % (int(i), int(fold)))\n",
    "            train_arr = np.loadtxt(f'data/{dataset}/data_dir/{i}/{fold}/train_arr.txt')\n",
    "            test_arr = np.loadtxt(f'data/{dataset}/data_dir/{i}/{fold}/test_arr.txt')\n",
    "            train_arr = train_arr.astype(np.int64)\n",
    "            test_arr = test_arr.astype(np.int64)\n",
    "            test_labels, scores, test_out_come = train(args, train_arr, test_arr, dataset, i, fold)\n",
    "            total_KFOLD_test_labels.append(test_labels)\n",
    "            total_FOLD_test_scores.append(scores)\n",
    "            KFOLD_test_out_come.append(test_out_come)\n",
    "\n",
    "    print('Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "association_matrix_shape: (39, 292)\n",
      "times: 0 Fold: 0 Test AUC: 0.9495 Test AUPR: 0.9474\n",
      "times: 0 Fold: 1 Test AUC: 0.9648 Test AUPR: 0.9527\n",
      "times: 0 Fold: 2 Test AUC: 0.9629 Test AUPR: 0.9596\n",
      "times: 0 Fold: 3 Test AUC: 0.9612 Test AUPR: 0.9576\n",
      "times: 0 Fold: 4 Test AUC: 0.9719 Test AUPR: 0.9784\n",
      "times: 1 Fold: 0 Test AUC: 0.9645 Test AUPR: 0.9644\n",
      "times: 1 Fold: 1 Test AUC: 0.9731 Test AUPR: 0.9681\n",
      "times: 1 Fold: 2 Test AUC: 0.9632 Test AUPR: 0.9591\n",
      "times: 1 Fold: 3 Test AUC: 0.9402 Test AUPR: 0.9366\n",
      "times: 1 Fold: 4 Test AUC: 0.9624 Test AUPR: 0.9574\n",
      "times: 2 Fold: 0 Test AUC: 0.9587 Test AUPR: 0.9629\n",
      "times: 2 Fold: 1 Test AUC: 0.9580 Test AUPR: 0.9644\n",
      "times: 2 Fold: 2 Test AUC: 0.9793 Test AUPR: 0.9802\n",
      "times: 2 Fold: 3 Test AUC: 0.9728 Test AUPR: 0.9729\n",
      "times: 2 Fold: 4 Test AUC: 0.9677 Test AUPR: 0.9668\n",
      "times: 3 Fold: 0 Test AUC: 0.9577 Test AUPR: 0.9509\n",
      "times: 3 Fold: 1 Test AUC: 0.9690 Test AUPR: 0.9537\n",
      "times: 3 Fold: 2 Test AUC: 0.9707 Test AUPR: 0.9718\n",
      "times: 3 Fold: 3 Test AUC: 0.9667 Test AUPR: 0.9655\n",
      "times: 3 Fold: 4 Test AUC: 0.9590 Test AUPR: 0.9521\n",
      "times: 4 Fold: 0 Test AUC: 0.9427 Test AUPR: 0.9369\n",
      "times: 4 Fold: 1 Test AUC: 0.9593 Test AUPR: 0.9518\n",
      "times: 4 Fold: 2 Test AUC: 0.9773 Test AUPR: 0.9823\n",
      "times: 4 Fold: 3 Test AUC: 0.9704 Test AUPR: 0.9632\n",
      "times: 4 Fold: 4 Test AUC: 0.9630 Test AUPR: 0.9644\n",
      "times: 5 Fold: 0 Test AUC: 0.9573 Test AUPR: 0.9597\n",
      "times: 5 Fold: 1 Test AUC: 0.9632 Test AUPR: 0.9606\n",
      "times: 5 Fold: 2 Test AUC: 0.9708 Test AUPR: 0.9701\n",
      "times: 5 Fold: 3 Test AUC: 0.9327 Test AUPR: 0.9164\n",
      "times: 5 Fold: 4 Test AUC: 0.9491 Test AUPR: 0.9442\n",
      "times: 6 Fold: 0 Test AUC: 0.9414 Test AUPR: 0.9377\n",
      "times: 6 Fold: 1 Test AUC: 0.9657 Test AUPR: 0.9663\n",
      "times: 6 Fold: 2 Test AUC: 0.9804 Test AUPR: 0.9768\n",
      "times: 6 Fold: 3 Test AUC: 0.9764 Test AUPR: 0.9763\n",
      "times: 6 Fold: 4 Test AUC: 0.9756 Test AUPR: 0.9749\n",
      "times: 7 Fold: 0 Test AUC: 0.9809 Test AUPR: 0.9795\n",
      "times: 7 Fold: 1 Test AUC: 0.9828 Test AUPR: 0.9832\n",
      "times: 7 Fold: 2 Test AUC: 0.9654 Test AUPR: 0.9622\n",
      "times: 7 Fold: 3 Test AUC: 0.9532 Test AUPR: 0.9504\n",
      "times: 7 Fold: 4 Test AUC: 0.9519 Test AUPR: 0.9309\n",
      "times: 8 Fold: 0 Test AUC: 0.9623 Test AUPR: 0.9614\n",
      "times: 8 Fold: 1 Test AUC: 0.9838 Test AUPR: 0.9849\n",
      "times: 8 Fold: 2 Test AUC: 0.9749 Test AUPR: 0.9756\n",
      "times: 8 Fold: 3 Test AUC: 0.9701 Test AUPR: 0.9700\n",
      "times: 8 Fold: 4 Test AUC: 0.9808 Test AUPR: 0.9806\n",
      "times: 9 Fold: 0 Test AUC: 0.9780 Test AUPR: 0.9740\n",
      "times: 9 Fold: 1 Test AUC: 0.9423 Test AUPR: 0.9449\n",
      "times: 9 Fold: 2 Test AUC: 0.9498 Test AUPR: 0.9468\n",
      "times: 9 Fold: 3 Test AUC: 0.9573 Test AUPR: 0.9545\n",
      "times: 9 Fold: 4 Test AUC: 0.9730 Test AUPR: 0.9764\n",
      "-AUC mean: 0.96410.0120 \n",
      " -AUPR mean: 0.96160.0148 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "statistic_total_AUC(args, total_KFOLD_test_labels, total_FOLD_test_scores, KFOLD_test_out_come)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement of GTGenie on LncRNADisease in 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow version 1.15.5 has been patched using tfdeterminism version 0.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times: 0, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "WARNING:tensorflow:From /hy-tmp/GTGenie_new/models/GAT.py:8: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /hy-tmp/GTGenie_new/models/GAT.py:19: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /hy-tmp/GTGenie_new/train.py:99: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "Epoch: 0001 | train_loss = 0.06445, train_auc = 0.46856, test_loss = 0.03880, test_auc = 0.36856, time = 2.17254\n",
      "Epoch: 0010 | train_loss = 0.03822, train_auc = 0.92992, test_loss = 0.02822, test_auc = 0.82354, time = 0.04894\n",
      "Epoch: 0020 | train_loss = 0.03176, train_auc = 0.93756, test_loss = 0.01829, test_auc = 0.90357, time = 0.04370\n",
      "Epoch: 0030 | train_loss = 0.02504, train_auc = 0.97215, test_loss = 0.01919, test_auc = 0.87314, time = 0.04443\n",
      "Epoch: 0040 | train_loss = 0.02247, train_auc = 0.97743, test_loss = 0.01864, test_auc = 0.88737, time = 0.04236\n",
      "Epoch: 0050 | train_loss = 0.01985, train_auc = 0.98362, test_loss = 0.01835, test_auc = 0.86784, time = 0.04247\n",
      "Epoch: 0060 | train_loss = 0.01892, train_auc = 0.98582, test_loss = 0.01635, test_auc = 0.92569, time = 0.04351\n",
      "Epoch: 0070 | train_loss = 0.01734, train_auc = 0.98824, test_loss = 0.01542, test_auc = 0.94967, time = 0.04255\n",
      "Epoch: 0080 | train_loss = 0.01444, train_auc = 0.99111, test_loss = 0.01454, test_auc = 0.96106, time = 0.04246\n",
      "Epoch: 0090 | train_loss = 0.01512, train_auc = 0.99166, test_loss = 0.01446, test_auc = 0.95713, time = 0.04200\n",
      "Epoch: 0100 | train_loss = 0.01461, train_auc = 0.99052, test_loss = 0.01415, test_auc = 0.96277, time = 0.04173\n",
      "Epoch: 0110 | train_loss = 0.01370, train_auc = 0.99231, test_loss = 0.01663, test_auc = 0.95413, time = 0.04184\n",
      "Epoch: 0120 | train_loss = 0.01115, train_auc = 0.99416, test_loss = 0.01404, test_auc = 0.96837, time = 0.04269\n",
      "Epoch: 0130 | train_loss = 0.01085, train_auc = 0.99383, test_loss = 0.01615, test_auc = 0.95740, time = 0.04260\n",
      "Epoch: 0140 | train_loss = 0.01104, train_auc = 0.99387, test_loss = 0.01371, test_auc = 0.96052, time = 0.04241\n",
      "Epoch: 0150 | train_loss = 0.01239, train_auc = 0.99191, test_loss = 0.01604, test_auc = 0.95262, time = 0.04211\n",
      "Epoch: 0160 | train_loss = 0.01105, train_auc = 0.99422, test_loss = 0.01507, test_auc = 0.96620, time = 0.04235\n",
      "Epoch: 0170 | train_loss = 0.01155, train_auc = 0.99435, test_loss = 0.01417, test_auc = 0.97000, time = 0.04219\n",
      "Epoch: 0180 | train_loss = 0.01101, train_auc = 0.99521, test_loss = 0.01230, test_auc = 0.97887, time = 0.04252\n",
      "Epoch: 0190 | train_loss = 0.00950, train_auc = 0.99497, test_loss = 0.01315, test_auc = 0.97188, time = 0.04320\n",
      "Epoch: 0200 | train_loss = 0.00954, train_auc = 0.99524, test_loss = 0.01280, test_auc = 0.97032, time = 0.04218\n",
      "Epoch: 0210 | train_loss = 0.00949, train_auc = 0.99542, test_loss = 0.01357, test_auc = 0.96404, time = 0.04330\n",
      "Epoch: 0220 | train_loss = 0.00996, train_auc = 0.99508, test_loss = 0.01796, test_auc = 0.94215, time = 0.04294\n",
      "Epoch: 0230 | train_loss = 0.00839, train_auc = 0.99602, test_loss = 0.01534, test_auc = 0.96453, time = 0.04327\n",
      "Epoch: 0240 | train_loss = 0.00942, train_auc = 0.99563, test_loss = 0.01210, test_auc = 0.98121, time = 0.04276\n",
      "Epoch: 0250 | train_loss = 0.00949, train_auc = 0.99550, test_loss = 0.01425, test_auc = 0.97110, time = 0.04418\n",
      "Epoch: 0260 | train_loss = 0.00897, train_auc = 0.99585, test_loss = 0.01281, test_auc = 0.98055, time = 0.04275\n",
      "Epoch: 0270 | train_loss = 0.00772, train_auc = 0.99566, test_loss = 0.01202, test_auc = 0.97516, time = 0.04238\n",
      "Epoch: 0280 | train_loss = 0.00748, train_auc = 0.99587, test_loss = 0.01306, test_auc = 0.96839, time = 0.04238\n",
      "Epoch: 0290 | train_loss = 0.00738, train_auc = 0.99615, test_loss = 0.01198, test_auc = 0.97862, time = 0.04233\n",
      "Epoch: 0300 | train_loss = 0.00748, train_auc = 0.99602, test_loss = 0.01159, test_auc = 0.97630, time = 0.04281\n",
      "times: 0, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06200, train_auc = 0.48107, test_loss = 0.02700, test_auc = 0.71899, time = 0.85278\n",
      "Epoch: 0010 | train_loss = 0.03812, train_auc = 0.93810, test_loss = 0.02452, test_auc = 0.87535, time = 0.05113\n",
      "Epoch: 0020 | train_loss = 0.02881, train_auc = 0.95769, test_loss = 0.02023, test_auc = 0.87797, time = 0.04433\n",
      "Epoch: 0030 | train_loss = 0.02524, train_auc = 0.96612, test_loss = 0.02133, test_auc = 0.81022, time = 0.04293\n",
      "Epoch: 0040 | train_loss = 0.02268, train_auc = 0.97531, test_loss = 0.02155, test_auc = 0.80406, time = 0.04342\n",
      "Epoch: 0050 | train_loss = 0.02033, train_auc = 0.97944, test_loss = 0.02092, test_auc = 0.80807, time = 0.04173\n",
      "Epoch: 0060 | train_loss = 0.01866, train_auc = 0.98410, test_loss = 0.01529, test_auc = 0.94777, time = 0.04305\n",
      "Epoch: 0070 | train_loss = 0.01769, train_auc = 0.98594, test_loss = 0.02004, test_auc = 0.86431, time = 0.04462\n",
      "Epoch: 0080 | train_loss = 0.01587, train_auc = 0.98822, test_loss = 0.01968, test_auc = 0.87727, time = 0.04302\n",
      "Epoch: 0090 | train_loss = 0.01702, train_auc = 0.98748, test_loss = 0.01643, test_auc = 0.94267, time = 0.05157\n",
      "Epoch: 0100 | train_loss = 0.01622, train_auc = 0.98986, test_loss = 0.01599, test_auc = 0.94692, time = 0.04189\n",
      "Epoch: 0110 | train_loss = 0.01285, train_auc = 0.99256, test_loss = 0.01724, test_auc = 0.94738, time = 0.04244\n",
      "Epoch: 0120 | train_loss = 0.01307, train_auc = 0.99291, test_loss = 0.01448, test_auc = 0.95430, time = 0.04220\n",
      "Epoch: 0130 | train_loss = 0.01445, train_auc = 0.98806, test_loss = 0.01742, test_auc = 0.93720, time = 0.04239\n",
      "Epoch: 0140 | train_loss = 0.01274, train_auc = 0.99373, test_loss = 0.01188, test_auc = 0.97908, time = 0.04172\n",
      "Epoch: 0150 | train_loss = 0.01080, train_auc = 0.99470, test_loss = 0.01178, test_auc = 0.97911, time = 0.04247\n",
      "Epoch: 0160 | train_loss = 0.01066, train_auc = 0.99639, test_loss = 0.01244, test_auc = 0.97708, time = 0.04170\n",
      "Epoch: 0170 | train_loss = 0.01080, train_auc = 0.99514, test_loss = 0.01318, test_auc = 0.97001, time = 0.04274\n",
      "Epoch: 0180 | train_loss = 0.01150, train_auc = 0.99523, test_loss = 0.01679, test_auc = 0.93561, time = 0.04249\n",
      "Epoch: 0190 | train_loss = 0.01014, train_auc = 0.99606, test_loss = 0.01563, test_auc = 0.94551, time = 0.04221\n",
      "Epoch: 0200 | train_loss = 0.00937, train_auc = 0.99610, test_loss = 0.01356, test_auc = 0.96489, time = 0.04255\n",
      "Epoch: 0210 | train_loss = 0.00915, train_auc = 0.99614, test_loss = 0.01346, test_auc = 0.96379, time = 0.04221\n",
      "Epoch: 0220 | train_loss = 0.00818, train_auc = 0.99658, test_loss = 0.01182, test_auc = 0.97784, time = 0.04207\n",
      "Epoch: 0230 | train_loss = 0.00950, train_auc = 0.99654, test_loss = 0.01357, test_auc = 0.97523, time = 0.04333\n",
      "Epoch: 0240 | train_loss = 0.00879, train_auc = 0.99658, test_loss = 0.01189, test_auc = 0.98046, time = 0.04770\n",
      "Epoch: 0250 | train_loss = 0.00977, train_auc = 0.99601, test_loss = 0.01097, test_auc = 0.98381, time = 0.04440\n",
      "Epoch: 0260 | train_loss = 0.00800, train_auc = 0.99649, test_loss = 0.01820, test_auc = 0.92541, time = 0.04420\n",
      "Epoch: 0270 | train_loss = 0.00803, train_auc = 0.99737, test_loss = 0.01196, test_auc = 0.97595, time = 0.04535\n",
      "Epoch: 0280 | train_loss = 0.00721, train_auc = 0.99712, test_loss = 0.01252, test_auc = 0.98186, time = 0.04431\n",
      "Epoch: 0290 | train_loss = 0.00824, train_auc = 0.99693, test_loss = 0.01099, test_auc = 0.98456, time = 0.04402\n",
      "Epoch: 0300 | train_loss = 0.00696, train_auc = 0.99666, test_loss = 0.01094, test_auc = 0.98283, time = 0.04319\n",
      "times: 0, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06216, train_auc = 0.46557, test_loss = 0.02949, test_auc = 0.65024, time = 0.81532\n",
      "Epoch: 0010 | train_loss = 0.03756, train_auc = 0.93321, test_loss = 0.02810, test_auc = 0.77583, time = 0.04729\n",
      "Epoch: 0020 | train_loss = 0.02812, train_auc = 0.96080, test_loss = 0.02401, test_auc = 0.79122, time = 0.04425\n",
      "Epoch: 0030 | train_loss = 0.02513, train_auc = 0.96927, test_loss = 0.02334, test_auc = 0.75685, time = 0.04236\n",
      "Epoch: 0040 | train_loss = 0.02298, train_auc = 0.97501, test_loss = 0.02207, test_auc = 0.78309, time = 0.04220\n",
      "Epoch: 0050 | train_loss = 0.02105, train_auc = 0.97906, test_loss = 0.02298, test_auc = 0.77462, time = 0.04269\n",
      "Epoch: 0060 | train_loss = 0.02057, train_auc = 0.98240, test_loss = 0.02177, test_auc = 0.80462, time = 0.04264\n",
      "Epoch: 0070 | train_loss = 0.01933, train_auc = 0.98360, test_loss = 0.02122, test_auc = 0.83951, time = 0.04236\n",
      "Epoch: 0080 | train_loss = 0.01760, train_auc = 0.98773, test_loss = 0.01449, test_auc = 0.96218, time = 0.04225\n",
      "Epoch: 0090 | train_loss = 0.01581, train_auc = 0.98987, test_loss = 0.01302, test_auc = 0.97377, time = 0.04257\n",
      "Epoch: 0100 | train_loss = 0.01568, train_auc = 0.99059, test_loss = 0.01705, test_auc = 0.93500, time = 0.04257\n",
      "Epoch: 0110 | train_loss = 0.01345, train_auc = 0.99314, test_loss = 0.01745, test_auc = 0.91240, time = 0.04240\n",
      "Epoch: 0120 | train_loss = 0.01245, train_auc = 0.99376, test_loss = 0.01239, test_auc = 0.97754, time = 0.04353\n",
      "Epoch: 0130 | train_loss = 0.01194, train_auc = 0.99544, test_loss = 0.01232, test_auc = 0.97832, time = 0.04283\n",
      "Epoch: 0140 | train_loss = 0.01242, train_auc = 0.99433, test_loss = 0.01494, test_auc = 0.95297, time = 0.04380\n",
      "Epoch: 0150 | train_loss = 0.01151, train_auc = 0.99481, test_loss = 0.01224, test_auc = 0.98000, time = 0.04280\n",
      "Epoch: 0160 | train_loss = 0.01117, train_auc = 0.99529, test_loss = 0.01304, test_auc = 0.97570, time = 0.04251\n",
      "Epoch: 0170 | train_loss = 0.00971, train_auc = 0.99605, test_loss = 0.01195, test_auc = 0.98017, time = 0.04354\n",
      "Epoch: 0180 | train_loss = 0.01053, train_auc = 0.99532, test_loss = 0.01678, test_auc = 0.92927, time = 0.04351\n",
      "Epoch: 0190 | train_loss = 0.00881, train_auc = 0.99618, test_loss = 0.01388, test_auc = 0.96661, time = 0.04751\n",
      "Epoch: 0200 | train_loss = 0.01027, train_auc = 0.99560, test_loss = 0.01223, test_auc = 0.97782, time = 0.04230\n",
      "Epoch: 0210 | train_loss = 0.00894, train_auc = 0.99547, test_loss = 0.01257, test_auc = 0.97873, time = 0.04223\n",
      "Epoch: 0220 | train_loss = 0.01114, train_auc = 0.99540, test_loss = 0.01505, test_auc = 0.92640, time = 0.04191\n",
      "Epoch: 0230 | train_loss = 0.00815, train_auc = 0.99616, test_loss = 0.01130, test_auc = 0.98403, time = 0.04212\n",
      "Epoch: 0240 | train_loss = 0.00881, train_auc = 0.99587, test_loss = 0.01194, test_auc = 0.98287, time = 0.04312\n",
      "Epoch: 0250 | train_loss = 0.00826, train_auc = 0.99556, test_loss = 0.01381, test_auc = 0.96951, time = 0.04180\n",
      "Epoch: 0260 | train_loss = 0.00840, train_auc = 0.99635, test_loss = 0.01228, test_auc = 0.97890, time = 0.04302\n",
      "Epoch: 0270 | train_loss = 0.00806, train_auc = 0.99572, test_loss = 0.01251, test_auc = 0.98332, time = 0.04144\n",
      "Epoch: 0280 | train_loss = 0.00731, train_auc = 0.99621, test_loss = 0.01644, test_auc = 0.97031, time = 0.04189\n",
      "Epoch: 0290 | train_loss = 0.00779, train_auc = 0.99574, test_loss = 0.01148, test_auc = 0.98206, time = 0.04140\n",
      "Epoch: 0300 | train_loss = 0.00842, train_auc = 0.99608, test_loss = 0.01165, test_auc = 0.98296, time = 0.04203\n",
      "times: 0, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06184, train_auc = 0.49468, test_loss = 0.03907, test_auc = 0.36836, time = 0.79421\n",
      "Epoch: 0010 | train_loss = 0.03962, train_auc = 0.93399, test_loss = 0.02572, test_auc = 0.91749, time = 0.04766\n",
      "Epoch: 0020 | train_loss = 0.02989, train_auc = 0.95493, test_loss = 0.02113, test_auc = 0.84381, time = 0.04555\n",
      "Epoch: 0030 | train_loss = 0.02582, train_auc = 0.96651, test_loss = 0.02318, test_auc = 0.74705, time = 0.04427\n",
      "Epoch: 0040 | train_loss = 0.02342, train_auc = 0.97356, test_loss = 0.02327, test_auc = 0.76820, time = 0.04400\n",
      "Epoch: 0050 | train_loss = 0.02217, train_auc = 0.97790, test_loss = 0.02312, test_auc = 0.77567, time = 0.04368\n",
      "Epoch: 0060 | train_loss = 0.02100, train_auc = 0.97936, test_loss = 0.02298, test_auc = 0.77522, time = 0.04398\n",
      "Epoch: 0070 | train_loss = 0.01933, train_auc = 0.98335, test_loss = 0.01539, test_auc = 0.94445, time = 0.04721\n",
      "Epoch: 0080 | train_loss = 0.01875, train_auc = 0.98483, test_loss = 0.01651, test_auc = 0.93846, time = 0.04406\n",
      "Epoch: 0090 | train_loss = 0.01738, train_auc = 0.98868, test_loss = 0.01430, test_auc = 0.95458, time = 0.04425\n",
      "Epoch: 0100 | train_loss = 0.01575, train_auc = 0.99152, test_loss = 0.01397, test_auc = 0.95845, time = 0.04386\n",
      "Epoch: 0110 | train_loss = 0.01568, train_auc = 0.99127, test_loss = 0.01572, test_auc = 0.93858, time = 0.04509\n",
      "Epoch: 0120 | train_loss = 0.01427, train_auc = 0.99267, test_loss = 0.01292, test_auc = 0.97064, time = 0.04427\n",
      "Epoch: 0130 | train_loss = 0.01260, train_auc = 0.99510, test_loss = 0.01537, test_auc = 0.93887, time = 0.04428\n",
      "Epoch: 0140 | train_loss = 0.01241, train_auc = 0.99485, test_loss = 0.01410, test_auc = 0.96961, time = 0.05122\n",
      "Epoch: 0150 | train_loss = 0.01271, train_auc = 0.99555, test_loss = 0.01555, test_auc = 0.96315, time = 0.04434\n",
      "Epoch: 0160 | train_loss = 0.01195, train_auc = 0.99585, test_loss = 0.01231, test_auc = 0.97726, time = 0.04396\n",
      "Epoch: 0170 | train_loss = 0.01032, train_auc = 0.99647, test_loss = 0.01164, test_auc = 0.97954, time = 0.04407\n",
      "Epoch: 0180 | train_loss = 0.01370, train_auc = 0.99206, test_loss = 0.01370, test_auc = 0.96538, time = 0.04457\n",
      "Epoch: 0190 | train_loss = 0.01043, train_auc = 0.99660, test_loss = 0.01284, test_auc = 0.97169, time = 0.04421\n",
      "Epoch: 0200 | train_loss = 0.00945, train_auc = 0.99676, test_loss = 0.01174, test_auc = 0.97842, time = 0.04446\n",
      "Epoch: 0210 | train_loss = 0.00893, train_auc = 0.99746, test_loss = 0.01195, test_auc = 0.97675, time = 0.04410\n",
      "Epoch: 0220 | train_loss = 0.00885, train_auc = 0.99732, test_loss = 0.01295, test_auc = 0.97856, time = 0.04360\n",
      "Epoch: 0230 | train_loss = 0.00873, train_auc = 0.99712, test_loss = 0.01197, test_auc = 0.97761, time = 0.04540\n",
      "Epoch: 0240 | train_loss = 0.00844, train_auc = 0.99795, test_loss = 0.01106, test_auc = 0.98080, time = 0.04391\n",
      "Epoch: 0250 | train_loss = 0.00762, train_auc = 0.99769, test_loss = 0.01244, test_auc = 0.97740, time = 0.04510\n",
      "Epoch: 0260 | train_loss = 0.00735, train_auc = 0.99756, test_loss = 0.01185, test_auc = 0.97900, time = 0.04470\n",
      "Epoch: 0270 | train_loss = 0.00765, train_auc = 0.99783, test_loss = 0.01174, test_auc = 0.97790, time = 0.04429\n",
      "Epoch: 0280 | train_loss = 0.00728, train_auc = 0.99778, test_loss = 0.01143, test_auc = 0.97471, time = 0.04462\n",
      "Epoch: 0290 | train_loss = 0.00729, train_auc = 0.99801, test_loss = 0.01150, test_auc = 0.98181, time = 0.04407\n",
      "Epoch: 0300 | train_loss = 0.00657, train_auc = 0.99786, test_loss = 0.01074, test_auc = 0.98092, time = 0.04545\n",
      "times: 0, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06302, train_auc = 0.45285, test_loss = 0.03679, test_auc = 0.44744, time = 0.81101\n",
      "Epoch: 0010 | train_loss = 0.03923, train_auc = 0.92942, test_loss = 0.03065, test_auc = 0.83499, time = 0.04969\n",
      "Epoch: 0020 | train_loss = 0.02900, train_auc = 0.95760, test_loss = 0.01742, test_auc = 0.93147, time = 0.04545\n",
      "Epoch: 0030 | train_loss = 0.02491, train_auc = 0.97220, test_loss = 0.02016, test_auc = 0.90234, time = 0.05048\n",
      "Epoch: 0040 | train_loss = 0.02288, train_auc = 0.97897, test_loss = 0.01838, test_auc = 0.87307, time = 0.04493\n",
      "Epoch: 0050 | train_loss = 0.02165, train_auc = 0.98127, test_loss = 0.01701, test_auc = 0.93237, time = 0.04706\n",
      "Epoch: 0060 | train_loss = 0.01904, train_auc = 0.98720, test_loss = 0.01611, test_auc = 0.93960, time = 0.04375\n",
      "Epoch: 0070 | train_loss = 0.01804, train_auc = 0.98854, test_loss = 0.01809, test_auc = 0.88007, time = 0.04546\n",
      "Epoch: 0080 | train_loss = 0.01557, train_auc = 0.99176, test_loss = 0.01983, test_auc = 0.92428, time = 0.04387\n",
      "Epoch: 0090 | train_loss = 0.01469, train_auc = 0.99327, test_loss = 0.01490, test_auc = 0.95947, time = 0.04325\n",
      "Epoch: 0100 | train_loss = 0.01272, train_auc = 0.99491, test_loss = 0.01535, test_auc = 0.94702, time = 0.04455\n",
      "Epoch: 0110 | train_loss = 0.01359, train_auc = 0.99450, test_loss = 0.01591, test_auc = 0.95906, time = 0.04276\n",
      "Epoch: 0120 | train_loss = 0.01294, train_auc = 0.99475, test_loss = 0.01374, test_auc = 0.96753, time = 0.04253\n",
      "Epoch: 0130 | train_loss = 0.01130, train_auc = 0.99655, test_loss = 0.01643, test_auc = 0.90310, time = 0.04384\n",
      "Epoch: 0140 | train_loss = 0.01063, train_auc = 0.99672, test_loss = 0.01194, test_auc = 0.97942, time = 0.04356\n",
      "Epoch: 0150 | train_loss = 0.00977, train_auc = 0.99724, test_loss = 0.01123, test_auc = 0.98048, time = 0.04420\n",
      "Epoch: 0160 | train_loss = 0.01089, train_auc = 0.99689, test_loss = 0.01311, test_auc = 0.97220, time = 0.04338\n",
      "Epoch: 0170 | train_loss = 0.01002, train_auc = 0.99644, test_loss = 0.01098, test_auc = 0.97618, time = 0.04321\n",
      "Epoch: 0180 | train_loss = 0.00990, train_auc = 0.99689, test_loss = 0.01495, test_auc = 0.95503, time = 0.04347\n",
      "Epoch: 0190 | train_loss = 0.00861, train_auc = 0.99730, test_loss = 0.01338, test_auc = 0.96231, time = 0.04364\n",
      "Epoch: 0200 | train_loss = 0.00804, train_auc = 0.99793, test_loss = 0.01242, test_auc = 0.97002, time = 0.04520\n",
      "Epoch: 0210 | train_loss = 0.00806, train_auc = 0.99787, test_loss = 0.01119, test_auc = 0.97686, time = 0.04342\n",
      "Epoch: 0220 | train_loss = 0.00904, train_auc = 0.99744, test_loss = 0.01135, test_auc = 0.97476, time = 0.04414\n",
      "Epoch: 0230 | train_loss = 0.00777, train_auc = 0.99773, test_loss = 0.01148, test_auc = 0.97905, time = 0.04413\n",
      "Epoch: 0240 | train_loss = 0.00706, train_auc = 0.99794, test_loss = 0.01253, test_auc = 0.97809, time = 0.04345\n",
      "Epoch: 0250 | train_loss = 0.00785, train_auc = 0.99771, test_loss = 0.01349, test_auc = 0.97432, time = 0.04360\n",
      "Epoch: 0260 | train_loss = 0.00755, train_auc = 0.99793, test_loss = 0.01222, test_auc = 0.97640, time = 0.04364\n",
      "Epoch: 0270 | train_loss = 0.00797, train_auc = 0.99792, test_loss = 0.01145, test_auc = 0.97711, time = 0.04262\n",
      "Epoch: 0280 | train_loss = 0.00698, train_auc = 0.99797, test_loss = 0.01116, test_auc = 0.97993, time = 0.04294\n",
      "Epoch: 0290 | train_loss = 0.00730, train_auc = 0.99797, test_loss = 0.01174, test_auc = 0.97820, time = 0.04644\n",
      "Epoch: 0300 | train_loss = 0.00708, train_auc = 0.99786, test_loss = 0.01383, test_auc = 0.96572, time = 0.04362\n",
      "times: 1, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06522, train_auc = 0.41176, test_loss = 0.03942, test_auc = 0.36225, time = 0.80279\n",
      "Epoch: 0010 | train_loss = 0.03573, train_auc = 0.93571, test_loss = 0.02757, test_auc = 0.83584, time = 0.04575\n",
      "Epoch: 0020 | train_loss = 0.02820, train_auc = 0.95933, test_loss = 0.01772, test_auc = 0.92352, time = 0.04196\n",
      "Epoch: 0030 | train_loss = 0.02506, train_auc = 0.97074, test_loss = 0.01783, test_auc = 0.91640, time = 0.04344\n",
      "Epoch: 0040 | train_loss = 0.02202, train_auc = 0.97931, test_loss = 0.01853, test_auc = 0.91830, time = 0.04149\n",
      "Epoch: 0050 | train_loss = 0.01998, train_auc = 0.98425, test_loss = 0.01905, test_auc = 0.90306, time = 0.04250\n",
      "Epoch: 0060 | train_loss = 0.01845, train_auc = 0.98685, test_loss = 0.01481, test_auc = 0.95832, time = 0.04224\n",
      "Epoch: 0070 | train_loss = 0.01789, train_auc = 0.98792, test_loss = 0.01536, test_auc = 0.94688, time = 0.04298\n",
      "Epoch: 0080 | train_loss = 0.01555, train_auc = 0.99120, test_loss = 0.01787, test_auc = 0.92458, time = 0.04290\n",
      "Epoch: 0090 | train_loss = 0.01492, train_auc = 0.99190, test_loss = 0.01221, test_auc = 0.97112, time = 0.04101\n",
      "Epoch: 0100 | train_loss = 0.01321, train_auc = 0.99436, test_loss = 0.01720, test_auc = 0.92691, time = 0.04135\n",
      "Epoch: 0110 | train_loss = 0.01236, train_auc = 0.99494, test_loss = 0.01484, test_auc = 0.94984, time = 0.04167\n",
      "Epoch: 0120 | train_loss = 0.01314, train_auc = 0.99393, test_loss = 0.01282, test_auc = 0.96415, time = 0.04122\n",
      "Epoch: 0130 | train_loss = 0.01252, train_auc = 0.99430, test_loss = 0.01227, test_auc = 0.96680, time = 0.04124\n",
      "Epoch: 0140 | train_loss = 0.01105, train_auc = 0.99605, test_loss = 0.02178, test_auc = 0.80379, time = 0.04122\n",
      "Epoch: 0150 | train_loss = 0.01171, train_auc = 0.99532, test_loss = 0.01720, test_auc = 0.95366, time = 0.04172\n",
      "Epoch: 0160 | train_loss = 0.00981, train_auc = 0.99681, test_loss = 0.01052, test_auc = 0.97731, time = 0.04115\n",
      "Epoch: 0170 | train_loss = 0.01053, train_auc = 0.99663, test_loss = 0.01193, test_auc = 0.97330, time = 0.04161\n",
      "Epoch: 0180 | train_loss = 0.00917, train_auc = 0.99691, test_loss = 0.01126, test_auc = 0.97439, time = 0.04139\n",
      "Epoch: 0190 | train_loss = 0.00976, train_auc = 0.99666, test_loss = 0.01142, test_auc = 0.97394, time = 0.04167\n",
      "Epoch: 0200 | train_loss = 0.00934, train_auc = 0.99788, test_loss = 0.01146, test_auc = 0.96831, time = 0.04141\n",
      "Epoch: 0210 | train_loss = 0.00902, train_auc = 0.99701, test_loss = 0.01089, test_auc = 0.97407, time = 0.04163\n",
      "Epoch: 0220 | train_loss = 0.00998, train_auc = 0.99708, test_loss = 0.01105, test_auc = 0.97780, time = 0.04186\n",
      "Epoch: 0230 | train_loss = 0.00971, train_auc = 0.99802, test_loss = 0.01438, test_auc = 0.95064, time = 0.04120\n",
      "Epoch: 0240 | train_loss = 0.00859, train_auc = 0.99755, test_loss = 0.01089, test_auc = 0.97254, time = 0.04168\n",
      "Epoch: 0250 | train_loss = 0.00828, train_auc = 0.99735, test_loss = 0.01612, test_auc = 0.95256, time = 0.04230\n",
      "Epoch: 0260 | train_loss = 0.00782, train_auc = 0.99776, test_loss = 0.01092, test_auc = 0.97295, time = 0.04136\n",
      "Epoch: 0270 | train_loss = 0.00739, train_auc = 0.99788, test_loss = 0.01176, test_auc = 0.96837, time = 0.04120\n",
      "Epoch: 0280 | train_loss = 0.00796, train_auc = 0.99802, test_loss = 0.01121, test_auc = 0.97198, time = 0.04137\n",
      "Epoch: 0290 | train_loss = 0.00655, train_auc = 0.99802, test_loss = 0.01059, test_auc = 0.97354, time = 0.04142\n",
      "Epoch: 0300 | train_loss = 0.00734, train_auc = 0.99779, test_loss = 0.01154, test_auc = 0.96960, time = 0.04137\n",
      "times: 1, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06744, train_auc = 0.36556, test_loss = 0.03744, test_auc = 0.41941, time = 0.76532\n",
      "Epoch: 0010 | train_loss = 0.04080, train_auc = 0.90253, test_loss = 0.02623, test_auc = 0.84365, time = 0.04542\n",
      "Epoch: 0020 | train_loss = 0.03232, train_auc = 0.94763, test_loss = 0.01828, test_auc = 0.91989, time = 0.04250\n",
      "Epoch: 0030 | train_loss = 0.02685, train_auc = 0.96616, test_loss = 0.01604, test_auc = 0.94166, time = 0.04206\n",
      "Epoch: 0040 | train_loss = 0.02314, train_auc = 0.97486, test_loss = 0.01918, test_auc = 0.87271, time = 0.04250\n",
      "Epoch: 0050 | train_loss = 0.02140, train_auc = 0.98120, test_loss = 0.01711, test_auc = 0.93372, time = 0.04215\n",
      "Epoch: 0060 | train_loss = 0.01932, train_auc = 0.98557, test_loss = 0.01515, test_auc = 0.94911, time = 0.04527\n",
      "Epoch: 0070 | train_loss = 0.01864, train_auc = 0.98769, test_loss = 0.01480, test_auc = 0.96004, time = 0.04166\n",
      "Epoch: 0080 | train_loss = 0.01719, train_auc = 0.98882, test_loss = 0.01516, test_auc = 0.95734, time = 0.04151\n",
      "Epoch: 0090 | train_loss = 0.01536, train_auc = 0.99173, test_loss = 0.01282, test_auc = 0.97216, time = 0.04138\n",
      "Epoch: 0100 | train_loss = 0.01460, train_auc = 0.99242, test_loss = 0.01544, test_auc = 0.91739, time = 0.04175\n",
      "Epoch: 0110 | train_loss = 0.01530, train_auc = 0.99109, test_loss = 0.01631, test_auc = 0.90944, time = 0.04111\n",
      "Epoch: 0120 | train_loss = 0.01372, train_auc = 0.99319, test_loss = 0.01399, test_auc = 0.96528, time = 0.04149\n",
      "Epoch: 0130 | train_loss = 0.01256, train_auc = 0.99410, test_loss = 0.01455, test_auc = 0.94667, time = 0.04165\n",
      "Epoch: 0140 | train_loss = 0.01168, train_auc = 0.99512, test_loss = 0.01461, test_auc = 0.95019, time = 0.04176\n",
      "Epoch: 0150 | train_loss = 0.01303, train_auc = 0.99445, test_loss = 0.01098, test_auc = 0.98276, time = 0.04180\n",
      "Epoch: 0160 | train_loss = 0.01172, train_auc = 0.99531, test_loss = 0.01243, test_auc = 0.98117, time = 0.04128\n",
      "Epoch: 0170 | train_loss = 0.01063, train_auc = 0.99568, test_loss = 0.01126, test_auc = 0.98068, time = 0.04149\n",
      "Epoch: 0180 | train_loss = 0.00991, train_auc = 0.99587, test_loss = 0.01353, test_auc = 0.96667, time = 0.04240\n",
      "Epoch: 0190 | train_loss = 0.01007, train_auc = 0.99640, test_loss = 0.01568, test_auc = 0.93874, time = 0.04201\n",
      "Epoch: 0200 | train_loss = 0.01007, train_auc = 0.99650, test_loss = 0.01485, test_auc = 0.93281, time = 0.04150\n",
      "Epoch: 0210 | train_loss = 0.00913, train_auc = 0.99712, test_loss = 0.01405, test_auc = 0.97704, time = 0.04162\n",
      "Epoch: 0220 | train_loss = 0.00908, train_auc = 0.99658, test_loss = 0.00953, test_auc = 0.98762, time = 0.04158\n",
      "Epoch: 0230 | train_loss = 0.00852, train_auc = 0.99650, test_loss = 0.01165, test_auc = 0.97449, time = 0.04152\n",
      "Epoch: 0240 | train_loss = 0.00921, train_auc = 0.99669, test_loss = 0.01411, test_auc = 0.96135, time = 0.04164\n",
      "Epoch: 0250 | train_loss = 0.00859, train_auc = 0.99665, test_loss = 0.01421, test_auc = 0.97300, time = 0.04134\n",
      "Epoch: 0260 | train_loss = 0.00836, train_auc = 0.99666, test_loss = 0.01057, test_auc = 0.98288, time = 0.04147\n",
      "Epoch: 0270 | train_loss = 0.00833, train_auc = 0.99646, test_loss = 0.01229, test_auc = 0.97848, time = 0.04134\n",
      "Epoch: 0280 | train_loss = 0.00848, train_auc = 0.99634, test_loss = 0.01215, test_auc = 0.97828, time = 0.04158\n",
      "Epoch: 0290 | train_loss = 0.00669, train_auc = 0.99663, test_loss = 0.01038, test_auc = 0.98305, time = 0.04143\n",
      "Epoch: 0300 | train_loss = 0.00831, train_auc = 0.99713, test_loss = 0.01316, test_auc = 0.97751, time = 0.04204\n",
      "times: 1, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06200, train_auc = 0.52055, test_loss = 0.03526, test_auc = 0.49965, time = 0.78631\n",
      "Epoch: 0010 | train_loss = 0.04094, train_auc = 0.91606, test_loss = 0.02786, test_auc = 0.87053, time = 0.04644\n",
      "Epoch: 0020 | train_loss = 0.03104, train_auc = 0.95036, test_loss = 0.01650, test_auc = 0.92382, time = 0.04367\n",
      "Epoch: 0030 | train_loss = 0.02588, train_auc = 0.96807, test_loss = 0.02386, test_auc = 0.73366, time = 0.04061\n",
      "Epoch: 0040 | train_loss = 0.02403, train_auc = 0.97285, test_loss = 0.01926, test_auc = 0.88605, time = 0.04151\n",
      "Epoch: 0050 | train_loss = 0.02188, train_auc = 0.97814, test_loss = 0.01999, test_auc = 0.89051, time = 0.04653\n",
      "Epoch: 0060 | train_loss = 0.01978, train_auc = 0.98250, test_loss = 0.01965, test_auc = 0.81496, time = 0.05121\n",
      "Epoch: 0070 | train_loss = 0.01868, train_auc = 0.98482, test_loss = 0.01459, test_auc = 0.94870, time = 0.04122\n",
      "Epoch: 0080 | train_loss = 0.01724, train_auc = 0.98641, test_loss = 0.01867, test_auc = 0.87173, time = 0.04148\n",
      "Epoch: 0090 | train_loss = 0.01639, train_auc = 0.98813, test_loss = 0.01833, test_auc = 0.94236, time = 0.04083\n",
      "Epoch: 0100 | train_loss = 0.01581, train_auc = 0.98732, test_loss = 0.01606, test_auc = 0.95254, time = 0.04070\n",
      "Epoch: 0110 | train_loss = 0.01475, train_auc = 0.98975, test_loss = 0.01111, test_auc = 0.97974, time = 0.04084\n",
      "Epoch: 0120 | train_loss = 0.01432, train_auc = 0.99169, test_loss = 0.01683, test_auc = 0.94421, time = 0.04078\n",
      "Epoch: 0130 | train_loss = 0.01380, train_auc = 0.99252, test_loss = 0.01767, test_auc = 0.92438, time = 0.04044\n",
      "Epoch: 0140 | train_loss = 0.01170, train_auc = 0.99364, test_loss = 0.01151, test_auc = 0.97845, time = 0.04073\n",
      "Epoch: 0150 | train_loss = 0.01242, train_auc = 0.99309, test_loss = 0.01557, test_auc = 0.95677, time = 0.04053\n",
      "Epoch: 0160 | train_loss = 0.01228, train_auc = 0.99357, test_loss = 0.01243, test_auc = 0.97474, time = 0.04038\n",
      "Epoch: 0170 | train_loss = 0.01053, train_auc = 0.99451, test_loss = 0.01097, test_auc = 0.97834, time = 0.04142\n",
      "Epoch: 0180 | train_loss = 0.01154, train_auc = 0.99415, test_loss = 0.01373, test_auc = 0.96600, time = 0.04122\n",
      "Epoch: 0190 | train_loss = 0.01105, train_auc = 0.99362, test_loss = 0.02051, test_auc = 0.92329, time = 0.04213\n",
      "Epoch: 0200 | train_loss = 0.01134, train_auc = 0.99460, test_loss = 0.01775, test_auc = 0.93650, time = 0.04030\n",
      "Epoch: 0210 | train_loss = 0.01174, train_auc = 0.99405, test_loss = 0.01152, test_auc = 0.97976, time = 0.04173\n",
      "Epoch: 0220 | train_loss = 0.01161, train_auc = 0.99420, test_loss = 0.01277, test_auc = 0.97323, time = 0.04008\n",
      "Epoch: 0230 | train_loss = 0.01010, train_auc = 0.99512, test_loss = 0.01664, test_auc = 0.94198, time = 0.04101\n",
      "Epoch: 0240 | train_loss = 0.01006, train_auc = 0.99584, test_loss = 0.01265, test_auc = 0.97278, time = 0.04066\n",
      "Epoch: 0250 | train_loss = 0.00876, train_auc = 0.99666, test_loss = 0.01430, test_auc = 0.96463, time = 0.04099\n",
      "Epoch: 0260 | train_loss = 0.00925, train_auc = 0.99587, test_loss = 0.01584, test_auc = 0.94730, time = 0.04095\n",
      "Epoch: 0270 | train_loss = 0.00951, train_auc = 0.99652, test_loss = 0.01070, test_auc = 0.98192, time = 0.04294\n",
      "Epoch: 0280 | train_loss = 0.00852, train_auc = 0.99698, test_loss = 0.01089, test_auc = 0.98075, time = 0.04106\n",
      "Epoch: 0290 | train_loss = 0.00751, train_auc = 0.99734, test_loss = 0.01498, test_auc = 0.96665, time = 0.04137\n",
      "Epoch: 0300 | train_loss = 0.00760, train_auc = 0.99675, test_loss = 0.01088, test_auc = 0.98210, time = 0.04132\n",
      "times: 1, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06129, train_auc = 0.48973, test_loss = 0.03499, test_auc = 0.47877, time = 0.77991\n",
      "Epoch: 0010 | train_loss = 0.04073, train_auc = 0.92723, test_loss = 0.02526, test_auc = 0.77010, time = 0.05070\n",
      "Epoch: 0020 | train_loss = 0.03035, train_auc = 0.96129, test_loss = 0.01812, test_auc = 0.92360, time = 0.04705\n",
      "Epoch: 0030 | train_loss = 0.02565, train_auc = 0.97099, test_loss = 0.01498, test_auc = 0.94713, time = 0.04655\n",
      "Epoch: 0040 | train_loss = 0.02356, train_auc = 0.97780, test_loss = 0.01508, test_auc = 0.94898, time = 0.04481\n",
      "Epoch: 0050 | train_loss = 0.02101, train_auc = 0.98273, test_loss = 0.02139, test_auc = 0.80063, time = 0.04429\n",
      "Epoch: 0060 | train_loss = 0.01912, train_auc = 0.98665, test_loss = 0.01437, test_auc = 0.95251, time = 0.04429\n",
      "Epoch: 0070 | train_loss = 0.01666, train_auc = 0.99039, test_loss = 0.01690, test_auc = 0.93389, time = 0.04418\n",
      "Epoch: 0080 | train_loss = 0.01565, train_auc = 0.99222, test_loss = 0.01378, test_auc = 0.96234, time = 0.04468\n",
      "Epoch: 0090 | train_loss = 0.01402, train_auc = 0.99353, test_loss = 0.01691, test_auc = 0.89178, time = 0.04387\n",
      "Epoch: 0100 | train_loss = 0.01417, train_auc = 0.99300, test_loss = 0.01351, test_auc = 0.96571, time = 0.04414\n",
      "Epoch: 0110 | train_loss = 0.01273, train_auc = 0.99543, test_loss = 0.01666, test_auc = 0.94519, time = 0.04460\n",
      "Epoch: 0120 | train_loss = 0.01240, train_auc = 0.99540, test_loss = 0.01305, test_auc = 0.96376, time = 0.04437\n",
      "Epoch: 0130 | train_loss = 0.01242, train_auc = 0.99564, test_loss = 0.01310, test_auc = 0.96768, time = 0.04430\n",
      "Epoch: 0140 | train_loss = 0.01117, train_auc = 0.99598, test_loss = 0.01288, test_auc = 0.97097, time = 0.04365\n",
      "Epoch: 0150 | train_loss = 0.01051, train_auc = 0.99649, test_loss = 0.01205, test_auc = 0.97438, time = 0.04595\n",
      "Epoch: 0160 | train_loss = 0.01023, train_auc = 0.99676, test_loss = 0.01132, test_auc = 0.97418, time = 0.04419\n",
      "Epoch: 0170 | train_loss = 0.01008, train_auc = 0.99669, test_loss = 0.01312, test_auc = 0.96794, time = 0.04400\n",
      "Epoch: 0180 | train_loss = 0.00978, train_auc = 0.99666, test_loss = 0.01301, test_auc = 0.96930, time = 0.04451\n",
      "Epoch: 0190 | train_loss = 0.00967, train_auc = 0.99726, test_loss = 0.01491, test_auc = 0.94094, time = 0.04386\n",
      "Epoch: 0200 | train_loss = 0.00932, train_auc = 0.99748, test_loss = 0.01399, test_auc = 0.96144, time = 0.04424\n",
      "Epoch: 0210 | train_loss = 0.00854, train_auc = 0.99796, test_loss = 0.01241, test_auc = 0.96729, time = 0.04413\n",
      "Epoch: 0220 | train_loss = 0.00860, train_auc = 0.99787, test_loss = 0.01606, test_auc = 0.95215, time = 0.04437\n",
      "Epoch: 0230 | train_loss = 0.00804, train_auc = 0.99815, test_loss = 0.01088, test_auc = 0.97670, time = 0.04398\n",
      "Epoch: 0240 | train_loss = 0.00846, train_auc = 0.99772, test_loss = 0.01671, test_auc = 0.94997, time = 0.04473\n",
      "Epoch: 0250 | train_loss = 0.00800, train_auc = 0.99776, test_loss = 0.01448, test_auc = 0.96648, time = 0.04420\n",
      "Epoch: 0260 | train_loss = 0.00745, train_auc = 0.99817, test_loss = 0.01272, test_auc = 0.96967, time = 0.05130\n",
      "Epoch: 0270 | train_loss = 0.00629, train_auc = 0.99830, test_loss = 0.01201, test_auc = 0.97039, time = 0.04409\n",
      "Epoch: 0280 | train_loss = 0.00779, train_auc = 0.99772, test_loss = 0.01238, test_auc = 0.97144, time = 0.04419\n",
      "Epoch: 0290 | train_loss = 0.00616, train_auc = 0.99845, test_loss = 0.01078, test_auc = 0.97691, time = 0.04439\n",
      "Epoch: 0300 | train_loss = 0.00728, train_auc = 0.99832, test_loss = 0.01258, test_auc = 0.96877, time = 0.04407\n",
      "times: 1, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06410, train_auc = 0.43642, test_loss = 0.03436, test_auc = 0.51842, time = 0.80163\n",
      "Epoch: 0010 | train_loss = 0.03884, train_auc = 0.93130, test_loss = 0.02749, test_auc = 0.79430, time = 0.04855\n",
      "Epoch: 0020 | train_loss = 0.02933, train_auc = 0.95840, test_loss = 0.01699, test_auc = 0.92757, time = 0.04552\n",
      "Epoch: 0030 | train_loss = 0.02470, train_auc = 0.97226, test_loss = 0.01644, test_auc = 0.93417, time = 0.04504\n",
      "Epoch: 0040 | train_loss = 0.02314, train_auc = 0.97818, test_loss = 0.01593, test_auc = 0.94036, time = 0.04403\n",
      "Epoch: 0050 | train_loss = 0.02029, train_auc = 0.98307, test_loss = 0.01515, test_auc = 0.95162, time = 0.04402\n",
      "Epoch: 0060 | train_loss = 0.01895, train_auc = 0.98574, test_loss = 0.01571, test_auc = 0.92864, time = 0.04398\n",
      "Epoch: 0070 | train_loss = 0.01762, train_auc = 0.98763, test_loss = 0.01582, test_auc = 0.92114, time = 0.04348\n",
      "Epoch: 0080 | train_loss = 0.01670, train_auc = 0.98990, test_loss = 0.01213, test_auc = 0.97320, time = 0.04419\n",
      "Epoch: 0090 | train_loss = 0.01450, train_auc = 0.99157, test_loss = 0.01305, test_auc = 0.96824, time = 0.04396\n",
      "Epoch: 0100 | train_loss = 0.01441, train_auc = 0.99128, test_loss = 0.01246, test_auc = 0.97542, time = 0.04398\n",
      "Epoch: 0110 | train_loss = 0.01353, train_auc = 0.99316, test_loss = 0.01275, test_auc = 0.97141, time = 0.04470\n",
      "Epoch: 0120 | train_loss = 0.01270, train_auc = 0.99368, test_loss = 0.01190, test_auc = 0.97372, time = 0.04569\n",
      "Epoch: 0130 | train_loss = 0.01191, train_auc = 0.99374, test_loss = 0.01606, test_auc = 0.93007, time = 0.04380\n",
      "Epoch: 0140 | train_loss = 0.01155, train_auc = 0.99403, test_loss = 0.01800, test_auc = 0.85457, time = 0.04389\n",
      "Epoch: 0150 | train_loss = 0.01103, train_auc = 0.99455, test_loss = 0.01379, test_auc = 0.97009, time = 0.04323\n",
      "Epoch: 0160 | train_loss = 0.01115, train_auc = 0.99542, test_loss = 0.01546, test_auc = 0.95166, time = 0.04297\n",
      "Epoch: 0170 | train_loss = 0.01141, train_auc = 0.99506, test_loss = 0.01437, test_auc = 0.96301, time = 0.04358\n",
      "Epoch: 0180 | train_loss = 0.00919, train_auc = 0.99626, test_loss = 0.01238, test_auc = 0.97204, time = 0.04376\n",
      "Epoch: 0190 | train_loss = 0.01163, train_auc = 0.99437, test_loss = 0.01203, test_auc = 0.97729, time = 0.04380\n",
      "Epoch: 0200 | train_loss = 0.01104, train_auc = 0.99536, test_loss = 0.01386, test_auc = 0.97021, time = 0.04405\n",
      "Epoch: 0210 | train_loss = 0.00954, train_auc = 0.99412, test_loss = 0.01436, test_auc = 0.97136, time = 0.04383\n",
      "Epoch: 0220 | train_loss = 0.00928, train_auc = 0.99549, test_loss = 0.01109, test_auc = 0.98112, time = 0.04388\n",
      "Epoch: 0230 | train_loss = 0.00984, train_auc = 0.99520, test_loss = 0.01070, test_auc = 0.97890, time = 0.04327\n",
      "Epoch: 0240 | train_loss = 0.00817, train_auc = 0.99642, test_loss = 0.01195, test_auc = 0.97967, time = 0.04371\n",
      "Epoch: 0250 | train_loss = 0.01004, train_auc = 0.99703, test_loss = 0.01041, test_auc = 0.98411, time = 0.04436\n",
      "Epoch: 0260 | train_loss = 0.00831, train_auc = 0.99663, test_loss = 0.01153, test_auc = 0.97989, time = 0.04424\n",
      "Epoch: 0270 | train_loss = 0.00726, train_auc = 0.99649, test_loss = 0.01079, test_auc = 0.98430, time = 0.04444\n",
      "Epoch: 0280 | train_loss = 0.00797, train_auc = 0.99691, test_loss = 0.01051, test_auc = 0.98175, time = 0.04376\n",
      "Epoch: 0290 | train_loss = 0.00834, train_auc = 0.99624, test_loss = 0.01016, test_auc = 0.98141, time = 0.04352\n",
      "Epoch: 0300 | train_loss = 0.00780, train_auc = 0.99677, test_loss = 0.00969, test_auc = 0.98521, time = 0.04400\n",
      "times: 2, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06398, train_auc = 0.43773, test_loss = 0.03658, test_auc = 0.42821, time = 0.80241\n",
      "Epoch: 0010 | train_loss = 0.03899, train_auc = 0.91284, test_loss = 0.03039, test_auc = 0.81903, time = 0.04774\n",
      "Epoch: 0020 | train_loss = 0.02990, train_auc = 0.95302, test_loss = 0.01656, test_auc = 0.93276, time = 0.04676\n",
      "Epoch: 0030 | train_loss = 0.02571, train_auc = 0.96971, test_loss = 0.02395, test_auc = 0.75903, time = 0.04339\n",
      "Epoch: 0040 | train_loss = 0.02331, train_auc = 0.97710, test_loss = 0.02185, test_auc = 0.77111, time = 0.04367\n",
      "Epoch: 0050 | train_loss = 0.02119, train_auc = 0.98166, test_loss = 0.01837, test_auc = 0.86639, time = 0.04342\n",
      "Epoch: 0060 | train_loss = 0.01857, train_auc = 0.98730, test_loss = 0.01365, test_auc = 0.95900, time = 0.04161\n",
      "Epoch: 0070 | train_loss = 0.01777, train_auc = 0.98670, test_loss = 0.02299, test_auc = 0.78090, time = 0.04499\n",
      "Epoch: 0080 | train_loss = 0.01611, train_auc = 0.98898, test_loss = 0.02112, test_auc = 0.83030, time = 0.04420\n",
      "Epoch: 0090 | train_loss = 0.01792, train_auc = 0.98567, test_loss = 0.01379, test_auc = 0.96373, time = 0.04387\n",
      "Epoch: 0100 | train_loss = 0.01650, train_auc = 0.98909, test_loss = 0.01683, test_auc = 0.92946, time = 0.04483\n",
      "Epoch: 0110 | train_loss = 0.01463, train_auc = 0.99246, test_loss = 0.01952, test_auc = 0.91105, time = 0.04468\n",
      "Epoch: 0120 | train_loss = 0.01307, train_auc = 0.99396, test_loss = 0.01773, test_auc = 0.89732, time = 0.04505\n",
      "Epoch: 0130 | train_loss = 0.01226, train_auc = 0.99422, test_loss = 0.01993, test_auc = 0.83165, time = 0.04502\n",
      "Epoch: 0140 | train_loss = 0.01169, train_auc = 0.99496, test_loss = 0.01807, test_auc = 0.92438, time = 0.04355\n",
      "Epoch: 0150 | train_loss = 0.01203, train_auc = 0.99535, test_loss = 0.01808, test_auc = 0.91377, time = 0.04472\n",
      "Epoch: 0160 | train_loss = 0.01075, train_auc = 0.99603, test_loss = 0.01309, test_auc = 0.96340, time = 0.04450\n",
      "Epoch: 0170 | train_loss = 0.01021, train_auc = 0.99593, test_loss = 0.01279, test_auc = 0.97118, time = 0.04429\n",
      "Epoch: 0180 | train_loss = 0.01112, train_auc = 0.99384, test_loss = 0.01915, test_auc = 0.90123, time = 0.04380\n",
      "Epoch: 0190 | train_loss = 0.00953, train_auc = 0.99646, test_loss = 0.01899, test_auc = 0.89441, time = 0.04410\n",
      "Epoch: 0200 | train_loss = 0.01014, train_auc = 0.99594, test_loss = 0.01916, test_auc = 0.90796, time = 0.04426\n",
      "Epoch: 0210 | train_loss = 0.00841, train_auc = 0.99679, test_loss = 0.01746, test_auc = 0.93678, time = 0.04428\n",
      "Epoch: 0220 | train_loss = 0.00842, train_auc = 0.99664, test_loss = 0.01130, test_auc = 0.97921, time = 0.04367\n",
      "Epoch: 0230 | train_loss = 0.00879, train_auc = 0.99676, test_loss = 0.01225, test_auc = 0.97054, time = 0.04410\n",
      "Epoch: 0240 | train_loss = 0.00827, train_auc = 0.99686, test_loss = 0.01089, test_auc = 0.97898, time = 0.04408\n",
      "Epoch: 0250 | train_loss = 0.00978, train_auc = 0.99651, test_loss = 0.01624, test_auc = 0.95848, time = 0.04407\n",
      "Epoch: 0260 | train_loss = 0.00782, train_auc = 0.99705, test_loss = 0.01290, test_auc = 0.97050, time = 0.04373\n",
      "Epoch: 0270 | train_loss = 0.00780, train_auc = 0.99671, test_loss = 0.01189, test_auc = 0.97594, time = 0.04391\n",
      "Epoch: 0280 | train_loss = 0.00849, train_auc = 0.99629, test_loss = 0.01392, test_auc = 0.96297, time = 0.04604\n",
      "Epoch: 0290 | train_loss = 0.00797, train_auc = 0.99703, test_loss = 0.01332, test_auc = 0.96667, time = 0.04472\n",
      "Epoch: 0300 | train_loss = 0.00854, train_auc = 0.99622, test_loss = 0.01092, test_auc = 0.97940, time = 0.04601\n",
      "times: 2, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.05993, train_auc = 0.55241, test_loss = 0.03820, test_auc = 0.39325, time = 0.79301\n",
      "Epoch: 0010 | train_loss = 0.03999, train_auc = 0.92570, test_loss = 0.02919, test_auc = 0.91072, time = 0.04775\n",
      "Epoch: 0020 | train_loss = 0.02978, train_auc = 0.95799, test_loss = 0.01708, test_auc = 0.93123, time = 0.04274\n",
      "Epoch: 0030 | train_loss = 0.02591, train_auc = 0.96702, test_loss = 0.01493, test_auc = 0.94742, time = 0.04165\n",
      "Epoch: 0040 | train_loss = 0.02230, train_auc = 0.97806, test_loss = 0.01917, test_auc = 0.86187, time = 0.04102\n",
      "Epoch: 0050 | train_loss = 0.02047, train_auc = 0.98248, test_loss = 0.01800, test_auc = 0.88120, time = 0.04250\n",
      "Epoch: 0060 | train_loss = 0.01918, train_auc = 0.98487, test_loss = 0.01704, test_auc = 0.93235, time = 0.04226\n",
      "Epoch: 0070 | train_loss = 0.01753, train_auc = 0.98694, test_loss = 0.01996, test_auc = 0.80919, time = 0.04215\n",
      "Epoch: 0080 | train_loss = 0.01857, train_auc = 0.98623, test_loss = 0.01706, test_auc = 0.93313, time = 0.04211\n",
      "Epoch: 0090 | train_loss = 0.01678, train_auc = 0.98785, test_loss = 0.01972, test_auc = 0.87192, time = 0.04156\n",
      "Epoch: 0100 | train_loss = 0.01422, train_auc = 0.99148, test_loss = 0.01895, test_auc = 0.88123, time = 0.04127\n",
      "Epoch: 0110 | train_loss = 0.01367, train_auc = 0.99294, test_loss = 0.01835, test_auc = 0.90760, time = 0.04151\n",
      "Epoch: 0120 | train_loss = 0.01362, train_auc = 0.99374, test_loss = 0.01590, test_auc = 0.94153, time = 0.04154\n",
      "Epoch: 0130 | train_loss = 0.01337, train_auc = 0.99179, test_loss = 0.02167, test_auc = 0.84460, time = 0.04187\n",
      "Epoch: 0140 | train_loss = 0.01245, train_auc = 0.99492, test_loss = 0.01609, test_auc = 0.92212, time = 0.04136\n",
      "Epoch: 0150 | train_loss = 0.01193, train_auc = 0.99559, test_loss = 0.01431, test_auc = 0.96444, time = 0.04638\n",
      "Epoch: 0160 | train_loss = 0.01258, train_auc = 0.99419, test_loss = 0.01183, test_auc = 0.97330, time = 0.04170\n",
      "Epoch: 0170 | train_loss = 0.01042, train_auc = 0.99575, test_loss = 0.01858, test_auc = 0.93096, time = 0.04143\n",
      "Epoch: 0180 | train_loss = 0.01039, train_auc = 0.99687, test_loss = 0.01889, test_auc = 0.92685, time = 0.04106\n",
      "Epoch: 0190 | train_loss = 0.01063, train_auc = 0.99569, test_loss = 0.01496, test_auc = 0.95420, time = 0.04133\n",
      "Epoch: 0200 | train_loss = 0.00929, train_auc = 0.99725, test_loss = 0.01319, test_auc = 0.96778, time = 0.04173\n",
      "Epoch: 0210 | train_loss = 0.00920, train_auc = 0.99733, test_loss = 0.01214, test_auc = 0.97772, time = 0.04139\n",
      "Epoch: 0220 | train_loss = 0.00952, train_auc = 0.99704, test_loss = 0.01331, test_auc = 0.97111, time = 0.04137\n",
      "Epoch: 0230 | train_loss = 0.01073, train_auc = 0.99591, test_loss = 0.01188, test_auc = 0.97769, time = 0.04144\n",
      "Epoch: 0240 | train_loss = 0.00873, train_auc = 0.99672, test_loss = 0.01398, test_auc = 0.96211, time = 0.04176\n",
      "Epoch: 0250 | train_loss = 0.00922, train_auc = 0.99523, test_loss = 0.01276, test_auc = 0.97265, time = 0.04125\n",
      "Epoch: 0260 | train_loss = 0.00831, train_auc = 0.99699, test_loss = 0.01350, test_auc = 0.97182, time = 0.04207\n",
      "Epoch: 0270 | train_loss = 0.00887, train_auc = 0.99667, test_loss = 0.01244, test_auc = 0.96727, time = 0.04231\n",
      "Epoch: 0280 | train_loss = 0.00750, train_auc = 0.99754, test_loss = 0.01287, test_auc = 0.97139, time = 0.04118\n",
      "Epoch: 0290 | train_loss = 0.00750, train_auc = 0.99763, test_loss = 0.01375, test_auc = 0.96194, time = 0.04161\n",
      "Epoch: 0300 | train_loss = 0.00750, train_auc = 0.99767, test_loss = 0.01233, test_auc = 0.97720, time = 0.04173\n",
      "times: 2, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06596, train_auc = 0.40755, test_loss = 0.03833, test_auc = 0.38386, time = 0.81055\n",
      "Epoch: 0010 | train_loss = 0.03833, train_auc = 0.92988, test_loss = 0.02637, test_auc = 0.90212, time = 0.04743\n",
      "Epoch: 0020 | train_loss = 0.02843, train_auc = 0.96080, test_loss = 0.02184, test_auc = 0.84265, time = 0.04453\n",
      "Epoch: 0030 | train_loss = 0.02405, train_auc = 0.97440, test_loss = 0.02105, test_auc = 0.82538, time = 0.04351\n",
      "Epoch: 0040 | train_loss = 0.02191, train_auc = 0.98001, test_loss = 0.01872, test_auc = 0.89568, time = 0.04338\n",
      "Epoch: 0050 | train_loss = 0.01989, train_auc = 0.98354, test_loss = 0.01846, test_auc = 0.89731, time = 0.04288\n",
      "Epoch: 0060 | train_loss = 0.01892, train_auc = 0.98528, test_loss = 0.01693, test_auc = 0.92898, time = 0.04290\n",
      "Epoch: 0070 | train_loss = 0.01770, train_auc = 0.98734, test_loss = 0.01956, test_auc = 0.90867, time = 0.04444\n",
      "Epoch: 0080 | train_loss = 0.01605, train_auc = 0.98919, test_loss = 0.01676, test_auc = 0.94872, time = 0.04318\n",
      "Epoch: 0090 | train_loss = 0.01593, train_auc = 0.99036, test_loss = 0.01885, test_auc = 0.91882, time = 0.04498\n",
      "Epoch: 0100 | train_loss = 0.01548, train_auc = 0.98952, test_loss = 0.01502, test_auc = 0.95479, time = 0.04293\n",
      "Epoch: 0110 | train_loss = 0.01470, train_auc = 0.99079, test_loss = 0.01360, test_auc = 0.96145, time = 0.04277\n",
      "Epoch: 0120 | train_loss = 0.01288, train_auc = 0.99321, test_loss = 0.01698, test_auc = 0.94129, time = 0.04325\n",
      "Epoch: 0130 | train_loss = 0.01114, train_auc = 0.99446, test_loss = 0.01435, test_auc = 0.96451, time = 0.04290\n",
      "Epoch: 0140 | train_loss = 0.01143, train_auc = 0.99523, test_loss = 0.01661, test_auc = 0.94955, time = 0.04315\n",
      "Epoch: 0150 | train_loss = 0.01099, train_auc = 0.99494, test_loss = 0.01276, test_auc = 0.97032, time = 0.04288\n",
      "Epoch: 0160 | train_loss = 0.01103, train_auc = 0.99533, test_loss = 0.01513, test_auc = 0.95667, time = 0.04334\n",
      "Epoch: 0170 | train_loss = 0.01099, train_auc = 0.99471, test_loss = 0.01195, test_auc = 0.97703, time = 0.04358\n",
      "Epoch: 0180 | train_loss = 0.01015, train_auc = 0.99543, test_loss = 0.01021, test_auc = 0.98508, time = 0.04296\n",
      "Epoch: 0190 | train_loss = 0.00945, train_auc = 0.99531, test_loss = 0.01437, test_auc = 0.96189, time = 0.04277\n",
      "Epoch: 0200 | train_loss = 0.01049, train_auc = 0.99584, test_loss = 0.01308, test_auc = 0.97237, time = 0.04261\n",
      "Epoch: 0210 | train_loss = 0.01031, train_auc = 0.99544, test_loss = 0.01262, test_auc = 0.97799, time = 0.04328\n",
      "Epoch: 0220 | train_loss = 0.00912, train_auc = 0.99620, test_loss = 0.01261, test_auc = 0.97265, time = 0.04400\n",
      "Epoch: 0230 | train_loss = 0.00986, train_auc = 0.99607, test_loss = 0.01417, test_auc = 0.95890, time = 0.04236\n",
      "Epoch: 0240 | train_loss = 0.00796, train_auc = 0.99675, test_loss = 0.01462, test_auc = 0.97089, time = 0.04313\n",
      "Epoch: 0250 | train_loss = 0.00879, train_auc = 0.99687, test_loss = 0.01247, test_auc = 0.97342, time = 0.04321\n",
      "Epoch: 0260 | train_loss = 0.00771, train_auc = 0.99762, test_loss = 0.01576, test_auc = 0.94656, time = 0.04545\n",
      "Epoch: 0270 | train_loss = 0.00685, train_auc = 0.99736, test_loss = 0.01631, test_auc = 0.95208, time = 0.04293\n",
      "Epoch: 0280 | train_loss = 0.00845, train_auc = 0.99658, test_loss = 0.01650, test_auc = 0.91083, time = 0.04365\n",
      "Epoch: 0290 | train_loss = 0.00758, train_auc = 0.99680, test_loss = 0.01360, test_auc = 0.96872, time = 0.04394\n",
      "Epoch: 0300 | train_loss = 0.00682, train_auc = 0.99737, test_loss = 0.01583, test_auc = 0.92948, time = 0.04306\n",
      "times: 2, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06043, train_auc = 0.52470, test_loss = 0.02958, test_auc = 0.66417, time = 0.81284\n",
      "Epoch: 0010 | train_loss = 0.04021, train_auc = 0.91325, test_loss = 0.02627, test_auc = 0.82522, time = 0.04821\n",
      "Epoch: 0020 | train_loss = 0.02979, train_auc = 0.95730, test_loss = 0.01761, test_auc = 0.92671, time = 0.04670\n",
      "Epoch: 0030 | train_loss = 0.02617, train_auc = 0.96931, test_loss = 0.02191, test_auc = 0.83365, time = 0.04440\n",
      "Epoch: 0040 | train_loss = 0.02287, train_auc = 0.97876, test_loss = 0.02201, test_auc = 0.79440, time = 0.04439\n",
      "Epoch: 0050 | train_loss = 0.02222, train_auc = 0.98076, test_loss = 0.01555, test_auc = 0.94667, time = 0.04561\n",
      "Epoch: 0060 | train_loss = 0.01960, train_auc = 0.98652, test_loss = 0.01844, test_auc = 0.91816, time = 0.04355\n",
      "Epoch: 0070 | train_loss = 0.01883, train_auc = 0.98671, test_loss = 0.01687, test_auc = 0.93208, time = 0.04307\n",
      "Epoch: 0080 | train_loss = 0.01761, train_auc = 0.98891, test_loss = 0.01451, test_auc = 0.95217, time = 0.04315\n",
      "Epoch: 0090 | train_loss = 0.01570, train_auc = 0.99087, test_loss = 0.01320, test_auc = 0.96776, time = 0.04267\n",
      "Epoch: 0100 | train_loss = 0.01463, train_auc = 0.99236, test_loss = 0.01351, test_auc = 0.96428, time = 0.04326\n",
      "Epoch: 0110 | train_loss = 0.01381, train_auc = 0.99328, test_loss = 0.01345, test_auc = 0.96340, time = 0.04261\n",
      "Epoch: 0120 | train_loss = 0.01262, train_auc = 0.99413, test_loss = 0.01400, test_auc = 0.95963, time = 0.04291\n",
      "Epoch: 0130 | train_loss = 0.01407, train_auc = 0.99259, test_loss = 0.02053, test_auc = 0.82862, time = 0.04323\n",
      "Epoch: 0140 | train_loss = 0.01178, train_auc = 0.99506, test_loss = 0.01651, test_auc = 0.94975, time = 0.04264\n",
      "Epoch: 0150 | train_loss = 0.01133, train_auc = 0.99508, test_loss = 0.01387, test_auc = 0.95849, time = 0.04237\n",
      "Epoch: 0160 | train_loss = 0.01080, train_auc = 0.99593, test_loss = 0.01457, test_auc = 0.95724, time = 0.04273\n",
      "Epoch: 0170 | train_loss = 0.00936, train_auc = 0.99657, test_loss = 0.01644, test_auc = 0.94481, time = 0.04274\n",
      "Epoch: 0180 | train_loss = 0.00937, train_auc = 0.99644, test_loss = 0.01332, test_auc = 0.96892, time = 0.04287\n",
      "Epoch: 0190 | train_loss = 0.01085, train_auc = 0.99606, test_loss = 0.01423, test_auc = 0.95825, time = 0.04279\n",
      "Epoch: 0200 | train_loss = 0.00971, train_auc = 0.99547, test_loss = 0.01509, test_auc = 0.95974, time = 0.04371\n",
      "Epoch: 0210 | train_loss = 0.01002, train_auc = 0.99603, test_loss = 0.01310, test_auc = 0.97127, time = 0.04451\n",
      "Epoch: 0220 | train_loss = 0.00913, train_auc = 0.99703, test_loss = 0.01289, test_auc = 0.96161, time = 0.04324\n",
      "Epoch: 0230 | train_loss = 0.00883, train_auc = 0.99689, test_loss = 0.01180, test_auc = 0.97780, time = 0.04303\n",
      "Epoch: 0240 | train_loss = 0.00961, train_auc = 0.99666, test_loss = 0.01310, test_auc = 0.97448, time = 0.04582\n",
      "Epoch: 0250 | train_loss = 0.00909, train_auc = 0.99718, test_loss = 0.01180, test_auc = 0.97802, time = 0.04265\n",
      "Epoch: 0260 | train_loss = 0.00942, train_auc = 0.99740, test_loss = 0.01165, test_auc = 0.97905, time = 0.04315\n",
      "Epoch: 0270 | train_loss = 0.00774, train_auc = 0.99794, test_loss = 0.01396, test_auc = 0.94943, time = 0.04419\n",
      "Epoch: 0280 | train_loss = 0.00949, train_auc = 0.99634, test_loss = 0.01722, test_auc = 0.94678, time = 0.04485\n",
      "Epoch: 0290 | train_loss = 0.00843, train_auc = 0.99765, test_loss = 0.01250, test_auc = 0.97615, time = 0.04376\n",
      "Epoch: 0300 | train_loss = 0.00612, train_auc = 0.99783, test_loss = 0.01107, test_auc = 0.97645, time = 0.04266\n",
      "times: 2, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06048, train_auc = 0.52023, test_loss = 0.03919, test_auc = 0.35947, time = 0.80543\n",
      "Epoch: 0010 | train_loss = 0.03705, train_auc = 0.93314, test_loss = 0.02356, test_auc = 0.86948, time = 0.04774\n",
      "Epoch: 0020 | train_loss = 0.02736, train_auc = 0.96430, test_loss = 0.01779, test_auc = 0.91970, time = 0.04276\n",
      "Epoch: 0030 | train_loss = 0.02357, train_auc = 0.97571, test_loss = 0.02279, test_auc = 0.79502, time = 0.04278\n",
      "Epoch: 0040 | train_loss = 0.02163, train_auc = 0.97900, test_loss = 0.02264, test_auc = 0.81729, time = 0.04116\n",
      "Epoch: 0050 | train_loss = 0.02051, train_auc = 0.98184, test_loss = 0.02167, test_auc = 0.86342, time = 0.04505\n",
      "Epoch: 0060 | train_loss = 0.01877, train_auc = 0.98530, test_loss = 0.02105, test_auc = 0.90199, time = 0.04106\n",
      "Epoch: 0070 | train_loss = 0.01698, train_auc = 0.98766, test_loss = 0.01490, test_auc = 0.94526, time = 0.04107\n",
      "Epoch: 0080 | train_loss = 0.01780, train_auc = 0.98693, test_loss = 0.01497, test_auc = 0.95751, time = 0.04106\n",
      "Epoch: 0090 | train_loss = 0.01598, train_auc = 0.98917, test_loss = 0.01339, test_auc = 0.96318, time = 0.04110\n",
      "Epoch: 0100 | train_loss = 0.01463, train_auc = 0.99105, test_loss = 0.01469, test_auc = 0.95045, time = 0.04112\n",
      "Epoch: 0110 | train_loss = 0.01347, train_auc = 0.99175, test_loss = 0.01424, test_auc = 0.96118, time = 0.04028\n",
      "Epoch: 0120 | train_loss = 0.01340, train_auc = 0.99225, test_loss = 0.01715, test_auc = 0.89960, time = 0.04094\n",
      "Epoch: 0130 | train_loss = 0.01255, train_auc = 0.99439, test_loss = 0.01611, test_auc = 0.92022, time = 0.04035\n",
      "Epoch: 0140 | train_loss = 0.01197, train_auc = 0.99448, test_loss = 0.01328, test_auc = 0.96944, time = 0.04030\n",
      "Epoch: 0150 | train_loss = 0.01226, train_auc = 0.99443, test_loss = 0.01607, test_auc = 0.92042, time = 0.04185\n",
      "Epoch: 0160 | train_loss = 0.01197, train_auc = 0.99211, test_loss = 0.01335, test_auc = 0.96416, time = 0.04128\n",
      "Epoch: 0170 | train_loss = 0.01117, train_auc = 0.99466, test_loss = 0.01331, test_auc = 0.96865, time = 0.04184\n",
      "Epoch: 0180 | train_loss = 0.01012, train_auc = 0.99501, test_loss = 0.01500, test_auc = 0.95507, time = 0.04121\n",
      "Epoch: 0190 | train_loss = 0.00926, train_auc = 0.99507, test_loss = 0.01278, test_auc = 0.96837, time = 0.04093\n",
      "Epoch: 0200 | train_loss = 0.00953, train_auc = 0.99526, test_loss = 0.01253, test_auc = 0.97097, time = 0.04108\n",
      "Epoch: 0210 | train_loss = 0.01000, train_auc = 0.99558, test_loss = 0.01241, test_auc = 0.97430, time = 0.04164\n",
      "Epoch: 0220 | train_loss = 0.01018, train_auc = 0.99542, test_loss = 0.01849, test_auc = 0.93767, time = 0.04101\n",
      "Epoch: 0230 | train_loss = 0.00964, train_auc = 0.99478, test_loss = 0.01390, test_auc = 0.96650, time = 0.04133\n",
      "Epoch: 0240 | train_loss = 0.01066, train_auc = 0.99623, test_loss = 0.01512, test_auc = 0.92744, time = 0.04066\n",
      "Epoch: 0250 | train_loss = 0.00954, train_auc = 0.99590, test_loss = 0.01249, test_auc = 0.97334, time = 0.04197\n",
      "Epoch: 0260 | train_loss = 0.00873, train_auc = 0.99635, test_loss = 0.01254, test_auc = 0.97342, time = 0.04748\n",
      "Epoch: 0270 | train_loss = 0.00839, train_auc = 0.99570, test_loss = 0.01359, test_auc = 0.96559, time = 0.04108\n",
      "Epoch: 0280 | train_loss = 0.00961, train_auc = 0.99608, test_loss = 0.01287, test_auc = 0.97576, time = 0.04078\n",
      "Epoch: 0290 | train_loss = 0.00882, train_auc = 0.99591, test_loss = 0.01257, test_auc = 0.97149, time = 0.04135\n",
      "Epoch: 0300 | train_loss = 0.00827, train_auc = 0.99651, test_loss = 0.01285, test_auc = 0.96789, time = 0.04101\n",
      "times: 3, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06232, train_auc = 0.46876, test_loss = 0.03646, test_auc = 0.45128, time = 0.82695\n",
      "Epoch: 0010 | train_loss = 0.03718, train_auc = 0.93275, test_loss = 0.02394, test_auc = 0.85798, time = 0.04976\n",
      "Epoch: 0020 | train_loss = 0.02913, train_auc = 0.95339, test_loss = 0.01820, test_auc = 0.90911, time = 0.04589\n",
      "Epoch: 0030 | train_loss = 0.02518, train_auc = 0.96951, test_loss = 0.01734, test_auc = 0.91465, time = 0.04509\n",
      "Epoch: 0040 | train_loss = 0.02280, train_auc = 0.97674, test_loss = 0.01774, test_auc = 0.91364, time = 0.04412\n",
      "Epoch: 0050 | train_loss = 0.02358, train_auc = 0.96663, test_loss = 0.01649, test_auc = 0.93776, time = 0.04514\n",
      "Epoch: 0060 | train_loss = 0.02017, train_auc = 0.98089, test_loss = 0.01720, test_auc = 0.92538, time = 0.04404\n",
      "Epoch: 0070 | train_loss = 0.01754, train_auc = 0.98596, test_loss = 0.01658, test_auc = 0.92537, time = 0.04468\n",
      "Epoch: 0080 | train_loss = 0.01759, train_auc = 0.98643, test_loss = 0.01662, test_auc = 0.93506, time = 0.04512\n",
      "Epoch: 0090 | train_loss = 0.01631, train_auc = 0.98908, test_loss = 0.01651, test_auc = 0.94412, time = 0.04399\n",
      "Epoch: 0100 | train_loss = 0.01497, train_auc = 0.98976, test_loss = 0.01513, test_auc = 0.95037, time = 0.04413\n",
      "Epoch: 0110 | train_loss = 0.01532, train_auc = 0.98999, test_loss = 0.01565, test_auc = 0.95131, time = 0.04405\n",
      "Epoch: 0120 | train_loss = 0.01295, train_auc = 0.99126, test_loss = 0.01482, test_auc = 0.95706, time = 0.04406\n",
      "Epoch: 0130 | train_loss = 0.01280, train_auc = 0.99343, test_loss = 0.01672, test_auc = 0.94623, time = 0.04472\n",
      "Epoch: 0140 | train_loss = 0.01238, train_auc = 0.99195, test_loss = 0.01341, test_auc = 0.96407, time = 0.04463\n",
      "Epoch: 0150 | train_loss = 0.01103, train_auc = 0.99263, test_loss = 0.01402, test_auc = 0.96408, time = 0.04387\n",
      "Epoch: 0160 | train_loss = 0.01182, train_auc = 0.99325, test_loss = 0.01472, test_auc = 0.95651, time = 0.04383\n",
      "Epoch: 0170 | train_loss = 0.01149, train_auc = 0.99445, test_loss = 0.01737, test_auc = 0.93539, time = 0.04448\n",
      "Epoch: 0180 | train_loss = 0.01203, train_auc = 0.99414, test_loss = 0.01512, test_auc = 0.95565, time = 0.04401\n",
      "Epoch: 0190 | train_loss = 0.01082, train_auc = 0.99423, test_loss = 0.02002, test_auc = 0.85972, time = 0.04587\n",
      "Epoch: 0200 | train_loss = 0.01058, train_auc = 0.99611, test_loss = 0.01294, test_auc = 0.96973, time = 0.04432\n",
      "Epoch: 0210 | train_loss = 0.00945, train_auc = 0.99632, test_loss = 0.01468, test_auc = 0.95787, time = 0.04386\n",
      "Epoch: 0220 | train_loss = 0.01103, train_auc = 0.99208, test_loss = 0.01333, test_auc = 0.96531, time = 0.04386\n",
      "Epoch: 0230 | train_loss = 0.01064, train_auc = 0.99260, test_loss = 0.01179, test_auc = 0.97536, time = 0.04581\n",
      "Epoch: 0240 | train_loss = 0.00929, train_auc = 0.99558, test_loss = 0.01288, test_auc = 0.96935, time = 0.04462\n",
      "Epoch: 0250 | train_loss = 0.00917, train_auc = 0.99605, test_loss = 0.01391, test_auc = 0.96062, time = 0.04359\n",
      "Epoch: 0260 | train_loss = 0.00843, train_auc = 0.99655, test_loss = 0.01254, test_auc = 0.97078, time = 0.04354\n",
      "Epoch: 0270 | train_loss = 0.00866, train_auc = 0.99643, test_loss = 0.01299, test_auc = 0.96900, time = 0.04730\n",
      "Epoch: 0280 | train_loss = 0.00828, train_auc = 0.99621, test_loss = 0.01219, test_auc = 0.97240, time = 0.04377\n",
      "Epoch: 0290 | train_loss = 0.00854, train_auc = 0.99735, test_loss = 0.01150, test_auc = 0.97370, time = 0.04798\n",
      "Epoch: 0300 | train_loss = 0.00867, train_auc = 0.99701, test_loss = 0.01462, test_auc = 0.96279, time = 0.04426\n",
      "times: 3, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06495, train_auc = 0.44086, test_loss = 0.03963, test_auc = 0.33398, time = 0.80590\n",
      "Epoch: 0010 | train_loss = 0.04289, train_auc = 0.88904, test_loss = 0.02499, test_auc = 0.84557, time = 0.05010\n",
      "Epoch: 0020 | train_loss = 0.03198, train_auc = 0.94575, test_loss = 0.02104, test_auc = 0.84420, time = 0.04819\n",
      "Epoch: 0030 | train_loss = 0.02838, train_auc = 0.95577, test_loss = 0.01745, test_auc = 0.91621, time = 0.04618\n",
      "Epoch: 0040 | train_loss = 0.02530, train_auc = 0.96931, test_loss = 0.01896, test_auc = 0.88124, time = 0.04646\n",
      "Epoch: 0050 | train_loss = 0.02434, train_auc = 0.97254, test_loss = 0.01949, test_auc = 0.85627, time = 0.04553\n",
      "Epoch: 0060 | train_loss = 0.02176, train_auc = 0.97986, test_loss = 0.02010, test_auc = 0.81930, time = 0.04551\n",
      "Epoch: 0070 | train_loss = 0.02221, train_auc = 0.97879, test_loss = 0.01717, test_auc = 0.90879, time = 0.04567\n",
      "Epoch: 0080 | train_loss = 0.01913, train_auc = 0.98783, test_loss = 0.01285, test_auc = 0.96793, time = 0.04586\n",
      "Epoch: 0090 | train_loss = 0.01823, train_auc = 0.98524, test_loss = 0.01767, test_auc = 0.88384, time = 0.04525\n",
      "Epoch: 0100 | train_loss = 0.01608, train_auc = 0.99199, test_loss = 0.01616, test_auc = 0.93744, time = 0.04576\n",
      "Epoch: 0110 | train_loss = 0.01438, train_auc = 0.99345, test_loss = 0.01816, test_auc = 0.89012, time = 0.04581\n",
      "Epoch: 0120 | train_loss = 0.01511, train_auc = 0.99220, test_loss = 0.01368, test_auc = 0.96152, time = 0.04554\n",
      "Epoch: 0130 | train_loss = 0.01342, train_auc = 0.99480, test_loss = 0.01575, test_auc = 0.93360, time = 0.04538\n",
      "Epoch: 0140 | train_loss = 0.01290, train_auc = 0.99607, test_loss = 0.01757, test_auc = 0.91318, time = 0.04676\n",
      "Epoch: 0150 | train_loss = 0.01338, train_auc = 0.99553, test_loss = 0.01842, test_auc = 0.88109, time = 0.04517\n",
      "Epoch: 0160 | train_loss = 0.01095, train_auc = 0.99702, test_loss = 0.01822, test_auc = 0.92215, time = 0.04660\n",
      "Epoch: 0170 | train_loss = 0.01077, train_auc = 0.99674, test_loss = 0.01515, test_auc = 0.94799, time = 0.04493\n",
      "Epoch: 0180 | train_loss = 0.00915, train_auc = 0.99729, test_loss = 0.01421, test_auc = 0.95691, time = 0.04527\n",
      "Epoch: 0190 | train_loss = 0.00963, train_auc = 0.99683, test_loss = 0.01290, test_auc = 0.97109, time = 0.04478\n",
      "Epoch: 0200 | train_loss = 0.00835, train_auc = 0.99710, test_loss = 0.01705, test_auc = 0.93982, time = 0.04591\n",
      "Epoch: 0210 | train_loss = 0.00971, train_auc = 0.99665, test_loss = 0.01238, test_auc = 0.96882, time = 0.04581\n",
      "Epoch: 0220 | train_loss = 0.00889, train_auc = 0.99698, test_loss = 0.01611, test_auc = 0.94829, time = 0.04495\n",
      "Epoch: 0230 | train_loss = 0.00814, train_auc = 0.99730, test_loss = 0.01807, test_auc = 0.90408, time = 0.04505\n",
      "Epoch: 0240 | train_loss = 0.00856, train_auc = 0.99759, test_loss = 0.01195, test_auc = 0.97533, time = 0.04519\n",
      "Epoch: 0250 | train_loss = 0.00765, train_auc = 0.99774, test_loss = 0.01062, test_auc = 0.97748, time = 0.04827\n",
      "Epoch: 0260 | train_loss = 0.01051, train_auc = 0.99647, test_loss = 0.01191, test_auc = 0.97609, time = 0.04531\n",
      "Epoch: 0270 | train_loss = 0.00917, train_auc = 0.99748, test_loss = 0.01338, test_auc = 0.96694, time = 0.04533\n",
      "Epoch: 0280 | train_loss = 0.00756, train_auc = 0.99757, test_loss = 0.01804, test_auc = 0.93324, time = 0.04638\n",
      "Epoch: 0290 | train_loss = 0.00718, train_auc = 0.99786, test_loss = 0.01338, test_auc = 0.97171, time = 0.04608\n",
      "Epoch: 0300 | train_loss = 0.00779, train_auc = 0.99804, test_loss = 0.01529, test_auc = 0.95246, time = 0.04577\n",
      "times: 3, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.05626, train_auc = 0.60090, test_loss = 0.03842, test_auc = 0.39545, time = 0.80351\n",
      "Epoch: 0010 | train_loss = 0.03758, train_auc = 0.92850, test_loss = 0.02620, test_auc = 0.85330, time = 0.04781\n",
      "Epoch: 0020 | train_loss = 0.03043, train_auc = 0.95291, test_loss = 0.02167, test_auc = 0.82724, time = 0.04291\n",
      "Epoch: 0030 | train_loss = 0.02635, train_auc = 0.96589, test_loss = 0.02025, test_auc = 0.83654, time = 0.04297\n",
      "Epoch: 0040 | train_loss = 0.02346, train_auc = 0.97491, test_loss = 0.02113, test_auc = 0.80225, time = 0.04358\n",
      "Epoch: 0050 | train_loss = 0.02130, train_auc = 0.98029, test_loss = 0.02023, test_auc = 0.86732, time = 0.04398\n",
      "Epoch: 0060 | train_loss = 0.01865, train_auc = 0.98493, test_loss = 0.01999, test_auc = 0.85535, time = 0.04423\n",
      "Epoch: 0070 | train_loss = 0.01909, train_auc = 0.98538, test_loss = 0.01435, test_auc = 0.94660, time = 0.04375\n",
      "Epoch: 0080 | train_loss = 0.01991, train_auc = 0.98414, test_loss = 0.01610, test_auc = 0.93678, time = 0.04269\n",
      "Epoch: 0090 | train_loss = 0.01564, train_auc = 0.98975, test_loss = 0.01508, test_auc = 0.94289, time = 0.04341\n",
      "Epoch: 0100 | train_loss = 0.01515, train_auc = 0.99142, test_loss = 0.01816, test_auc = 0.89752, time = 0.04346\n",
      "Epoch: 0110 | train_loss = 0.01391, train_auc = 0.99391, test_loss = 0.01534, test_auc = 0.95597, time = 0.04326\n",
      "Epoch: 0120 | train_loss = 0.01341, train_auc = 0.99325, test_loss = 0.01267, test_auc = 0.97094, time = 0.04392\n",
      "Epoch: 0130 | train_loss = 0.01273, train_auc = 0.99518, test_loss = 0.01257, test_auc = 0.96981, time = 0.04374\n",
      "Epoch: 0140 | train_loss = 0.01090, train_auc = 0.99357, test_loss = 0.01267, test_auc = 0.97086, time = 0.04366\n",
      "Epoch: 0150 | train_loss = 0.01240, train_auc = 0.99564, test_loss = 0.01199, test_auc = 0.97271, time = 0.04394\n",
      "Epoch: 0160 | train_loss = 0.01180, train_auc = 0.99615, test_loss = 0.01138, test_auc = 0.97488, time = 0.04312\n",
      "Epoch: 0170 | train_loss = 0.01119, train_auc = 0.99643, test_loss = 0.01568, test_auc = 0.95218, time = 0.04363\n",
      "Epoch: 0180 | train_loss = 0.01053, train_auc = 0.99723, test_loss = 0.01298, test_auc = 0.97101, time = 0.04287\n",
      "Epoch: 0190 | train_loss = 0.00933, train_auc = 0.99681, test_loss = 0.01108, test_auc = 0.97964, time = 0.04324\n",
      "Epoch: 0200 | train_loss = 0.00904, train_auc = 0.99721, test_loss = 0.01185, test_auc = 0.97620, time = 0.04288\n",
      "Epoch: 0210 | train_loss = 0.01166, train_auc = 0.99629, test_loss = 0.01145, test_auc = 0.97564, time = 0.04353\n",
      "Epoch: 0220 | train_loss = 0.00920, train_auc = 0.99751, test_loss = 0.01329, test_auc = 0.96565, time = 0.04341\n",
      "Epoch: 0230 | train_loss = 0.01120, train_auc = 0.99596, test_loss = 0.01158, test_auc = 0.98115, time = 0.04266\n",
      "Epoch: 0240 | train_loss = 0.00877, train_auc = 0.99718, test_loss = 0.01141, test_auc = 0.98478, time = 0.04304\n",
      "Epoch: 0250 | train_loss = 0.00717, train_auc = 0.99747, test_loss = 0.01232, test_auc = 0.97603, time = 0.04330\n",
      "Epoch: 0260 | train_loss = 0.00844, train_auc = 0.99735, test_loss = 0.01185, test_auc = 0.98228, time = 0.04286\n",
      "Epoch: 0270 | train_loss = 0.00875, train_auc = 0.99723, test_loss = 0.01080, test_auc = 0.98316, time = 0.04382\n",
      "Epoch: 0280 | train_loss = 0.00817, train_auc = 0.99738, test_loss = 0.00949, test_auc = 0.98989, time = 0.04381\n",
      "Epoch: 0290 | train_loss = 0.00761, train_auc = 0.99812, test_loss = 0.01366, test_auc = 0.96778, time = 0.04348\n",
      "Epoch: 0300 | train_loss = 0.00725, train_auc = 0.99856, test_loss = 0.00956, test_auc = 0.98988, time = 0.04322\n",
      "times: 3, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06159, train_auc = 0.50687, test_loss = 0.03923, test_auc = 0.35235, time = 0.80570\n",
      "Epoch: 0010 | train_loss = 0.03918, train_auc = 0.93055, test_loss = 0.02398, test_auc = 0.88785, time = 0.04975\n",
      "Epoch: 0020 | train_loss = 0.03057, train_auc = 0.95443, test_loss = 0.01655, test_auc = 0.92666, time = 0.04582\n",
      "Epoch: 0030 | train_loss = 0.02757, train_auc = 0.96200, test_loss = 0.01989, test_auc = 0.86032, time = 0.04289\n",
      "Epoch: 0040 | train_loss = 0.02515, train_auc = 0.97013, test_loss = 0.02071, test_auc = 0.83085, time = 0.04225\n",
      "Epoch: 0050 | train_loss = 0.02255, train_auc = 0.97829, test_loss = 0.01583, test_auc = 0.93872, time = 0.04324\n",
      "Epoch: 0060 | train_loss = 0.01998, train_auc = 0.98391, test_loss = 0.01410, test_auc = 0.95269, time = 0.04365\n",
      "Epoch: 0070 | train_loss = 0.01955, train_auc = 0.98585, test_loss = 0.01485, test_auc = 0.95751, time = 0.04550\n",
      "Epoch: 0080 | train_loss = 0.01743, train_auc = 0.98911, test_loss = 0.01422, test_auc = 0.95784, time = 0.04968\n",
      "Epoch: 0090 | train_loss = 0.01471, train_auc = 0.99313, test_loss = 0.01995, test_auc = 0.93159, time = 0.04566\n",
      "Epoch: 0100 | train_loss = 0.01543, train_auc = 0.99148, test_loss = 0.01341, test_auc = 0.96530, time = 0.04403\n",
      "Epoch: 0110 | train_loss = 0.01395, train_auc = 0.99242, test_loss = 0.01390, test_auc = 0.96152, time = 0.06476\n",
      "Epoch: 0120 | train_loss = 0.01240, train_auc = 0.99415, test_loss = 0.01242, test_auc = 0.96604, time = 0.05687\n",
      "Epoch: 0130 | train_loss = 0.01205, train_auc = 0.99372, test_loss = 0.01685, test_auc = 0.94619, time = 0.04416\n",
      "Epoch: 0140 | train_loss = 0.01157, train_auc = 0.99479, test_loss = 0.01543, test_auc = 0.96898, time = 0.04349\n",
      "Epoch: 0150 | train_loss = 0.01118, train_auc = 0.99451, test_loss = 0.01359, test_auc = 0.96452, time = 0.05502\n",
      "Epoch: 0160 | train_loss = 0.01046, train_auc = 0.99502, test_loss = 0.01212, test_auc = 0.96853, time = 0.04194\n",
      "Epoch: 0170 | train_loss = 0.01105, train_auc = 0.99508, test_loss = 0.01137, test_auc = 0.97286, time = 0.04392\n",
      "Epoch: 0180 | train_loss = 0.01001, train_auc = 0.99535, test_loss = 0.01315, test_auc = 0.95990, time = 0.04328\n",
      "Epoch: 0190 | train_loss = 0.00891, train_auc = 0.99553, test_loss = 0.01174, test_auc = 0.96726, time = 0.04216\n",
      "Epoch: 0200 | train_loss = 0.00913, train_auc = 0.99553, test_loss = 0.01249, test_auc = 0.97029, time = 0.04421\n",
      "Epoch: 0210 | train_loss = 0.00909, train_auc = 0.99572, test_loss = 0.01366, test_auc = 0.94957, time = 0.04234\n",
      "Epoch: 0220 | train_loss = 0.00890, train_auc = 0.99566, test_loss = 0.01437, test_auc = 0.94922, time = 0.04378\n",
      "Epoch: 0230 | train_loss = 0.00893, train_auc = 0.99560, test_loss = 0.01351, test_auc = 0.96447, time = 0.04341\n",
      "Epoch: 0240 | train_loss = 0.00827, train_auc = 0.99590, test_loss = 0.01287, test_auc = 0.96499, time = 0.04246\n",
      "Epoch: 0250 | train_loss = 0.00749, train_auc = 0.99580, test_loss = 0.01317, test_auc = 0.96517, time = 0.04374\n",
      "Epoch: 0260 | train_loss = 0.00863, train_auc = 0.99544, test_loss = 0.01143, test_auc = 0.96928, time = 0.04320\n",
      "Epoch: 0270 | train_loss = 0.00799, train_auc = 0.99539, test_loss = 0.01365, test_auc = 0.96246, time = 0.05551\n",
      "Epoch: 0280 | train_loss = 0.00865, train_auc = 0.99580, test_loss = 0.01466, test_auc = 0.94990, time = 0.04241\n",
      "Epoch: 0290 | train_loss = 0.00805, train_auc = 0.99572, test_loss = 0.01214, test_auc = 0.96683, time = 0.04349\n",
      "Epoch: 0300 | train_loss = 0.00731, train_auc = 0.99594, test_loss = 0.01522, test_auc = 0.95980, time = 0.04320\n",
      "times: 3, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06390, train_auc = 0.45427, test_loss = 0.03890, test_auc = 0.37889, time = 0.79701\n",
      "Epoch: 0010 | train_loss = 0.04257, train_auc = 0.89846, test_loss = 0.02539, test_auc = 0.82053, time = 0.04698\n",
      "Epoch: 0020 | train_loss = 0.03033, train_auc = 0.95533, test_loss = 0.01573, test_auc = 0.94398, time = 0.04307\n",
      "Epoch: 0030 | train_loss = 0.02657, train_auc = 0.96300, test_loss = 0.01873, test_auc = 0.89284, time = 0.04238\n",
      "Epoch: 0040 | train_loss = 0.02381, train_auc = 0.97370, test_loss = 0.01423, test_auc = 0.95862, time = 0.04208\n",
      "Epoch: 0050 | train_loss = 0.02123, train_auc = 0.98028, test_loss = 0.01682, test_auc = 0.90617, time = 0.04224\n",
      "Epoch: 0060 | train_loss = 0.01943, train_auc = 0.98432, test_loss = 0.01325, test_auc = 0.96985, time = 0.04394\n",
      "Epoch: 0070 | train_loss = 0.01755, train_auc = 0.98703, test_loss = 0.01541, test_auc = 0.95287, time = 0.04247\n",
      "Epoch: 0080 | train_loss = 0.01674, train_auc = 0.98794, test_loss = 0.01620, test_auc = 0.94885, time = 0.04189\n",
      "Epoch: 0090 | train_loss = 0.01743, train_auc = 0.98597, test_loss = 0.01461, test_auc = 0.96457, time = 0.04367\n",
      "Epoch: 0100 | train_loss = 0.01548, train_auc = 0.98773, test_loss = 0.01309, test_auc = 0.97271, time = 0.04317\n",
      "Epoch: 0110 | train_loss = 0.01494, train_auc = 0.98890, test_loss = 0.01629, test_auc = 0.94676, time = 0.04315\n",
      "Epoch: 0120 | train_loss = 0.01489, train_auc = 0.98770, test_loss = 0.01654, test_auc = 0.93166, time = 0.04250\n",
      "Epoch: 0130 | train_loss = 0.01317, train_auc = 0.99276, test_loss = 0.01182, test_auc = 0.97698, time = 0.04288\n",
      "Epoch: 0140 | train_loss = 0.01179, train_auc = 0.99390, test_loss = 0.00986, test_auc = 0.98746, time = 0.04236\n",
      "Epoch: 0150 | train_loss = 0.01101, train_auc = 0.99437, test_loss = 0.01159, test_auc = 0.98182, time = 0.04209\n",
      "Epoch: 0160 | train_loss = 0.01079, train_auc = 0.99442, test_loss = 0.01089, test_auc = 0.98578, time = 0.04233\n",
      "Epoch: 0170 | train_loss = 0.01091, train_auc = 0.99457, test_loss = 0.01376, test_auc = 0.97374, time = 0.04279\n",
      "Epoch: 0180 | train_loss = 0.00934, train_auc = 0.99489, test_loss = 0.01141, test_auc = 0.97785, time = 0.04318\n",
      "Epoch: 0190 | train_loss = 0.00928, train_auc = 0.99515, test_loss = 0.01570, test_auc = 0.94696, time = 0.04353\n",
      "Epoch: 0200 | train_loss = 0.01004, train_auc = 0.99516, test_loss = 0.01312, test_auc = 0.96907, time = 0.04180\n",
      "Epoch: 0210 | train_loss = 0.00947, train_auc = 0.99567, test_loss = 0.01008, test_auc = 0.98648, time = 0.04207\n",
      "Epoch: 0220 | train_loss = 0.00900, train_auc = 0.99572, test_loss = 0.00980, test_auc = 0.98558, time = 0.04250\n",
      "Epoch: 0230 | train_loss = 0.00885, train_auc = 0.99586, test_loss = 0.01109, test_auc = 0.97885, time = 0.04162\n",
      "Epoch: 0240 | train_loss = 0.00837, train_auc = 0.99596, test_loss = 0.01018, test_auc = 0.98142, time = 0.04182\n",
      "Epoch: 0250 | train_loss = 0.00738, train_auc = 0.99588, test_loss = 0.01460, test_auc = 0.96333, time = 0.04255\n",
      "Epoch: 0260 | train_loss = 0.00814, train_auc = 0.99634, test_loss = 0.01121, test_auc = 0.98271, time = 0.04217\n",
      "Epoch: 0270 | train_loss = 0.00877, train_auc = 0.99668, test_loss = 0.01137, test_auc = 0.98019, time = 0.04230\n",
      "Epoch: 0280 | train_loss = 0.00722, train_auc = 0.99760, test_loss = 0.01008, test_auc = 0.98644, time = 0.04475\n",
      "Epoch: 0290 | train_loss = 0.00684, train_auc = 0.99757, test_loss = 0.01637, test_auc = 0.93248, time = 0.04401\n",
      "Epoch: 0300 | train_loss = 0.00660, train_auc = 0.99869, test_loss = 0.01785, test_auc = 0.87773, time = 0.04168\n",
      "times: 4, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06325, train_auc = 0.46824, test_loss = 0.03109, test_auc = 0.60947, time = 0.81073\n",
      "Epoch: 0010 | train_loss = 0.03887, train_auc = 0.92625, test_loss = 0.03069, test_auc = 0.81115, time = 0.04821\n",
      "Epoch: 0020 | train_loss = 0.02729, train_auc = 0.96823, test_loss = 0.01546, test_auc = 0.96163, time = 0.04480\n",
      "Epoch: 0030 | train_loss = 0.02330, train_auc = 0.97948, test_loss = 0.02081, test_auc = 0.86228, time = 0.04436\n",
      "Epoch: 0040 | train_loss = 0.02040, train_auc = 0.98568, test_loss = 0.01843, test_auc = 0.88541, time = 0.04307\n",
      "Epoch: 0050 | train_loss = 0.01898, train_auc = 0.98874, test_loss = 0.01573, test_auc = 0.94393, time = 0.04271\n",
      "Epoch: 0060 | train_loss = 0.01697, train_auc = 0.99145, test_loss = 0.02038, test_auc = 0.86453, time = 0.04269\n",
      "Epoch: 0070 | train_loss = 0.01527, train_auc = 0.99367, test_loss = 0.01494, test_auc = 0.94782, time = 0.04369\n",
      "Epoch: 0080 | train_loss = 0.01302, train_auc = 0.99570, test_loss = 0.01984, test_auc = 0.90348, time = 0.04314\n",
      "Epoch: 0090 | train_loss = 0.01341, train_auc = 0.99532, test_loss = 0.01745, test_auc = 0.90823, time = 0.04431\n",
      "Epoch: 0100 | train_loss = 0.01146, train_auc = 0.99593, test_loss = 0.01764, test_auc = 0.92210, time = 0.04281\n",
      "Epoch: 0110 | train_loss = 0.01202, train_auc = 0.99563, test_loss = 0.01731, test_auc = 0.92074, time = 0.04424\n",
      "Epoch: 0120 | train_loss = 0.00984, train_auc = 0.99665, test_loss = 0.01296, test_auc = 0.96633, time = 0.04348\n",
      "Epoch: 0130 | train_loss = 0.01003, train_auc = 0.99645, test_loss = 0.01513, test_auc = 0.95351, time = 0.04313\n",
      "Epoch: 0140 | train_loss = 0.00958, train_auc = 0.99717, test_loss = 0.02022, test_auc = 0.82996, time = 0.04324\n",
      "Epoch: 0150 | train_loss = 0.01027, train_auc = 0.99689, test_loss = 0.01627, test_auc = 0.92720, time = 0.04321\n",
      "Epoch: 0160 | train_loss = 0.00943, train_auc = 0.99726, test_loss = 0.01581, test_auc = 0.94228, time = 0.05159\n",
      "Epoch: 0170 | train_loss = 0.00852, train_auc = 0.99763, test_loss = 0.01511, test_auc = 0.94486, time = 0.04424\n",
      "Epoch: 0180 | train_loss = 0.00854, train_auc = 0.99774, test_loss = 0.01107, test_auc = 0.97879, time = 0.04279\n",
      "Epoch: 0190 | train_loss = 0.00818, train_auc = 0.99769, test_loss = 0.01418, test_auc = 0.96262, time = 0.04349\n",
      "Epoch: 0200 | train_loss = 0.00917, train_auc = 0.99747, test_loss = 0.01830, test_auc = 0.90896, time = 0.04366\n",
      "Epoch: 0210 | train_loss = 0.00778, train_auc = 0.99807, test_loss = 0.01518, test_auc = 0.95985, time = 0.04327\n",
      "Epoch: 0220 | train_loss = 0.00802, train_auc = 0.99780, test_loss = 0.01689, test_auc = 0.93539, time = 0.04333\n",
      "Epoch: 0230 | train_loss = 0.00886, train_auc = 0.99775, test_loss = 0.01285, test_auc = 0.97171, time = 0.04446\n",
      "Epoch: 0240 | train_loss = 0.00785, train_auc = 0.99806, test_loss = 0.01457, test_auc = 0.96083, time = 0.04337\n",
      "Epoch: 0250 | train_loss = 0.00753, train_auc = 0.99806, test_loss = 0.01183, test_auc = 0.97537, time = 0.04333\n",
      "Epoch: 0260 | train_loss = 0.00708, train_auc = 0.99794, test_loss = 0.01215, test_auc = 0.97722, time = 0.04334\n",
      "Epoch: 0270 | train_loss = 0.00703, train_auc = 0.99823, test_loss = 0.01706, test_auc = 0.93200, time = 0.04326\n",
      "Epoch: 0280 | train_loss = 0.00673, train_auc = 0.99822, test_loss = 0.01621, test_auc = 0.94875, time = 0.04318\n",
      "Epoch: 0290 | train_loss = 0.00685, train_auc = 0.99764, test_loss = 0.01472, test_auc = 0.96842, time = 0.04355\n",
      "Epoch: 0300 | train_loss = 0.00635, train_auc = 0.99811, test_loss = 0.01046, test_auc = 0.97886, time = 0.04349\n",
      "times: 4, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06527, train_auc = 0.42871, test_loss = 0.03990, test_auc = 0.32340, time = 0.78487\n",
      "Epoch: 0010 | train_loss = 0.04230, train_auc = 0.91352, test_loss = 0.03106, test_auc = 0.86688, time = 0.04948\n",
      "Epoch: 0020 | train_loss = 0.03104, train_auc = 0.95119, test_loss = 0.01723, test_auc = 0.92870, time = 0.04961\n",
      "Epoch: 0030 | train_loss = 0.02520, train_auc = 0.97270, test_loss = 0.02105, test_auc = 0.82474, time = 0.04367\n",
      "Epoch: 0040 | train_loss = 0.02221, train_auc = 0.98101, test_loss = 0.01919, test_auc = 0.86643, time = 0.04327\n",
      "Epoch: 0050 | train_loss = 0.01999, train_auc = 0.98524, test_loss = 0.01980, test_auc = 0.87685, time = 0.04304\n",
      "Epoch: 0060 | train_loss = 0.01733, train_auc = 0.98956, test_loss = 0.01681, test_auc = 0.93200, time = 0.04278\n",
      "Epoch: 0070 | train_loss = 0.01645, train_auc = 0.99099, test_loss = 0.02136, test_auc = 0.82769, time = 0.04287\n",
      "Epoch: 0080 | train_loss = 0.01702, train_auc = 0.98965, test_loss = 0.01847, test_auc = 0.92141, time = 0.04308\n",
      "Epoch: 0090 | train_loss = 0.01425, train_auc = 0.99346, test_loss = 0.01872, test_auc = 0.92554, time = 0.04456\n",
      "Epoch: 0100 | train_loss = 0.01300, train_auc = 0.99487, test_loss = 0.01418, test_auc = 0.96483, time = 0.04420\n",
      "Epoch: 0110 | train_loss = 0.01229, train_auc = 0.99448, test_loss = 0.01427, test_auc = 0.96208, time = 0.04315\n",
      "Epoch: 0120 | train_loss = 0.01204, train_auc = 0.99517, test_loss = 0.01457, test_auc = 0.95158, time = 0.04303\n",
      "Epoch: 0130 | train_loss = 0.01145, train_auc = 0.99482, test_loss = 0.01326, test_auc = 0.96848, time = 0.04270\n",
      "Epoch: 0140 | train_loss = 0.01069, train_auc = 0.99602, test_loss = 0.01280, test_auc = 0.97160, time = 0.04535\n",
      "Epoch: 0150 | train_loss = 0.01090, train_auc = 0.99665, test_loss = 0.01305, test_auc = 0.97487, time = 0.04268\n",
      "Epoch: 0160 | train_loss = 0.00940, train_auc = 0.99644, test_loss = 0.01626, test_auc = 0.94598, time = 0.04364\n",
      "Epoch: 0170 | train_loss = 0.01002, train_auc = 0.99697, test_loss = 0.01666, test_auc = 0.94998, time = 0.04340\n",
      "Epoch: 0180 | train_loss = 0.01034, train_auc = 0.99720, test_loss = 0.01233, test_auc = 0.97414, time = 0.04355\n",
      "Epoch: 0190 | train_loss = 0.00860, train_auc = 0.99798, test_loss = 0.01709, test_auc = 0.93980, time = 0.04412\n",
      "Epoch: 0200 | train_loss = 0.00808, train_auc = 0.99782, test_loss = 0.01682, test_auc = 0.95179, time = 0.04321\n",
      "Epoch: 0210 | train_loss = 0.00806, train_auc = 0.99833, test_loss = 0.01289, test_auc = 0.97754, time = 0.04501\n",
      "Epoch: 0220 | train_loss = 0.00792, train_auc = 0.99801, test_loss = 0.01318, test_auc = 0.96751, time = 0.04440\n",
      "Epoch: 0230 | train_loss = 0.00721, train_auc = 0.99820, test_loss = 0.01166, test_auc = 0.97605, time = 0.04238\n",
      "Epoch: 0240 | train_loss = 0.00718, train_auc = 0.99816, test_loss = 0.01434, test_auc = 0.96361, time = 0.04283\n",
      "Epoch: 0250 | train_loss = 0.00745, train_auc = 0.99813, test_loss = 0.01345, test_auc = 0.96599, time = 0.04320\n",
      "Epoch: 0260 | train_loss = 0.00677, train_auc = 0.99813, test_loss = 0.01290, test_auc = 0.97161, time = 0.04258\n",
      "Epoch: 0270 | train_loss = 0.00872, train_auc = 0.99804, test_loss = 0.01278, test_auc = 0.96725, time = 0.04324\n",
      "Epoch: 0280 | train_loss = 0.00692, train_auc = 0.99817, test_loss = 0.01208, test_auc = 0.97137, time = 0.04254\n",
      "Epoch: 0290 | train_loss = 0.00711, train_auc = 0.99812, test_loss = 0.01429, test_auc = 0.96971, time = 0.04230\n",
      "Epoch: 0300 | train_loss = 0.00640, train_auc = 0.99880, test_loss = 0.01356, test_auc = 0.96793, time = 0.04258\n",
      "times: 4, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06008, train_auc = 0.51944, test_loss = 0.03386, test_auc = 0.52511, time = 0.79736\n",
      "Epoch: 0010 | train_loss = 0.03665, train_auc = 0.93809, test_loss = 0.02501, test_auc = 0.80021, time = 0.04545\n",
      "Epoch: 0020 | train_loss = 0.02753, train_auc = 0.96856, test_loss = 0.01903, test_auc = 0.89819, time = 0.04379\n",
      "Epoch: 0030 | train_loss = 0.02331, train_auc = 0.97916, test_loss = 0.01981, test_auc = 0.84471, time = 0.04318\n",
      "Epoch: 0040 | train_loss = 0.02110, train_auc = 0.98367, test_loss = 0.01566, test_auc = 0.94913, time = 0.04322\n",
      "Epoch: 0050 | train_loss = 0.01892, train_auc = 0.98771, test_loss = 0.01435, test_auc = 0.96024, time = 0.04274\n",
      "Epoch: 0060 | train_loss = 0.01713, train_auc = 0.98962, test_loss = 0.01832, test_auc = 0.86334, time = 0.04249\n",
      "Epoch: 0070 | train_loss = 0.01652, train_auc = 0.99098, test_loss = 0.01653, test_auc = 0.91483, time = 0.04314\n",
      "Epoch: 0080 | train_loss = 0.01504, train_auc = 0.99329, test_loss = 0.01366, test_auc = 0.96705, time = 0.04426\n",
      "Epoch: 0090 | train_loss = 0.01328, train_auc = 0.99452, test_loss = 0.01389, test_auc = 0.96382, time = 0.04313\n",
      "Epoch: 0100 | train_loss = 0.01243, train_auc = 0.99509, test_loss = 0.01235, test_auc = 0.97381, time = 0.04364\n",
      "Epoch: 0110 | train_loss = 0.01127, train_auc = 0.99561, test_loss = 0.01331, test_auc = 0.96721, time = 0.04448\n",
      "Epoch: 0120 | train_loss = 0.01203, train_auc = 0.99513, test_loss = 0.01692, test_auc = 0.91143, time = 0.04552\n",
      "Epoch: 0130 | train_loss = 0.01133, train_auc = 0.99550, test_loss = 0.01168, test_auc = 0.97572, time = 0.04355\n",
      "Epoch: 0140 | train_loss = 0.01050, train_auc = 0.99628, test_loss = 0.01051, test_auc = 0.98401, time = 0.04354\n",
      "Epoch: 0150 | train_loss = 0.00964, train_auc = 0.99626, test_loss = 0.01011, test_auc = 0.98845, time = 0.04308\n",
      "Epoch: 0160 | train_loss = 0.01042, train_auc = 0.99602, test_loss = 0.01197, test_auc = 0.97958, time = 0.04311\n",
      "Epoch: 0170 | train_loss = 0.00895, train_auc = 0.99640, test_loss = 0.01389, test_auc = 0.96506, time = 0.04341\n",
      "Epoch: 0180 | train_loss = 0.01017, train_auc = 0.99633, test_loss = 0.01034, test_auc = 0.98386, time = 0.04342\n",
      "Epoch: 0190 | train_loss = 0.00990, train_auc = 0.99608, test_loss = 0.01185, test_auc = 0.98051, time = 0.04307\n",
      "Epoch: 0200 | train_loss = 0.00974, train_auc = 0.99618, test_loss = 0.01012, test_auc = 0.98620, time = 0.04276\n",
      "Epoch: 0210 | train_loss = 0.00907, train_auc = 0.99653, test_loss = 0.01275, test_auc = 0.97578, time = 0.04258\n",
      "Epoch: 0220 | train_loss = 0.00885, train_auc = 0.99651, test_loss = 0.01660, test_auc = 0.93236, time = 0.04331\n",
      "Epoch: 0230 | train_loss = 0.00842, train_auc = 0.99659, test_loss = 0.00907, test_auc = 0.99078, time = 0.04538\n",
      "Epoch: 0240 | train_loss = 0.00853, train_auc = 0.99680, test_loss = 0.01091, test_auc = 0.98494, time = 0.04274\n",
      "Epoch: 0250 | train_loss = 0.00721, train_auc = 0.99673, test_loss = 0.00918, test_auc = 0.98663, time = 0.04253\n",
      "Epoch: 0260 | train_loss = 0.00757, train_auc = 0.99678, test_loss = 0.01115, test_auc = 0.98114, time = 0.04427\n",
      "Epoch: 0270 | train_loss = 0.00726, train_auc = 0.99680, test_loss = 0.01060, test_auc = 0.98677, time = 0.04696\n",
      "Epoch: 0280 | train_loss = 0.00804, train_auc = 0.99667, test_loss = 0.01094, test_auc = 0.98303, time = 0.04358\n",
      "Epoch: 0290 | train_loss = 0.00795, train_auc = 0.99688, test_loss = 0.00992, test_auc = 0.98824, time = 0.04747\n",
      "Epoch: 0300 | train_loss = 0.00765, train_auc = 0.99670, test_loss = 0.00944, test_auc = 0.98499, time = 0.04329\n",
      "times: 4, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06010, train_auc = 0.54936, test_loss = 0.03943, test_auc = 0.35475, time = 0.79593\n",
      "Epoch: 0010 | train_loss = 0.04158, train_auc = 0.93110, test_loss = 0.02773, test_auc = 0.92325, time = 0.04876\n",
      "Epoch: 0020 | train_loss = 0.03095, train_auc = 0.94753, test_loss = 0.01830, test_auc = 0.91164, time = 0.04460\n",
      "Epoch: 0030 | train_loss = 0.02537, train_auc = 0.96978, test_loss = 0.02081, test_auc = 0.80788, time = 0.04404\n",
      "Epoch: 0040 | train_loss = 0.02313, train_auc = 0.97553, test_loss = 0.02075, test_auc = 0.83218, time = 0.04350\n",
      "Epoch: 0050 | train_loss = 0.02137, train_auc = 0.97978, test_loss = 0.02221, test_auc = 0.79812, time = 0.04425\n",
      "Epoch: 0060 | train_loss = 0.01866, train_auc = 0.98370, test_loss = 0.02202, test_auc = 0.78802, time = 0.04430\n",
      "Epoch: 0070 | train_loss = 0.01729, train_auc = 0.98617, test_loss = 0.02098, test_auc = 0.82330, time = 0.04306\n",
      "Epoch: 0080 | train_loss = 0.01667, train_auc = 0.98840, test_loss = 0.01577, test_auc = 0.95339, time = 0.04320\n",
      "Epoch: 0090 | train_loss = 0.01502, train_auc = 0.98934, test_loss = 0.01804, test_auc = 0.87682, time = 0.04386\n",
      "Epoch: 0100 | train_loss = 0.01473, train_auc = 0.99116, test_loss = 0.01700, test_auc = 0.93908, time = 0.04596\n",
      "Epoch: 0110 | train_loss = 0.01383, train_auc = 0.99212, test_loss = 0.01546, test_auc = 0.95006, time = 0.04414\n",
      "Epoch: 0120 | train_loss = 0.01328, train_auc = 0.99337, test_loss = 0.01692, test_auc = 0.95377, time = 0.04358\n",
      "Epoch: 0130 | train_loss = 0.01289, train_auc = 0.99148, test_loss = 0.01873, test_auc = 0.90347, time = 0.04497\n",
      "Epoch: 0140 | train_loss = 0.01292, train_auc = 0.99322, test_loss = 0.02108, test_auc = 0.86533, time = 0.04554\n",
      "Epoch: 0150 | train_loss = 0.01133, train_auc = 0.99557, test_loss = 0.01746, test_auc = 0.95341, time = 0.04479\n",
      "Epoch: 0160 | train_loss = 0.00987, train_auc = 0.99568, test_loss = 0.01305, test_auc = 0.97454, time = 0.04999\n",
      "Epoch: 0170 | train_loss = 0.01015, train_auc = 0.99559, test_loss = 0.01717, test_auc = 0.95156, time = 0.04367\n",
      "Epoch: 0180 | train_loss = 0.00927, train_auc = 0.99626, test_loss = 0.01584, test_auc = 0.95629, time = 0.04465\n",
      "Epoch: 0190 | train_loss = 0.00949, train_auc = 0.99667, test_loss = 0.01206, test_auc = 0.97237, time = 0.04417\n",
      "Epoch: 0200 | train_loss = 0.00795, train_auc = 0.99721, test_loss = 0.01273, test_auc = 0.97105, time = 0.04414\n",
      "Epoch: 0210 | train_loss = 0.00926, train_auc = 0.99676, test_loss = 0.01152, test_auc = 0.97390, time = 0.04256\n",
      "Epoch: 0220 | train_loss = 0.00831, train_auc = 0.99787, test_loss = 0.01157, test_auc = 0.97944, time = 0.04405\n",
      "Epoch: 0230 | train_loss = 0.00803, train_auc = 0.99754, test_loss = 0.01235, test_auc = 0.97522, time = 0.04536\n",
      "Epoch: 0240 | train_loss = 0.00815, train_auc = 0.99748, test_loss = 0.01105, test_auc = 0.97619, time = 0.04455\n",
      "Epoch: 0250 | train_loss = 0.00771, train_auc = 0.99756, test_loss = 0.01531, test_auc = 0.95896, time = 0.04468\n",
      "Epoch: 0260 | train_loss = 0.00719, train_auc = 0.99787, test_loss = 0.01297, test_auc = 0.97708, time = 0.04519\n",
      "Epoch: 0270 | train_loss = 0.00643, train_auc = 0.99813, test_loss = 0.01384, test_auc = 0.95747, time = 0.04409\n",
      "Epoch: 0280 | train_loss = 0.00719, train_auc = 0.99764, test_loss = 0.01419, test_auc = 0.97301, time = 0.04520\n",
      "Epoch: 0290 | train_loss = 0.00684, train_auc = 0.99765, test_loss = 0.01249, test_auc = 0.97480, time = 0.04530\n",
      "Epoch: 0300 | train_loss = 0.00752, train_auc = 0.99768, test_loss = 0.01565, test_auc = 0.97544, time = 0.04654\n",
      "times: 4, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.05965, train_auc = 0.54132, test_loss = 0.03361, test_auc = 0.47021, time = 0.79224\n",
      "Epoch: 0010 | train_loss = 0.04021, train_auc = 0.90967, test_loss = 0.02187, test_auc = 0.88265, time = 0.04776\n",
      "Epoch: 0020 | train_loss = 0.03010, train_auc = 0.94666, test_loss = 0.01933, test_auc = 0.87896, time = 0.04429\n",
      "Epoch: 0030 | train_loss = 0.02474, train_auc = 0.97596, test_loss = 0.01960, test_auc = 0.86237, time = 0.04296\n",
      "Epoch: 0040 | train_loss = 0.02266, train_auc = 0.97809, test_loss = 0.02212, test_auc = 0.81638, time = 0.04148\n",
      "Epoch: 0050 | train_loss = 0.02154, train_auc = 0.98164, test_loss = 0.01870, test_auc = 0.89813, time = 0.04376\n",
      "Epoch: 0060 | train_loss = 0.01965, train_auc = 0.98647, test_loss = 0.01839, test_auc = 0.91706, time = 0.04364\n",
      "Epoch: 0070 | train_loss = 0.01816, train_auc = 0.98910, test_loss = 0.01985, test_auc = 0.88772, time = 0.04345\n",
      "Epoch: 0080 | train_loss = 0.01715, train_auc = 0.99015, test_loss = 0.02120, test_auc = 0.82519, time = 0.04352\n",
      "Epoch: 0090 | train_loss = 0.01540, train_auc = 0.99144, test_loss = 0.02077, test_auc = 0.83542, time = 0.04325\n",
      "Epoch: 0100 | train_loss = 0.01415, train_auc = 0.99233, test_loss = 0.01984, test_auc = 0.84325, time = 0.04410\n",
      "Epoch: 0110 | train_loss = 0.01230, train_auc = 0.99362, test_loss = 0.01916, test_auc = 0.88848, time = 0.04423\n",
      "Epoch: 0120 | train_loss = 0.01100, train_auc = 0.99501, test_loss = 0.01414, test_auc = 0.95830, time = 0.04340\n",
      "Epoch: 0130 | train_loss = 0.01122, train_auc = 0.99452, test_loss = 0.01704, test_auc = 0.93522, time = 0.04324\n",
      "Epoch: 0140 | train_loss = 0.01062, train_auc = 0.99449, test_loss = 0.02000, test_auc = 0.86293, time = 0.04330\n",
      "Epoch: 0150 | train_loss = 0.01064, train_auc = 0.99304, test_loss = 0.01926, test_auc = 0.91552, time = 0.04305\n",
      "Epoch: 0160 | train_loss = 0.01122, train_auc = 0.99447, test_loss = 0.01829, test_auc = 0.89378, time = 0.04407\n",
      "Epoch: 0170 | train_loss = 0.01098, train_auc = 0.99479, test_loss = 0.01498, test_auc = 0.94486, time = 0.04385\n",
      "Epoch: 0180 | train_loss = 0.01042, train_auc = 0.99563, test_loss = 0.01499, test_auc = 0.95757, time = 0.04370\n",
      "Epoch: 0190 | train_loss = 0.01007, train_auc = 0.99611, test_loss = 0.01969, test_auc = 0.92493, time = 0.04397\n",
      "Epoch: 0200 | train_loss = 0.00919, train_auc = 0.99596, test_loss = 0.01726, test_auc = 0.92548, time = 0.04377\n",
      "Epoch: 0210 | train_loss = 0.00950, train_auc = 0.99601, test_loss = 0.01620, test_auc = 0.93263, time = 0.04354\n",
      "Epoch: 0220 | train_loss = 0.00868, train_auc = 0.99634, test_loss = 0.01632, test_auc = 0.92666, time = 0.04361\n",
      "Epoch: 0230 | train_loss = 0.00980, train_auc = 0.99745, test_loss = 0.01332, test_auc = 0.96683, time = 0.04396\n",
      "Epoch: 0240 | train_loss = 0.00846, train_auc = 0.99673, test_loss = 0.01373, test_auc = 0.96999, time = 0.04507\n",
      "Epoch: 0250 | train_loss = 0.00769, train_auc = 0.99762, test_loss = 0.01373, test_auc = 0.95638, time = 0.04393\n",
      "Epoch: 0260 | train_loss = 0.00772, train_auc = 0.99805, test_loss = 0.01513, test_auc = 0.95903, time = 0.04400\n",
      "Epoch: 0270 | train_loss = 0.00772, train_auc = 0.99825, test_loss = 0.01200, test_auc = 0.97321, time = 0.04383\n",
      "Epoch: 0280 | train_loss = 0.00744, train_auc = 0.99822, test_loss = 0.01345, test_auc = 0.96788, time = 0.04372\n",
      "Epoch: 0290 | train_loss = 0.00637, train_auc = 0.99856, test_loss = 0.01584, test_auc = 0.95599, time = 0.04446\n",
      "Epoch: 0300 | train_loss = 0.00759, train_auc = 0.99803, test_loss = 0.01155, test_auc = 0.97470, time = 0.04336\n",
      "times: 5, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06499, train_auc = 0.43359, test_loss = 0.03479, test_auc = 0.49591, time = 0.78336\n",
      "Epoch: 0010 | train_loss = 0.04078, train_auc = 0.92451, test_loss = 0.02395, test_auc = 0.90107, time = 0.04871\n",
      "Epoch: 0020 | train_loss = 0.03026, train_auc = 0.95460, test_loss = 0.01830, test_auc = 0.90138, time = 0.04323\n",
      "Epoch: 0030 | train_loss = 0.02612, train_auc = 0.96758, test_loss = 0.01598, test_auc = 0.94177, time = 0.04133\n",
      "Epoch: 0040 | train_loss = 0.02367, train_auc = 0.97612, test_loss = 0.02151, test_auc = 0.81462, time = 0.04178\n",
      "Epoch: 0050 | train_loss = 0.02305, train_auc = 0.97647, test_loss = 0.01602, test_auc = 0.94293, time = 0.04220\n",
      "Epoch: 0060 | train_loss = 0.01999, train_auc = 0.98381, test_loss = 0.01785, test_auc = 0.93271, time = 0.04175\n",
      "Epoch: 0070 | train_loss = 0.01874, train_auc = 0.98648, test_loss = 0.02010, test_auc = 0.85849, time = 0.04218\n",
      "Epoch: 0080 | train_loss = 0.01624, train_auc = 0.99138, test_loss = 0.01824, test_auc = 0.91942, time = 0.04072\n",
      "Epoch: 0090 | train_loss = 0.01699, train_auc = 0.98962, test_loss = 0.01492, test_auc = 0.96264, time = 0.04135\n",
      "Epoch: 0100 | train_loss = 0.01440, train_auc = 0.99316, test_loss = 0.01652, test_auc = 0.94321, time = 0.04232\n",
      "Epoch: 0110 | train_loss = 0.01416, train_auc = 0.99370, test_loss = 0.01839, test_auc = 0.90960, time = 0.04194\n",
      "Epoch: 0120 | train_loss = 0.01294, train_auc = 0.99459, test_loss = 0.01777, test_auc = 0.91534, time = 0.04080\n",
      "Epoch: 0130 | train_loss = 0.01270, train_auc = 0.99316, test_loss = 0.01446, test_auc = 0.96398, time = 0.04089\n",
      "Epoch: 0140 | train_loss = 0.01268, train_auc = 0.99502, test_loss = 0.01675, test_auc = 0.91543, time = 0.04064\n",
      "Epoch: 0150 | train_loss = 0.01240, train_auc = 0.99526, test_loss = 0.01200, test_auc = 0.97556, time = 0.04060\n",
      "Epoch: 0160 | train_loss = 0.01169, train_auc = 0.99536, test_loss = 0.01571, test_auc = 0.94309, time = 0.04080\n",
      "Epoch: 0170 | train_loss = 0.01163, train_auc = 0.99570, test_loss = 0.01232, test_auc = 0.97302, time = 0.04099\n",
      "Epoch: 0180 | train_loss = 0.01109, train_auc = 0.99464, test_loss = 0.01382, test_auc = 0.97385, time = 0.04084\n",
      "Epoch: 0190 | train_loss = 0.01113, train_auc = 0.99595, test_loss = 0.01387, test_auc = 0.96806, time = 0.04172\n",
      "Epoch: 0200 | train_loss = 0.00974, train_auc = 0.99623, test_loss = 0.01248, test_auc = 0.97869, time = 0.04058\n",
      "Epoch: 0210 | train_loss = 0.00922, train_auc = 0.99640, test_loss = 0.01029, test_auc = 0.98641, time = 0.04047\n",
      "Epoch: 0220 | train_loss = 0.00920, train_auc = 0.99623, test_loss = 0.01053, test_auc = 0.98653, time = 0.04207\n",
      "Epoch: 0230 | train_loss = 0.00901, train_auc = 0.99618, test_loss = 0.01091, test_auc = 0.98549, time = 0.04140\n",
      "Epoch: 0240 | train_loss = 0.00986, train_auc = 0.99745, test_loss = 0.01053, test_auc = 0.98613, time = 0.04180\n",
      "Epoch: 0250 | train_loss = 0.00786, train_auc = 0.99763, test_loss = 0.01026, test_auc = 0.98856, time = 0.04104\n",
      "Epoch: 0260 | train_loss = 0.00826, train_auc = 0.99686, test_loss = 0.01033, test_auc = 0.98476, time = 0.04114\n",
      "Epoch: 0270 | train_loss = 0.00769, train_auc = 0.99724, test_loss = 0.00999, test_auc = 0.98979, time = 0.04271\n",
      "Epoch: 0280 | train_loss = 0.00878, train_auc = 0.99661, test_loss = 0.01112, test_auc = 0.98054, time = 0.04114\n",
      "Epoch: 0290 | train_loss = 0.00681, train_auc = 0.99795, test_loss = 0.01431, test_auc = 0.96565, time = 0.04094\n",
      "Epoch: 0300 | train_loss = 0.00835, train_auc = 0.99745, test_loss = 0.01224, test_auc = 0.98507, time = 0.04201\n",
      "times: 5, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06374, train_auc = 0.46993, test_loss = 0.04305, test_auc = 0.18292, time = 0.78086\n",
      "Epoch: 0010 | train_loss = 0.03975, train_auc = 0.93274, test_loss = 0.02417, test_auc = 0.86198, time = 0.04974\n",
      "Epoch: 0020 | train_loss = 0.02917, train_auc = 0.95878, test_loss = 0.01847, test_auc = 0.88563, time = 0.04485\n",
      "Epoch: 0030 | train_loss = 0.02553, train_auc = 0.97206, test_loss = 0.01890, test_auc = 0.89827, time = 0.04346\n",
      "Epoch: 0040 | train_loss = 0.02250, train_auc = 0.98073, test_loss = 0.02127, test_auc = 0.79517, time = 0.04368\n",
      "Epoch: 0050 | train_loss = 0.02012, train_auc = 0.98655, test_loss = 0.01720, test_auc = 0.91752, time = 0.04294\n",
      "Epoch: 0060 | train_loss = 0.01786, train_auc = 0.98994, test_loss = 0.01788, test_auc = 0.90862, time = 0.04334\n",
      "Epoch: 0070 | train_loss = 0.01714, train_auc = 0.99181, test_loss = 0.01442, test_auc = 0.95630, time = 0.04322\n",
      "Epoch: 0080 | train_loss = 0.01536, train_auc = 0.99413, test_loss = 0.01927, test_auc = 0.90534, time = 0.04290\n",
      "Epoch: 0090 | train_loss = 0.01439, train_auc = 0.99501, test_loss = 0.01395, test_auc = 0.96942, time = 0.04281\n",
      "Epoch: 0100 | train_loss = 0.01482, train_auc = 0.99452, test_loss = 0.01556, test_auc = 0.93884, time = 0.04274\n",
      "Epoch: 0110 | train_loss = 0.01384, train_auc = 0.99521, test_loss = 0.01502, test_auc = 0.94831, time = 0.04262\n",
      "Epoch: 0120 | train_loss = 0.01254, train_auc = 0.99659, test_loss = 0.01277, test_auc = 0.96979, time = 0.04309\n",
      "Epoch: 0130 | train_loss = 0.01122, train_auc = 0.99771, test_loss = 0.01151, test_auc = 0.98001, time = 0.04544\n",
      "Epoch: 0140 | train_loss = 0.01080, train_auc = 0.99773, test_loss = 0.01074, test_auc = 0.97897, time = 0.04298\n",
      "Epoch: 0150 | train_loss = 0.00812, train_auc = 0.99848, test_loss = 0.01137, test_auc = 0.97905, time = 0.04353\n",
      "Epoch: 0160 | train_loss = 0.00943, train_auc = 0.99822, test_loss = 0.01112, test_auc = 0.97722, time = 0.04359\n",
      "Epoch: 0170 | train_loss = 0.00877, train_auc = 0.99845, test_loss = 0.01173, test_auc = 0.97047, time = 0.04324\n",
      "Epoch: 0180 | train_loss = 0.01136, train_auc = 0.99757, test_loss = 0.01263, test_auc = 0.97468, time = 0.04366\n",
      "Epoch: 0190 | train_loss = 0.00883, train_auc = 0.99844, test_loss = 0.01157, test_auc = 0.98046, time = 0.04429\n",
      "Epoch: 0200 | train_loss = 0.00821, train_auc = 0.99828, test_loss = 0.01137, test_auc = 0.98130, time = 0.04353\n",
      "Epoch: 0210 | train_loss = 0.00724, train_auc = 0.99873, test_loss = 0.01208, test_auc = 0.97660, time = 0.04375\n",
      "Epoch: 0220 | train_loss = 0.00814, train_auc = 0.99846, test_loss = 0.01051, test_auc = 0.98065, time = 0.04429\n",
      "Epoch: 0230 | train_loss = 0.00832, train_auc = 0.99827, test_loss = 0.01136, test_auc = 0.98119, time = 0.04292\n",
      "Epoch: 0240 | train_loss = 0.00786, train_auc = 0.99882, test_loss = 0.01322, test_auc = 0.97139, time = 0.04365\n",
      "Epoch: 0250 | train_loss = 0.00695, train_auc = 0.99879, test_loss = 0.00971, test_auc = 0.98382, time = 0.04462\n",
      "Epoch: 0260 | train_loss = 0.00747, train_auc = 0.99861, test_loss = 0.01001, test_auc = 0.98193, time = 0.04413\n",
      "Epoch: 0270 | train_loss = 0.00785, train_auc = 0.99863, test_loss = 0.01033, test_auc = 0.98160, time = 0.04408\n",
      "Epoch: 0280 | train_loss = 0.00722, train_auc = 0.99896, test_loss = 0.01566, test_auc = 0.94553, time = 0.04623\n",
      "Epoch: 0290 | train_loss = 0.00787, train_auc = 0.99855, test_loss = 0.01248, test_auc = 0.97349, time = 0.04454\n",
      "Epoch: 0300 | train_loss = 0.00671, train_auc = 0.99877, test_loss = 0.01024, test_auc = 0.98638, time = 0.04420\n",
      "times: 5, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.05968, train_auc = 0.54863, test_loss = 0.03376, test_auc = 0.51989, time = 0.77471\n",
      "Epoch: 0010 | train_loss = 0.03927, train_auc = 0.91840, test_loss = 0.02740, test_auc = 0.78837, time = 0.04948\n",
      "Epoch: 0020 | train_loss = 0.03058, train_auc = 0.94936, test_loss = 0.01894, test_auc = 0.93120, time = 0.04737\n",
      "Epoch: 0030 | train_loss = 0.02677, train_auc = 0.95832, test_loss = 0.01595, test_auc = 0.93645, time = 0.04360\n",
      "Epoch: 0040 | train_loss = 0.02419, train_auc = 0.96713, test_loss = 0.01510, test_auc = 0.94947, time = 0.04334\n",
      "Epoch: 0050 | train_loss = 0.02262, train_auc = 0.97285, test_loss = 0.01458, test_auc = 0.95670, time = 0.04267\n",
      "Epoch: 0060 | train_loss = 0.02095, train_auc = 0.97904, test_loss = 0.01490, test_auc = 0.95223, time = 0.04249\n",
      "Epoch: 0070 | train_loss = 0.01896, train_auc = 0.98420, test_loss = 0.01436, test_auc = 0.95659, time = 0.04272\n",
      "Epoch: 0080 | train_loss = 0.01743, train_auc = 0.98830, test_loss = 0.01420, test_auc = 0.95916, time = 0.04293\n",
      "Epoch: 0090 | train_loss = 0.01680, train_auc = 0.98975, test_loss = 0.01653, test_auc = 0.94286, time = 0.04215\n",
      "Epoch: 0100 | train_loss = 0.01554, train_auc = 0.99207, test_loss = 0.01728, test_auc = 0.92848, time = 0.04246\n",
      "Epoch: 0110 | train_loss = 0.01523, train_auc = 0.99244, test_loss = 0.01302, test_auc = 0.97196, time = 0.04254\n",
      "Epoch: 0120 | train_loss = 0.01311, train_auc = 0.99504, test_loss = 0.01290, test_auc = 0.96804, time = 0.04243\n",
      "Epoch: 0130 | train_loss = 0.01188, train_auc = 0.99709, test_loss = 0.01279, test_auc = 0.97239, time = 0.04293\n",
      "Epoch: 0140 | train_loss = 0.01172, train_auc = 0.99677, test_loss = 0.01265, test_auc = 0.97400, time = 0.04243\n",
      "Epoch: 0150 | train_loss = 0.01290, train_auc = 0.99701, test_loss = 0.01135, test_auc = 0.97778, time = 0.04216\n",
      "Epoch: 0160 | train_loss = 0.01069, train_auc = 0.99766, test_loss = 0.01189, test_auc = 0.97885, time = 0.04288\n",
      "Epoch: 0170 | train_loss = 0.01029, train_auc = 0.99811, test_loss = 0.01218, test_auc = 0.96681, time = 0.04308\n",
      "Epoch: 0180 | train_loss = 0.01107, train_auc = 0.99695, test_loss = 0.01418, test_auc = 0.96705, time = 0.04657\n",
      "Epoch: 0190 | train_loss = 0.00936, train_auc = 0.99843, test_loss = 0.01338, test_auc = 0.96433, time = 0.04284\n",
      "Epoch: 0200 | train_loss = 0.00907, train_auc = 0.99836, test_loss = 0.01130, test_auc = 0.98219, time = 0.04304\n",
      "Epoch: 0210 | train_loss = 0.00847, train_auc = 0.99870, test_loss = 0.01111, test_auc = 0.98218, time = 0.04317\n",
      "Epoch: 0220 | train_loss = 0.00887, train_auc = 0.99872, test_loss = 0.01301, test_auc = 0.97867, time = 0.04371\n",
      "Epoch: 0230 | train_loss = 0.00926, train_auc = 0.99737, test_loss = 0.01303, test_auc = 0.97236, time = 0.04295\n",
      "Epoch: 0240 | train_loss = 0.00817, train_auc = 0.99908, test_loss = 0.01767, test_auc = 0.91299, time = 0.04348\n",
      "Epoch: 0250 | train_loss = 0.00717, train_auc = 0.99925, test_loss = 0.01522, test_auc = 0.95770, time = 0.04276\n",
      "Epoch: 0260 | train_loss = 0.00806, train_auc = 0.99896, test_loss = 0.01122, test_auc = 0.98007, time = 0.04250\n",
      "Epoch: 0270 | train_loss = 0.00922, train_auc = 0.99881, test_loss = 0.01126, test_auc = 0.98209, time = 0.04297\n",
      "Epoch: 0280 | train_loss = 0.00694, train_auc = 0.99922, test_loss = 0.01218, test_auc = 0.97894, time = 0.04287\n",
      "Epoch: 0290 | train_loss = 0.00731, train_auc = 0.99935, test_loss = 0.01510, test_auc = 0.96368, time = 0.04291\n",
      "Epoch: 0300 | train_loss = 0.00772, train_auc = 0.99866, test_loss = 0.01494, test_auc = 0.97088, time = 0.04271\n",
      "times: 5, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06034, train_auc = 0.52077, test_loss = 0.03391, test_auc = 0.51837, time = 0.77728\n",
      "Epoch: 0010 | train_loss = 0.03857, train_auc = 0.94015, test_loss = 0.03023, test_auc = 0.88196, time = 0.04737\n",
      "Epoch: 0020 | train_loss = 0.02753, train_auc = 0.96443, test_loss = 0.02083, test_auc = 0.82426, time = 0.04530\n",
      "Epoch: 0030 | train_loss = 0.02415, train_auc = 0.97358, test_loss = 0.02250, test_auc = 0.78863, time = 0.04367\n",
      "Epoch: 0040 | train_loss = 0.02159, train_auc = 0.98085, test_loss = 0.01597, test_auc = 0.93734, time = 0.04332\n",
      "Epoch: 0050 | train_loss = 0.01930, train_auc = 0.98533, test_loss = 0.01455, test_auc = 0.95726, time = 0.04327\n",
      "Epoch: 0060 | train_loss = 0.01815, train_auc = 0.98816, test_loss = 0.01864, test_auc = 0.90770, time = 0.04312\n",
      "Epoch: 0070 | train_loss = 0.01648, train_auc = 0.98965, test_loss = 0.01350, test_auc = 0.96934, time = 0.04305\n",
      "Epoch: 0080 | train_loss = 0.01512, train_auc = 0.99115, test_loss = 0.01419, test_auc = 0.96452, time = 0.04379\n",
      "Epoch: 0090 | train_loss = 0.01307, train_auc = 0.99304, test_loss = 0.01710, test_auc = 0.95532, time = 0.04340\n",
      "Epoch: 0100 | train_loss = 0.01294, train_auc = 0.99382, test_loss = 0.01480, test_auc = 0.94911, time = 0.04338\n",
      "Epoch: 0110 | train_loss = 0.01273, train_auc = 0.99330, test_loss = 0.01398, test_auc = 0.96574, time = 0.04315\n",
      "Epoch: 0120 | train_loss = 0.01256, train_auc = 0.99421, test_loss = 0.01149, test_auc = 0.97759, time = 0.04398\n",
      "Epoch: 0130 | train_loss = 0.01149, train_auc = 0.99493, test_loss = 0.01501, test_auc = 0.96168, time = 0.04305\n",
      "Epoch: 0140 | train_loss = 0.01075, train_auc = 0.99581, test_loss = 0.01324, test_auc = 0.97152, time = 0.04368\n",
      "Epoch: 0150 | train_loss = 0.00947, train_auc = 0.99575, test_loss = 0.01724, test_auc = 0.95517, time = 0.04335\n",
      "Epoch: 0160 | train_loss = 0.00963, train_auc = 0.99603, test_loss = 0.01209, test_auc = 0.98102, time = 0.04432\n",
      "Epoch: 0170 | train_loss = 0.01125, train_auc = 0.99539, test_loss = 0.01160, test_auc = 0.98042, time = 0.04349\n",
      "Epoch: 0180 | train_loss = 0.00889, train_auc = 0.99634, test_loss = 0.01238, test_auc = 0.97654, time = 0.04431\n",
      "Epoch: 0190 | train_loss = 0.00946, train_auc = 0.99652, test_loss = 0.01290, test_auc = 0.97567, time = 0.04557\n",
      "Epoch: 0200 | train_loss = 0.00923, train_auc = 0.99626, test_loss = 0.01235, test_auc = 0.98039, time = 0.04449\n",
      "Epoch: 0210 | train_loss = 0.00875, train_auc = 0.99651, test_loss = 0.01245, test_auc = 0.97706, time = 0.04371\n",
      "Epoch: 0220 | train_loss = 0.00812, train_auc = 0.99626, test_loss = 0.01167, test_auc = 0.98271, time = 0.04327\n",
      "Epoch: 0230 | train_loss = 0.00841, train_auc = 0.99687, test_loss = 0.01426, test_auc = 0.96657, time = 0.04348\n",
      "Epoch: 0240 | train_loss = 0.00797, train_auc = 0.99651, test_loss = 0.01111, test_auc = 0.98446, time = 0.04293\n",
      "Epoch: 0250 | train_loss = 0.00784, train_auc = 0.99637, test_loss = 0.01735, test_auc = 0.95170, time = 0.04405\n",
      "Epoch: 0260 | train_loss = 0.00762, train_auc = 0.99667, test_loss = 0.01114, test_auc = 0.98364, time = 0.04363\n",
      "Epoch: 0270 | train_loss = 0.00598, train_auc = 0.99696, test_loss = 0.01287, test_auc = 0.97678, time = 0.04354\n",
      "Epoch: 0280 | train_loss = 0.00864, train_auc = 0.99670, test_loss = 0.01399, test_auc = 0.97520, time = 0.04297\n",
      "Epoch: 0290 | train_loss = 0.00803, train_auc = 0.99650, test_loss = 0.01272, test_auc = 0.97517, time = 0.04327\n",
      "Epoch: 0300 | train_loss = 0.00731, train_auc = 0.99734, test_loss = 0.01107, test_auc = 0.98537, time = 0.04347\n",
      "times: 5, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06161, train_auc = 0.50140, test_loss = 0.04048, test_auc = 0.24948, time = 0.82418\n",
      "Epoch: 0010 | train_loss = 0.03626, train_auc = 0.93960, test_loss = 0.03100, test_auc = 0.79445, time = 0.04954\n",
      "Epoch: 0020 | train_loss = 0.02649, train_auc = 0.96937, test_loss = 0.01677, test_auc = 0.93281, time = 0.04585\n",
      "Epoch: 0030 | train_loss = 0.02277, train_auc = 0.97950, test_loss = 0.01827, test_auc = 0.91619, time = 0.04385\n",
      "Epoch: 0040 | train_loss = 0.02005, train_auc = 0.98667, test_loss = 0.01777, test_auc = 0.92099, time = 0.04339\n",
      "Epoch: 0050 | train_loss = 0.01900, train_auc = 0.98740, test_loss = 0.02059, test_auc = 0.86935, time = 0.04458\n",
      "Epoch: 0060 | train_loss = 0.01748, train_auc = 0.99061, test_loss = 0.01735, test_auc = 0.92445, time = 0.04410\n",
      "Epoch: 0070 | train_loss = 0.01615, train_auc = 0.99187, test_loss = 0.02018, test_auc = 0.87675, time = 0.04358\n",
      "Epoch: 0080 | train_loss = 0.01451, train_auc = 0.99325, test_loss = 0.01837, test_auc = 0.87982, time = 0.04380\n",
      "Epoch: 0090 | train_loss = 0.01311, train_auc = 0.99483, test_loss = 0.01781, test_auc = 0.91350, time = 0.04308\n",
      "Epoch: 0100 | train_loss = 0.01222, train_auc = 0.99438, test_loss = 0.01490, test_auc = 0.94865, time = 0.04363\n",
      "Epoch: 0110 | train_loss = 0.01160, train_auc = 0.99549, test_loss = 0.01681, test_auc = 0.90841, time = 0.04358\n",
      "Epoch: 0120 | train_loss = 0.01071, train_auc = 0.99557, test_loss = 0.01305, test_auc = 0.96533, time = 0.04315\n",
      "Epoch: 0130 | train_loss = 0.01097, train_auc = 0.99468, test_loss = 0.01535, test_auc = 0.95431, time = 0.04382\n",
      "Epoch: 0140 | train_loss = 0.01016, train_auc = 0.99513, test_loss = 0.01493, test_auc = 0.96028, time = 0.04380\n",
      "Epoch: 0150 | train_loss = 0.00891, train_auc = 0.99592, test_loss = 0.01136, test_auc = 0.97307, time = 0.04363\n",
      "Epoch: 0160 | train_loss = 0.00908, train_auc = 0.99621, test_loss = 0.01614, test_auc = 0.95546, time = 0.04380\n",
      "Epoch: 0170 | train_loss = 0.00925, train_auc = 0.99591, test_loss = 0.01497, test_auc = 0.96140, time = 0.04387\n",
      "Epoch: 0180 | train_loss = 0.00908, train_auc = 0.99624, test_loss = 0.01546, test_auc = 0.95157, time = 0.04357\n",
      "Epoch: 0190 | train_loss = 0.00894, train_auc = 0.99635, test_loss = 0.01405, test_auc = 0.96201, time = 0.05150\n",
      "Epoch: 0200 | train_loss = 0.00872, train_auc = 0.99614, test_loss = 0.01295, test_auc = 0.97227, time = 0.04921\n",
      "Epoch: 0210 | train_loss = 0.00871, train_auc = 0.99574, test_loss = 0.01637, test_auc = 0.95393, time = 0.04405\n",
      "Epoch: 0220 | train_loss = 0.00922, train_auc = 0.99656, test_loss = 0.01468, test_auc = 0.95571, time = 0.04474\n",
      "Epoch: 0230 | train_loss = 0.00895, train_auc = 0.99617, test_loss = 0.01266, test_auc = 0.96536, time = 0.04702\n",
      "Epoch: 0240 | train_loss = 0.00808, train_auc = 0.99640, test_loss = 0.01145, test_auc = 0.97279, time = 0.04365\n",
      "Epoch: 0250 | train_loss = 0.00814, train_auc = 0.99660, test_loss = 0.01490, test_auc = 0.95105, time = 0.04361\n",
      "Epoch: 0260 | train_loss = 0.00832, train_auc = 0.99678, test_loss = 0.01470, test_auc = 0.96026, time = 0.04307\n",
      "Epoch: 0270 | train_loss = 0.00841, train_auc = 0.99642, test_loss = 0.01068, test_auc = 0.97281, time = 0.04316\n",
      "Epoch: 0280 | train_loss = 0.00759, train_auc = 0.99635, test_loss = 0.01479, test_auc = 0.95623, time = 0.04390\n",
      "Epoch: 0290 | train_loss = 0.00715, train_auc = 0.99684, test_loss = 0.01282, test_auc = 0.96832, time = 0.04402\n",
      "Epoch: 0300 | train_loss = 0.00648, train_auc = 0.99690, test_loss = 0.01562, test_auc = 0.95491, time = 0.04442\n",
      "times: 6, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06033, train_auc = 0.51885, test_loss = 0.04086, test_auc = 0.28832, time = 0.79699\n",
      "Epoch: 0010 | train_loss = 0.03826, train_auc = 0.92988, test_loss = 0.02387, test_auc = 0.85973, time = 0.04713\n",
      "Epoch: 0020 | train_loss = 0.03017, train_auc = 0.95243, test_loss = 0.01768, test_auc = 0.92419, time = 0.04511\n",
      "Epoch: 0030 | train_loss = 0.02560, train_auc = 0.96669, test_loss = 0.01671, test_auc = 0.93017, time = 0.04353\n",
      "Epoch: 0040 | train_loss = 0.02388, train_auc = 0.97118, test_loss = 0.01851, test_auc = 0.88476, time = 0.04305\n",
      "Epoch: 0050 | train_loss = 0.02245, train_auc = 0.97410, test_loss = 0.01619, test_auc = 0.94217, time = 0.04447\n",
      "Epoch: 0060 | train_loss = 0.01961, train_auc = 0.98195, test_loss = 0.01995, test_auc = 0.85688, time = 0.04380\n",
      "Epoch: 0070 | train_loss = 0.01848, train_auc = 0.98427, test_loss = 0.01743, test_auc = 0.92698, time = 0.04384\n",
      "Epoch: 0080 | train_loss = 0.01699, train_auc = 0.98638, test_loss = 0.01826, test_auc = 0.91941, time = 0.04320\n",
      "Epoch: 0090 | train_loss = 0.01578, train_auc = 0.98836, test_loss = 0.01410, test_auc = 0.96112, time = 0.04342\n",
      "Epoch: 0100 | train_loss = 0.01459, train_auc = 0.98911, test_loss = 0.01378, test_auc = 0.96655, time = 0.04381\n",
      "Epoch: 0110 | train_loss = 0.01365, train_auc = 0.98942, test_loss = 0.01534, test_auc = 0.95095, time = 0.04296\n",
      "Epoch: 0120 | train_loss = 0.01389, train_auc = 0.99246, test_loss = 0.01422, test_auc = 0.96580, time = 0.04452\n",
      "Epoch: 0130 | train_loss = 0.01377, train_auc = 0.99043, test_loss = 0.01571, test_auc = 0.95587, time = 0.04396\n",
      "Epoch: 0140 | train_loss = 0.01261, train_auc = 0.99208, test_loss = 0.01447, test_auc = 0.96950, time = 0.04357\n",
      "Epoch: 0150 | train_loss = 0.01163, train_auc = 0.99289, test_loss = 0.01265, test_auc = 0.97154, time = 0.04327\n",
      "Epoch: 0160 | train_loss = 0.01157, train_auc = 0.99370, test_loss = 0.01648, test_auc = 0.94951, time = 0.04359\n",
      "Epoch: 0170 | train_loss = 0.01053, train_auc = 0.99378, test_loss = 0.01770, test_auc = 0.91645, time = 0.04342\n",
      "Epoch: 0180 | train_loss = 0.01053, train_auc = 0.99503, test_loss = 0.01410, test_auc = 0.96633, time = 0.04396\n",
      "Epoch: 0190 | train_loss = 0.01038, train_auc = 0.99537, test_loss = 0.01241, test_auc = 0.97601, time = 0.04327\n",
      "Epoch: 0200 | train_loss = 0.00907, train_auc = 0.99632, test_loss = 0.01729, test_auc = 0.92720, time = 0.04373\n",
      "Epoch: 0210 | train_loss = 0.01004, train_auc = 0.99616, test_loss = 0.01595, test_auc = 0.96664, time = 0.04433\n",
      "Epoch: 0220 | train_loss = 0.01000, train_auc = 0.99596, test_loss = 0.01644, test_auc = 0.95114, time = 0.04362\n",
      "Epoch: 0230 | train_loss = 0.00914, train_auc = 0.99679, test_loss = 0.01276, test_auc = 0.97406, time = 0.04357\n",
      "Epoch: 0240 | train_loss = 0.00815, train_auc = 0.99646, test_loss = 0.01398, test_auc = 0.96856, time = 0.04448\n",
      "Epoch: 0250 | train_loss = 0.00795, train_auc = 0.99671, test_loss = 0.01674, test_auc = 0.96116, time = 0.04458\n",
      "Epoch: 0260 | train_loss = 0.00855, train_auc = 0.99672, test_loss = 0.01335, test_auc = 0.97380, time = 0.04388\n",
      "Epoch: 0270 | train_loss = 0.00844, train_auc = 0.99693, test_loss = 0.01418, test_auc = 0.97862, time = 0.04392\n",
      "Epoch: 0280 | train_loss = 0.00752, train_auc = 0.99681, test_loss = 0.01398, test_auc = 0.96520, time = 0.04385\n",
      "Epoch: 0290 | train_loss = 0.00827, train_auc = 0.99658, test_loss = 0.01154, test_auc = 0.97546, time = 0.04753\n",
      "Epoch: 0300 | train_loss = 0.00741, train_auc = 0.99706, test_loss = 0.01221, test_auc = 0.97901, time = 0.04386\n",
      "times: 6, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.05931, train_auc = 0.54333, test_loss = 0.03631, test_auc = 0.43041, time = 0.77885\n",
      "Epoch: 0010 | train_loss = 0.03895, train_auc = 0.92675, test_loss = 0.02456, test_auc = 0.89452, time = 0.04946\n",
      "Epoch: 0020 | train_loss = 0.02880, train_auc = 0.95624, test_loss = 0.01643, test_auc = 0.93601, time = 0.04422\n",
      "Epoch: 0030 | train_loss = 0.02544, train_auc = 0.97186, test_loss = 0.01883, test_auc = 0.90733, time = 0.04253\n",
      "Epoch: 0040 | train_loss = 0.02238, train_auc = 0.98012, test_loss = 0.01843, test_auc = 0.88864, time = 0.04271\n",
      "Epoch: 0050 | train_loss = 0.02069, train_auc = 0.98434, test_loss = 0.01876, test_auc = 0.87832, time = 0.04310\n",
      "Epoch: 0060 | train_loss = 0.01857, train_auc = 0.98827, test_loss = 0.01430, test_auc = 0.95955, time = 0.04241\n",
      "Epoch: 0070 | train_loss = 0.01678, train_auc = 0.99111, test_loss = 0.01747, test_auc = 0.93060, time = 0.04270\n",
      "Epoch: 0080 | train_loss = 0.01577, train_auc = 0.99259, test_loss = 0.01449, test_auc = 0.95911, time = 0.04292\n",
      "Epoch: 0090 | train_loss = 0.01390, train_auc = 0.99470, test_loss = 0.01682, test_auc = 0.89947, time = 0.04539\n",
      "Epoch: 0100 | train_loss = 0.01307, train_auc = 0.99518, test_loss = 0.01540, test_auc = 0.93984, time = 0.04550\n",
      "Epoch: 0110 | train_loss = 0.01175, train_auc = 0.99612, test_loss = 0.01272, test_auc = 0.97471, time = 0.04349\n",
      "Epoch: 0120 | train_loss = 0.01081, train_auc = 0.99646, test_loss = 0.01375, test_auc = 0.96433, time = 0.04360\n",
      "Epoch: 0130 | train_loss = 0.01173, train_auc = 0.99600, test_loss = 0.01211, test_auc = 0.97631, time = 0.04383\n",
      "Epoch: 0140 | train_loss = 0.00940, train_auc = 0.99710, test_loss = 0.01213, test_auc = 0.97700, time = 0.04424\n",
      "Epoch: 0150 | train_loss = 0.01040, train_auc = 0.99655, test_loss = 0.01511, test_auc = 0.96919, time = 0.04378\n",
      "Epoch: 0160 | train_loss = 0.00962, train_auc = 0.99681, test_loss = 0.01603, test_auc = 0.96440, time = 0.04489\n",
      "Epoch: 0170 | train_loss = 0.00961, train_auc = 0.99677, test_loss = 0.01278, test_auc = 0.96983, time = 0.04340\n",
      "Epoch: 0180 | train_loss = 0.00938, train_auc = 0.99688, test_loss = 0.01265, test_auc = 0.97438, time = 0.04376\n",
      "Epoch: 0190 | train_loss = 0.00873, train_auc = 0.99703, test_loss = 0.01148, test_auc = 0.98035, time = 0.04371\n",
      "Epoch: 0200 | train_loss = 0.00905, train_auc = 0.99722, test_loss = 0.01117, test_auc = 0.97806, time = 0.04343\n",
      "Epoch: 0210 | train_loss = 0.00980, train_auc = 0.99694, test_loss = 0.01495, test_auc = 0.94819, time = 0.04282\n",
      "Epoch: 0220 | train_loss = 0.00809, train_auc = 0.99724, test_loss = 0.01375, test_auc = 0.95469, time = 0.04397\n",
      "Epoch: 0230 | train_loss = 0.00847, train_auc = 0.99700, test_loss = 0.01246, test_auc = 0.97049, time = 0.04419\n",
      "Epoch: 0240 | train_loss = 0.00821, train_auc = 0.99735, test_loss = 0.01451, test_auc = 0.95835, time = 0.04403\n",
      "Epoch: 0250 | train_loss = 0.00680, train_auc = 0.99772, test_loss = 0.01254, test_auc = 0.97137, time = 0.04438\n",
      "Epoch: 0260 | train_loss = 0.00818, train_auc = 0.99748, test_loss = 0.01219, test_auc = 0.97650, time = 0.04353\n",
      "Epoch: 0270 | train_loss = 0.00856, train_auc = 0.99747, test_loss = 0.01222, test_auc = 0.97852, time = 0.05191\n",
      "Epoch: 0280 | train_loss = 0.00703, train_auc = 0.99762, test_loss = 0.01387, test_auc = 0.97109, time = 0.04319\n",
      "Epoch: 0290 | train_loss = 0.00861, train_auc = 0.99742, test_loss = 0.01026, test_auc = 0.98456, time = 0.04386\n",
      "Epoch: 0300 | train_loss = 0.00662, train_auc = 0.99770, test_loss = 0.01140, test_auc = 0.97722, time = 0.04394\n",
      "times: 6, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06325, train_auc = 0.43444, test_loss = 0.03942, test_auc = 0.34272, time = 0.79888\n",
      "Epoch: 0010 | train_loss = 0.04144, train_auc = 0.87995, test_loss = 0.02390, test_auc = 0.87999, time = 0.04650\n",
      "Epoch: 0020 | train_loss = 0.02855, train_auc = 0.95809, test_loss = 0.02458, test_auc = 0.71894, time = 0.04171\n",
      "Epoch: 0030 | train_loss = 0.02525, train_auc = 0.97077, test_loss = 0.02573, test_auc = 0.69226, time = 0.04214\n",
      "Epoch: 0040 | train_loss = 0.02264, train_auc = 0.97810, test_loss = 0.02369, test_auc = 0.73985, time = 0.04418\n",
      "Epoch: 0050 | train_loss = 0.02048, train_auc = 0.98303, test_loss = 0.02205, test_auc = 0.80321, time = 0.04570\n",
      "Epoch: 0060 | train_loss = 0.01867, train_auc = 0.98556, test_loss = 0.02255, test_auc = 0.79275, time = 0.04223\n",
      "Epoch: 0070 | train_loss = 0.01738, train_auc = 0.98815, test_loss = 0.01953, test_auc = 0.90246, time = 0.04184\n",
      "Epoch: 0080 | train_loss = 0.01621, train_auc = 0.99019, test_loss = 0.01437, test_auc = 0.95152, time = 0.04502\n",
      "Epoch: 0090 | train_loss = 0.01498, train_auc = 0.99115, test_loss = 0.01424, test_auc = 0.94640, time = 0.04244\n",
      "Epoch: 0100 | train_loss = 0.01459, train_auc = 0.99235, test_loss = 0.01675, test_auc = 0.93074, time = 0.04332\n",
      "Epoch: 0110 | train_loss = 0.01311, train_auc = 0.99359, test_loss = 0.01367, test_auc = 0.96399, time = 0.04215\n",
      "Epoch: 0120 | train_loss = 0.01246, train_auc = 0.99440, test_loss = 0.02022, test_auc = 0.83262, time = 0.04312\n",
      "Epoch: 0130 | train_loss = 0.01169, train_auc = 0.99437, test_loss = 0.01688, test_auc = 0.94375, time = 0.04210\n",
      "Epoch: 0140 | train_loss = 0.01228, train_auc = 0.99528, test_loss = 0.01478, test_auc = 0.95441, time = 0.04179\n",
      "Epoch: 0150 | train_loss = 0.01108, train_auc = 0.99586, test_loss = 0.01335, test_auc = 0.96334, time = 0.04269\n",
      "Epoch: 0160 | train_loss = 0.01041, train_auc = 0.99663, test_loss = 0.01350, test_auc = 0.96324, time = 0.04237\n",
      "Epoch: 0170 | train_loss = 0.00994, train_auc = 0.99714, test_loss = 0.01334, test_auc = 0.96031, time = 0.04241\n",
      "Epoch: 0180 | train_loss = 0.01058, train_auc = 0.99649, test_loss = 0.01509, test_auc = 0.95536, time = 0.04321\n",
      "Epoch: 0190 | train_loss = 0.00881, train_auc = 0.99761, test_loss = 0.01610, test_auc = 0.94746, time = 0.04276\n",
      "Epoch: 0200 | train_loss = 0.00947, train_auc = 0.99791, test_loss = 0.01385, test_auc = 0.96507, time = 0.04275\n",
      "Epoch: 0210 | train_loss = 0.00825, train_auc = 0.99811, test_loss = 0.01281, test_auc = 0.96988, time = 0.04531\n",
      "Epoch: 0220 | train_loss = 0.00758, train_auc = 0.99811, test_loss = 0.01672, test_auc = 0.96026, time = 0.04270\n",
      "Epoch: 0230 | train_loss = 0.00868, train_auc = 0.99796, test_loss = 0.01480, test_auc = 0.95785, time = 0.04308\n",
      "Epoch: 0240 | train_loss = 0.00812, train_auc = 0.99848, test_loss = 0.01320, test_auc = 0.96731, time = 0.04224\n",
      "Epoch: 0250 | train_loss = 0.00708, train_auc = 0.99834, test_loss = 0.01856, test_auc = 0.94259, time = 0.04348\n",
      "Epoch: 0260 | train_loss = 0.00718, train_auc = 0.99824, test_loss = 0.01704, test_auc = 0.94576, time = 0.04205\n",
      "Epoch: 0270 | train_loss = 0.00638, train_auc = 0.99829, test_loss = 0.01120, test_auc = 0.97457, time = 0.04197\n",
      "Epoch: 0280 | train_loss = 0.00773, train_auc = 0.99817, test_loss = 0.01289, test_auc = 0.97113, time = 0.04198\n",
      "Epoch: 0290 | train_loss = 0.00761, train_auc = 0.99830, test_loss = 0.01206, test_auc = 0.97345, time = 0.04238\n",
      "Epoch: 0300 | train_loss = 0.00651, train_auc = 0.99830, test_loss = 0.01148, test_auc = 0.97661, time = 0.04357\n",
      "times: 6, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06377, train_auc = 0.47705, test_loss = 0.03578, test_auc = 0.47712, time = 0.82221\n",
      "Epoch: 0010 | train_loss = 0.04131, train_auc = 0.91528, test_loss = 0.02508, test_auc = 0.88175, time = 0.04468\n",
      "Epoch: 0020 | train_loss = 0.03167, train_auc = 0.95074, test_loss = 0.01669, test_auc = 0.93120, time = 0.04334\n",
      "Epoch: 0030 | train_loss = 0.02705, train_auc = 0.96515, test_loss = 0.01473, test_auc = 0.95039, time = 0.04219\n",
      "Epoch: 0040 | train_loss = 0.02357, train_auc = 0.97593, test_loss = 0.01873, test_auc = 0.85765, time = 0.04181\n",
      "Epoch: 0050 | train_loss = 0.02151, train_auc = 0.98133, test_loss = 0.01974, test_auc = 0.88057, time = 0.04225\n",
      "Epoch: 0060 | train_loss = 0.01908, train_auc = 0.98605, test_loss = 0.01454, test_auc = 0.95642, time = 0.04296\n",
      "Epoch: 0070 | train_loss = 0.01852, train_auc = 0.98708, test_loss = 0.01476, test_auc = 0.94855, time = 0.04167\n",
      "Epoch: 0080 | train_loss = 0.01636, train_auc = 0.98986, test_loss = 0.01534, test_auc = 0.93262, time = 0.04304\n",
      "Epoch: 0090 | train_loss = 0.01641, train_auc = 0.99083, test_loss = 0.01278, test_auc = 0.96721, time = 0.04154\n",
      "Epoch: 0100 | train_loss = 0.01432, train_auc = 0.99205, test_loss = 0.01411, test_auc = 0.95803, time = 0.04171\n",
      "Epoch: 0110 | train_loss = 0.01359, train_auc = 0.99355, test_loss = 0.01431, test_auc = 0.96390, time = 0.04156\n",
      "Epoch: 0120 | train_loss = 0.01225, train_auc = 0.99395, test_loss = 0.01335, test_auc = 0.96246, time = 0.04206\n",
      "Epoch: 0130 | train_loss = 0.01217, train_auc = 0.99402, test_loss = 0.01636, test_auc = 0.92799, time = 0.04289\n",
      "Epoch: 0140 | train_loss = 0.01077, train_auc = 0.99480, test_loss = 0.01619, test_auc = 0.94176, time = 0.04153\n",
      "Epoch: 0150 | train_loss = 0.01145, train_auc = 0.99562, test_loss = 0.01276, test_auc = 0.96768, time = 0.04191\n",
      "Epoch: 0160 | train_loss = 0.01230, train_auc = 0.99406, test_loss = 0.01383, test_auc = 0.95859, time = 0.04234\n",
      "Epoch: 0170 | train_loss = 0.01165, train_auc = 0.99514, test_loss = 0.01246, test_auc = 0.97211, time = 0.04213\n",
      "Epoch: 0180 | train_loss = 0.01034, train_auc = 0.99697, test_loss = 0.01541, test_auc = 0.95004, time = 0.04240\n",
      "Epoch: 0190 | train_loss = 0.01030, train_auc = 0.99670, test_loss = 0.01239, test_auc = 0.96790, time = 0.04203\n",
      "Epoch: 0200 | train_loss = 0.01010, train_auc = 0.99749, test_loss = 0.01275, test_auc = 0.97149, time = 0.04203\n",
      "Epoch: 0210 | train_loss = 0.00991, train_auc = 0.99754, test_loss = 0.01097, test_auc = 0.97837, time = 0.04200\n",
      "Epoch: 0220 | train_loss = 0.00773, train_auc = 0.99831, test_loss = 0.01393, test_auc = 0.96432, time = 0.04317\n",
      "Epoch: 0230 | train_loss = 0.00916, train_auc = 0.99825, test_loss = 0.01346, test_auc = 0.96805, time = 0.04241\n",
      "Epoch: 0240 | train_loss = 0.00722, train_auc = 0.99862, test_loss = 0.01168, test_auc = 0.97327, time = 0.04239\n",
      "Epoch: 0250 | train_loss = 0.00789, train_auc = 0.99877, test_loss = 0.01321, test_auc = 0.96801, time = 0.04204\n",
      "Epoch: 0260 | train_loss = 0.00779, train_auc = 0.99875, test_loss = 0.01454, test_auc = 0.95041, time = 0.04206\n",
      "Epoch: 0270 | train_loss = 0.00717, train_auc = 0.99891, test_loss = 0.01199, test_auc = 0.97476, time = 0.04179\n",
      "Epoch: 0280 | train_loss = 0.00743, train_auc = 0.99868, test_loss = 0.01895, test_auc = 0.92144, time = 0.04184\n",
      "Epoch: 0290 | train_loss = 0.00785, train_auc = 0.99906, test_loss = 0.01208, test_auc = 0.97231, time = 0.04116\n",
      "Epoch: 0300 | train_loss = 0.00789, train_auc = 0.99901, test_loss = 0.01215, test_auc = 0.97124, time = 0.04312\n",
      "times: 6, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06001, train_auc = 0.52558, test_loss = 0.04061, test_auc = 0.30807, time = 0.81858\n",
      "Epoch: 0010 | train_loss = 0.03966, train_auc = 0.92959, test_loss = 0.03017, test_auc = 0.82662, time = 0.04775\n",
      "Epoch: 0020 | train_loss = 0.03147, train_auc = 0.94830, test_loss = 0.01664, test_auc = 0.93557, time = 0.04541\n",
      "Epoch: 0030 | train_loss = 0.02681, train_auc = 0.96203, test_loss = 0.02195, test_auc = 0.77862, time = 0.04430\n",
      "Epoch: 0040 | train_loss = 0.02451, train_auc = 0.97163, test_loss = 0.02039, test_auc = 0.82442, time = 0.04461\n",
      "Epoch: 0050 | train_loss = 0.02247, train_auc = 0.97543, test_loss = 0.02044, test_auc = 0.82090, time = 0.04429\n",
      "Epoch: 0060 | train_loss = 0.02049, train_auc = 0.98068, test_loss = 0.02123, test_auc = 0.79224, time = 0.04367\n",
      "Epoch: 0070 | train_loss = 0.01881, train_auc = 0.98501, test_loss = 0.01861, test_auc = 0.89244, time = 0.04319\n",
      "Epoch: 0080 | train_loss = 0.01832, train_auc = 0.98546, test_loss = 0.01655, test_auc = 0.94137, time = 0.04373\n",
      "Epoch: 0090 | train_loss = 0.01601, train_auc = 0.98827, test_loss = 0.01733, test_auc = 0.91750, time = 0.04378\n",
      "Epoch: 0100 | train_loss = 0.01555, train_auc = 0.98984, test_loss = 0.01288, test_auc = 0.96866, time = 0.04339\n",
      "Epoch: 0110 | train_loss = 0.01454, train_auc = 0.99196, test_loss = 0.01659, test_auc = 0.94173, time = 0.04360\n",
      "Epoch: 0120 | train_loss = 0.01369, train_auc = 0.99412, test_loss = 0.01510, test_auc = 0.93905, time = 0.04403\n",
      "Epoch: 0130 | train_loss = 0.01200, train_auc = 0.99467, test_loss = 0.01540, test_auc = 0.96906, time = 0.04322\n",
      "Epoch: 0140 | train_loss = 0.01161, train_auc = 0.99436, test_loss = 0.01814, test_auc = 0.88770, time = 0.04323\n",
      "Epoch: 0150 | train_loss = 0.01130, train_auc = 0.99560, test_loss = 0.01420, test_auc = 0.96289, time = 0.04350\n",
      "Epoch: 0160 | train_loss = 0.01039, train_auc = 0.99624, test_loss = 0.01238, test_auc = 0.96839, time = 0.04345\n",
      "Epoch: 0170 | train_loss = 0.01097, train_auc = 0.99575, test_loss = 0.01297, test_auc = 0.95948, time = 0.04312\n",
      "Epoch: 0180 | train_loss = 0.01014, train_auc = 0.99571, test_loss = 0.01362, test_auc = 0.97620, time = 0.04378\n",
      "Epoch: 0190 | train_loss = 0.01011, train_auc = 0.99652, test_loss = 0.01293, test_auc = 0.96246, time = 0.04430\n",
      "Epoch: 0200 | train_loss = 0.00888, train_auc = 0.99647, test_loss = 0.01384, test_auc = 0.96333, time = 0.04522\n",
      "Epoch: 0210 | train_loss = 0.00894, train_auc = 0.99728, test_loss = 0.01153, test_auc = 0.97505, time = 0.04338\n",
      "Epoch: 0220 | train_loss = 0.00850, train_auc = 0.99765, test_loss = 0.01190, test_auc = 0.98071, time = 0.04319\n",
      "Epoch: 0230 | train_loss = 0.00773, train_auc = 0.99819, test_loss = 0.01091, test_auc = 0.98207, time = 0.04556\n",
      "Epoch: 0240 | train_loss = 0.00803, train_auc = 0.99887, test_loss = 0.01134, test_auc = 0.98252, time = 0.04305\n",
      "Epoch: 0250 | train_loss = 0.00866, train_auc = 0.99783, test_loss = 0.01427, test_auc = 0.95420, time = 0.04296\n",
      "Epoch: 0260 | train_loss = 0.00825, train_auc = 0.99829, test_loss = 0.01309, test_auc = 0.96935, time = 0.04331\n",
      "Epoch: 0270 | train_loss = 0.00870, train_auc = 0.99837, test_loss = 0.01262, test_auc = 0.97274, time = 0.04389\n",
      "Epoch: 0280 | train_loss = 0.00838, train_auc = 0.99843, test_loss = 0.01384, test_auc = 0.96449, time = 0.04354\n",
      "Epoch: 0290 | train_loss = 0.00735, train_auc = 0.99884, test_loss = 0.01170, test_auc = 0.97637, time = 0.04307\n",
      "Epoch: 0300 | train_loss = 0.00798, train_auc = 0.99861, test_loss = 0.01161, test_auc = 0.97765, time = 0.04358\n",
      "times: 7, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06099, train_auc = 0.51580, test_loss = 0.03936, test_auc = 0.33325, time = 0.89300\n",
      "Epoch: 0010 | train_loss = 0.04092, train_auc = 0.92821, test_loss = 0.02877, test_auc = 0.84209, time = 0.04725\n",
      "Epoch: 0020 | train_loss = 0.02951, train_auc = 0.95626, test_loss = 0.01898, test_auc = 0.89769, time = 0.04224\n",
      "Epoch: 0030 | train_loss = 0.02594, train_auc = 0.96476, test_loss = 0.02004, test_auc = 0.87665, time = 0.04121\n",
      "Epoch: 0040 | train_loss = 0.02345, train_auc = 0.97424, test_loss = 0.02287, test_auc = 0.82718, time = 0.04195\n",
      "Epoch: 0050 | train_loss = 0.02144, train_auc = 0.97916, test_loss = 0.02273, test_auc = 0.74489, time = 0.04098\n",
      "Epoch: 0060 | train_loss = 0.01906, train_auc = 0.98413, test_loss = 0.01955, test_auc = 0.90701, time = 0.04053\n",
      "Epoch: 0070 | train_loss = 0.01751, train_auc = 0.98688, test_loss = 0.01921, test_auc = 0.89518, time = 0.04086\n",
      "Epoch: 0080 | train_loss = 0.01612, train_auc = 0.98908, test_loss = 0.01521, test_auc = 0.94990, time = 0.04082\n",
      "Epoch: 0090 | train_loss = 0.01596, train_auc = 0.98934, test_loss = 0.01722, test_auc = 0.93852, time = 0.04060\n",
      "Epoch: 0100 | train_loss = 0.01458, train_auc = 0.99038, test_loss = 0.01620, test_auc = 0.94818, time = 0.04106\n",
      "Epoch: 0110 | train_loss = 0.01315, train_auc = 0.99180, test_loss = 0.01673, test_auc = 0.94087, time = 0.04168\n",
      "Epoch: 0120 | train_loss = 0.01267, train_auc = 0.99286, test_loss = 0.01702, test_auc = 0.93894, time = 0.04079\n",
      "Epoch: 0130 | train_loss = 0.01331, train_auc = 0.99233, test_loss = 0.01574, test_auc = 0.95266, time = 0.04038\n",
      "Epoch: 0140 | train_loss = 0.01403, train_auc = 0.99155, test_loss = 0.01595, test_auc = 0.94638, time = 0.04113\n",
      "Epoch: 0150 | train_loss = 0.01260, train_auc = 0.99302, test_loss = 0.01613, test_auc = 0.94978, time = 0.04118\n",
      "Epoch: 0160 | train_loss = 0.01160, train_auc = 0.99396, test_loss = 0.01364, test_auc = 0.95438, time = 0.04137\n",
      "Epoch: 0170 | train_loss = 0.01055, train_auc = 0.99508, test_loss = 0.01341, test_auc = 0.96541, time = 0.04142\n",
      "Epoch: 0180 | train_loss = 0.01120, train_auc = 0.99451, test_loss = 0.01378, test_auc = 0.96683, time = 0.04028\n",
      "Epoch: 0190 | train_loss = 0.01050, train_auc = 0.99509, test_loss = 0.01133, test_auc = 0.97569, time = 0.04179\n",
      "Epoch: 0200 | train_loss = 0.00907, train_auc = 0.99511, test_loss = 0.01213, test_auc = 0.97332, time = 0.04068\n",
      "Epoch: 0210 | train_loss = 0.01078, train_auc = 0.99486, test_loss = 0.02116, test_auc = 0.87226, time = 0.04120\n",
      "Epoch: 0220 | train_loss = 0.01042, train_auc = 0.99553, test_loss = 0.01298, test_auc = 0.96754, time = 0.04130\n",
      "Epoch: 0230 | train_loss = 0.00934, train_auc = 0.99603, test_loss = 0.01062, test_auc = 0.98039, time = 0.04108\n",
      "Epoch: 0240 | train_loss = 0.00887, train_auc = 0.99510, test_loss = 0.01253, test_auc = 0.97596, time = 0.04087\n",
      "Epoch: 0250 | train_loss = 0.00838, train_auc = 0.99594, test_loss = 0.01143, test_auc = 0.97977, time = 0.04084\n",
      "Epoch: 0260 | train_loss = 0.00735, train_auc = 0.99604, test_loss = 0.01273, test_auc = 0.97118, time = 0.04074\n",
      "Epoch: 0270 | train_loss = 0.00789, train_auc = 0.99595, test_loss = 0.01512, test_auc = 0.94541, time = 0.04221\n",
      "Epoch: 0280 | train_loss = 0.00775, train_auc = 0.99602, test_loss = 0.01155, test_auc = 0.97151, time = 0.04184\n",
      "Epoch: 0290 | train_loss = 0.01004, train_auc = 0.99553, test_loss = 0.01312, test_auc = 0.97287, time = 0.04107\n",
      "Epoch: 0300 | train_loss = 0.00829, train_auc = 0.99614, test_loss = 0.01029, test_auc = 0.98186, time = 0.04132\n",
      "times: 7, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06328, train_auc = 0.44956, test_loss = 0.03569, test_auc = 0.47335, time = 0.79437\n",
      "Epoch: 0010 | train_loss = 0.03769, train_auc = 0.92521, test_loss = 0.02657, test_auc = 0.75659, time = 0.04917\n",
      "Epoch: 0020 | train_loss = 0.02788, train_auc = 0.96098, test_loss = 0.02229, test_auc = 0.77026, time = 0.04427\n",
      "Epoch: 0030 | train_loss = 0.02464, train_auc = 0.97210, test_loss = 0.02170, test_auc = 0.78302, time = 0.04213\n",
      "Epoch: 0040 | train_loss = 0.02154, train_auc = 0.97992, test_loss = 0.01363, test_auc = 0.95992, time = 0.04209\n",
      "Epoch: 0050 | train_loss = 0.01999, train_auc = 0.98281, test_loss = 0.01633, test_auc = 0.92430, time = 0.04170\n",
      "Epoch: 0060 | train_loss = 0.02016, train_auc = 0.98154, test_loss = 0.01695, test_auc = 0.88931, time = 0.04190\n",
      "Epoch: 0070 | train_loss = 0.01767, train_auc = 0.98681, test_loss = 0.01695, test_auc = 0.89558, time = 0.04174\n",
      "Epoch: 0080 | train_loss = 0.01640, train_auc = 0.98859, test_loss = 0.01667, test_auc = 0.94060, time = 0.04129\n",
      "Epoch: 0090 | train_loss = 0.01567, train_auc = 0.98982, test_loss = 0.01234, test_auc = 0.97081, time = 0.04155\n",
      "Epoch: 0100 | train_loss = 0.01385, train_auc = 0.99056, test_loss = 0.01188, test_auc = 0.97068, time = 0.04166\n",
      "Epoch: 0110 | train_loss = 0.01257, train_auc = 0.99232, test_loss = 0.01455, test_auc = 0.94461, time = 0.04295\n",
      "Epoch: 0120 | train_loss = 0.01313, train_auc = 0.99300, test_loss = 0.01275, test_auc = 0.97271, time = 0.04107\n",
      "Epoch: 0130 | train_loss = 0.01274, train_auc = 0.99286, test_loss = 0.01372, test_auc = 0.96195, time = 0.04129\n",
      "Epoch: 0140 | train_loss = 0.01213, train_auc = 0.99397, test_loss = 0.01372, test_auc = 0.96574, time = 0.04140\n",
      "Epoch: 0150 | train_loss = 0.01096, train_auc = 0.99494, test_loss = 0.01162, test_auc = 0.97996, time = 0.04198\n",
      "Epoch: 0160 | train_loss = 0.01020, train_auc = 0.99552, test_loss = 0.01227, test_auc = 0.97355, time = 0.04314\n",
      "Epoch: 0170 | train_loss = 0.01109, train_auc = 0.99574, test_loss = 0.01176, test_auc = 0.97570, time = 0.04247\n",
      "Epoch: 0180 | train_loss = 0.00885, train_auc = 0.99632, test_loss = 0.01505, test_auc = 0.95971, time = 0.04237\n",
      "Epoch: 0190 | train_loss = 0.00909, train_auc = 0.99681, test_loss = 0.01993, test_auc = 0.87444, time = 0.04162\n",
      "Epoch: 0200 | train_loss = 0.00898, train_auc = 0.99690, test_loss = 0.01068, test_auc = 0.97977, time = 0.04125\n",
      "Epoch: 0210 | train_loss = 0.00819, train_auc = 0.99717, test_loss = 0.01123, test_auc = 0.98119, time = 0.04134\n",
      "Epoch: 0220 | train_loss = 0.00844, train_auc = 0.99742, test_loss = 0.01103, test_auc = 0.98278, time = 0.04112\n",
      "Epoch: 0230 | train_loss = 0.00826, train_auc = 0.99750, test_loss = 0.01259, test_auc = 0.97558, time = 0.04120\n",
      "Epoch: 0240 | train_loss = 0.00809, train_auc = 0.99785, test_loss = 0.01016, test_auc = 0.98481, time = 0.04106\n",
      "Epoch: 0250 | train_loss = 0.00686, train_auc = 0.99820, test_loss = 0.00935, test_auc = 0.98386, time = 0.04295\n",
      "Epoch: 0260 | train_loss = 0.00816, train_auc = 0.99741, test_loss = 0.01062, test_auc = 0.98572, time = 0.04095\n",
      "Epoch: 0270 | train_loss = 0.00787, train_auc = 0.99812, test_loss = 0.01107, test_auc = 0.97986, time = 0.04188\n",
      "Epoch: 0280 | train_loss = 0.00839, train_auc = 0.99810, test_loss = 0.01364, test_auc = 0.97300, time = 0.04180\n",
      "Epoch: 0290 | train_loss = 0.00833, train_auc = 0.99803, test_loss = 0.00935, test_auc = 0.98702, time = 0.04129\n",
      "Epoch: 0300 | train_loss = 0.00721, train_auc = 0.99791, test_loss = 0.01171, test_auc = 0.97980, time = 0.04277\n",
      "times: 7, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06315, train_auc = 0.47746, test_loss = 0.03941, test_auc = 0.35147, time = 0.80354\n",
      "Epoch: 0010 | train_loss = 0.03720, train_auc = 0.92776, test_loss = 0.01979, test_auc = 0.88332, time = 0.04788\n",
      "Epoch: 0020 | train_loss = 0.02768, train_auc = 0.96541, test_loss = 0.01842, test_auc = 0.90435, time = 0.04298\n",
      "Epoch: 0030 | train_loss = 0.02376, train_auc = 0.97702, test_loss = 0.01942, test_auc = 0.88127, time = 0.04363\n",
      "Epoch: 0040 | train_loss = 0.02138, train_auc = 0.98206, test_loss = 0.02086, test_auc = 0.80802, time = 0.04395\n",
      "Epoch: 0050 | train_loss = 0.02000, train_auc = 0.98564, test_loss = 0.02371, test_auc = 0.74650, time = 0.04176\n",
      "Epoch: 0060 | train_loss = 0.01800, train_auc = 0.98800, test_loss = 0.01971, test_auc = 0.84711, time = 0.04293\n",
      "Epoch: 0070 | train_loss = 0.01717, train_auc = 0.99007, test_loss = 0.01742, test_auc = 0.93210, time = 0.04238\n",
      "Epoch: 0080 | train_loss = 0.01502, train_auc = 0.99302, test_loss = 0.01978, test_auc = 0.85529, time = 0.04175\n",
      "Epoch: 0090 | train_loss = 0.01377, train_auc = 0.99322, test_loss = 0.01558, test_auc = 0.92484, time = 0.04171\n",
      "Epoch: 0100 | train_loss = 0.01264, train_auc = 0.99441, test_loss = 0.01308, test_auc = 0.96166, time = 0.04202\n",
      "Epoch: 0110 | train_loss = 0.01200, train_auc = 0.99479, test_loss = 0.01737, test_auc = 0.89579, time = 0.04173\n",
      "Epoch: 0120 | train_loss = 0.01049, train_auc = 0.99550, test_loss = 0.01372, test_auc = 0.96106, time = 0.04216\n",
      "Epoch: 0130 | train_loss = 0.01033, train_auc = 0.99545, test_loss = 0.01363, test_auc = 0.96923, time = 0.04200\n",
      "Epoch: 0140 | train_loss = 0.01055, train_auc = 0.99542, test_loss = 0.01235, test_auc = 0.97227, time = 0.04278\n",
      "Epoch: 0150 | train_loss = 0.00967, train_auc = 0.99598, test_loss = 0.01540, test_auc = 0.94711, time = 0.04464\n",
      "Epoch: 0160 | train_loss = 0.01115, train_auc = 0.99558, test_loss = 0.01281, test_auc = 0.96957, time = 0.04225\n",
      "Epoch: 0170 | train_loss = 0.01190, train_auc = 0.99540, test_loss = 0.01295, test_auc = 0.97425, time = 0.04224\n",
      "Epoch: 0180 | train_loss = 0.00950, train_auc = 0.99571, test_loss = 0.01753, test_auc = 0.93137, time = 0.04258\n",
      "Epoch: 0190 | train_loss = 0.00978, train_auc = 0.99611, test_loss = 0.01586, test_auc = 0.95483, time = 0.04244\n",
      "Epoch: 0200 | train_loss = 0.00870, train_auc = 0.99669, test_loss = 0.01404, test_auc = 0.95878, time = 0.04234\n",
      "Epoch: 0210 | train_loss = 0.00961, train_auc = 0.99643, test_loss = 0.01282, test_auc = 0.97255, time = 0.04261\n",
      "Epoch: 0220 | train_loss = 0.00812, train_auc = 0.99678, test_loss = 0.01254, test_auc = 0.97394, time = 0.04304\n",
      "Epoch: 0230 | train_loss = 0.00836, train_auc = 0.99639, test_loss = 0.01199, test_auc = 0.97537, time = 0.04386\n",
      "Epoch: 0240 | train_loss = 0.00845, train_auc = 0.99663, test_loss = 0.01233, test_auc = 0.97210, time = 0.04200\n",
      "Epoch: 0250 | train_loss = 0.00835, train_auc = 0.99644, test_loss = 0.01290, test_auc = 0.97493, time = 0.04162\n",
      "Epoch: 0260 | train_loss = 0.00794, train_auc = 0.99657, test_loss = 0.01113, test_auc = 0.97931, time = 0.04232\n",
      "Epoch: 0270 | train_loss = 0.00763, train_auc = 0.99672, test_loss = 0.01232, test_auc = 0.97494, time = 0.04324\n",
      "Epoch: 0280 | train_loss = 0.00716, train_auc = 0.99670, test_loss = 0.01294, test_auc = 0.97244, time = 0.04190\n",
      "Epoch: 0290 | train_loss = 0.00804, train_auc = 0.99719, test_loss = 0.01347, test_auc = 0.97074, time = 0.04206\n",
      "Epoch: 0300 | train_loss = 0.00832, train_auc = 0.99694, test_loss = 0.01329, test_auc = 0.96737, time = 0.04218\n",
      "times: 7, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06238, train_auc = 0.47305, test_loss = 0.03314, test_auc = 0.55988, time = 0.82078\n",
      "Epoch: 0010 | train_loss = 0.04140, train_auc = 0.90571, test_loss = 0.02750, test_auc = 0.84958, time = 0.05006\n",
      "Epoch: 0020 | train_loss = 0.03002, train_auc = 0.95731, test_loss = 0.01976, test_auc = 0.85414, time = 0.04657\n",
      "Epoch: 0030 | train_loss = 0.02603, train_auc = 0.96638, test_loss = 0.02152, test_auc = 0.82807, time = 0.04623\n",
      "Epoch: 0040 | train_loss = 0.02346, train_auc = 0.97418, test_loss = 0.01974, test_auc = 0.86822, time = 0.04381\n",
      "Epoch: 0050 | train_loss = 0.02149, train_auc = 0.97927, test_loss = 0.02186, test_auc = 0.84832, time = 0.04464\n",
      "Epoch: 0060 | train_loss = 0.01988, train_auc = 0.98144, test_loss = 0.01837, test_auc = 0.91176, time = 0.04477\n",
      "Epoch: 0070 | train_loss = 0.01902, train_auc = 0.98470, test_loss = 0.01600, test_auc = 0.94222, time = 0.04499\n",
      "Epoch: 0080 | train_loss = 0.01804, train_auc = 0.98622, test_loss = 0.01933, test_auc = 0.85804, time = 0.04523\n",
      "Epoch: 0090 | train_loss = 0.01657, train_auc = 0.98831, test_loss = 0.01945, test_auc = 0.92009, time = 0.04512\n",
      "Epoch: 0100 | train_loss = 0.01611, train_auc = 0.98890, test_loss = 0.01510, test_auc = 0.95621, time = 0.04290\n",
      "Epoch: 0110 | train_loss = 0.01431, train_auc = 0.99166, test_loss = 0.01502, test_auc = 0.94287, time = 0.04851\n",
      "Epoch: 0120 | train_loss = 0.01570, train_auc = 0.98982, test_loss = 0.01484, test_auc = 0.96266, time = 0.04252\n",
      "Epoch: 0130 | train_loss = 0.01419, train_auc = 0.99169, test_loss = 0.01284, test_auc = 0.97088, time = 0.04354\n",
      "Epoch: 0140 | train_loss = 0.01236, train_auc = 0.99238, test_loss = 0.01448, test_auc = 0.96563, time = 0.04260\n",
      "Epoch: 0150 | train_loss = 0.01216, train_auc = 0.99293, test_loss = 0.01551, test_auc = 0.93955, time = 0.04247\n",
      "Epoch: 0160 | train_loss = 0.01129, train_auc = 0.99309, test_loss = 0.01448, test_auc = 0.96655, time = 0.04275\n",
      "Epoch: 0170 | train_loss = 0.01093, train_auc = 0.99357, test_loss = 0.01143, test_auc = 0.97958, time = 0.04253\n",
      "Epoch: 0180 | train_loss = 0.01057, train_auc = 0.99424, test_loss = 0.01127, test_auc = 0.97674, time = 0.04237\n",
      "Epoch: 0190 | train_loss = 0.01096, train_auc = 0.99416, test_loss = 0.01116, test_auc = 0.98143, time = 0.04239\n",
      "Epoch: 0200 | train_loss = 0.00987, train_auc = 0.99496, test_loss = 0.01224, test_auc = 0.97645, time = 0.04291\n",
      "Epoch: 0210 | train_loss = 0.00961, train_auc = 0.99532, test_loss = 0.01497, test_auc = 0.95926, time = 0.04446\n",
      "Epoch: 0220 | train_loss = 0.00948, train_auc = 0.99551, test_loss = 0.01299, test_auc = 0.96767, time = 0.04356\n",
      "Epoch: 0230 | train_loss = 0.00932, train_auc = 0.99580, test_loss = 0.01467, test_auc = 0.96215, time = 0.04369\n",
      "Epoch: 0240 | train_loss = 0.00840, train_auc = 0.99609, test_loss = 0.01365, test_auc = 0.97077, time = 0.04342\n",
      "Epoch: 0250 | train_loss = 0.00798, train_auc = 0.99548, test_loss = 0.01188, test_auc = 0.97576, time = 0.04339\n",
      "Epoch: 0260 | train_loss = 0.00834, train_auc = 0.99556, test_loss = 0.01364, test_auc = 0.97020, time = 0.04357\n",
      "Epoch: 0270 | train_loss = 0.00859, train_auc = 0.99566, test_loss = 0.01228, test_auc = 0.97766, time = 0.04352\n",
      "Epoch: 0280 | train_loss = 0.00782, train_auc = 0.99563, test_loss = 0.01267, test_auc = 0.96769, time = 0.04215\n",
      "Epoch: 0290 | train_loss = 0.00982, train_auc = 0.99565, test_loss = 0.01343, test_auc = 0.97210, time = 0.04344\n",
      "Epoch: 0300 | train_loss = 0.00957, train_auc = 0.99616, test_loss = 0.01181, test_auc = 0.97749, time = 0.04176\n",
      "times: 7, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06278, train_auc = 0.48422, test_loss = 0.03492, test_auc = 0.50394, time = 0.78161\n",
      "Epoch: 0010 | train_loss = 0.03846, train_auc = 0.91669, test_loss = 0.02723, test_auc = 0.87354, time = 0.04688\n",
      "Epoch: 0020 | train_loss = 0.02965, train_auc = 0.95390, test_loss = 0.01807, test_auc = 0.89313, time = 0.04429\n",
      "Epoch: 0030 | train_loss = 0.02534, train_auc = 0.96857, test_loss = 0.01944, test_auc = 0.87862, time = 0.04204\n",
      "Epoch: 0040 | train_loss = 0.02263, train_auc = 0.97744, test_loss = 0.02037, test_auc = 0.82460, time = 0.04495\n",
      "Epoch: 0050 | train_loss = 0.02082, train_auc = 0.98137, test_loss = 0.01904, test_auc = 0.84626, time = 0.04350\n",
      "Epoch: 0060 | train_loss = 0.01925, train_auc = 0.98490, test_loss = 0.01979, test_auc = 0.82380, time = 0.04257\n",
      "Epoch: 0070 | train_loss = 0.01746, train_auc = 0.98660, test_loss = 0.01561, test_auc = 0.93982, time = 0.04210\n",
      "Epoch: 0080 | train_loss = 0.01722, train_auc = 0.98757, test_loss = 0.01677, test_auc = 0.93333, time = 0.04365\n",
      "Epoch: 0090 | train_loss = 0.01507, train_auc = 0.98850, test_loss = 0.01965, test_auc = 0.89157, time = 0.04336\n",
      "Epoch: 0100 | train_loss = 0.01474, train_auc = 0.98882, test_loss = 0.01698, test_auc = 0.91356, time = 0.04995\n",
      "Epoch: 0110 | train_loss = 0.01347, train_auc = 0.99003, test_loss = 0.01751, test_auc = 0.91962, time = 0.04299\n",
      "Epoch: 0120 | train_loss = 0.01294, train_auc = 0.99002, test_loss = 0.01869, test_auc = 0.89346, time = 0.04297\n",
      "Epoch: 0130 | train_loss = 0.01298, train_auc = 0.98932, test_loss = 0.01768, test_auc = 0.88841, time = 0.04316\n",
      "Epoch: 0140 | train_loss = 0.01153, train_auc = 0.99083, test_loss = 0.01811, test_auc = 0.90146, time = 0.04235\n",
      "Epoch: 0150 | train_loss = 0.01279, train_auc = 0.99161, test_loss = 0.01374, test_auc = 0.96088, time = 0.04583\n",
      "Epoch: 0160 | train_loss = 0.01208, train_auc = 0.99158, test_loss = 0.01643, test_auc = 0.94053, time = 0.04426\n",
      "Epoch: 0170 | train_loss = 0.01062, train_auc = 0.99168, test_loss = 0.01785, test_auc = 0.91998, time = 0.04265\n",
      "Epoch: 0180 | train_loss = 0.01096, train_auc = 0.99124, test_loss = 0.01577, test_auc = 0.95634, time = 0.04232\n",
      "Epoch: 0190 | train_loss = 0.01056, train_auc = 0.99153, test_loss = 0.01888, test_auc = 0.84044, time = 0.04254\n",
      "Epoch: 0200 | train_loss = 0.00994, train_auc = 0.99120, test_loss = 0.01711, test_auc = 0.94758, time = 0.04317\n",
      "Epoch: 0210 | train_loss = 0.00962, train_auc = 0.99178, test_loss = 0.01623, test_auc = 0.93304, time = 0.04218\n",
      "Epoch: 0220 | train_loss = 0.01039, train_auc = 0.99201, test_loss = 0.01560, test_auc = 0.94626, time = 0.04231\n",
      "Epoch: 0230 | train_loss = 0.01062, train_auc = 0.99170, test_loss = 0.01451, test_auc = 0.95154, time = 0.04253\n",
      "Epoch: 0240 | train_loss = 0.00967, train_auc = 0.99112, test_loss = 0.01482, test_auc = 0.95211, time = 0.04263\n",
      "Epoch: 0250 | train_loss = 0.01032, train_auc = 0.99176, test_loss = 0.01430, test_auc = 0.95903, time = 0.04278\n",
      "Epoch: 0260 | train_loss = 0.01016, train_auc = 0.99068, test_loss = 0.01511, test_auc = 0.94863, time = 0.04274\n",
      "Epoch: 0270 | train_loss = 0.00911, train_auc = 0.99187, test_loss = 0.01639, test_auc = 0.93993, time = 0.04341\n",
      "Epoch: 0280 | train_loss = 0.00930, train_auc = 0.99181, test_loss = 0.01467, test_auc = 0.95314, time = 0.04252\n",
      "Epoch: 0290 | train_loss = 0.01012, train_auc = 0.99151, test_loss = 0.01813, test_auc = 0.92714, time = 0.04198\n",
      "Epoch: 0300 | train_loss = 0.00858, train_auc = 0.99245, test_loss = 0.01736, test_auc = 0.94419, time = 0.04367\n",
      "times: 8, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06160, train_auc = 0.49185, test_loss = 0.03349, test_auc = 0.53149, time = 0.82793\n",
      "Epoch: 0010 | train_loss = 0.04041, train_auc = 0.92038, test_loss = 0.02847, test_auc = 0.86483, time = 0.05097\n",
      "Epoch: 0020 | train_loss = 0.02937, train_auc = 0.95983, test_loss = 0.02452, test_auc = 0.77068, time = 0.04692\n",
      "Epoch: 0030 | train_loss = 0.02529, train_auc = 0.97340, test_loss = 0.02345, test_auc = 0.74715, time = 0.04462\n",
      "Epoch: 0040 | train_loss = 0.02183, train_auc = 0.98234, test_loss = 0.02040, test_auc = 0.84390, time = 0.04469\n",
      "Epoch: 0050 | train_loss = 0.02032, train_auc = 0.98359, test_loss = 0.02028, test_auc = 0.82214, time = 0.04367\n",
      "Epoch: 0060 | train_loss = 0.01934, train_auc = 0.98570, test_loss = 0.01329, test_auc = 0.96617, time = 0.04409\n",
      "Epoch: 0070 | train_loss = 0.01806, train_auc = 0.98830, test_loss = 0.01495, test_auc = 0.96300, time = 0.04527\n",
      "Epoch: 0080 | train_loss = 0.01677, train_auc = 0.99023, test_loss = 0.01342, test_auc = 0.95880, time = 0.04449\n",
      "Epoch: 0090 | train_loss = 0.01591, train_auc = 0.99101, test_loss = 0.01240, test_auc = 0.96964, time = 0.04541\n",
      "Epoch: 0100 | train_loss = 0.01505, train_auc = 0.99291, test_loss = 0.01472, test_auc = 0.95545, time = 0.04434\n",
      "Epoch: 0110 | train_loss = 0.01300, train_auc = 0.99477, test_loss = 0.01218, test_auc = 0.97439, time = 0.04499\n",
      "Epoch: 0120 | train_loss = 0.01211, train_auc = 0.99598, test_loss = 0.01259, test_auc = 0.97285, time = 0.04498\n",
      "Epoch: 0130 | train_loss = 0.01199, train_auc = 0.99561, test_loss = 0.01262, test_auc = 0.96921, time = 0.04377\n",
      "Epoch: 0140 | train_loss = 0.01243, train_auc = 0.99307, test_loss = 0.01173, test_auc = 0.97835, time = 0.04416\n",
      "Epoch: 0150 | train_loss = 0.01284, train_auc = 0.99272, test_loss = 0.01122, test_auc = 0.98025, time = 0.04399\n",
      "Epoch: 0160 | train_loss = 0.01329, train_auc = 0.99410, test_loss = 0.01471, test_auc = 0.94646, time = 0.04492\n",
      "Epoch: 0170 | train_loss = 0.01112, train_auc = 0.99639, test_loss = 0.01431, test_auc = 0.96118, time = 0.04743\n",
      "Epoch: 0180 | train_loss = 0.00924, train_auc = 0.99738, test_loss = 0.01113, test_auc = 0.97470, time = 0.04355\n",
      "Epoch: 0190 | train_loss = 0.00948, train_auc = 0.99696, test_loss = 0.01071, test_auc = 0.98071, time = 0.04435\n",
      "Epoch: 0200 | train_loss = 0.00974, train_auc = 0.99682, test_loss = 0.01086, test_auc = 0.98112, time = 0.04690\n",
      "Epoch: 0210 | train_loss = 0.00822, train_auc = 0.99723, test_loss = 0.01103, test_auc = 0.97869, time = 0.04439\n",
      "Epoch: 0220 | train_loss = 0.00892, train_auc = 0.99745, test_loss = 0.01126, test_auc = 0.97963, time = 0.04341\n",
      "Epoch: 0230 | train_loss = 0.00852, train_auc = 0.99754, test_loss = 0.00971, test_auc = 0.98112, time = 0.04352\n",
      "Epoch: 0240 | train_loss = 0.00801, train_auc = 0.99786, test_loss = 0.01139, test_auc = 0.97866, time = 0.04351\n",
      "Epoch: 0250 | train_loss = 0.00758, train_auc = 0.99821, test_loss = 0.01268, test_auc = 0.97221, time = 0.04483\n",
      "Epoch: 0260 | train_loss = 0.00899, train_auc = 0.99789, test_loss = 0.01094, test_auc = 0.98148, time = 0.04352\n",
      "Epoch: 0270 | train_loss = 0.00842, train_auc = 0.99783, test_loss = 0.01010, test_auc = 0.98527, time = 0.04398\n",
      "Epoch: 0280 | train_loss = 0.00865, train_auc = 0.99853, test_loss = 0.01107, test_auc = 0.97680, time = 0.05472\n",
      "Epoch: 0290 | train_loss = 0.00664, train_auc = 0.99823, test_loss = 0.01243, test_auc = 0.97580, time = 0.04632\n",
      "Epoch: 0300 | train_loss = 0.00726, train_auc = 0.99860, test_loss = 0.01101, test_auc = 0.97540, time = 0.04496\n",
      "times: 8, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06177, train_auc = 0.48191, test_loss = 0.03409, test_auc = 0.52676, time = 0.83403\n",
      "Epoch: 0010 | train_loss = 0.03884, train_auc = 0.92531, test_loss = 0.03287, test_auc = 0.77493, time = 0.05018\n",
      "Epoch: 0020 | train_loss = 0.02982, train_auc = 0.95429, test_loss = 0.01777, test_auc = 0.90827, time = 0.04585\n",
      "Epoch: 0030 | train_loss = 0.02631, train_auc = 0.96901, test_loss = 0.01691, test_auc = 0.92982, time = 0.04379\n",
      "Epoch: 0040 | train_loss = 0.02360, train_auc = 0.97644, test_loss = 0.01537, test_auc = 0.94320, time = 0.04658\n",
      "Epoch: 0050 | train_loss = 0.02197, train_auc = 0.97901, test_loss = 0.02139, test_auc = 0.78126, time = 0.04391\n",
      "Epoch: 0060 | train_loss = 0.01801, train_auc = 0.98890, test_loss = 0.01852, test_auc = 0.88646, time = 0.04583\n",
      "Epoch: 0070 | train_loss = 0.01709, train_auc = 0.99013, test_loss = 0.02113, test_auc = 0.79213, time = 0.04406\n",
      "Epoch: 0080 | train_loss = 0.01654, train_auc = 0.98912, test_loss = 0.01930, test_auc = 0.82820, time = 0.04391\n",
      "Epoch: 0090 | train_loss = 0.01564, train_auc = 0.98983, test_loss = 0.02168, test_auc = 0.79331, time = 0.04541\n",
      "Epoch: 0100 | train_loss = 0.01453, train_auc = 0.99195, test_loss = 0.01797, test_auc = 0.91003, time = 0.04368\n",
      "Epoch: 0110 | train_loss = 0.01242, train_auc = 0.99357, test_loss = 0.01395, test_auc = 0.95966, time = 0.04446\n",
      "Epoch: 0120 | train_loss = 0.01155, train_auc = 0.99436, test_loss = 0.01301, test_auc = 0.96523, time = 0.04400\n",
      "Epoch: 0130 | train_loss = 0.01200, train_auc = 0.99414, test_loss = 0.01676, test_auc = 0.94465, time = 0.04368\n",
      "Epoch: 0140 | train_loss = 0.01208, train_auc = 0.99657, test_loss = 0.01265, test_auc = 0.97380, time = 0.04544\n",
      "Epoch: 0150 | train_loss = 0.01126, train_auc = 0.99692, test_loss = 0.01828, test_auc = 0.89187, time = 0.04414\n",
      "Epoch: 0160 | train_loss = 0.01071, train_auc = 0.99601, test_loss = 0.01718, test_auc = 0.93609, time = 0.04403\n",
      "Epoch: 0170 | train_loss = 0.01047, train_auc = 0.99615, test_loss = 0.01348, test_auc = 0.96790, time = 0.04359\n",
      "Epoch: 0180 | train_loss = 0.00971, train_auc = 0.99792, test_loss = 0.01194, test_auc = 0.97404, time = 0.04419\n",
      "Epoch: 0190 | train_loss = 0.00902, train_auc = 0.99830, test_loss = 0.01586, test_auc = 0.95670, time = 0.04402\n",
      "Epoch: 0200 | train_loss = 0.00856, train_auc = 0.99817, test_loss = 0.01277, test_auc = 0.96979, time = 0.04340\n",
      "Epoch: 0210 | train_loss = 0.00751, train_auc = 0.99878, test_loss = 0.01206, test_auc = 0.97541, time = 0.04388\n",
      "Epoch: 0220 | train_loss = 0.00829, train_auc = 0.99859, test_loss = 0.01231, test_auc = 0.96722, time = 0.04300\n",
      "Epoch: 0230 | train_loss = 0.00737, train_auc = 0.99880, test_loss = 0.01162, test_auc = 0.97555, time = 0.04471\n",
      "Epoch: 0240 | train_loss = 0.00793, train_auc = 0.99866, test_loss = 0.01293, test_auc = 0.96873, time = 0.04425\n",
      "Epoch: 0250 | train_loss = 0.00696, train_auc = 0.99876, test_loss = 0.01301, test_auc = 0.96984, time = 0.04371\n",
      "Epoch: 0260 | train_loss = 0.00675, train_auc = 0.99866, test_loss = 0.01605, test_auc = 0.95506, time = 0.04385\n",
      "Epoch: 0270 | train_loss = 0.00706, train_auc = 0.99881, test_loss = 0.01796, test_auc = 0.92787, time = 0.04364\n",
      "Epoch: 0280 | train_loss = 0.00605, train_auc = 0.99880, test_loss = 0.01698, test_auc = 0.94240, time = 0.04355\n",
      "Epoch: 0290 | train_loss = 0.00795, train_auc = 0.99856, test_loss = 0.01226, test_auc = 0.97578, time = 0.04377\n",
      "Epoch: 0300 | train_loss = 0.00787, train_auc = 0.99851, test_loss = 0.01296, test_auc = 0.97014, time = 0.04403\n",
      "times: 8, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06069, train_auc = 0.51306, test_loss = 0.03869, test_auc = 0.36552, time = 0.77985\n",
      "Epoch: 0010 | train_loss = 0.04183, train_auc = 0.92022, test_loss = 0.02935, test_auc = 0.90479, time = 0.04688\n",
      "Epoch: 0020 | train_loss = 0.03052, train_auc = 0.95186, test_loss = 0.01562, test_auc = 0.94153, time = 0.04469\n",
      "Epoch: 0030 | train_loss = 0.02609, train_auc = 0.96991, test_loss = 0.01951, test_auc = 0.87047, time = 0.04221\n",
      "Epoch: 0040 | train_loss = 0.02323, train_auc = 0.97654, test_loss = 0.01794, test_auc = 0.92013, time = 0.04506\n",
      "Epoch: 0050 | train_loss = 0.02108, train_auc = 0.98145, test_loss = 0.01918, test_auc = 0.90457, time = 0.04229\n",
      "Epoch: 0060 | train_loss = 0.01969, train_auc = 0.98473, test_loss = 0.01997, test_auc = 0.85634, time = 0.04230\n",
      "Epoch: 0070 | train_loss = 0.01929, train_auc = 0.98523, test_loss = 0.02369, test_auc = 0.75259, time = 0.04210\n",
      "Epoch: 0080 | train_loss = 0.01645, train_auc = 0.98844, test_loss = 0.02071, test_auc = 0.87303, time = 0.04253\n",
      "Epoch: 0090 | train_loss = 0.01480, train_auc = 0.99199, test_loss = 0.02267, test_auc = 0.76832, time = 0.04232\n",
      "Epoch: 0100 | train_loss = 0.01528, train_auc = 0.99094, test_loss = 0.01758, test_auc = 0.92876, time = 0.04192\n",
      "Epoch: 0110 | train_loss = 0.01472, train_auc = 0.99269, test_loss = 0.02113, test_auc = 0.87041, time = 0.04271\n",
      "Epoch: 0120 | train_loss = 0.01346, train_auc = 0.99398, test_loss = 0.02191, test_auc = 0.84580, time = 0.04349\n",
      "Epoch: 0130 | train_loss = 0.01304, train_auc = 0.99540, test_loss = 0.01601, test_auc = 0.95568, time = 0.04209\n",
      "Epoch: 0140 | train_loss = 0.01266, train_auc = 0.99378, test_loss = 0.01403, test_auc = 0.96339, time = 0.04237\n",
      "Epoch: 0150 | train_loss = 0.01225, train_auc = 0.99638, test_loss = 0.01720, test_auc = 0.93295, time = 0.04330\n",
      "Epoch: 0160 | train_loss = 0.01007, train_auc = 0.99695, test_loss = 0.01280, test_auc = 0.97104, time = 0.04193\n",
      "Epoch: 0170 | train_loss = 0.01013, train_auc = 0.99678, test_loss = 0.01225, test_auc = 0.97338, time = 0.04195\n",
      "Epoch: 0180 | train_loss = 0.01061, train_auc = 0.99693, test_loss = 0.01469, test_auc = 0.95423, time = 0.04227\n",
      "Epoch: 0190 | train_loss = 0.01030, train_auc = 0.99681, test_loss = 0.01704, test_auc = 0.92862, time = 0.04804\n",
      "Epoch: 0200 | train_loss = 0.00939, train_auc = 0.99722, test_loss = 0.01914, test_auc = 0.87606, time = 0.04204\n",
      "Epoch: 0210 | train_loss = 0.01037, train_auc = 0.99702, test_loss = 0.01415, test_auc = 0.96305, time = 0.04191\n",
      "Epoch: 0220 | train_loss = 0.00840, train_auc = 0.99792, test_loss = 0.01564, test_auc = 0.92387, time = 0.04165\n",
      "Epoch: 0230 | train_loss = 0.00706, train_auc = 0.99793, test_loss = 0.01756, test_auc = 0.94309, time = 0.04197\n",
      "Epoch: 0240 | train_loss = 0.00745, train_auc = 0.99751, test_loss = 0.02015, test_auc = 0.84601, time = 0.04180\n",
      "Epoch: 0250 | train_loss = 0.00820, train_auc = 0.99785, test_loss = 0.01569, test_auc = 0.94635, time = 0.04217\n",
      "Epoch: 0260 | train_loss = 0.00722, train_auc = 0.99790, test_loss = 0.01435, test_auc = 0.96163, time = 0.04277\n",
      "Epoch: 0270 | train_loss = 0.00626, train_auc = 0.99782, test_loss = 0.01295, test_auc = 0.96467, time = 0.04249\n",
      "Epoch: 0280 | train_loss = 0.00746, train_auc = 0.99779, test_loss = 0.01267, test_auc = 0.96896, time = 0.04198\n",
      "Epoch: 0290 | train_loss = 0.00752, train_auc = 0.99779, test_loss = 0.01379, test_auc = 0.96465, time = 0.04219\n",
      "Epoch: 0300 | train_loss = 0.00585, train_auc = 0.99826, test_loss = 0.01355, test_auc = 0.96143, time = 0.04840\n",
      "times: 8, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06134, train_auc = 0.49916, test_loss = 0.04140, test_auc = 0.23991, time = 0.81219\n",
      "Epoch: 0010 | train_loss = 0.03609, train_auc = 0.93953, test_loss = 0.02091, test_auc = 0.88677, time = 0.05269\n",
      "Epoch: 0020 | train_loss = 0.02812, train_auc = 0.96160, test_loss = 0.01921, test_auc = 0.88314, time = 0.04762\n",
      "Epoch: 0030 | train_loss = 0.02498, train_auc = 0.97185, test_loss = 0.02115, test_auc = 0.84825, time = 0.04533\n",
      "Epoch: 0040 | train_loss = 0.02272, train_auc = 0.97811, test_loss = 0.01629, test_auc = 0.94295, time = 0.04479\n",
      "Epoch: 0050 | train_loss = 0.02101, train_auc = 0.98209, test_loss = 0.01785, test_auc = 0.94048, time = 0.04507\n",
      "Epoch: 0060 | train_loss = 0.02011, train_auc = 0.98381, test_loss = 0.01501, test_auc = 0.96010, time = 0.04457\n",
      "Epoch: 0070 | train_loss = 0.01873, train_auc = 0.98572, test_loss = 0.01454, test_auc = 0.95690, time = 0.04708\n",
      "Epoch: 0080 | train_loss = 0.01692, train_auc = 0.98947, test_loss = 0.01733, test_auc = 0.94211, time = 0.04492\n",
      "Epoch: 0090 | train_loss = 0.01557, train_auc = 0.99240, test_loss = 0.01578, test_auc = 0.94318, time = 0.04788\n",
      "Epoch: 0100 | train_loss = 0.01381, train_auc = 0.99418, test_loss = 0.01675, test_auc = 0.94380, time = 0.04524\n",
      "Epoch: 0110 | train_loss = 0.01416, train_auc = 0.99385, test_loss = 0.01283, test_auc = 0.97244, time = 0.04608\n",
      "Epoch: 0120 | train_loss = 0.01285, train_auc = 0.99482, test_loss = 0.01284, test_auc = 0.97082, time = 0.05627\n",
      "Epoch: 0130 | train_loss = 0.01162, train_auc = 0.99571, test_loss = 0.01495, test_auc = 0.94369, time = 0.04566\n",
      "Epoch: 0140 | train_loss = 0.01146, train_auc = 0.99575, test_loss = 0.01205, test_auc = 0.97657, time = 0.04580\n",
      "Epoch: 0150 | train_loss = 0.01124, train_auc = 0.99591, test_loss = 0.01379, test_auc = 0.97153, time = 0.04587\n",
      "Epoch: 0160 | train_loss = 0.01231, train_auc = 0.99450, test_loss = 0.01455, test_auc = 0.94611, time = 0.04554\n",
      "Epoch: 0170 | train_loss = 0.01012, train_auc = 0.99615, test_loss = 0.01203, test_auc = 0.97821, time = 0.04657\n",
      "Epoch: 0180 | train_loss = 0.00925, train_auc = 0.99694, test_loss = 0.01254, test_auc = 0.97546, time = 0.04744\n",
      "Epoch: 0190 | train_loss = 0.01018, train_auc = 0.99609, test_loss = 0.01504, test_auc = 0.94209, time = 0.04802\n",
      "Epoch: 0200 | train_loss = 0.00864, train_auc = 0.99651, test_loss = 0.01323, test_auc = 0.93844, time = 0.04499\n",
      "Epoch: 0210 | train_loss = 0.00906, train_auc = 0.99647, test_loss = 0.01545, test_auc = 0.94458, time = 0.04741\n",
      "Epoch: 0220 | train_loss = 0.00964, train_auc = 0.99624, test_loss = 0.01340, test_auc = 0.97721, time = 0.04483\n",
      "Epoch: 0230 | train_loss = 0.00931, train_auc = 0.99662, test_loss = 0.01163, test_auc = 0.97619, time = 0.04575\n",
      "Epoch: 0240 | train_loss = 0.00872, train_auc = 0.99677, test_loss = 0.01228, test_auc = 0.95874, time = 0.04555\n",
      "Epoch: 0250 | train_loss = 0.00771, train_auc = 0.99720, test_loss = 0.01212, test_auc = 0.97472, time = 0.04603\n",
      "Epoch: 0260 | train_loss = 0.00822, train_auc = 0.99700, test_loss = 0.01394, test_auc = 0.97080, time = 0.04583\n",
      "Epoch: 0270 | train_loss = 0.01010, train_auc = 0.99670, test_loss = 0.01340, test_auc = 0.97446, time = 0.04594\n",
      "Epoch: 0280 | train_loss = 0.00738, train_auc = 0.99742, test_loss = 0.01378, test_auc = 0.97301, time = 0.04481\n",
      "Epoch: 0290 | train_loss = 0.00708, train_auc = 0.99774, test_loss = 0.00998, test_auc = 0.98659, time = 0.04521\n",
      "Epoch: 0300 | train_loss = 0.00745, train_auc = 0.99775, test_loss = 0.00940, test_auc = 0.98730, time = 0.04458\n",
      "times: 8, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06253, train_auc = 0.47030, test_loss = 0.03825, test_auc = 0.38803, time = 0.79307\n",
      "Epoch: 0010 | train_loss = 0.03729, train_auc = 0.93558, test_loss = 0.02493, test_auc = 0.88025, time = 0.04878\n",
      "Epoch: 0020 | train_loss = 0.02809, train_auc = 0.96312, test_loss = 0.01796, test_auc = 0.91344, time = 0.04602\n",
      "Epoch: 0030 | train_loss = 0.02437, train_auc = 0.97488, test_loss = 0.01947, test_auc = 0.88099, time = 0.04535\n",
      "Epoch: 0040 | train_loss = 0.02294, train_auc = 0.97740, test_loss = 0.01555, test_auc = 0.94191, time = 0.04551\n",
      "Epoch: 0050 | train_loss = 0.02073, train_auc = 0.98286, test_loss = 0.01977, test_auc = 0.86789, time = 0.04668\n",
      "Epoch: 0060 | train_loss = 0.02059, train_auc = 0.98290, test_loss = 0.01560, test_auc = 0.94563, time = 0.04495\n",
      "Epoch: 0070 | train_loss = 0.01848, train_auc = 0.98550, test_loss = 0.01383, test_auc = 0.95799, time = 0.05039\n",
      "Epoch: 0080 | train_loss = 0.01657, train_auc = 0.98833, test_loss = 0.01605, test_auc = 0.93317, time = 0.04545\n",
      "Epoch: 0090 | train_loss = 0.01608, train_auc = 0.98904, test_loss = 0.02026, test_auc = 0.84010, time = 0.04555\n",
      "Epoch: 0100 | train_loss = 0.01558, train_auc = 0.98925, test_loss = 0.01476, test_auc = 0.95305, time = 0.04470\n",
      "Epoch: 0110 | train_loss = 0.01398, train_auc = 0.99119, test_loss = 0.01782, test_auc = 0.92153, time = 0.04481\n",
      "Epoch: 0120 | train_loss = 0.01284, train_auc = 0.99199, test_loss = 0.01923, test_auc = 0.91254, time = 0.04514\n",
      "Epoch: 0130 | train_loss = 0.01272, train_auc = 0.99231, test_loss = 0.01377, test_auc = 0.96016, time = 0.04516\n",
      "Epoch: 0140 | train_loss = 0.01258, train_auc = 0.99285, test_loss = 0.01669, test_auc = 0.93211, time = 0.04483\n",
      "Epoch: 0150 | train_loss = 0.01212, train_auc = 0.99426, test_loss = 0.01260, test_auc = 0.96803, time = 0.04478\n",
      "Epoch: 0160 | train_loss = 0.01132, train_auc = 0.99477, test_loss = 0.01933, test_auc = 0.87864, time = 0.04477\n",
      "Epoch: 0170 | train_loss = 0.01128, train_auc = 0.99372, test_loss = 0.01793, test_auc = 0.91689, time = 0.04439\n",
      "Epoch: 0180 | train_loss = 0.01190, train_auc = 0.99596, test_loss = 0.01448, test_auc = 0.96252, time = 0.04447\n",
      "Epoch: 0190 | train_loss = 0.00982, train_auc = 0.99508, test_loss = 0.01262, test_auc = 0.96971, time = 0.04448\n",
      "Epoch: 0200 | train_loss = 0.00990, train_auc = 0.99650, test_loss = 0.01319, test_auc = 0.96432, time = 0.04476\n",
      "Epoch: 0210 | train_loss = 0.00948, train_auc = 0.99687, test_loss = 0.01320, test_auc = 0.96420, time = 0.04472\n",
      "Epoch: 0220 | train_loss = 0.00833, train_auc = 0.99731, test_loss = 0.01297, test_auc = 0.96768, time = 0.04480\n",
      "Epoch: 0230 | train_loss = 0.00812, train_auc = 0.99698, test_loss = 0.01854, test_auc = 0.92528, time = 0.04464\n",
      "Epoch: 0240 | train_loss = 0.00862, train_auc = 0.99724, test_loss = 0.01313, test_auc = 0.96861, time = 0.04487\n",
      "Epoch: 0250 | train_loss = 0.00913, train_auc = 0.99689, test_loss = 0.01245, test_auc = 0.96727, time = 0.04446\n",
      "Epoch: 0260 | train_loss = 0.00845, train_auc = 0.99709, test_loss = 0.01510, test_auc = 0.96016, time = 0.04453\n",
      "Epoch: 0270 | train_loss = 0.00778, train_auc = 0.99707, test_loss = 0.01877, test_auc = 0.91590, time = 0.04454\n",
      "Epoch: 0280 | train_loss = 0.00748, train_auc = 0.99728, test_loss = 0.01939, test_auc = 0.90092, time = 0.04609\n",
      "Epoch: 0290 | train_loss = 0.00784, train_auc = 0.99721, test_loss = 0.01989, test_auc = 0.90112, time = 0.04457\n",
      "Epoch: 0300 | train_loss = 0.00800, train_auc = 0.99704, test_loss = 0.01397, test_auc = 0.96004, time = 0.04512\n",
      "times: 9, fold: 0\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06311, train_auc = 0.47627, test_loss = 0.03483, test_auc = 0.51038, time = 0.78343\n",
      "Epoch: 0010 | train_loss = 0.03747, train_auc = 0.93522, test_loss = 0.02362, test_auc = 0.92933, time = 0.05074\n",
      "Epoch: 0020 | train_loss = 0.02818, train_auc = 0.96261, test_loss = 0.01811, test_auc = 0.90597, time = 0.04912\n",
      "Epoch: 0030 | train_loss = 0.02402, train_auc = 0.97549, test_loss = 0.01947, test_auc = 0.83284, time = 0.04830\n",
      "Epoch: 0040 | train_loss = 0.02166, train_auc = 0.98037, test_loss = 0.02031, test_auc = 0.82053, time = 0.04647\n",
      "Epoch: 0050 | train_loss = 0.02039, train_auc = 0.98402, test_loss = 0.01542, test_auc = 0.94928, time = 0.04944\n",
      "Epoch: 0060 | train_loss = 0.01872, train_auc = 0.98777, test_loss = 0.01929, test_auc = 0.88058, time = 0.04760\n",
      "Epoch: 0070 | train_loss = 0.01809, train_auc = 0.98768, test_loss = 0.01454, test_auc = 0.95825, time = 0.04683\n",
      "Epoch: 0080 | train_loss = 0.01579, train_auc = 0.99111, test_loss = 0.01471, test_auc = 0.95680, time = 0.04664\n",
      "Epoch: 0090 | train_loss = 0.01472, train_auc = 0.99269, test_loss = 0.01488, test_auc = 0.95634, time = 0.04648\n",
      "Epoch: 0100 | train_loss = 0.01398, train_auc = 0.99347, test_loss = 0.01862, test_auc = 0.86968, time = 0.04653\n",
      "Epoch: 0110 | train_loss = 0.01339, train_auc = 0.99383, test_loss = 0.01520, test_auc = 0.95658, time = 0.04656\n",
      "Epoch: 0120 | train_loss = 0.01495, train_auc = 0.99297, test_loss = 0.01497, test_auc = 0.95907, time = 0.04598\n",
      "Epoch: 0130 | train_loss = 0.01280, train_auc = 0.99542, test_loss = 0.01910, test_auc = 0.84719, time = 0.04615\n",
      "Epoch: 0140 | train_loss = 0.01177, train_auc = 0.99548, test_loss = 0.01834, test_auc = 0.85134, time = 0.04622\n",
      "Epoch: 0150 | train_loss = 0.01021, train_auc = 0.99692, test_loss = 0.01515, test_auc = 0.95252, time = 0.04629\n",
      "Epoch: 0160 | train_loss = 0.01062, train_auc = 0.99721, test_loss = 0.01527, test_auc = 0.95309, time = 0.04624\n",
      "Epoch: 0170 | train_loss = 0.00942, train_auc = 0.99763, test_loss = 0.01324, test_auc = 0.97590, time = 0.04625\n",
      "Epoch: 0180 | train_loss = 0.01027, train_auc = 0.99794, test_loss = 0.01137, test_auc = 0.97989, time = 0.04603\n",
      "Epoch: 0190 | train_loss = 0.00950, train_auc = 0.99830, test_loss = 0.01404, test_auc = 0.95644, time = 0.04634\n",
      "Epoch: 0200 | train_loss = 0.01048, train_auc = 0.99744, test_loss = 0.01255, test_auc = 0.97436, time = 0.05580\n",
      "Epoch: 0210 | train_loss = 0.00837, train_auc = 0.99797, test_loss = 0.01303, test_auc = 0.97215, time = 0.04748\n",
      "Epoch: 0220 | train_loss = 0.00733, train_auc = 0.99827, test_loss = 0.01883, test_auc = 0.87590, time = 0.04678\n",
      "Epoch: 0230 | train_loss = 0.00706, train_auc = 0.99834, test_loss = 0.01297, test_auc = 0.97211, time = 0.04674\n",
      "Epoch: 0240 | train_loss = 0.00882, train_auc = 0.99794, test_loss = 0.01337, test_auc = 0.96708, time = 0.04770\n",
      "Epoch: 0250 | train_loss = 0.00744, train_auc = 0.99851, test_loss = 0.01312, test_auc = 0.97842, time = 0.04660\n",
      "Epoch: 0260 | train_loss = 0.00761, train_auc = 0.99858, test_loss = 0.01253, test_auc = 0.96788, time = 0.05007\n",
      "Epoch: 0270 | train_loss = 0.00742, train_auc = 0.99830, test_loss = 0.01427, test_auc = 0.96609, time = 0.04897\n",
      "Epoch: 0280 | train_loss = 0.00719, train_auc = 0.99825, test_loss = 0.01124, test_auc = 0.98147, time = 0.04774\n",
      "Epoch: 0290 | train_loss = 0.00683, train_auc = 0.99826, test_loss = 0.01354, test_auc = 0.96194, time = 0.04766\n",
      "Epoch: 0300 | train_loss = 0.00681, train_auc = 0.99853, test_loss = 0.01417, test_auc = 0.96486, time = 0.04681\n",
      "times: 9, fold: 1\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06748, train_auc = 0.36594, test_loss = 0.03616, test_auc = 0.42316, time = 0.82491\n",
      "Epoch: 0010 | train_loss = 0.03843, train_auc = 0.93078, test_loss = 0.02620, test_auc = 0.85653, time = 0.05476\n",
      "Epoch: 0020 | train_loss = 0.02925, train_auc = 0.96028, test_loss = 0.01641, test_auc = 0.92662, time = 0.06712\n",
      "Epoch: 0030 | train_loss = 0.02480, train_auc = 0.97329, test_loss = 0.01862, test_auc = 0.89288, time = 0.06302\n",
      "Epoch: 0040 | train_loss = 0.02233, train_auc = 0.97914, test_loss = 0.02041, test_auc = 0.83908, time = 0.05174\n",
      "Epoch: 0050 | train_loss = 0.01985, train_auc = 0.98567, test_loss = 0.01881, test_auc = 0.88055, time = 0.04883\n",
      "Epoch: 0060 | train_loss = 0.01894, train_auc = 0.98742, test_loss = 0.01751, test_auc = 0.90915, time = 0.04773\n",
      "Epoch: 0070 | train_loss = 0.01665, train_auc = 0.99159, test_loss = 0.01478, test_auc = 0.95037, time = 0.04717\n",
      "Epoch: 0080 | train_loss = 0.01692, train_auc = 0.99140, test_loss = 0.01726, test_auc = 0.94229, time = 0.04652\n",
      "Epoch: 0090 | train_loss = 0.01516, train_auc = 0.99370, test_loss = 0.01898, test_auc = 0.86537, time = 0.04652\n",
      "Epoch: 0100 | train_loss = 0.01401, train_auc = 0.99448, test_loss = 0.01499, test_auc = 0.93838, time = 0.04662\n",
      "Epoch: 0110 | train_loss = 0.01550, train_auc = 0.99153, test_loss = 0.01483, test_auc = 0.95391, time = 0.04629\n",
      "Epoch: 0120 | train_loss = 0.01218, train_auc = 0.99629, test_loss = 0.01971, test_auc = 0.85012, time = 0.04599\n",
      "Epoch: 0130 | train_loss = 0.01216, train_auc = 0.99712, test_loss = 0.01615, test_auc = 0.89516, time = 0.04751\n",
      "Epoch: 0140 | train_loss = 0.01172, train_auc = 0.99711, test_loss = 0.01215, test_auc = 0.97405, time = 0.04630\n",
      "Epoch: 0150 | train_loss = 0.01009, train_auc = 0.99824, test_loss = 0.01682, test_auc = 0.94844, time = 0.04630\n",
      "Epoch: 0160 | train_loss = 0.00849, train_auc = 0.99871, test_loss = 0.01290, test_auc = 0.97366, time = 0.04636\n",
      "Epoch: 0170 | train_loss = 0.00943, train_auc = 0.99805, test_loss = 0.01567, test_auc = 0.94359, time = 0.04666\n",
      "Epoch: 0180 | train_loss = 0.00937, train_auc = 0.99881, test_loss = 0.01121, test_auc = 0.97868, time = 0.04687\n",
      "Epoch: 0190 | train_loss = 0.00738, train_auc = 0.99906, test_loss = 0.00998, test_auc = 0.98187, time = 0.04690\n",
      "Epoch: 0200 | train_loss = 0.00923, train_auc = 0.99880, test_loss = 0.01325, test_auc = 0.96305, time = 0.04699\n",
      "Epoch: 0210 | train_loss = 0.00775, train_auc = 0.99879, test_loss = 0.01338, test_auc = 0.95412, time = 0.04734\n",
      "Epoch: 0220 | train_loss = 0.00981, train_auc = 0.99891, test_loss = 0.01070, test_auc = 0.97872, time = 0.04679\n",
      "Epoch: 0230 | train_loss = 0.00772, train_auc = 0.99909, test_loss = 0.01432, test_auc = 0.96601, time = 0.04680\n",
      "Epoch: 0240 | train_loss = 0.00829, train_auc = 0.99889, test_loss = 0.01367, test_auc = 0.96365, time = 0.04705\n",
      "Epoch: 0250 | train_loss = 0.00869, train_auc = 0.99925, test_loss = 0.01024, test_auc = 0.98328, time = 0.04616\n",
      "Epoch: 0260 | train_loss = 0.00804, train_auc = 0.99955, test_loss = 0.01036, test_auc = 0.98037, time = 0.04721\n",
      "Epoch: 0270 | train_loss = 0.00906, train_auc = 0.99933, test_loss = 0.01161, test_auc = 0.97602, time = 0.04645\n",
      "Epoch: 0280 | train_loss = 0.00692, train_auc = 0.99958, test_loss = 0.01008, test_auc = 0.97839, time = 0.04647\n",
      "Epoch: 0290 | train_loss = 0.00674, train_auc = 0.99951, test_loss = 0.00989, test_auc = 0.97964, time = 0.04636\n",
      "Epoch: 0300 | train_loss = 0.00661, train_auc = 0.99944, test_loss = 0.01018, test_auc = 0.97965, time = 0.04710\n",
      "times: 9, fold: 2\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.05827, train_auc = 0.57225, test_loss = 0.03817, test_auc = 0.38778, time = 0.81586\n",
      "Epoch: 0010 | train_loss = 0.03731, train_auc = 0.92790, test_loss = 0.02489, test_auc = 0.91763, time = 0.05347\n",
      "Epoch: 0020 | train_loss = 0.02782, train_auc = 0.96295, test_loss = 0.02081, test_auc = 0.81705, time = 0.04917\n",
      "Epoch: 0030 | train_loss = 0.02447, train_auc = 0.97370, test_loss = 0.01994, test_auc = 0.82481, time = 0.04772\n",
      "Epoch: 0040 | train_loss = 0.02108, train_auc = 0.98487, test_loss = 0.01911, test_auc = 0.87739, time = 0.04733\n",
      "Epoch: 0050 | train_loss = 0.02058, train_auc = 0.98452, test_loss = 0.01912, test_auc = 0.87060, time = 0.04912\n",
      "Epoch: 0060 | train_loss = 0.01762, train_auc = 0.99013, test_loss = 0.01648, test_auc = 0.94658, time = 0.04668\n",
      "Epoch: 0070 | train_loss = 0.01820, train_auc = 0.98909, test_loss = 0.01491, test_auc = 0.96478, time = 0.04688\n",
      "Epoch: 0080 | train_loss = 0.01524, train_auc = 0.99425, test_loss = 0.01624, test_auc = 0.95121, time = 0.04656\n",
      "Epoch: 0090 | train_loss = 0.01438, train_auc = 0.99531, test_loss = 0.01626, test_auc = 0.94736, time = 0.04667\n",
      "Epoch: 0100 | train_loss = 0.01269, train_auc = 0.99633, test_loss = 0.01326, test_auc = 0.97493, time = 0.04609\n",
      "Epoch: 0110 | train_loss = 0.01211, train_auc = 0.99687, test_loss = 0.01351, test_auc = 0.97501, time = 0.04621\n",
      "Epoch: 0120 | train_loss = 0.01176, train_auc = 0.99655, test_loss = 0.01376, test_auc = 0.96145, time = 0.04826\n",
      "Epoch: 0130 | train_loss = 0.01131, train_auc = 0.99665, test_loss = 0.01277, test_auc = 0.97531, time = 0.04646\n",
      "Epoch: 0140 | train_loss = 0.00993, train_auc = 0.99761, test_loss = 0.01696, test_auc = 0.96383, time = 0.04898\n",
      "Epoch: 0150 | train_loss = 0.01023, train_auc = 0.99703, test_loss = 0.01237, test_auc = 0.97658, time = 0.04804\n",
      "Epoch: 0160 | train_loss = 0.00982, train_auc = 0.99751, test_loss = 0.01143, test_auc = 0.97994, time = 0.04662\n",
      "Epoch: 0170 | train_loss = 0.00881, train_auc = 0.99760, test_loss = 0.01369, test_auc = 0.97346, time = 0.04655\n",
      "Epoch: 0180 | train_loss = 0.00900, train_auc = 0.99777, test_loss = 0.01120, test_auc = 0.98208, time = 0.04753\n",
      "Epoch: 0190 | train_loss = 0.00857, train_auc = 0.99778, test_loss = 0.01377, test_auc = 0.97099, time = 0.04813\n",
      "Epoch: 0200 | train_loss = 0.00842, train_auc = 0.99774, test_loss = 0.01157, test_auc = 0.98039, time = 0.04830\n",
      "Epoch: 0210 | train_loss = 0.00896, train_auc = 0.99777, test_loss = 0.01503, test_auc = 0.95557, time = 0.04664\n",
      "Epoch: 0220 | train_loss = 0.00767, train_auc = 0.99805, test_loss = 0.01045, test_auc = 0.98500, time = 0.04614\n",
      "Epoch: 0230 | train_loss = 0.00781, train_auc = 0.99810, test_loss = 0.01242, test_auc = 0.97588, time = 0.04660\n",
      "Epoch: 0240 | train_loss = 0.00760, train_auc = 0.99805, test_loss = 0.01622, test_auc = 0.96682, time = 0.04730\n",
      "Epoch: 0250 | train_loss = 0.00660, train_auc = 0.99852, test_loss = 0.01242, test_auc = 0.97189, time = 0.04628\n",
      "Epoch: 0260 | train_loss = 0.00856, train_auc = 0.99806, test_loss = 0.01265, test_auc = 0.97556, time = 0.04639\n",
      "Epoch: 0270 | train_loss = 0.00763, train_auc = 0.99828, test_loss = 0.01137, test_auc = 0.97928, time = 0.04676\n",
      "Epoch: 0280 | train_loss = 0.00720, train_auc = 0.99826, test_loss = 0.01062, test_auc = 0.98450, time = 0.04929\n",
      "Epoch: 0290 | train_loss = 0.00646, train_auc = 0.99835, test_loss = 0.01344, test_auc = 0.97625, time = 0.04593\n",
      "Epoch: 0300 | train_loss = 0.00746, train_auc = 0.99845, test_loss = 0.01253, test_auc = 0.98017, time = 0.04781\n",
      "times: 9, fold: 3\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06091, train_auc = 0.51030, test_loss = 0.03874, test_auc = 0.36882, time = 0.78839\n",
      "Epoch: 0010 | train_loss = 0.03644, train_auc = 0.94141, test_loss = 0.02665, test_auc = 0.86114, time = 0.04990\n",
      "Epoch: 0020 | train_loss = 0.02821, train_auc = 0.96165, test_loss = 0.01901, test_auc = 0.88773, time = 0.04626\n",
      "Epoch: 0030 | train_loss = 0.02423, train_auc = 0.97554, test_loss = 0.02022, test_auc = 0.86380, time = 0.04462\n",
      "Epoch: 0040 | train_loss = 0.02150, train_auc = 0.98163, test_loss = 0.02134, test_auc = 0.80324, time = 0.04445\n",
      "Epoch: 0050 | train_loss = 0.01962, train_auc = 0.98623, test_loss = 0.01828, test_auc = 0.89532, time = 0.04458\n",
      "Epoch: 0060 | train_loss = 0.01812, train_auc = 0.98902, test_loss = 0.02211, test_auc = 0.78179, time = 0.04456\n",
      "Epoch: 0070 | train_loss = 0.01706, train_auc = 0.98671, test_loss = 0.02076, test_auc = 0.80481, time = 0.04613\n",
      "Epoch: 0080 | train_loss = 0.01702, train_auc = 0.99024, test_loss = 0.01782, test_auc = 0.90220, time = 0.04515\n",
      "Epoch: 0090 | train_loss = 0.01458, train_auc = 0.99098, test_loss = 0.01527, test_auc = 0.96150, time = 0.04420\n",
      "Epoch: 0100 | train_loss = 0.01337, train_auc = 0.99193, test_loss = 0.01417, test_auc = 0.97186, time = 0.04679\n",
      "Epoch: 0110 | train_loss = 0.01379, train_auc = 0.99270, test_loss = 0.02180, test_auc = 0.80300, time = 0.04618\n",
      "Epoch: 0120 | train_loss = 0.01235, train_auc = 0.99523, test_loss = 0.01888, test_auc = 0.87316, time = 0.04438\n",
      "Epoch: 0130 | train_loss = 0.01069, train_auc = 0.99645, test_loss = 0.01279, test_auc = 0.97379, time = 0.04492\n",
      "Epoch: 0140 | train_loss = 0.01086, train_auc = 0.99645, test_loss = 0.01357, test_auc = 0.96967, time = 0.04422\n",
      "Epoch: 0150 | train_loss = 0.01001, train_auc = 0.99692, test_loss = 0.01526, test_auc = 0.96023, time = 0.04507\n",
      "Epoch: 0160 | train_loss = 0.01141, train_auc = 0.99710, test_loss = 0.01434, test_auc = 0.95970, time = 0.04510\n",
      "Epoch: 0170 | train_loss = 0.01117, train_auc = 0.99714, test_loss = 0.01631, test_auc = 0.96162, time = 0.04563\n",
      "Epoch: 0180 | train_loss = 0.01073, train_auc = 0.99770, test_loss = 0.01698, test_auc = 0.92769, time = 0.04394\n",
      "Epoch: 0190 | train_loss = 0.00845, train_auc = 0.99861, test_loss = 0.01354, test_auc = 0.96906, time = 0.04422\n",
      "Epoch: 0200 | train_loss = 0.00882, train_auc = 0.99856, test_loss = 0.01195, test_auc = 0.98291, time = 0.04485\n",
      "Epoch: 0210 | train_loss = 0.00827, train_auc = 0.99871, test_loss = 0.01381, test_auc = 0.96860, time = 0.04493\n",
      "Epoch: 0220 | train_loss = 0.00855, train_auc = 0.99876, test_loss = 0.01112, test_auc = 0.98558, time = 0.04483\n",
      "Epoch: 0230 | train_loss = 0.00747, train_auc = 0.99896, test_loss = 0.01031, test_auc = 0.98555, time = 0.04419\n",
      "Epoch: 0240 | train_loss = 0.00847, train_auc = 0.99859, test_loss = 0.01375, test_auc = 0.97348, time = 0.04406\n",
      "Epoch: 0250 | train_loss = 0.00774, train_auc = 0.99883, test_loss = 0.01308, test_auc = 0.96064, time = 0.04438\n",
      "Epoch: 0260 | train_loss = 0.00737, train_auc = 0.99893, test_loss = 0.01385, test_auc = 0.96607, time = 0.04463\n",
      "Epoch: 0270 | train_loss = 0.00643, train_auc = 0.99931, test_loss = 0.01106, test_auc = 0.98451, time = 0.04456\n",
      "Epoch: 0280 | train_loss = 0.00848, train_auc = 0.99873, test_loss = 0.00964, test_auc = 0.99058, time = 0.04527\n",
      "Epoch: 0290 | train_loss = 0.00679, train_auc = 0.99927, test_loss = 0.01043, test_auc = 0.98943, time = 0.04710\n",
      "Epoch: 0300 | train_loss = 0.00660, train_auc = 0.99931, test_loss = 0.01404, test_auc = 0.96731, time = 0.04468\n",
      "times: 9, fold: 4\n",
      "----- Archi. hyperparams -----\n",
      " dataset: LncRNADisease\n",
      " epoch: 300\n",
      " lr: 0.003\n",
      " Graph units: [64]\n",
      " dense0: 64\n",
      " dense1: 32\n",
      " layers num: 4\n",
      " attention_drop:0.1\n",
      " feedforward_drop:0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:13: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  disease_df = pd.read_excel('data/'+dataset+'/diseases.xlsx',header=None,names=['id','disease'])\n",
      "/hy-tmp/GTGenie_new/text_encoding/get_text_embedding.py:19: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  biomarker_df = pd.read_excel('data/' + dataset + '/lncRNAs.xlsx', header=None, names=['id', 'lncRNA'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_nodes:###### 1209\n",
      "<dtype: 'float32'>\n",
      "Epoch: 0001 | train_loss = 0.06043, train_auc = 0.55087, test_loss = 0.03565, test_auc = 0.41822, time = 0.77665\n",
      "Epoch: 0010 | train_loss = 0.03706, train_auc = 0.93212, test_loss = 0.02140, test_auc = 0.92181, time = 0.05625\n",
      "Epoch: 0020 | train_loss = 0.02984, train_auc = 0.95261, test_loss = 0.01677, test_auc = 0.92878, time = 0.04701\n",
      "Epoch: 0030 | train_loss = 0.02586, train_auc = 0.96546, test_loss = 0.01728, test_auc = 0.90502, time = 0.04440\n",
      "Epoch: 0040 | train_loss = 0.02443, train_auc = 0.97047, test_loss = 0.01472, test_auc = 0.95174, time = 0.04475\n",
      "Epoch: 0050 | train_loss = 0.02233, train_auc = 0.97630, test_loss = 0.01547, test_auc = 0.94154, time = 0.04818\n",
      "Epoch: 0060 | train_loss = 0.01987, train_auc = 0.98453, test_loss = 0.02111, test_auc = 0.82181, time = 0.04430\n",
      "Epoch: 0070 | train_loss = 0.01783, train_auc = 0.98989, test_loss = 0.01953, test_auc = 0.87345, time = 0.04447\n",
      "Epoch: 0080 | train_loss = 0.01558, train_auc = 0.99269, test_loss = 0.01404, test_auc = 0.95954, time = 0.04566\n",
      "Epoch: 0090 | train_loss = 0.01478, train_auc = 0.99369, test_loss = 0.01815, test_auc = 0.91224, time = 0.04484\n",
      "Epoch: 0100 | train_loss = 0.01487, train_auc = 0.99056, test_loss = 0.01377, test_auc = 0.97155, time = 0.04426\n",
      "Epoch: 0110 | train_loss = 0.01325, train_auc = 0.99398, test_loss = 0.01391, test_auc = 0.97077, time = 0.04431\n",
      "Epoch: 0120 | train_loss = 0.01350, train_auc = 0.99412, test_loss = 0.01522, test_auc = 0.95520, time = 0.04436\n",
      "Epoch: 0130 | train_loss = 0.01194, train_auc = 0.99560, test_loss = 0.01640, test_auc = 0.92773, time = 0.04489\n",
      "Epoch: 0140 | train_loss = 0.01220, train_auc = 0.99541, test_loss = 0.01484, test_auc = 0.96459, time = 0.04440\n",
      "Epoch: 0150 | train_loss = 0.01029, train_auc = 0.99588, test_loss = 0.01560, test_auc = 0.95592, time = 0.04494\n",
      "Epoch: 0160 | train_loss = 0.01045, train_auc = 0.99618, test_loss = 0.01360, test_auc = 0.96656, time = 0.04431\n",
      "Epoch: 0170 | train_loss = 0.01028, train_auc = 0.99555, test_loss = 0.01300, test_auc = 0.97261, time = 0.04511\n",
      "Epoch: 0180 | train_loss = 0.00952, train_auc = 0.99654, test_loss = 0.01484, test_auc = 0.95869, time = 0.04334\n",
      "Epoch: 0190 | train_loss = 0.00780, train_auc = 0.99688, test_loss = 0.01352, test_auc = 0.97037, time = 0.04622\n",
      "Epoch: 0200 | train_loss = 0.00908, train_auc = 0.99697, test_loss = 0.01191, test_auc = 0.97657, time = 0.04500\n",
      "Epoch: 0210 | train_loss = 0.00866, train_auc = 0.99649, test_loss = 0.01377, test_auc = 0.96885, time = 0.04493\n",
      "Epoch: 0220 | train_loss = 0.01005, train_auc = 0.99646, test_loss = 0.01886, test_auc = 0.93484, time = 0.04301\n",
      "Epoch: 0230 | train_loss = 0.00860, train_auc = 0.99662, test_loss = 0.01672, test_auc = 0.94074, time = 0.04405\n",
      "Epoch: 0240 | train_loss = 0.00931, train_auc = 0.99708, test_loss = 0.01371, test_auc = 0.96962, time = 0.04384\n",
      "Epoch: 0250 | train_loss = 0.01036, train_auc = 0.99531, test_loss = 0.01433, test_auc = 0.96110, time = 0.04399\n",
      "Epoch: 0260 | train_loss = 0.00997, train_auc = 0.99631, test_loss = 0.01835, test_auc = 0.93229, time = 0.04375\n",
      "Epoch: 0270 | train_loss = 0.00963, train_auc = 0.99634, test_loss = 0.01871, test_auc = 0.94618, time = 0.04350\n",
      "Epoch: 0280 | train_loss = 0.00923, train_auc = 0.99663, test_loss = 0.01371, test_auc = 0.96967, time = 0.04444\n",
      "Epoch: 0290 | train_loss = 0.00864, train_auc = 0.99699, test_loss = 0.01840, test_auc = 0.92832, time = 0.04418\n",
      "Epoch: 0300 | train_loss = 0.00782, train_auc = 0.99753, test_loss = 0.01305, test_auc = 0.96645, time = 0.04475\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "from utils import sample\n",
    "from train import train\n",
    "from evaluation import *\n",
    "from tfdeterminism import patch\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Training')\n",
    "    parser.add_argument('--GPU', type=str, default='0')\n",
    "    parser.add_argument('--epoch', type=int, default=300)\n",
    "    parser.add_argument('--hid_units', type=int, default=64, help='number of neurons in GAT')\n",
    "    parser.add_argument('--dense0', type=int, default=64, help='number of neurons in BFN')\n",
    "    parser.add_argument('--dense1', type=int, default=32, help='number of neurons in BFN')\n",
    "    parser.add_argument('--layers', type=int, default=4, help='number of layer aggregator in GAT')\n",
    "    parser.add_argument('--lr', type=float, default=0.003)\n",
    "    parser.add_argument('--attention_drop', type=float, default=0.1)\n",
    "    parser.add_argument('--feedforward_drop', type=float, default=0.1)\n",
    "    parser.add_argument('--dataset', type=str, default='LncRNADisease')\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    patch()\n",
    "    SEED = 1000\n",
    "    tf.set_random_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.GPU\n",
    "\n",
    "    dataset = args.dataset\n",
    "    times = 10\n",
    "    total_KFOLD_test_labels, total_FOLD_test_scores = [], []\n",
    "    KFOLD_test_out_come = []\n",
    "    for i in range(times):\n",
    "        for fold in range(5):\n",
    "            print(\"times: %d, fold: %d\" % (int(i), int(fold)))\n",
    "            train_arr = np.loadtxt(f'data/{dataset}/data_dir/{i}/{fold}/train_arr.txt')\n",
    "            test_arr = np.loadtxt(f'data/{dataset}/data_dir/{i}/{fold}/test_arr.txt')\n",
    "            train_arr = train_arr.astype(np.int64)\n",
    "            test_arr = test_arr.astype(np.int64)\n",
    "            test_labels, scores, test_out_come = train(args, train_arr, test_arr, dataset, i, fold)\n",
    "            total_KFOLD_test_labels.append(test_labels)\n",
    "            total_FOLD_test_scores.append(scores)\n",
    "            KFOLD_test_out_come.append(test_out_come)\n",
    "    print('Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "association_matrix_shape: (328, 881)\n",
      "times: 0 Fold: 0 Test AUC: 0.9830 Test AUPR: 0.9807\n",
      "times: 0 Fold: 1 Test AUC: 0.9872 Test AUPR: 0.9863\n",
      "times: 0 Fold: 2 Test AUC: 0.9885 Test AUPR: 0.9880\n",
      "times: 0 Fold: 3 Test AUC: 0.9833 Test AUPR: 0.9781\n",
      "times: 0 Fold: 4 Test AUC: 0.9805 Test AUPR: 0.9735\n",
      "times: 1 Fold: 0 Test AUC: 0.9818 Test AUPR: 0.9751\n",
      "times: 1 Fold: 1 Test AUC: 0.9886 Test AUPR: 0.9871\n",
      "times: 1 Fold: 2 Test AUC: 0.9842 Test AUPR: 0.9774\n",
      "times: 1 Fold: 3 Test AUC: 0.9782 Test AUPR: 0.9699\n",
      "times: 1 Fold: 4 Test AUC: 0.9885 Test AUPR: 0.9856\n",
      "times: 2 Fold: 0 Test AUC: 0.9808 Test AUPR: 0.9782\n",
      "times: 2 Fold: 1 Test AUC: 0.9816 Test AUPR: 0.9773\n",
      "times: 2 Fold: 2 Test AUC: 0.9870 Test AUPR: 0.9834\n",
      "times: 2 Fold: 3 Test AUC: 0.9826 Test AUPR: 0.9758\n",
      "times: 2 Fold: 4 Test AUC: 0.9779 Test AUPR: 0.9711\n",
      "times: 3 Fold: 0 Test AUC: 0.9782 Test AUPR: 0.9693\n",
      "times: 3 Fold: 1 Test AUC: 0.9818 Test AUPR: 0.9743\n",
      "times: 3 Fold: 2 Test AUC: 0.9909 Test AUPR: 0.9907\n",
      "times: 3 Fold: 3 Test AUC: 0.9751 Test AUPR: 0.9632\n",
      "times: 3 Fold: 4 Test AUC: 0.9907 Test AUPR: 0.9895\n",
      "times: 4 Fold: 0 Test AUC: 0.9800 Test AUPR: 0.9717\n",
      "times: 4 Fold: 1 Test AUC: 0.9784 Test AUPR: 0.9763\n",
      "times: 4 Fold: 2 Test AUC: 0.9908 Test AUPR: 0.9897\n",
      "times: 4 Fold: 3 Test AUC: 0.9819 Test AUPR: 0.9788\n",
      "times: 4 Fold: 4 Test AUC: 0.9759 Test AUPR: 0.9687\n",
      "times: 5 Fold: 0 Test AUC: 0.9903 Test AUPR: 0.9902\n",
      "times: 5 Fold: 1 Test AUC: 0.9864 Test AUPR: 0.9826\n",
      "times: 5 Fold: 2 Test AUC: 0.9855 Test AUPR: 0.9834\n",
      "times: 5 Fold: 3 Test AUC: 0.9856 Test AUPR: 0.9847\n",
      "times: 5 Fold: 4 Test AUC: 0.9784 Test AUPR: 0.9745\n",
      "times: 6 Fold: 0 Test AUC: 0.9823 Test AUPR: 0.9817\n",
      "times: 6 Fold: 1 Test AUC: 0.9849 Test AUPR: 0.9825\n",
      "times: 6 Fold: 2 Test AUC: 0.9766 Test AUPR: 0.9704\n",
      "times: 6 Fold: 3 Test AUC: 0.9795 Test AUPR: 0.9721\n",
      "times: 6 Fold: 4 Test AUC: 0.9871 Test AUPR: 0.9832\n",
      "times: 7 Fold: 0 Test AUC: 0.9829 Test AUPR: 0.9811\n",
      "times: 7 Fold: 1 Test AUC: 0.9870 Test AUPR: 0.9827\n",
      "times: 7 Fold: 2 Test AUC: 0.9819 Test AUPR: 0.9777\n",
      "times: 7 Fold: 3 Test AUC: 0.9814 Test AUPR: 0.9783\n",
      "times: 7 Fold: 4 Test AUC: 0.9729 Test AUPR: 0.9662\n",
      "times: 8 Fold: 0 Test AUC: 0.9853 Test AUPR: 0.9845\n",
      "times: 8 Fold: 1 Test AUC: 0.9822 Test AUPR: 0.9758\n",
      "times: 8 Fold: 2 Test AUC: 0.9769 Test AUPR: 0.9719\n",
      "times: 8 Fold: 3 Test AUC: 0.9873 Test AUPR: 0.9853\n",
      "times: 8 Fold: 4 Test AUC: 0.9734 Test AUPR: 0.9659\n",
      "times: 9 Fold: 0 Test AUC: 0.9840 Test AUPR: 0.9807\n",
      "times: 9 Fold: 1 Test AUC: 0.9833 Test AUPR: 0.9788\n",
      "times: 9 Fold: 2 Test AUC: 0.9850 Test AUPR: 0.9832\n",
      "times: 9 Fold: 3 Test AUC: 0.9910 Test AUPR: 0.9908\n",
      "times: 9 Fold: 4 Test AUC: 0.9796 Test AUPR: 0.9763\n",
      "-AUC mean: 0.98300.0046 \n",
      " -AUPR mean: 0.97890.0069 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "statistic_total_AUC(args, total_KFOLD_test_labels, total_FOLD_test_scores, KFOLD_test_out_come)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
